From 1ab6801504cca6bdf0823afd5bb08f8f45327531 Mon Sep 17 00:00:00 2001
From: Wolf Lin <Wolf_Lin@pegatroncorp.com>
Date: Mon, 29 Nov 2021 16:51:18 +0800
Subject: [PATCH] Marvell support for armada8040 and octeon-tx2 cn9130

---
 arch/Kconfig                                  |   15 +
 arch/arm64/Kconfig                            |   14 +
 arch/arm64/Kconfig.platforms                  |    1 +
 arch/arm64/boot/dts/marvell/Makefile          |    1 +
 .../arm64/boot/dts/marvell/armada-3720-db.dts |   67 +-
 .../dts/marvell/armada-3720-espressobin.dts   |   22 +-
 arch/arm64/boot/dts/marvell/armada-372x.dtsi  |    2 +-
 arch/arm64/boot/dts/marvell/armada-37xx.dtsi  |   87 +-
 .../arm64/boot/dts/marvell/armada-7040-db.dts |  154 +-
 .../boot/dts/marvell/armada-7040-db.dtsi      |  208 +
 arch/arm64/boot/dts/marvell/armada-7040.dtsi  |   28 +
 arch/arm64/boot/dts/marvell/armada-70x0.dtsi  |   44 +-
 .../arm64/boot/dts/marvell/armada-8040-db.dts |  257 +-
 .../boot/dts/marvell/armada-8040-db.dtsi      |  288 ++
 .../boot/dts/marvell/armada-8040-mcbin.dts    |   77 +-
 arch/arm64/boot/dts/marvell/armada-8040.dtsi  |   40 +
 arch/arm64/boot/dts/marvell/armada-80x0.dtsi  |  100 +-
 .../boot/dts/marvell/armada-ap806-dual.dtsi   |   95 +-
 .../boot/dts/marvell/armada-ap806-quad.dtsi   |  196 +-
 arch/arm64/boot/dts/marvell/armada-ap806.dtsi |  262 +-
 .../boot/dts/marvell/armada-ap807-quad.dtsi   |  270 ++
 arch/arm64/boot/dts/marvell/armada-ap807.dtsi |   75 +
 arch/arm64/boot/dts/marvell/armada-ap80x.dtsi |  537 +++
 .../arm64/boot/dts/marvell/armada-common.dtsi |    4 +-
 arch/arm64/boot/dts/marvell/armada-cp110.dtsi |  439 +-
 arch/arm64/boot/dts/marvell/cn9130-db-A.dts   |  197 +
 arch/arm64/boot/dts/marvell/cn9130-db.dtsi    |  177 +
 arch/arm64/boot/dts/marvell/cn9130.dtsi       |  132 +
 arch/arm64/include/asm/cputype.h              |   12 +-
 arch/arm64/include/asm/io.h                   |   46 +
 arch/arm64/include/asm/mmu_context.h          |    6 +
 arch/arm64/include/asm/thread_info.h          |    7 +-
 arch/arm64/include/uapi/asm/bitsperlong.h     |    9 +-
 arch/arm64/include/uapi/asm/unistd.h          |   13 +
 arch/arm64/kernel/cpu_errata.c                |    6 +-
 arch/arm64/mm/context.c                       |   80 +-
 arch/arm64/mm/mmap.c                          |    2 +-
 drivers/Makefile                              |    6 +-
 drivers/ata/libahci_platform.c                |    6 +
 drivers/clk/mvebu/Kconfig                     |    8 +
 drivers/clk/mvebu/Makefile                    |    2 +
 drivers/clk/mvebu/ap806-system-controller.c   |  187 +-
 drivers/clk/mvebu/ap810-system-controller.c   |  306 ++
 drivers/clk/mvebu/armada-37xx-xtal.c          |    4 +-
 drivers/clk/mvebu/armada_ap_cp_helper.c       |   30 +
 drivers/clk/mvebu/armada_ap_cp_helper.h       |   11 +
 drivers/clk/mvebu/cp110-system-controller.c   |   32 +-
 drivers/gpio/Kconfig                          |   12 +
 drivers/gpio/Makefile                         |    1 +
 drivers/gpio/gpio-i2c.c                       |  204 +
 drivers/i2c/busses/i2c-mv64xxx.c              |   46 +-
 drivers/i2c/i2c-core-base.c                   |  147 +-
 drivers/irqchip/Kconfig                       |    3 +
 drivers/irqchip/Makefile                      |    5 +-
 drivers/irqchip/irq-gic-v2m.c                 |    2 +-
 drivers/irqchip/irq-gic-v3-its.c              |   43 +-
 drivers/irqchip/irq-gic-v3-quirks.c           |  161 +
 drivers/irqchip/irq-gic-v3-quirks.h           |   25 +
 drivers/irqchip/irq-gic-v3.c                  |   58 +-
 drivers/irqchip/irq-mvebu-icu.c               |   24 +
 drivers/irqchip/irq-mvebu-pic.c               |   14 +-
 drivers/irqchip/irq-mvebu-sei.c               |  507 +++
 drivers/misc/Kconfig                          |   10 +
 drivers/misc/Makefile                         |    1 +
 drivers/misc/mvebu/Kconfig                    |   17 +
 drivers/misc/mvebu/Makefile                   |    2 +
 drivers/misc/mvebu/mv_soc_info.c              |   78 +
 drivers/misc/mvebu/mvebu-a8k-debugfs.c        |  312 ++
 drivers/mmc/host/sdhci-xenon-phy.c            |   34 +-
 drivers/mmc/host/sdhci-xenon.c                |   22 +-
 drivers/mtd/spi-nor/spi-nor.c                 |   21 +-
 drivers/net/ethernet/marvell/mv643xx_eth.c    |   13 +-
 drivers/net/ethernet/marvell/mvmdio.c         |   27 +-
 drivers/net/ethernet/marvell/mvneta.c         |  477 +-
 drivers/net/ethernet/marvell/mvpp2/mvpp2.h    |  485 +-
 .../net/ethernet/marvell/mvpp2/mvpp2_cls.c    |  136 +-
 .../net/ethernet/marvell/mvpp2/mvpp2_cls.h    |   19 +-
 .../ethernet/marvell/mvpp2/mvpp2_debugfs.c    |  106 +-
 .../net/ethernet/marvell/mvpp2/mvpp2_main.c   | 4026 +++++++++++++----
 .../net/ethernet/marvell/mvpp2/mvpp2_prs.c    |  257 +-
 .../net/ethernet/marvell/mvpp2/mvpp2_prs.h    |   11 +-
 drivers/net/ethernet/marvell/pxa168_eth.c     |    7 +-
 drivers/net/phy/phylink.c                     |  104 +-
 drivers/net/phy/sfp.c                         |   53 +-
 drivers/net/phy/swphy.c                       |    6 +
 drivers/net/usb/ax88179_178a.c                |    2 -
 drivers/pci/controller/dwc/pcie-armada8k.c    |  280 +-
 .../pci/controller/dwc/pcie-designware-host.c |   22 +
 drivers/pci/controller/dwc/pcie-designware.h  |    5 +
 drivers/pci/iov.c                             |    2 +
 drivers/pci/probe.c                           |   61 +-
 drivers/pci/quirks.c                          |  239 +-
 drivers/phy/Kconfig                           |   11 +
 drivers/phy/Makefile                          |    1 +
 drivers/phy/allwinner/phy-sun4i-usb.c         |    3 +-
 drivers/phy/amlogic/phy-meson-gxl-usb2.c      |    5 +-
 drivers/phy/marvell/phy-mvebu-cp110-comphy.c  |  835 ++--
 drivers/phy/phy-core.c                        |   21 +-
 drivers/phy/phy-utmi-mvebu.c                  |  664 +++
 drivers/phy/qualcomm/phy-qcom-usb-hs.c        |    3 +-
 drivers/phy/ti/phy-da8xx-usb.c                |    3 +-
 drivers/phy/ti/phy-tusb1210.c                 |    2 +-
 drivers/pinctrl/mvebu/pinctrl-armada-cp110.c  |   24 +-
 drivers/spi/spi-orion.c                       |   54 +-
 drivers/spi/spi.c                             |    2 +
 drivers/usb/host/xhci-plat.c                  |   57 +-
 include/asm-generic/io.h                      |   39 +-
 include/dt-bindings/phy/phy-comphy-mvebu.h    |  145 +
 include/dt-bindings/phy/phy-utmi-mvebu.h      |   19 +
 include/dt-bindings/soc/ap810-stream-id.h     |   31 +
 include/linux/armada-pcie-ep.h                |   54 +
 include/linux/fcntl.h                         |    2 +-
 include/linux/i2c.h                           |   11 +
 include/linux/irqchip/arm-gic-v3.h            |    4 +
 include/linux/irqdomain.h                     |    1 +
 include/linux/kernel.h                        |    6 +
 include/linux/linkmode.h                      |   76 +
 include/linux/mii.h                           |    1 +
 include/linux/miscdevice.h                    |    2 +
 include/linux/mv_soc_info.h                   |   23 +
 include/linux/of_pci.h                        |   11 +
 include/linux/phy.h                           |   10 +
 include/linux/phy/phy.h                       |   26 +-
 include/linux/sched/task.h                    |    3 +
 include/linux/spi/spi.h                       |    1 +
 include/linux/thread_bits.h                   |   88 +
 include/linux/thread_info.h                   |   79 +-
 include/linux/usb/hcd.h                       |    2 +
 include/uapi/asm-generic/unistd.h             |   10 +-
 include/uapi/linux/ethtool.h                  |   18 +-
 include/uapi/linux/pci_regs.h                 |    6 +
 kernel/exit.c                                 |   79 +
 kernel/irq/manage.c                           |    2 +
 kernel/sched/core.c                           |   12 +
 134 files changed, 12324 insertions(+), 2771 deletions(-)
 mode change 100644 => 100755 arch/arm64/boot/dts/marvell/Makefile
 mode change 100644 => 100755 arch/arm64/boot/dts/marvell/armada-3720-espressobin.dts
 mode change 100644 => 100755 arch/arm64/boot/dts/marvell/armada-37xx.dtsi
 mode change 100644 => 100755 arch/arm64/boot/dts/marvell/armada-7040-db.dts
 create mode 100644 arch/arm64/boot/dts/marvell/armada-7040-db.dtsi
 mode change 100644 => 100755 arch/arm64/boot/dts/marvell/armada-70x0.dtsi
 mode change 100644 => 100755 arch/arm64/boot/dts/marvell/armada-8040-db.dts
 create mode 100644 arch/arm64/boot/dts/marvell/armada-8040-db.dtsi
 mode change 100644 => 100755 arch/arm64/boot/dts/marvell/armada-8040-mcbin.dts
 mode change 100644 => 100755 arch/arm64/boot/dts/marvell/armada-80x0.dtsi
 mode change 100644 => 100755 arch/arm64/boot/dts/marvell/armada-ap806-dual.dtsi
 mode change 100644 => 100755 arch/arm64/boot/dts/marvell/armada-ap806-quad.dtsi
 mode change 100644 => 100755 arch/arm64/boot/dts/marvell/armada-ap806.dtsi
 create mode 100644 arch/arm64/boot/dts/marvell/armada-ap807-quad.dtsi
 create mode 100755 arch/arm64/boot/dts/marvell/armada-ap807.dtsi
 create mode 100644 arch/arm64/boot/dts/marvell/armada-ap80x.dtsi
 mode change 100644 => 100755 arch/arm64/boot/dts/marvell/armada-common.dtsi
 mode change 100644 => 100755 arch/arm64/boot/dts/marvell/armada-cp110.dtsi
 create mode 100644 arch/arm64/boot/dts/marvell/cn9130-db-A.dts
 create mode 100644 arch/arm64/boot/dts/marvell/cn9130-db.dtsi
 create mode 100644 arch/arm64/boot/dts/marvell/cn9130.dtsi
 mode change 100644 => 100755 arch/arm64/include/asm/cputype.h
 create mode 100644 drivers/clk/mvebu/ap810-system-controller.c
 create mode 100644 drivers/clk/mvebu/armada_ap_cp_helper.c
 create mode 100644 drivers/clk/mvebu/armada_ap_cp_helper.h
 create mode 100644 drivers/gpio/gpio-i2c.c
 create mode 100644 drivers/irqchip/irq-gic-v3-quirks.c
 create mode 100644 drivers/irqchip/irq-gic-v3-quirks.h
 create mode 100644 drivers/irqchip/irq-mvebu-sei.c
 create mode 100644 drivers/misc/mvebu/Kconfig
 create mode 100644 drivers/misc/mvebu/Makefile
 create mode 100644 drivers/misc/mvebu/mv_soc_info.c
 create mode 100644 drivers/misc/mvebu/mvebu-a8k-debugfs.c
 mode change 100644 => 100755 drivers/net/ethernet/marvell/mvpp2/mvpp2_prs.c
 mode change 100644 => 100755 drivers/net/ethernet/marvell/mvpp2/mvpp2_prs.h
 create mode 100644 drivers/phy/phy-utmi-mvebu.c
 create mode 100644 include/dt-bindings/phy/phy-comphy-mvebu.h
 create mode 100644 include/dt-bindings/phy/phy-utmi-mvebu.h
 create mode 100644 include/dt-bindings/soc/ap810-stream-id.h
 create mode 100644 include/linux/armada-pcie-ep.h
 create mode 100644 include/linux/linkmode.h
 create mode 100644 include/linux/mv_soc_info.h
 create mode 100644 include/linux/thread_bits.h

diff --git a/arch/Kconfig b/arch/Kconfig
index a336548487e6..ffe42080ece5 100644
--- a/arch/Kconfig
+++ b/arch/Kconfig
@@ -276,6 +276,21 @@ config ARCH_THREAD_STACK_ALLOCATOR
 config ARCH_WANTS_DYNAMIC_TASK_STRUCT
 	bool
 
+config ARCH_32BIT_OFF_T
+	bool
+	depends on !64BIT
+	help
+	  All new 32-bit architectures should have 64-bit off_t type on
+	  userspace side which corresponds to the loff_t kernel type. This
+	  is the requirement for modern ABIs. Some existing architectures
+	  already have 32-bit off_t. This option is enabled for all such
+	  architectures explicitly. Namely: arc, arm, blackfin, cris, frv,
+	  h8300, hexagon, m32r, m68k, metag, microblaze, mips32, mn10300,
+	  nios2, openrisc, parisc32, powerpc32, score, sh, sparc, tile32,
+	  unicore32, x86_32 and xtensa. This is the complete list. Any
+	  new 32-bit architecture should declare 64-bit off_t type on user
+	  side and so should not enable this option.
+
 config HAVE_REGS_AND_STACK_ACCESS_API
 	bool
 	help
diff --git a/arch/arm64/Kconfig b/arch/arm64/Kconfig
index 1fe3e5cb2927..409d2aeb5d6d 100644
--- a/arch/arm64/Kconfig
+++ b/arch/arm64/Kconfig
@@ -635,6 +635,14 @@ config QCOM_FALKOR_ERRATUM_E1041
 
 endmenu
 
+config MRVL_OCTEONTX_EL0_INTR
+	bool "Handle interrupts in EL0 via EL3"
+	default y
+	help
+	  Handle certain interrupts in EL0 with the help of EL3 firmware to achieve
+	  low latency and also not break task isolation.
+	  Generally implemented and tested on OcteonTx and its successive
+	  generation CPUs.
 
 choice
 	prompt "Page size"
@@ -737,6 +745,12 @@ config CPU_BIG_ENDIAN
        help
          Say Y if you plan on running a kernel in big-endian mode.
 
+config MMIO_64BIT
+	bool "64BIT MMIO Access"
+	default y
+	help
+	  Say Y if you your platform supports 64bit MMIO access.
+
 config SCHED_MC
 	bool "Multi-core scheduler support"
 	help
diff --git a/arch/arm64/Kconfig.platforms b/arch/arm64/Kconfig.platforms
index 393d2b524284..5a89a957641b 100644
--- a/arch/arm64/Kconfig.platforms
+++ b/arch/arm64/Kconfig.platforms
@@ -128,6 +128,7 @@ config ARCH_MVEBU
 	select MVEBU_ICU
 	select MVEBU_ODMI
 	select MVEBU_PIC
+	select MVEBU_SEI
 	select OF_GPIO
 	select PINCTRL
 	select PINCTRL_ARMADA_37XX
diff --git a/arch/arm64/boot/dts/marvell/Makefile b/arch/arm64/boot/dts/marvell/Makefile
old mode 100644
new mode 100755
index ea9d49f2a911..4517da471831
--- a/arch/arm64/boot/dts/marvell/Makefile
+++ b/arch/arm64/boot/dts/marvell/Makefile
@@ -6,3 +6,4 @@ dtb-$(CONFIG_ARCH_MVEBU) += armada-7040-db.dtb
 dtb-$(CONFIG_ARCH_MVEBU) += armada-8040-db.dtb
 dtb-$(CONFIG_ARCH_MVEBU) += armada-8040-mcbin.dtb
 dtb-$(CONFIG_ARCH_MVEBU) += armada-8080-db.dtb
+dtb-$(CONFIG_ARCH_MVEBU) += cn9130-db-A.dtb
diff --git a/arch/arm64/boot/dts/marvell/armada-3720-db.dts b/arch/arm64/boot/dts/marvell/armada-3720-db.dts
index f2cc00594d64..b1c132090fe5 100644
--- a/arch/arm64/boot/dts/marvell/armada-3720-db.dts
+++ b/arch/arm64/boot/dts/marvell/armada-3720-db.dts
@@ -1,7 +1,7 @@
 // SPDX-License-Identifier: (GPL-2.0+ OR MIT)
 /*
  * Device Tree file for Marvell Armada 3720 development board
- * (DB-88F3720-DDR3)
+ * (DB-88F3720 with either DDR3 or DDR4)
  * Copyright (C) 2016 Marvell
  *
  * Gregory CLEMENT <gregory.clement@free-electrons.com>
@@ -17,7 +17,7 @@
 #include "armada-372x.dtsi"
 
 / {
-	model = "Marvell Armada 3720 Development Board DB-88F3720-DDR3";
+	model = "Marvell Armada 3720 Development Board DB-88F3720";
 	compatible = "marvell,armada-3720-db", "marvell,armada3720", "marvell,armada3710";
 
 	chosen {
@@ -44,9 +44,24 @@
 		vcc-supply = <&exp_usb3_vbus>;
 	};
 
-	vcc_sd_reg1: regulator {
+	exp_usb2_vbus: usb2-vbus {
+		compatible = "regulator-fixed";
+		regulator-name = "usb2-vbus";
+		regulator-min-microvolt = <5000000>;
+		regulator-max-microvolt = <5000000>;
+		enable-active-high;
+		regulator-always-on;
+		gpio = <&gpio_exp 0 GPIO_ACTIVE_HIGH>;
+	};
+
+	usb2_phy: usb2-phy {
+		compatible = "usb-nop-xceiv";
+		vcc-supply = <&exp_usb2_vbus>;
+	};
+
+	vcc_sd_reg0: regulator {
 		compatible = "regulator-gpio";
-		regulator-name = "vcc_sd1";
+		regulator-name = "vcc_sd0";
 		regulator-min-microvolt = <1800000>;
 		regulator-max-microvolt = <3300000>;
 		regulator-boot-on;
@@ -58,9 +73,9 @@
 		enable-active-high;
 	};
 
-	vcc_sd_reg2: regulator-vmcc {
+	vcc_sd_reg1: regulator-vmcc {
 		compatible = "regulator-fixed";
-		regulator-name = "vcc_sd2";
+		regulator-name = "vcc_sd1";
 		regulator-min-microvolt = <3300000>;
 		regulator-max-microvolt = <3300000>;
 		regulator-boot-on;
@@ -78,13 +93,6 @@
 	status = "okay";
 };
 
-/* Gigabit module on CON18(V2.0)/CON20(V1.4) */
-&eth1 {
-	phy-mode = "sgmii";
-	phy = <&phy1>;
-	status = "okay";
-};
-
 &i2c0 {
 	pinctrl-names = "default";
 	pinctrl-0 = <&i2c1_pins>;
@@ -113,30 +121,37 @@
 		compatible = "dallas,ds1337";
 		reg = <0x68>;
 	};
+
+	eeprom@57 {
+		compatible = "atmel,24c64";
+		reg = <0x57>;
+		pagesize = <32>;
+	};
 };
 
+/* Gigabit module on CON19(V2.0)/CON21(V1.4) only */
 &mdio {
 	status = "okay";
 	phy0: ethernet-phy@0 {
 		reg = <0>;
 	};
-
-	phy1: ethernet-phy@1 {
-		reg = <1>;
-	};
 };
 
 /* CON15(V2.0)/CON17(V1.4) : PCIe / CON15(V2.0)/CON12(V1.4) :mini-PCIe */
 &pcie0 {
 	status = "okay";
+	/* Generic PHY, providing serdes lanes */
+	phys = <&a3700_comphy1 0>;
 };
 
 /* CON3 */
 &sata {
 	status = "okay";
+	/* Generic PHY, providing serdes lanes */
+	phys = <&a3700_comphy2 0>;
 };
 
-&sdhci0 {
+&sdhci1 {
 	non-removable;
 	bus-width = <8>;
 	mmc-ddr-1_8v;
@@ -146,13 +161,13 @@
 };
 
 /* SD slot module on CON14(V2.0)/CON15(V1.4) */
-&sdhci1 {
+&sdhci0 {
 	wp-inverted;
 	cd-gpios = <&gpiosb 2 GPIO_ACTIVE_LOW>;
 	bus-width = <4>;
 	marvell,pad-type = "sd";
-	vqmmc-supply = <&vcc_sd_reg1>;
-	vmmc-supply = <&vcc_sd_reg2>;
+	vqmmc-supply = <&vcc_sd_reg0>;
+	vmmc-supply = <&vcc_sd_reg1>;
 	status = "okay";
 };
 
@@ -208,10 +223,20 @@
 /* CON27(V2.0)/CON29(V1.4) */
 &usb2 {
 	status = "okay";
+	usb-phy = <&usb2_phy>;
+	phys = <&utmi_usb2>;
+	phy-names = "usb";
+};
+
+&utmi_usb2 {
+	status = "okay";
 };
 
 /* CON29(V2.0)/CON31(V1.4) */
 &usb3 {
 	status = "okay";
 	usb-phy = <&usb3_phy>;
+	/* Generic PHY, providing serdes lanes */
+	phys = <&a3700_comphy0 0>;
+	phy-names = "usb";
 };
diff --git a/arch/arm64/boot/dts/marvell/armada-3720-espressobin.dts b/arch/arm64/boot/dts/marvell/armada-3720-espressobin.dts
old mode 100644
new mode 100755
index 6cbdd66921aa..0826ed62f0ee
--- a/arch/arm64/boot/dts/marvell/armada-3720-espressobin.dts
+++ b/arch/arm64/boot/dts/marvell/armada-3720-espressobin.dts
@@ -17,12 +17,11 @@
 
 / {
 	model = "Globalscale Marvell ESPRESSOBin Board";
-	compatible = "globalscale,espressobin", "marvell,armada3720", "marvell,armada3710";
+	compatible = "globalscale,espressobin",
+		     "marvell,armada3720", "marvell,armada3710";
 
 	aliases {
 		ethernet0 = &eth0;
-		serial0 = &uart0;
-		serial1 = &uart1;
 	};
 
 	chosen {
@@ -34,9 +33,9 @@
 		reg = <0x00000000 0x00000000 0x00000000 0x20000000>;
 	};
 
-	vcc_sd_reg1: regulator {
+	vcc_sd_reg0: regulator {
 		compatible = "regulator-gpio";
-		regulator-name = "vcc_sd1";
+		regulator-name = "vcc_sd0";
 		regulator-min-microvolt = <1800000>;
 		regulator-max-microvolt = <3300000>;
 		regulator-boot-on;
@@ -52,20 +51,26 @@
 /* J9 */
 &pcie0 {
 	status = "okay";
+	/* Generic PHY, providing serdes lanes */
+	phys = <&a3700_comphy1 0>;
 };
 
 /* J6 */
 &sata {
 	status = "okay";
+	/* Generic PHY, providing serdes lanes */
+	phys = <&a3700_comphy2 0>;
 };
 
 /* J1 */
-&sdhci1 {
+&sdhci0 {
+	pinctrl-names = "default";
+	pinctrl-0 = <&sdio_pins>;
 	wp-inverted;
 	bus-width = <4>;
 	cd-gpios = <&gpionb 3 GPIO_ACTIVE_LOW>;
 	marvell,pad-type = "sd";
-	vqmmc-supply = <&vcc_sd_reg1>;
+	vqmmc-supply = <&vcc_sd_reg0>;
 	status = "okay";
 };
 
@@ -116,6 +121,9 @@
 /* J7 */
 &usb3 {
 	status = "okay";
+	/* Generic PHY, providing serdes lanes */
+	phys = <&a3700_comphy0 0>;
+	phy-names = "usb";
 };
 
 /* J8 */
diff --git a/arch/arm64/boot/dts/marvell/armada-372x.dtsi b/arch/arm64/boot/dts/marvell/armada-372x.dtsi
index 97558a64e276..6800945a88ad 100644
--- a/arch/arm64/boot/dts/marvell/armada-372x.dtsi
+++ b/arch/arm64/boot/dts/marvell/armada-372x.dtsi
@@ -16,7 +16,7 @@
 	compatible = "marvell,armada3720", "marvell,armada3710";
 
 	cpus {
-		cpu@1 {
+		cpu1: cpu@1 {
 			device_type = "cpu";
 			compatible = "arm,cortex-a53","arm,armv8";
 			reg = <0x1>;
diff --git a/arch/arm64/boot/dts/marvell/armada-37xx.dtsi b/arch/arm64/boot/dts/marvell/armada-37xx.dtsi
old mode 100644
new mode 100755
index d9531e242eb4..b2faf0d342e3
--- a/arch/arm64/boot/dts/marvell/armada-37xx.dtsi
+++ b/arch/arm64/boot/dts/marvell/armada-37xx.dtsi
@@ -9,6 +9,7 @@
  */
 
 #include <dt-bindings/interrupt-controller/arm-gic.h>
+#include <dt-bindings/phy/phy-utmi-mvebu.h>
 
 / {
 	model = "Marvell Armada 37xx SoC";
@@ -18,6 +19,8 @@
 	#size-cells = <2>;
 
 	aliases {
+		ethernet0 = &eth0;
+		ethernet1 = &eth1;
 		serial0 = &uart0;
 		serial1 = &uart1;
 	};
@@ -35,12 +38,17 @@
 			reg = <0 0x4000000 0 0x200000>;
 			no-map;
 		};
+
+		tee@4400000 {
+			reg = <0 0x4400000 0 0x1000000>;
+			no-map;
+		};
 	};
 
 	cpus {
 		#address-cells = <1>;
 		#size-cells = <0>;
-		cpu@0 {
+		cpu0: cpu@0 {
 			device_type = "cpu";
 			compatible = "arm,cortex-a53", "arm,armv8";
 			reg = <0>;
@@ -79,6 +87,13 @@
 			compatible = "simple-bus";
 			/* 32M internal register @ 0xd000_0000 */
 			ranges = <0x0 0x0 0xd0000000 0x2000000>;
+			dma-coherent;
+
+			wdt: watchdog-timer@8300 {
+				compatible = "marvell,armada-3700-wdt";
+				reg = <0xd064 0x4>, <0x8300 0x40>;
+				clocks = <&xtalclk>;
+			};
 
 			spi0: spi@10600 {
 				compatible = "marvell,armada-3700-spi";
@@ -142,6 +157,11 @@
 				status = "disabled";
 			};
 
+			uio-sam {
+				compatible = "marvell,uio-sam";
+				eip_access = <&crypto>;
+			};
+
 			nb_periph_clk: nb-periph-clk@13000 {
 				compatible = "marvell,armada-3700-periph-clock-nb";
 				reg = <0x13000 0x100>;
@@ -158,6 +178,31 @@
 				#clock-cells = <1>;
 			};
 
+			a3700_comphy: comphy@18300 {
+				compatible = "marvell,comphy-a3700";
+				reg = <0x18300 0x300>, <0x1f000 0x1000>,
+				      <0x5c000 0x1000>, <0xe0178 0x8>;
+				reg-names = "comphy", "serdes",
+					    "usb3_gbe1_phy", "indirect_ahci";
+				#address-cells = <1>;
+				#size-cells = <0>;
+
+				a3700_comphy0: phy@0 {
+					reg = <0>;
+					#phy-cells = <1>;
+				};
+
+				a3700_comphy1: phy@1 {
+					reg = <1>;
+					#phy-cells = <1>;
+				};
+
+				a3700_comphy2: phy@2 {
+					reg = <2>;
+					#phy-cells = <1>;
+				};
+			};
+
 			tbg: tbg@13200 {
 				compatible = "marvell,armada-3700-tbg-clock";
 				reg = <0x13200 0x100>;
@@ -221,6 +266,11 @@
 					groups = "uart2";
 					function = "uart";
 				};
+
+				mmc_pins: mmc-pins {
+					groups = "emmc_nb";
+					function = "emmc";
+				};
 			};
 
 			nb_pm: syscon@14000 {
@@ -253,6 +303,11 @@
 					function = "mii";
 				};
 
+				sdio_pins: sdio-pins {
+					groups = "sdio_sb";
+					function = "sdio";
+				};
+
 			};
 
 			eth0: ethernet@30000 {
@@ -289,11 +344,19 @@
 
 			usb2: usb@5e000 {
 				compatible = "marvell,armada-3700-ehci";
-				reg = <0x5e000 0x2000>;
+				reg = <0x5e000 0x1000>;
 				interrupts = <GIC_SPI 17 IRQ_TYPE_LEVEL_HIGH>;
 				status = "disabled";
 			};
 
+			utmi_usb2: utmi@5f000 {
+				compatible = "marvell,armada-3700-utmi-phy";
+				reg = <0x5f000 0x1000>;
+				utmi-port = <UTMI_PHY_TO_USB2_HOST0>;
+				#phy-cells = <0>;
+				status = "disabled";
+			};
+
 			xor@60900 {
 				compatible = "marvell,armada-3700-xor";
 				reg = <0x60900 0x100>,
@@ -319,9 +382,10 @@
 				interrupt-names = "mem", "ring0", "ring1",
 						  "ring2", "ring3", "eip";
 				clocks = <&nb_periph_clk 15>;
+				cell-index = <0>;
 			};
 
-			sdhci1: sdhci@d0000 {
+			sdhci0: sdhci@d0000 {
 				compatible = "marvell,armada-3700-sdhci",
 					     "marvell,sdhci-xenon";
 				reg = <0xd0000 0x300>,
@@ -332,7 +396,7 @@
 				status = "disabled";
 			};
 
-			sdhci0: sdhci@d8000 {
+			sdhci1: sdhci@d8000 {
 				compatible = "marvell,armada-3700-sdhci",
 					     "marvell,sdhci-xenon";
 				reg = <0xd8000 0x300>,
@@ -345,7 +409,7 @@
 
 			sata: sata@e0000 {
 				compatible = "marvell,armada-3700-ahci";
-				reg = <0xe0000 0x2000>;
+				reg = <0xe0000 0x178>;
 				interrupts = <GIC_SPI 27 IRQ_TYPE_LEVEL_HIGH>;
 				status = "disabled";
 			};
@@ -361,6 +425,10 @@
 				      <0x1da0000 0x20000>; /* GICV */
 				interrupts = <GIC_PPI 9 IRQ_TYPE_LEVEL_HIGH>;
 			};
+
+			musdk_cma {
+				compatible = "marvell,musdk-cma";
+			};
 		};
 
 		pcie0: pcie@d0070000 {
@@ -375,6 +443,7 @@
 			#interrupt-cells = <1>;
 			msi-parent = <&pcie0>;
 			msi-controller;
+			dma-coherent;
 			ranges = <0x82000000 0 0xe8000000   0 0xe8000000 0 0x1000000 /* Port 0 MEM */
 				  0x81000000 0 0xe9000000   0 0xe9000000 0 0x10000>; /* Port 0 IO*/
 			interrupt-map-mask = <0 0 0 7>;
@@ -388,4 +457,12 @@
 			};
 		};
 	};
+
+	firmware {
+		optee {
+			compatible = "linaro,optee-tz";
+			method = "smc";
+			status = "okay";
+		};
+	};
 };
diff --git a/arch/arm64/boot/dts/marvell/armada-7040-db.dts b/arch/arm64/boot/dts/marvell/armada-7040-db.dts
old mode 100644
new mode 100755
index 412efdb46e7c..73b260b11835
--- a/arch/arm64/boot/dts/marvell/armada-7040-db.dts
+++ b/arch/arm64/boot/dts/marvell/armada-7040-db.dts
@@ -6,55 +6,23 @@
  */
 
 #include <dt-bindings/gpio/gpio.h>
-#include "armada-7040.dtsi"
+#include "armada-7040-db.dtsi"
 
 / {
-	model = "Marvell Armada 7040 DB board";
-	compatible = "marvell,armada7040-db", "marvell,armada7040",
-		     "marvell,armada-ap806-quad", "marvell,armada-ap806";
+	model = "Marvell Armada 7040 development board default (A) setup";
+	compatible = "marvell,armada7040-db-default", "marvell,armada7040-db",
+		     "marvell,armada7040", "marvell,armada-ap806-quad",
+		     "marvell,armada-ap806";
 
 	chosen {
 		stdout-path = "serial0:115200n8";
 	};
 
-	memory@0 {
-		device_type = "memory";
-		reg = <0x0 0x0 0x0 0x80000000>;
-	};
-
 	aliases {
 		ethernet0 = &cp0_eth0;
 		ethernet1 = &cp0_eth1;
 		ethernet2 = &cp0_eth2;
 	};
-
-	cp0_reg_usb3_0_vbus: cp0-usb3-0-vbus {
-		compatible = "regulator-fixed";
-		regulator-name = "usb3h0-vbus";
-		regulator-min-microvolt = <5000000>;
-		regulator-max-microvolt = <5000000>;
-		enable-active-high;
-		gpio = <&expander0 0 GPIO_ACTIVE_HIGH>;
-	};
-
-	cp0_reg_usb3_1_vbus: cp0-usb3-1-vbus {
-		compatible = "regulator-fixed";
-		regulator-name = "usb3h1-vbus";
-		regulator-min-microvolt = <5000000>;
-		regulator-max-microvolt = <5000000>;
-		enable-active-high;
-		gpio = <&expander0 1 GPIO_ACTIVE_HIGH>;
-	};
-
-	cp0_usb3_0_phy: cp0-usb3-0-phy {
-		compatible = "usb-nop-xceiv";
-		vcc-supply = <&cp0_reg_usb3_0_vbus>;
-	};
-
-	cp0_usb3_1_phy: cp0-usb3-1-phy {
-		compatible = "usb-nop-xceiv";
-		vcc-supply = <&cp0_reg_usb3_1_vbus>;
-	};
 };
 
 &i2c0 {
@@ -64,40 +32,16 @@
 
 &spi0 {
 	status = "okay";
-
-	spi-flash@0 {
-		#address-cells = <1>;
-		#size-cells = <1>;
-		compatible = "jedec,spi-nor";
-		reg = <0>;
-		spi-max-frequency = <10000000>;
-
-		partitions {
-			compatible = "fixed-partitions";
-			#address-cells = <1>;
-			#size-cells = <1>;
-
-			partition@0 {
-				label = "U-Boot";
-				reg = <0 0x200000>;
-			};
-			partition@400000 {
-				label = "Filesystem";
-				reg = <0x200000 0xce0000>;
-			};
-		};
-	};
 };
 
 &uart0 {
 	status = "okay";
-	pinctrl-0 = <&uart0_pins>;
-	pinctrl-names = "default";
 };
 
 
 &cp0_pcie2 {
 	status = "okay";
+	phys = <&cp0_comphy5 2>;
 };
 
 &cp0_i2c0 {
@@ -133,91 +77,48 @@
 	pinctrl-0 = <&nand_pins>, <&nand_rb>;
 	pinctrl-names = "default";
 
-	nand@0 {
-		reg = <0>;
-		label = "pxa3xx_nand-0";
-		nand-rb = <0>;
-		nand-on-flash-bbt;
-		nand-ecc-strength = <4>;
-		nand-ecc-step-size = <512>;
-
-		partitions {
-			compatible = "fixed-partitions";
-			#address-cells = <1>;
-			#size-cells = <1>;
-
-			partition@0 {
-				label = "U-Boot";
-				reg = <0 0x200000>;
-			};
-
-			partition@200000 {
-				label = "Linux";
-				reg = <0x200000 0xe00000>;
-			};
-
-			partition@1000000 {
-				label = "Filesystem";
-				reg = <0x1000000 0x3f000000>;
-			};
-
-		};
-	};
 };
 
 &cp0_spi1 {
 	status = "okay";
+};
 
-	spi-flash@0 {
-		#address-cells = <0x1>;
-		#size-cells = <0x1>;
-		compatible = "jedec,spi-nor";
-		reg = <0x0>;
-		spi-max-frequency = <20000000>;
-
-		partitions {
-			compatible = "fixed-partitions";
-			#address-cells = <1>;
-			#size-cells = <1>;
-
-			partition@0 {
-				label = "U-Boot";
-				reg = <0x0 0x200000>;
-			};
+&cp0_sata0 {
+	status = "okay";
 
-			partition@400000 {
-				label = "Filesystem";
-				reg = <0x200000 0xe00000>;
-			};
-		};
+	sata-port@1 {
+		status = "okay";
+		/* Generic PHY, providing serdes lanes */
+		phys = <&cp0_comphy3 1>;
 	};
 };
 
-&cp0_sata0 {
+&cp0_utmi0 {
 	status = "okay";
 };
 
 &cp0_usb3_0 {
-	usb-phy = <&cp0_usb3_0_phy>;
+	phys = <&cp0_utmi0>, <&cp0_comphy1 0>;
+	phy-names = "usb", "usb3";
+	status = "okay";
+};
+
+&cp0_utmi1 {
 	status = "okay";
 };
 
 &cp0_usb3_1 {
-	usb-phy = <&cp0_usb3_1_phy>;
+	phys = <&cp0_utmi1>, <&cp0_comphy4 1>;
+	phy-names = "usb", "usb3";
 	status = "okay";
 };
 
 &ap_sdhci0 {
 	status = "okay";
-	bus-width = <4>;
-	no-1-8-v;
-	non-removable;
 };
 
 &cp0_sdhci0 {
 	status = "okay";
-	bus-width = <4>;
-	no-1-8-v;
 	cd-gpios = <&expander0 12 GPIO_ACTIVE_LOW>;
 };
 
@@ -242,11 +143,8 @@
 	phy-mode = "10gbase-kr";
 	/* Generic PHY, providing serdes lanes */
 	phys = <&cp0_comphy2 0>;
-
-	fixed-link {
-		speed = <10000>;
-		full-duplex;
-	};
+	managed = "in-band-status";
+	sfp = <&sfp_eth0>;
 };
 
 &cp0_eth1 {
@@ -263,3 +161,7 @@
 	phy = <&phy1>;
 	phy-mode = "rgmii-id";
 };
+
+&cp0_crypto {
+	status = "okay";
+};
diff --git a/arch/arm64/boot/dts/marvell/armada-7040-db.dtsi b/arch/arm64/boot/dts/marvell/armada-7040-db.dtsi
new file mode 100644
index 000000000000..478e11a62498
--- /dev/null
+++ b/arch/arm64/boot/dts/marvell/armada-7040-db.dtsi
@@ -0,0 +1,208 @@
+// SPDX-License-Identifier: (GPL-2.0+ OR MIT)
+/*
+ * Device Tree file for Marvell Armada 7040 development board platform
+ */
+
+#include <dt-bindings/gpio/gpio.h>
+#include "armada-7040.dtsi"
+
+/ {
+	model = "Marvell Armada 7040 development board";
+	compatible = "marvell,armada7040-db", "marvell,armada7040",
+			"marvell,armada-ap806-quad", "marvell,armada-ap806";
+
+	memory@0 {
+		device_type = "memory";
+		reg = <0x0 0x0 0x0 0x80000000>;
+	};
+
+	cp0_reg_usb3_0_vbus: cp0-usb3-0-vbus {
+		compatible = "regulator-fixed";
+		regulator-name = "usb3h0-vbus";
+		regulator-min-microvolt = <5000000>;
+		regulator-max-microvolt = <5000000>;
+		enable-active-high;
+		gpio = <&expander0 0 GPIO_ACTIVE_HIGH>;
+	};
+
+	cp0_reg_usb3_1_vbus: cp0-usb3-1-vbus {
+		compatible = "regulator-fixed";
+		regulator-name = "usb3h1-vbus";
+		regulator-min-microvolt = <5000000>;
+		regulator-max-microvolt = <5000000>;
+		enable-active-high;
+		gpio = <&expander0 1 GPIO_ACTIVE_HIGH>;
+	};
+
+	cp0_vccq_sd0_reg: cp0_vccq_sd0 {
+		compatible = "regulator-gpio";
+		regulator-name = "cp0-vccq-sd0";
+		regulator-min-microvolt = <1800000>;
+		regulator-max-microvolt = <3300000>;
+		regulator-boot-on;
+		gpios = <&expander0 15 GPIO_ACTIVE_HIGH>;
+		gpios-states = <0>;
+		states = <1800000 0x1
+			  3300000 0x0>;
+		enable-active-high;
+	};
+
+	cp0_usb3_0_phy: cp0-usb3-0-phy {
+		compatible = "usb-nop-xceiv";
+		/* vcc-supply can be changed by io-expander or GPIO,
+		 * for A7040-DB we are using by default io-expander
+		 * for other board GPIO may be needed, should update
+		 * the phandle to gpio regulator
+		 */
+		vcc-supply = <&cp0_reg_usb3_0_vbus>;
+		current-limiter-supply = <&exp_usb3_0_current_limiter>;
+	};
+
+	cp0_usb3_1_phy: cp0-usb3-1-phy {
+		compatible = "usb-nop-xceiv";
+		vcc-supply = <&cp0_reg_usb3_1_vbus>;
+		current-limiter-supply = <&exp_usb3_1_current_limiter>;
+	};
+	exp_usb3_0_current_limiter: usb3-0-current-limiter {
+		compatible = "regulator-fixed";
+		regulator-name = "usb3-0-current-limiter";
+		enable-active-high;
+		gpio = <&expander0 4 GPIO_ACTIVE_HIGH>;
+	};
+	exp_usb3_1_current_limiter: usb3-1-current-limiter {
+		compatible = "regulator-fixed";
+		regulator-name = "usb3-1-current-limiter";
+		enable-active-high;
+		gpio = <&expander0 5 GPIO_ACTIVE_HIGH>;
+	};
+
+	sfp_eth0: sfp-eth0 {
+		compatible = "sff,sfp";
+	};
+};
+
+&uart0 {
+	pinctrl-0 = <&uart0_pins>;
+	pinctrl-names = "default";
+};
+
+&ap_sdhci0 {
+	bus-width = <4>;
+	no-1-8-v;
+	non-removable;
+};
+
+&cp0_config_space {
+	ranges = /* internal regs */
+		 <0x0 0x0 0xf2000000 0x2000000>,
+		 /* SPI1-DEV0 */
+		 <0x2000000 0 0xf9000000 0x1000000>;
+};
+
+&cp0_i2c0 {
+	expander0: pca9555@21 {
+		compatible = "nxp,pca9555";
+		pinctrl-names = "default";
+		gpio-controller;
+		#gpio-cells = <2>;
+		reg = <0x21>;
+	};
+
+	eeprom0: eeprom@50 {
+		compatible = "atmel,24c64";
+		reg = <0x50>;
+		pagesize = <0x20>;
+	};
+
+	eeprom1: eeprom@57 {
+		compatible = "atmel,24c64";
+		reg = <0x57>;
+		pagesize = <0x20>;
+	};
+};
+
+&cp0_nand_controller {
+	pinctrl-names = "default";
+	pinctrl-0 = <&nand_pins &nand_rb>;
+
+	nand@0 {
+		reg = <0>;
+		label = "main-storage";
+		nand-rb = <0>;
+		nand-ecc-mode = "hw";
+		nand-on-flash-bbt;
+		nand-ecc-strength = <8>;
+		nand-ecc-step-size = <512>;
+
+		partitions {
+			compatible = "fixed-partitions";
+			#address-cells = <1>;
+			#size-cells = <1>;
+
+			partition@0 {
+				label = "U-Boot";
+				reg = <0 0x200000>;
+			};
+			partition@200000 {
+				label = "Linux";
+				reg = <0x200000 0xe00000>;
+			};
+			partition@1000000 {
+				label = "Filesystem";
+				reg = <0x1000000 0x3f000000>;
+			};
+		};
+	};
+};
+
+&cp0_spi1 {
+	reg = <0x700680 0x50>,          /* control */
+	      <0x2000000 0x1000000>;    /* CS0 */
+	spi-flash@0 {
+		#address-cells = <0x1>;
+		#size-cells = <0x1>;
+		compatible = "jedec,spi-nor";
+		reg = <0x0>;
+		spi-max-frequency = <20000000>;
+
+		partitions {
+			compatible = "fixed-partitions";
+			#address-cells = <1>;
+			#size-cells = <1>;
+
+			partition@0 {
+				label = "U-Boot";
+				reg = <0x0 0x400000>;
+			};
+
+			partition@400000 {
+				label = "Filesystem";
+				reg = <0x400000 0xc00000>;
+			};
+		};
+	};
+};
+
+&cp0_sdhci0 {
+	pinctrl-names = "default";
+	pinctrl-0 = <&sdhci_pins>;
+	bus-width = <4>;
+	vqmmc-supply = <&cp0_vccq_sd0_reg>;
+	non-removable;
+};
+
+&cp0_usb3_0 {
+	usb-phy = <&cp0_usb3_0_phy>;
+	status = "disabled";
+	/* Generic PHY, providing serdes lanes */
+	phys = <&cp0_comphy1 0>;
+	phy-names = "usb";
+};
+
+&cp0_usb3_1 {
+	usb-phy = <&cp0_usb3_1_phy>;
+	status = "disabled";
+	/* Generic PHY, providing serdes lanes */
+	phys = <&cp0_comphy4 1>;
+	phy-names = "usb";
+};
diff --git a/arch/arm64/boot/dts/marvell/armada-7040.dtsi b/arch/arm64/boot/dts/marvell/armada-7040.dtsi
index 47247215770d..0cbba6e891ff 100644
--- a/arch/arm64/boot/dts/marvell/armada-7040.dtsi
+++ b/arch/arm64/boot/dts/marvell/armada-7040.dtsi
@@ -14,3 +14,31 @@
 	compatible = "marvell,armada7040", "marvell,armada-ap806-quad",
 		     "marvell,armada-ap806";
 };
+
+&smmu {
+	status = "disabled";
+};
+
+&cp0_pcie0 {
+	iommu-map =
+		<0x0   &smmu 0x480 0x20>,
+		<0x100 &smmu 0x4a0 0x20>,
+		<0x200 &smmu 0x4c0 0x20>;
+	iommu-map-mask = <0x031f>;
+};
+
+&cp0_sata0 {
+	iommus = <&smmu 0x444>;
+};
+
+&cp0_sdhci0 {
+	iommus = <&smmu 0x445>;
+};
+
+&cp0_usb3_0 {
+	iommus = <&smmu 0x440>;
+};
+
+&cp0_usb3_1 {
+	iommus = <&smmu 0x441>;
+};
diff --git a/arch/arm64/boot/dts/marvell/armada-70x0.dtsi b/arch/arm64/boot/dts/marvell/armada-70x0.dtsi
old mode 100644
new mode 100755
index e5c6d7c25819..304638371fb9
--- a/arch/arm64/boot/dts/marvell/armada-70x0.dtsi
+++ b/arch/arm64/boot/dts/marvell/armada-70x0.dtsi
@@ -5,6 +5,25 @@
  * Device Tree file for the Armada 70x0 SoC
  */
 
+/*
+ * Instantiate the CP110
+ */
+#define CP110_NUM				0
+#define CP110_BASE				0xf2000000
+#define CP110_PCIE_MEM_SIZE(iface)		0xf00000
+#define CP110_PCIEx_CPU_MEM_BASE(iface)		(0xf6000000 + (iface) *  0x1000000)
+#define CP110_PCIEx_BUS_MEM_BASE(iface)		(CP110_PCIEx_CPU_MEM_BASE(iface))
+#define CP110_PCIE_BUS_MEM_CFG			(0x82000000)
+
+#include "armada-cp110.dtsi"
+
+#undef CP110_NUM
+#undef CP110_BASE
+#undef CP110_PCIE_MEM_SIZE
+#undef CP110_PCIEx_CPU_MEM_BASE
+#undef CP110_PCIEx_BUS_MEM_BASE
+#undef CP110_PCIE_BUS_MEM_CFG
+
 / {
 	aliases {
 		gpio1 = &cp0_gpio1;
@@ -14,26 +33,7 @@
 	};
 };
 
-/*
- * Instantiate the CP110
- */
-#define CP110_NAME		cp0
-#define CP110_BASE		f2000000
-#define CP110_PCIE_IO_BASE	0xf9000000
-#define CP110_PCIE_MEM_BASE	0xf6000000
-#define CP110_PCIE0_BASE	f2600000
-#define CP110_PCIE1_BASE	f2620000
-#define CP110_PCIE2_BASE	f2640000
-
-#include "armada-cp110.dtsi"
 
-#undef CP110_NAME
-#undef CP110_BASE
-#undef CP110_PCIE_IO_BASE
-#undef CP110_PCIE_MEM_BASE
-#undef CP110_PCIE0_BASE
-#undef CP110_PCIE1_BASE
-#undef CP110_PCIE2_BASE
 
 &cp0_gpio1 {
 	status = "okay";
@@ -47,6 +47,12 @@
 	cp0_pinctrl: pinctrl {
 		compatible = "marvell,armada-7k-pinctrl";
 
+		sdhci_pins: sdhi-pins {
+			marvell,pins = "mpp56", "mpp57", "mpp58",
+				       "mpp59", "mpp60", "mpp61", "mpp62";
+			marvell,function = "sdio";
+		};
+
 		nand_pins: nand-pins {
 			marvell,pins =
 			"mpp15", "mpp16", "mpp17", "mpp18",
diff --git a/arch/arm64/boot/dts/marvell/armada-8040-db.dts b/arch/arm64/boot/dts/marvell/armada-8040-db.dts
old mode 100644
new mode 100755
index 1bac437369a1..160ed80d421d
--- a/arch/arm64/boot/dts/marvell/armada-8040-db.dts
+++ b/arch/arm64/boot/dts/marvell/armada-8040-db.dts
@@ -6,12 +6,13 @@
  */
 
 #include <dt-bindings/gpio/gpio.h>
-#include "armada-8040.dtsi"
+#include "armada-8040-db.dtsi"
 
 / {
-	model = "Marvell Armada 8040 DB board";
-	compatible = "marvell,armada8040-db", "marvell,armada8040",
-		     "marvell,armada-ap806-quad", "marvell,armada-ap806";
+	model = "Marvell Armada 8040 development board default (A) setup";
+	compatible = "marvell,armada8040-db-default", "marvell,armada8040-db",
+		"marvell,armada8040", "marvell,armada-ap806-quad",
+		"marvell,armada-ap806";
 
 	chosen {
 		stdout-path = "serial0:115200n8";
@@ -28,138 +29,66 @@
 		ethernet2 = &cp1_eth0;
 		ethernet3 = &cp1_eth1;
 	};
-
-	cp0_reg_usb3_0_vbus: cp0-usb3-0-vbus {
-		compatible = "regulator-fixed";
-		regulator-name = "cp0-usb3h0-vbus";
-		regulator-min-microvolt = <5000000>;
-		regulator-max-microvolt = <5000000>;
-		enable-active-high;
-		gpio = <&expander0 0 GPIO_ACTIVE_HIGH>;
-	};
-
-	cp0_reg_usb3_1_vbus: cp0-usb3-1-vbus {
-		compatible = "regulator-fixed";
-		regulator-name = "cp0-usb3h1-vbus";
-		regulator-min-microvolt = <5000000>;
-		regulator-max-microvolt = <5000000>;
-		enable-active-high;
-		gpio = <&expander0 1 GPIO_ACTIVE_HIGH>;
-	};
-
-	cp0_usb3_0_phy: cp0-usb3-0-phy {
-		compatible = "usb-nop-xceiv";
-		vcc-supply = <&cp0_reg_usb3_0_vbus>;
-	};
-
-	cp0_usb3_1_phy: cp0-usb3-1-phy {
-		compatible = "usb-nop-xceiv";
-		vcc-supply = <&cp0_reg_usb3_1_vbus>;
-	};
-
-	cp1_reg_usb3_0_vbus: cp1-usb3-0-vbus {
-		compatible = "regulator-fixed";
-		regulator-name = "cp1-usb3h0-vbus";
-		regulator-min-microvolt = <5000000>;
-		regulator-max-microvolt = <5000000>;
-		enable-active-high;
-		gpio = <&expander1 0 GPIO_ACTIVE_HIGH>;
-	};
-
-	cp1_usb3_0_phy: cp1-usb3-0-phy {
-		compatible = "usb-nop-xceiv";
-		vcc-supply = <&cp1_reg_usb3_0_vbus>;
-	};
-};
-
-&i2c0 {
-	status = "okay";
-	clock-frequency = <100000>;
-};
-
-&spi0 {
-	status = "okay";
-
-	spi-flash@0 {
-		#address-cells = <1>;
-		#size-cells = <1>;
-		compatible = "jedec,spi-nor";
-		reg = <0>;
-		spi-max-frequency = <10000000>;
-
-		partitions {
-			compatible = "fixed-partitions";
-			#address-cells = <1>;
-			#size-cells = <1>;
-
-			partition@0 {
-				label = "U-Boot";
-				reg = <0 0x200000>;
-			};
-			partition@400000 {
-				label = "Filesystem";
-				reg = <0x200000 0xce0000>;
-			};
-		};
-	};
 };
 
 /* Accessible over the mini-USB CON9 connector on the main board */
 &uart0 {
 	status = "okay";
-	pinctrl-0 = <&uart0_pins>;
-	pinctrl-names = "default";
 };
 
 /* CON6 on CP0 expansion */
 &cp0_pcie0 {
 	status = "okay";
+	phys = <&cp0_comphy0 0>;
 };
 
 /* CON5 on CP0 expansion */
 &cp0_pcie2 {
 	status = "okay";
+	phys = <&cp0_comphy5 2>;
 };
 
 &cp0_i2c0 {
 	status = "okay";
-	clock-frequency = <100000>;
+};
 
-	/* U31 */
-	expander0: pca9555@21 {
-		compatible = "nxp,pca9555";
-		pinctrl-names = "default";
-		gpio-controller;
-		#gpio-cells = <2>;
-		reg = <0x21>;
+&cp0_sata0 {
+	status = "okay";
+	/* CON2 on CP0 expansion */
+	sata-port@0 {
+		status = "okay";
+		/* Generic PHY, providing serdes lanes */
+		phys = <&cp0_comphy1 0>;
 	};
-
-	/* U25 */
-	expander1: pca9555@25 {
-		compatible = "nxp,pca9555";
-		pinctrl-names = "default";
-		gpio-controller;
-		#gpio-cells = <2>;
-		reg = <0x25>;
+	/* CON4 on CP0 expansion */
+	sata-port@1 {
+		status = "okay";
+		/* Generic PHY, providing serdes lanes */
+		phys = <&cp0_comphy3 1>;
 	};
-
 };
 
-/* CON4 on CP0 expansion */
-&cp0_sata0 {
+/* CON9 on CP0 expansion */
+&cp0_utmi0 {
 	status = "okay";
 };
 
-/* CON9 on CP0 expansion */
 &cp0_usb3_0 {
-	usb-phy = <&cp0_usb3_0_phy>;
+	phys = <&cp0_utmi0>;
+	phy-names = "usb	";
 	status = "okay";
 };
 
 /* CON10 on CP0 expansion */
+&cp0_utmi1 {
+	status = "okay";
+};
+
 &cp0_usb3_1 {
-	usb-phy = <&cp0_usb3_1_phy>;
 	status = "okay";
+	/* Generic PHY, providing serdes lanes */
+	phys = <&cp0_utmi1>, <&cp0_comphy4 1>;
+	phy-names = "usb", "usb3";
 };
 
 &cp0_mdio {
@@ -177,11 +106,10 @@
 &cp0_eth0 {
 	status = "okay";
 	phy-mode = "10gbase-kr";
-
-	fixed-link {
-		speed = <10000>;
-		full-duplex;
-	};
+	/* Generic PHY, providing serdes lanes */
+	phys = <&cp0_comphy2 0>;
+	managed = "in-band-status";
+	sfp = <&sfp_eth0>;
 };
 
 &cp0_eth2 {
@@ -193,16 +121,19 @@
 /* CON6 on CP1 expansion */
 &cp1_pcie0 {
 	status = "okay";
+	phys = <&cp1_comphy0 0>;
 };
 
 /* CON7 on CP1 expansion */
 &cp1_pcie1 {
 	status = "okay";
+	phys = <&cp1_comphy4 1>;
 };
 
 /* CON5 on CP1 expansion */
 &cp1_pcie2 {
 	status = "okay";
+	phys = <&cp1_comphy5 2>;
 };
 
 &cp1_i2c0 {
@@ -212,33 +143,6 @@
 
 &cp1_spi1 {
 	status = "okay";
-
-	spi-flash@0 {
-		#address-cells = <0x1>;
-		#size-cells = <0x1>;
-		compatible = "jedec,spi-nor";
-		reg = <0x0>;
-		spi-max-frequency = <20000000>;
-
-		partitions {
-			compatible = "fixed-partitions";
-			#address-cells = <1>;
-			#size-cells = <1>;
-
-			partition@0 {
-				label = "Boot";
-				reg = <0x0 0x200000>;
-			};
-			partition@200000 {
-				label = "Filesystem";
-				reg = <0x200000 0xd00000>;
-			};
-			partition@f00000 {
-				label = "Boot_2nd";
-				reg = <0xf00000 0x100000>;
-			};
-		};
-	};
 };
 
 /*
@@ -248,48 +152,44 @@
 &cp1_nand_controller {
 	pinctrl-0 = <&nand_pins>, <&nand_rb>;
 	pinctrl-names = "default";
-
-	nand@0 {
-		reg = <0>;
-		nand-rb = <0>;
-		nand-on-flash-bbt;
-		nand-ecc-strength = <4>;
-		nand-ecc-step-size = <512>;
-
-		partitions {
-			compatible = "fixed-partitions";
-			#address-cells = <1>;
-			#size-cells = <1>;
-
-			partition@0 {
-				label = "U-Boot";
-				reg = <0 0x200000>;
-			};
-			partition@200000 {
-				label = "Linux";
-				reg = <0x200000 0xe00000>;
-			};
-			partition@1000000 {
-				label = "Filesystem";
-				reg = <0x1000000 0x3f000000>;
-			};
-		};
-	};
 };
 
-/* CON4 on CP1 expansion */
 &cp1_sata0 {
 	status = "okay";
+	/* CON2 on CP1 expansion */
+	sata-port@0 {
+		status = "okay";
+		/* Generic PHY, providing serdes lanes */
+		phys = <&cp1_comphy1 0>;
+	};
+	/* CON4 on CP1 expansion */
+	sata-port@1 {
+		status = "okay";
+		/* Generic PHY, providing serdes lanes */
+		phys = <&cp1_comphy3 1>;
+	};
 };
 
 /* CON9 on CP1 expansion */
+&cp1_utmi0 {
+	status = "okay";
+};
+
 &cp1_usb3_0 {
-	usb-phy = <&cp1_usb3_0_phy>;
+	phys = <&cp1_utmi0>;
+	phy-names = "usb";
+	status = "okay";
+};
+
+/* CON10 on CP0 expansion */
+&cp1_utmi1 {
 	status = "okay";
 };
 
-/* CON10 on CP1 expansion */
 &cp1_usb3_1 {
+	/* Generic PHY, providing serdes lanes */
+	phys = <&cp1_utmi1>, <&cp1_comphy4 1>;
+	phy-names = "usb", "usb3";
 	status = "okay";
 };
 
@@ -308,11 +208,10 @@
 &cp1_eth0 {
 	status = "okay";
 	phy-mode = "10gbase-kr";
-
-	fixed-link {
-		speed = <10000>;
-		full-duplex;
-	};
+	/* Generic PHY, providing serdes lanes */
+	phys = <&cp1_comphy2 0>;
+	managed = "in-band-status";
+	sfp = <&sfp_eth1>;
 };
 
 &cp1_eth1 {
@@ -323,12 +222,26 @@
 
 &ap_sdhci0 {
 	status = "okay";
-	bus-width = <4>;
+	bus-width = <8>;
+	/* The below property should be added to boards with AP806-B0
+	 * for enabling HS400 speed mode. Otherwise the device highest
+	 * speed mode will be HS200.
+	 * Should not be added to boards with earlier release of AP806
+	 * since it will cause SDHCI driver to fail upon initialization.
+	 *
+	 * mmc-hs400-1_8v;
+	 */
 	non-removable;
 };
 
 &cp0_sdhci0 {
 	status = "okay";
-	bus-width = <8>;
-	non-removable;
+};
+
+&cp0_crypto {
+	status = "okay";
+};
+
+&cp1_crypto {
+	status = "okay";
 };
diff --git a/arch/arm64/boot/dts/marvell/armada-8040-db.dtsi b/arch/arm64/boot/dts/marvell/armada-8040-db.dtsi
new file mode 100644
index 000000000000..db97d9e3a039
--- /dev/null
+++ b/arch/arm64/boot/dts/marvell/armada-8040-db.dtsi
@@ -0,0 +1,288 @@
+// SPDX-License-Identifier: (GPL-2.0+ OR MIT)
+/*
+ * Device Tree file for Marvell Armada 8040 development board platform
+ */
+
+#include <dt-bindings/gpio/gpio.h>
+#include "armada-8040.dtsi"
+
+/ {
+	model = "Marvell Armada 8040 development board";
+	compatible = "marvell,armada8040-db", "marvell,armada8040",
+		"marvell,armada-ap806-quad", "marvell,armada-ap806";
+
+	memory@0 {
+		device_type = "memory";
+		reg = <0x0 0x0 0x0 0x80000000>;
+	};
+
+	cp0_reg_usb3_0_vbus: cp0-usb3-0-vbus {
+		compatible = "regulator-fixed";
+		regulator-name = "cp0-usb3h0-vbus";
+		regulator-min-microvolt = <5000000>;
+		regulator-max-microvolt = <5000000>;
+		enable-active-high;
+		gpio = <&expander0 0 GPIO_ACTIVE_HIGH>;
+	};
+
+	cp0_reg_usb3_1_vbus: cp0-usb3-1-vbus {
+		compatible = "regulator-fixed";
+		regulator-name = "cp0-usb3h1-vbus";
+		regulator-min-microvolt = <5000000>;
+		regulator-max-microvolt = <5000000>;
+		enable-active-high;
+		gpio = <&expander0 1 GPIO_ACTIVE_HIGH>;
+	};
+
+	cp0_usb3_0_phy: cp0-usb3-0-phy {
+		compatible = "usb-nop-xceiv";
+		vcc-supply = <&cp0_reg_usb3_0_vbus>;
+		current-limiter-supply = <&cp0_reg_usb3_0_current_limiter>;
+	};
+	cp0_reg_usb3_0_current_limiter: cp0_usb3-current-limiter0 {
+		compatible = "regulator-fixed";
+		regulator-name = "cp0-usb3-current-limiter-h0";
+		enable-active-high;
+		gpio = <&expander0 4 GPIO_ACTIVE_HIGH>;
+	};
+
+
+	cp0_usb3_1_phy: cp0-usb3-1-phy {
+		compatible = "usb-nop-xceiv";
+		vcc-supply = <&cp0_reg_usb3_1_vbus>;
+		current-limiter-supply = <&cp0_reg_usb3_1_current_limiter>;
+	};
+	cp0_reg_usb3_1_current_limiter: cp0_usb3-current-limiter1 {
+		compatible = "regulator-fixed";
+		regulator-name = "cp0-usb3-current-limiter-h1";
+		enable-active-high;
+		gpio = <&expander0 5 GPIO_ACTIVE_HIGH>;
+	};
+
+
+	cp1_reg_usb3_0_vbus: cp1-usb3-0-vbus {
+		compatible = "regulator-fixed";
+		regulator-name = "cp1-usb3h0-vbus";
+		regulator-min-microvolt = <5000000>;
+		regulator-max-microvolt = <5000000>;
+		enable-active-high;
+		gpio = <&expander1 0 GPIO_ACTIVE_HIGH>;
+	};
+
+	cp1_reg_usb3_1_vbus: cp1-usb3-1-vbus {
+		compatible = "regulator-fixed";
+		regulator-name = "cp1-usb3h1-vbus";
+		regulator-min-microvolt = <5000000>;
+		regulator-max-microvolt = <5000000>;
+		enable-active-high;
+		gpio = <&expander1 1 GPIO_ACTIVE_HIGH>;
+	};
+
+	cp1_usb3_0_phy: cp1-usb3-0-phy {
+		compatible = "usb-nop-xceiv";
+		vcc-supply = <&cp1_reg_usb3_0_vbus>;
+		current-limiter-supply = <&cp1_reg_usb3_0_current_limiter>;
+	};
+
+	cp1_reg_usb3_0_current_limiter: cps_usb3-current-limiter0 {
+		compatible = "regulator-fixed";
+		regulator-name = "cps-usb3-current-limiter-h0";
+		enable-active-high;
+		gpio = <&expander1 4 GPIO_ACTIVE_HIGH>;
+	};
+	cp1_usb3_1_phy: cp1-usb3-1-phy {
+		compatible = "usb-nop-xceiv";
+		vcc-supply = <&cp1_reg_usb3_1_vbus>;
+	};
+
+	cp0_vccq_sd0_reg: cp0_vccq_sd0 {
+		compatible = "regulator-gpio";
+		regulator-name = "cp0-vccq-sd0";
+		regulator-min-microvolt = <1800000>;
+		regulator-max-microvolt = <3300000>;
+		regulator-boot-on;
+		gpios = <&expander0 15 GPIO_ACTIVE_HIGH>;
+		gpios-states = <0>;
+		states = <1800000 0x1
+			  3300000 0x0>;
+		enable-active-high;
+	};
+
+	sfp_eth0: sfp-eth0 {
+		compatible = "sff,sfp";
+	};
+
+	sfp_eth1: sfp-eth1 {
+		compatible = "sff,sfp";
+	};
+};
+
+/* Accessible over the mini-USB CON9 connector on the main board */
+&uart0 {
+	pinctrl-0 = <&uart0_pins>;
+	pinctrl-names = "default";
+};
+
+&ap_sdhci0 {
+	bus-width = <8>;
+	non-removable;
+};
+
+&spi0 {
+	status = "disabled";
+	spi-flash@0 {
+		#address-cells = <0x1>;
+		#size-cells = <0x1>;
+		compatible = "jedec,spi-nor";
+		reg = <0x0>;
+		spi-max-frequency = <20000000>;
+		partition@0 {
+			label = "boot";
+			reg = <0x0 0x200000>;
+		};
+		partition@200000 {
+			label = "recovery_image";
+			reg = <0x200000 0x200000>;
+		};
+		partition@400000 {
+			label = "Filesystem";
+			reg = <0x400000 0xc00000>;
+		};
+	};
+};
+
+&cp0_i2c0 {
+	clock-frequency = <100000>;
+
+	/* U31 */
+	expander0: pca9555@21 {
+		compatible = "nxp,pca9555";
+		pinctrl-names = "default";
+		gpio-controller;
+		#gpio-cells = <2>;
+		reg = <0x21>;
+	};
+
+	/* U25 */
+	expander1: pca9555@25 {
+		compatible = "nxp,pca9555";
+		pinctrl-names = "default";
+		gpio-controller;
+		#gpio-cells = <2>;
+		reg = <0x25>;
+	};
+
+	eeprom0: eeprom@50 {
+		compatible = "atmel,24c64";
+		reg = <0x50>;
+		pagesize = <0x20>;
+	};
+
+	eeprom1: eeprom@57 {
+		compatible = "atmel,24c64";
+		reg = <0x57>;
+		pagesize = <0x20>;
+	};
+
+};
+
+&cp0_sdhci0 {
+	pinctrl-names = "default";
+	pinctrl-0 = <&sdhci_pins>;
+	bus-width = <4>;
+	vqmmc-supply = <&cp0_vccq_sd0_reg>;
+	non-removable;
+};
+
+/* CON9 on CP0 expansion */
+&cp0_usb3_0 {
+	usb-phy = <&cp0_usb3_0_phy>;
+};
+
+/* CON10 on CP0 expansion */
+&cp0_usb3_1 {
+	usb-phy = <&cp0_usb3_1_phy>;
+	/* Generic PHY, providing serdes lanes */
+	phys = <&cp0_comphy4 1>;
+	phy-names = "usb";
+};
+
+&cp1_config_space {
+	ranges = /* internal regs */
+		 <0x0 0x0 0xf4000000 0x2000000>,
+		 /* SPI1-DEV0 */
+		 <0x2000000 0 0xf9000000 0x1000000>;
+};
+
+&cp1_spi1 {
+	reg = <0x700680 0x50>,          /* control */
+	      <0x2000000 0x1000000>;    /* CS0 */
+	status = "disabled";
+
+	spi-flash@0 {
+		#address-cells = <0x1>;
+		#size-cells = <0x1>;
+		compatible = "jedec,spi-nor";
+		reg = <0x0>;
+		spi-max-frequency = <20000000>;
+
+		partitions {
+			compatible = "fixed-partitions";
+			#address-cells = <1>;
+			#size-cells = <1>;
+
+			partition@0 {
+				label = "Boot";
+				reg = <0x0 0x400000>;
+			};
+			partition@400000 {
+				label = "Filesystem";
+				reg = <0x400000 0xc00000>;
+			};
+		};
+	};
+};
+
+&cp1_nand_controller {
+	pinctrl-names = "default";
+	pinctrl-0 = <&nand_pins &nand_rb>;
+
+	nand@0 {
+		reg = <0>;
+		label = "main-storage";
+		nand-rb = <0>;
+		nand-ecc-mode = "hw";
+		nand-on-flash-bbt;
+		nand-ecc-strength = <8>;
+		nand-ecc-step-size = <512>;
+
+		partitions {
+			compatible = "fixed-partitions";
+			#address-cells = <1>;
+			#size-cells = <1>;
+
+			partition@0 {
+				label = "U-Boot";
+				reg = <0 0x200000>;
+			};
+			partition@200000 {
+				label = "Linux";
+				reg = <0x200000 0xe00000>;
+			};
+			partition@1000000 {
+				label = "Filesystem";
+				reg = <0x1000000 0x3f000000>;
+			};
+		};
+	};
+};
+
+/* CON9 on CP1 expansion */
+&cp1_usb3_0 {
+	usb-phy = <&cp1_usb3_0_phy>;
+};
+
+/* CON10 on CP0 expansion */
+&cp1_usb3_1 {
+	usb-phy = <&cp1_usb3_1_phy>;
+};
diff --git a/arch/arm64/boot/dts/marvell/armada-8040-mcbin.dts b/arch/arm64/boot/dts/marvell/armada-8040-mcbin.dts
old mode 100644
new mode 100755
index 56fa44860909..96362699c1aa
--- a/arch/arm64/boot/dts/marvell/armada-8040-mcbin.dts
+++ b/arch/arm64/boot/dts/marvell/armada-8040-mcbin.dts
@@ -111,17 +111,12 @@
 
 &ap_sdhci0 {
 	bus-width = <8>;
-	/*
-	 * Not stable in HS modes - phy needs "more calibration", so add
-	 * the "slow-mode" and disable SDR104, SDR50 and DDR50 modes.
-	 */
-	marvell,xenon-phy-slow-mode;
 	no-1-8-v;
 	no-sd;
 	no-sdio;
 	non-removable;
 	status = "okay";
-	vqmmc-supply = <&v_vddo_h>;
+	vqmmc-supply = <&v_3_3>;
 };
 
 &cp0_i2c0 {
@@ -183,7 +178,18 @@
 	pinctrl-0 = <&cp0_pcie_pins>;
 	num-lanes = <4>;
 	num-viewport = <8>;
-	reset-gpio = <&cp0_gpio1 20 GPIO_ACTIVE_LOW>;
+	reset-gpio = <&cp0_gpio2 20 GPIO_ACTIVE_HIGH>;
+
+	ranges = <0x1000000 0x0 0x00000000 0x0 0xeff00000 0x0 0x00010000>,
+		 <0x2000000 0x0 0xc0000000 0x0 0xc0000000 0x0 0x20000000>,
+		 <0x3000000 0x8 0x00000000 0x8 0x00000000 0x1 0x00000000>;
+
+	/* Generic PHY, providing serdes lanes */
+	phys = <&cp0_comphy0 0
+		&cp0_comphy1 0
+		&cp0_comphy2 0
+		&cp0_comphy3 0>;
+
 	status = "okay";
 };
 
@@ -259,6 +265,16 @@
 &cp0_sata0 {
 	/* CPM Lane 0 - U29 */
 	status = "okay";
+
+	sata-port@0 {
+		status = "disabled";
+	};
+
+	sata-port@1 {
+		status = "okay";
+		/* Generic PHY, providing serdes lanes */
+		phys = <&cp0_comphy5 1>;
+	};
 };
 
 &cp0_sdhci0 {
@@ -271,16 +287,35 @@
 	vqmmc-supply = <&v_3_3>;
 };
 
+&cp0_utmi0 {
+	status = "okay";
+};
+
 &cp0_usb3_0 {
 	/* J38? - USB2.0 only */
+	phys = <&cp0_utmi0>;
+	phy-names = "usb";
+	status = "okay";
+};
+
+&cp0_utmi1 {
 	status = "okay";
 };
 
 &cp0_usb3_1 {
 	/* J38? - USB2.0 only */
+	phys = <&cp0_utmi1>;
+	phy-names = "usb";
 	status = "okay";
 };
 
+&cp1_config_space {
+	ranges = /* internal regs */
+		 <0x0 0x0 0xf4000000 0x2000000>,
+		 /* SPI1-DEV0 */
+		 <0x2000000 0 0xf9000000 0x1000000>;
+};
+
 &cp1_ethernet {
 	status = "okay";
 };
@@ -349,11 +384,24 @@
 	/* CPS Lane 1 - U32 */
 	/* CPS Lane 3 - U31 */
 	status = "okay";
+	sata-port@0 {
+		status = "okay";
+		/* Generic PHY, providing serdes lanes */
+		phys = <&cp1_comphy1 0>;
+	};
+
+	sata-port@1 {
+		status = "okay";
+		/* Generic PHY, providing serdes lanes */
+		phys = <&cp1_comphy3 1>;
+	};
 };
 
 &cp1_spi1 {
 	pinctrl-names = "default";
 	pinctrl-0 = <&cp1_spi1_pins>;
+	reg = <0x700680 0x50>,          /* control */
+	      <0x2000000 0x1000000>;    /* CS0 */
 	status = "okay";
 
 	spi-flash@0 {
@@ -363,8 +411,23 @@
 	};
 };
 
+&cp1_utmi1 {
+	status = "okay";
+};
+
 &cp1_usb3_0 {
 	/* CPS Lane 2 - CON7 */
 	usb-phy = <&usb3h0_phy>;
 	status = "okay";
+	/* Generic PHY, providing serdes lanes */
+	phys = <&cp1_utmi1>, <&cp1_comphy2 0>;
+	phy-names = "usb", "usb3";
+};
+
+&cp0_crypto {
+	status = "okay";
+};
+
+&cp1_crypto {
+	status = "okay";
 };
diff --git a/arch/arm64/boot/dts/marvell/armada-8040.dtsi b/arch/arm64/boot/dts/marvell/armada-8040.dtsi
index 7699b19224c2..101be8fa68bd 100644
--- a/arch/arm64/boot/dts/marvell/armada-8040.dtsi
+++ b/arch/arm64/boot/dts/marvell/armada-8040.dtsi
@@ -15,6 +15,18 @@
 		     "marvell,armada-ap806";
 };
 
+&smmu {
+	status = "disabled";
+};
+
+&cp0_pcie0 {
+	iommu-map =
+		<0x0   &smmu 0x480 0x20>,
+		<0x100 &smmu 0x4a0 0x20>,
+		<0x200 &smmu 0x4c0 0x20>;
+	iommu-map-mask = <0x031f>;
+};
+
 /* The RTC requires external oscillator. But on Aramda 80x0, the RTC clock
  * in CP master is not connected (by package) to the oscillator. So
  * disable it. However, the RTC clock in CP slave is connected to the
@@ -23,3 +35,31 @@
 &cp0_rtc {
 	status = "disabled";
 };
+
+&cp0_sata0 {
+	iommus = <&smmu 0x444>;
+};
+
+&cp0_sdhci0 {
+	iommus = <&smmu 0x445>;
+};
+
+&cp0_usb3_0 {
+	iommus = <&smmu 0x440>;
+};
+
+&cp0_usb3_1 {
+	iommus = <&smmu 0x441>;
+};
+
+&cp1_sata0 {
+	iommus = <&smmu 0x454>;
+};
+
+&cp1_usb3_0 {
+	iommus = <&smmu 0x450>;
+};
+
+&cp1_usb3_1 {
+	iommus = <&smmu 0x451>;
+};
diff --git a/arch/arm64/boot/dts/marvell/armada-80x0.dtsi b/arch/arm64/boot/dts/marvell/armada-80x0.dtsi
old mode 100644
new mode 100755
index 8129b40f12a4..64b035c3adbe
--- a/arch/arm64/boot/dts/marvell/armada-80x0.dtsi
+++ b/arch/arm64/boot/dts/marvell/armada-80x0.dtsi
@@ -5,58 +5,55 @@
  * Device Tree file for the Armada 80x0 SoC family
  */
 
-/ {
-	aliases {
-		gpio1 = &cp1_gpio1;
-		gpio2 = &cp0_gpio2;
-		spi1 = &cp0_spi0;
-		spi2 = &cp0_spi1;
-		spi3 = &cp1_spi0;
-		spi4 = &cp1_spi1;
-	};
-};
-
 /*
  * Instantiate the master CP110
  */
-#define CP110_NAME		cp0
-#define CP110_BASE		f2000000
-#define CP110_PCIE_IO_BASE	0xf9000000
-#define CP110_PCIE_MEM_BASE	0xf6000000
-#define CP110_PCIE0_BASE	f2600000
-#define CP110_PCIE1_BASE	f2620000
-#define CP110_PCIE2_BASE	f2640000
+#define CP110_NUM				0
+#define CP110_BASE				0xf2000000
+#define CP110_PCIE_MEM_SIZE(iface)		0xf00000
+#define CP110_PCIEx_CPU_MEM_BASE(iface)		(0xf6000000 + (iface) *  0x1000000)
+#define CP110_PCIEx_BUS_MEM_BASE(iface)		(CP110_PCIEx_CPU_MEM_BASE(iface))
+#define CP110_PCIE_BUS_MEM_CFG			(0x82000000)
 
 #include "armada-cp110.dtsi"
 
-#undef CP110_NAME
+#undef CP110_NUM
 #undef CP110_BASE
-#undef CP110_PCIE_IO_BASE
-#undef CP110_PCIE_MEM_BASE
-#undef CP110_PCIE0_BASE
-#undef CP110_PCIE1_BASE
-#undef CP110_PCIE2_BASE
+#undef CP110_PCIE_MEM_SIZE
+#undef CP110_PCIEx_CPU_MEM_BASE
+#undef CP110_PCIEx_BUS_MEM_BASE
+#undef CP110_PCIE_BUS_MEM_CFG
 
 /*
  * Instantiate the slave CP110
  */
-#define CP110_NAME		cp1
-#define CP110_BASE		f4000000
-#define CP110_PCIE_IO_BASE	0xfd000000
-#define CP110_PCIE_MEM_BASE	0xfa000000
-#define CP110_PCIE0_BASE	f4600000
-#define CP110_PCIE1_BASE	f4620000
-#define CP110_PCIE2_BASE	f4640000
+#define CP110_NUM				1
+#define CP110_BASE				0xf4000000
+#define CP110_PCIE_MEM_SIZE(iface)		0xf00000
+#define CP110_PCIEx_CPU_MEM_BASE(iface)		(0xfa000000 + (iface) *  0x1000000)
+#define CP110_PCIEx_BUS_MEM_BASE(iface)		(CP110_PCIEx_CPU_MEM_BASE(iface))
+#define CP110_PCIE_BUS_MEM_CFG			(0x82000000)
+
 
 #include "armada-cp110.dtsi"
 
-#undef CP110_NAME
+#undef CP110_NUM
 #undef CP110_BASE
-#undef CP110_PCIE_IO_BASE
-#undef CP110_PCIE_MEM_BASE
-#undef CP110_PCIE0_BASE
-#undef CP110_PCIE1_BASE
-#undef CP110_PCIE2_BASE
+#undef CP110_PCIE_MEM_SIZE
+#undef CP110_PCIEx_CPU_MEM_BASE
+#undef CP110_PCIEx_BUS_MEM_BASE
+#undef CP110_PCIE_BUS_MEM_CFG
+
+/ {
+	aliases {
+		gpio1 = &cp1_gpio1;
+		gpio2 = &cp0_gpio2;
+		spi1 = &cp0_spi0;
+		spi2 = &cp0_spi1;
+		spi3 = &cp1_spi0;
+		spi4 = &cp1_spi1;
+	};
+};
 
 /* The 80x0 has two CP blocks, but uses only one block from each. */
 &cp1_gpio1 {
@@ -70,6 +67,12 @@
 &cp0_syscon0 {
 	cp0_pinctrl: pinctrl {
 		compatible = "marvell,armada-8k-cpm-pinctrl";
+
+		sdhci_pins: sdhi-pins {
+			marvell,pins = "mpp56", "mpp57", "mpp58",
+				       "mpp59", "mpp60", "mpp61", "mpp62";
+			marvell,function = "sdio";
+		};
 	};
 };
 
@@ -77,6 +80,18 @@
 	cp1_pinctrl: pinctrl {
 		compatible = "marvell,armada-8k-cps-pinctrl";
 
+		cp1_spi0_pins: spi-pins-0 {
+			marvell,pins = "mpp7", "mpp8", "mpp9",
+				       "mpp10", "mpp11";
+			marvell,function = "spi0";
+		};
+
+		cp1_tdm_pins: tdm-pins {
+			marvell,pins = "mpp0", "mpp1", "mpp2",
+				       "mpp3", "mpp4", "mpp5";
+			marvell,function = "tdm";
+		};
+
 		nand_pins: nand-pins {
 			marvell,pins =
 			"mpp0", "mpp1", "mpp2", "mpp3",
@@ -95,14 +110,3 @@
 		};
 	};
 };
-
-&cp1_crypto {
-	/*
-	 * The cryptographic engine found on the cp110
-	 * master is enabled by default at the SoC
-	 * level. Because it is not possible as of now
-	 * to enable two cryptographic engines in
-	 * parallel, disable this one by default.
-	 */
-	status = "disabled";
-};
diff --git a/arch/arm64/boot/dts/marvell/armada-ap806-dual.dtsi b/arch/arm64/boot/dts/marvell/armada-ap806-dual.dtsi
old mode 100644
new mode 100755
index 64b5e61a698e..d8d054a06dd4
--- a/arch/arm64/boot/dts/marvell/armada-ap806-dual.dtsi
+++ b/arch/arm64/boot/dts/marvell/armada-ap806-dual.dtsi
@@ -15,17 +15,108 @@
 		#address-cells = <1>;
 		#size-cells = <0>;
 
-		cpu@0 {
+		cpu0: cpu@0 {
 			device_type = "cpu";
 			compatible = "arm,cortex-a72", "arm,armv8";
 			reg = <0x000>;
 			enable-method = "psci";
+			#cooling-cells = <2>;
+			i-cache-size = <0xc000>;
+			i-cache-line-size = <64>;
+			i-cache-sets = <256>;
+			d-cache-size = <0x8000>;
+			d-cache-line-size = <64>;
+			d-cache-sets = <256>;
+			next-level-cache = <&l2>;
 		};
-		cpu@1 {
+		cpu1: cpu@1 {
 			device_type = "cpu";
 			compatible = "arm,cortex-a72", "arm,armv8";
 			reg = <0x001>;
 			enable-method = "psci";
+			#cooling-cells = <2>;
+			i-cache-size = <0xc000>;
+			i-cache-line-size = <64>;
+			i-cache-sets = <256>;
+			d-cache-size = <0x8000>;
+			d-cache-line-size = <64>;
+			d-cache-sets = <256>;
+			next-level-cache = <&l2>;
+		};
+
+		l2: l2-cache {
+			compatible = "cache";
+			cache-size = <0x80000>;
+			cache-line-size = <64>;
+			cache-sets = <512>;
+		};
+	};
+
+	thermal-zones {
+		ap_thermal_cpu0: ap-thermal-cpu0 {
+			polling-delay-passive = <1000>;
+			polling-delay = <1000>;
+
+			thermal-sensors = <&ap_thermal 1>;
+
+			trips {
+				cpu0_hot: cpu0-hot {
+					temperature = <85000>;
+					hysteresis = <2000>;
+					type = "passive";
+				};
+				cpu0_emerg: cpu0-emerg {
+					temperature = <95000>;
+					hysteresis = <2000>;
+					type = "passive";
+				};
+			};
+
+			cooling-maps {
+				map0_hot: map0-hot {
+					trip = <&cpu0_hot>;
+					cooling-device = <&cpu0 1 2>,
+						<&cpu1 1 2>;
+				};
+				map0_emerg: map0-ermerg {
+					trip = <&cpu0_emerg>;
+					cooling-device = <&cpu0 3 3>,
+						<&cpu1 3 3>;
+				};
+			};
+		};
+
+		ap_thermal_cpu1: ap-thermal-cpu1 {
+			polling-delay-passive = <1000>;
+			polling-delay = <1000>;
+
+			thermal-sensors = <&ap_thermal 2>;
+
+			trips {
+				cpu1_hot: cpu1-hot {
+					temperature = <85000>;
+					hysteresis = <2000>;
+					type = "passive";
+				};
+				cpu1_emerg: cpu1-emerg {
+					temperature = <95000>;
+					hysteresis = <2000>;
+					type = "passive";
+				};
+			};
+
+			cooling-maps {
+				map1_hot: map1-hot {
+					trip = <&cpu1_hot>;
+					cooling-device = <&cpu0 1 2>,
+						<&cpu1 1 2>;
+				};
+				map1_emerg: map1-emerg {
+					trip = <&cpu1_emerg>;
+					cooling-device = <&cpu0 3 3>,
+						<&cpu1 3 3>;
+				};
+			};
 		};
 	};
 };
diff --git a/arch/arm64/boot/dts/marvell/armada-ap806-quad.dtsi b/arch/arm64/boot/dts/marvell/armada-ap806-quad.dtsi
old mode 100644
new mode 100755
index 746e792767f5..170436b05c86
--- a/arch/arm64/boot/dts/marvell/armada-ap806-quad.dtsi
+++ b/arch/arm64/boot/dts/marvell/armada-ap806-quad.dtsi
@@ -15,29 +15,217 @@
 		#address-cells = <1>;
 		#size-cells = <0>;
 
-		cpu@0 {
+		cpu0: cpu@0 {
 			device_type = "cpu";
 			compatible = "arm,cortex-a72", "arm,armv8";
 			reg = <0x000>;
 			enable-method = "psci";
+			#cooling-cells = <2>;
+			clocks = <&cpu_clk 0>;
+			cpu-idle-states = <&CPU_SLEEP_0>;
+			i-cache-size = <0xc000>;
+			i-cache-line-size = <64>;
+			i-cache-sets = <256>;
+			d-cache-size = <0x8000>;
+			d-cache-line-size = <64>;
+			d-cache-sets = <256>;
+			next-level-cache = <&l2_0>;
 		};
-		cpu@1 {
+		cpu1: cpu@1 {
 			device_type = "cpu";
 			compatible = "arm,cortex-a72", "arm,armv8";
 			reg = <0x001>;
 			enable-method = "psci";
+			#cooling-cells = <2>;
+			clocks = <&cpu_clk 0>;
+			cpu-idle-states = <&CPU_SLEEP_0>;
+			i-cache-size = <0xc000>;
+			i-cache-line-size = <64>;
+			i-cache-sets = <256>;
+			d-cache-size = <0x8000>;
+			d-cache-line-size = <64>;
+			d-cache-sets = <256>;
+			next-level-cache = <&l2_0>;
 		};
-		cpu@100 {
+		cpu2: cpu@100 {
 			device_type = "cpu";
 			compatible = "arm,cortex-a72", "arm,armv8";
 			reg = <0x100>;
 			enable-method = "psci";
+			#cooling-cells = <2>;
+			clocks = <&cpu_clk 1>;
+			cpu-idle-states = <&CPU_SLEEP_0>;
+			i-cache-size = <0xc000>;
+			i-cache-line-size = <64>;
+			i-cache-sets = <256>;
+			d-cache-size = <0x8000>;
+			d-cache-line-size = <64>;
+			d-cache-sets = <256>;
+			next-level-cache = <&l2_1>;
 		};
-		cpu@101 {
+		cpu3: cpu@101 {
 			device_type = "cpu";
 			compatible = "arm,cortex-a72", "arm,armv8";
 			reg = <0x101>;
 			enable-method = "psci";
+			#cooling-cells = <2>;
+			clocks = <&cpu_clk 1>;
+			cpu-idle-states = <&CPU_SLEEP_0>;
+			i-cache-size = <0xc000>;
+			i-cache-line-size = <64>;
+			i-cache-sets = <256>;
+			d-cache-size = <0x8000>;
+			d-cache-line-size = <64>;
+			d-cache-sets = <256>;
+			next-level-cache = <&l2_1>;
+		};
+
+		l2_0: l2-cache0 {
+			compatible = "cache";
+			cache-size = <0x80000>;
+			cache-line-size = <64>;
+			cache-sets = <512>;
+		};
+
+		l2_1: l2-cache1 {
+			compatible = "cache";
+			cache-size = <0x80000>;
+			cache-line-size = <64>;
+			cache-sets = <512>;
+		};
+	};
+
+	thermal-zones {
+		ap_thermal_cpu0: ap-thermal-cpu0 {
+			polling-delay-passive = <1000>;
+			polling-delay = <1000>;
+
+			thermal-sensors = <&ap_thermal 1>;
+
+			trips {
+				cpu0_hot: cpu0-hot {
+					temperature = <85000>;
+					hysteresis = <2000>;
+					type = "passive";
+				};
+				cpu0_emerg: cpu0-emerg {
+					temperature = <95000>;
+					hysteresis = <2000>;
+					type = "passive";
+				};
+			};
+
+			cooling-maps {
+				map0_hot: map0-hot {
+					trip = <&cpu0_hot>;
+					cooling-device = <&cpu0 1 2>,
+						<&cpu1 1 2>;
+				};
+				map0_emerg: map0-ermerg {
+					trip = <&cpu0_emerg>;
+					cooling-device = <&cpu0 3 3>,
+						<&cpu1 3 3>;
+				};
+			};
+		};
+
+		ap_thermal_cpu1: ap-thermal-cpu1 {
+			polling-delay-passive = <1000>;
+			polling-delay = <1000>;
+
+			thermal-sensors = <&ap_thermal 2>;
+
+			trips {
+				cpu1_hot: cpu1-hot {
+					temperature = <85000>;
+					hysteresis = <2000>;
+					type = "passive";
+				};
+				cpu1_emerg: cpu1-emerg {
+					temperature = <95000>;
+					hysteresis = <2000>;
+					type = "passive";
+				};
+			};
+
+			cooling-maps {
+				map1_hot: map1-hot {
+					trip = <&cpu1_hot>;
+					cooling-device = <&cpu0 1 2>,
+						<&cpu1 1 2>;
+				};
+				map1_emerg: map1-emerg {
+					trip = <&cpu1_emerg>;
+					cooling-device = <&cpu0 3 3>,
+						<&cpu1 3 3>;
+				};
+			};
+		};
+
+		ap_thermal_cpu2: ap-thermal-cpu2 {
+			polling-delay-passive = <1000>;
+			polling-delay = <1000>;
+
+			thermal-sensors = <&ap_thermal 3>;
+
+			trips {
+				cpu2_hot: cpu2-hot {
+					temperature = <85000>;
+					hysteresis = <2000>;
+					type = "passive";
+				};
+				cpu2_emerg: cpu2-emerg {
+					temperature = <95000>;
+					hysteresis = <2000>;
+					type = "passive";
+				};
+			};
+
+			cooling-maps {
+				map2_hot: map2-hot {
+					trip = <&cpu2_hot>;
+					cooling-device = <&cpu2 1 2>,
+						<&cpu3 1 2>;
+				};
+				map2_emerg: map2-emerg {
+					trip = <&cpu2_emerg>;
+					cooling-device = <&cpu2 3 3>,
+						<&cpu3 3 3>;
+				};
+			};
+		};
+
+		ap_thermal_cpu3: ap-thermal-cpu3 {
+			polling-delay-passive = <1000>;
+			polling-delay = <1000>;
+
+			thermal-sensors = <&ap_thermal 4>;
+
+			trips {
+				cpu3_hot: cpu3-hot {
+					temperature = <85000>;
+					hysteresis = <2000>;
+					type = "passive";
+				};
+				cpu3_emerg: cpu3-emerg {
+					temperature = <95000>;
+					hysteresis = <2000>;
+					type = "passive";
+				};
+			};
+
+			cooling-maps {
+				map3_hot: map3-bhot {
+					trip = <&cpu3_hot>;
+					cooling-device = <&cpu2 1 2>,
+						<&cpu3 1 2>;
+				};
+				map3_emerg: map3-emerg {
+					trip = <&cpu3_emerg>;
+					cooling-device = <&cpu2 3 3>,
+						<&cpu3 3 3>;
+				};
+			};
 		};
 	};
 };
diff --git a/arch/arm64/boot/dts/marvell/armada-ap806.dtsi b/arch/arm64/boot/dts/marvell/armada-ap806.dtsi
old mode 100644
new mode 100755
index ec0da5b3d7fd..5aae726b0794
--- a/arch/arm64/boot/dts/marvell/armada-ap806.dtsi
+++ b/arch/arm64/boot/dts/marvell/armada-ap806.dtsi
@@ -1,273 +1,31 @@
 // SPDX-License-Identifier: (GPL-2.0+ OR MIT)
 /*
- * Copyright (C) 2016 Marvell Technology Group Ltd.
+ * Copyright (C) 2018 Marvell Technology Group Ltd.
  *
  * Device Tree file for Marvell Armada AP806.
  */
 
 #include <dt-bindings/interrupt-controller/arm-gic.h>
-
-/dts-v1/;
+#define AP_NAME		ap806
+#include "armada-ap80x.dtsi"
 
 / {
 	model = "Marvell Armada AP806";
-	compatible = "marvell,armada-ap806";
-	#address-cells = <2>;
-	#size-cells = <2>;
-
-	aliases {
-		serial0 = &uart0;
-		serial1 = &uart1;
-		gpio0 = &ap_gpio;
-		spi0 = &spi0;
-	};
-
-	psci {
-		compatible = "arm,psci-0.2";
-		method = "smc";
-	};
-
-	reserved-memory {
-		#address-cells = <2>;
-		#size-cells = <2>;
-		ranges;
-
-		/*
-		 * This area matches the mapping done with a
-		 * mainline U-Boot, and should be updated by the
-		 * bootloader.
-		 */
-
-		psci-area@4000000 {
-			reg = <0x0 0x4000000 0x0 0x200000>;
-			no-map;
-		};
-	};
-
-	ap806 {
-		#address-cells = <2>;
-		#size-cells = <2>;
-		compatible = "simple-bus";
-		interrupt-parent = <&gic>;
-		ranges;
-
+	AP_NAME {
 		config-space@f0000000 {
-			#address-cells = <1>;
-			#size-cells = <1>;
-			compatible = "simple-bus";
-			ranges = <0x0 0x0 0xf0000000 0x1000000>;
-
-			gic: interrupt-controller@210000 {
-				compatible = "arm,gic-400";
-				#interrupt-cells = <3>;
-				#address-cells = <1>;
-				#size-cells = <1>;
-				ranges;
-				interrupt-controller;
-				interrupts = <GIC_PPI 9 (GIC_CPU_MASK_SIMPLE(4) | IRQ_TYPE_LEVEL_HIGH)>;
-				reg = <0x210000 0x10000>,
-				      <0x220000 0x20000>,
-				      <0x240000 0x20000>,
-				      <0x260000 0x20000>;
-
-				gic_v2m0: v2m@280000 {
-					compatible = "arm,gic-v2m-frame";
-					msi-controller;
-					reg = <0x280000 0x1000>;
-					arm,msi-base-spi = <160>;
-					arm,msi-num-spis = <32>;
-				};
-				gic_v2m1: v2m@290000 {
-					compatible = "arm,gic-v2m-frame";
-					msi-controller;
-					reg = <0x290000 0x1000>;
-					arm,msi-base-spi = <192>;
-					arm,msi-num-spis = <32>;
-				};
-				gic_v2m2: v2m@2a0000 {
-					compatible = "arm,gic-v2m-frame";
-					msi-controller;
-					reg = <0x2a0000 0x1000>;
-					arm,msi-base-spi = <224>;
-					arm,msi-num-spis = <32>;
-				};
-				gic_v2m3: v2m@2b0000 {
-					compatible = "arm,gic-v2m-frame";
-					msi-controller;
-					reg = <0x2b0000 0x1000>;
-					arm,msi-base-spi = <256>;
-					arm,msi-num-spis = <32>;
+			ap_syscon1:system-controller@6f8000 {
+				cpu_clk: clock-cpu {
+					compatible = "marvell,ap806-cpu-clock";
+					clocks = <&ap_clk 0>, <&ap_clk 1>;
+					#clock-cells = <1>;
 				};
 			};
 
-			timer {
-				compatible = "arm,armv8-timer";
-				interrupts = <GIC_PPI 13 (GIC_CPU_MASK_SIMPLE(4) | IRQ_TYPE_LEVEL_LOW)>,
-					     <GIC_PPI 14 (GIC_CPU_MASK_SIMPLE(4) | IRQ_TYPE_LEVEL_LOW)>,
-					     <GIC_PPI 11 (GIC_CPU_MASK_SIMPLE(4) | IRQ_TYPE_LEVEL_LOW)>,
-					     <GIC_PPI 10 (GIC_CPU_MASK_SIMPLE(4) | IRQ_TYPE_LEVEL_LOW)>;
-			};
-
-			pmu {
-				compatible = "arm,cortex-a72-pmu";
-				interrupt-parent = <&pic>;
-				interrupts = <17>;
-			};
-
-			odmi: odmi@300000 {
-				compatible = "marvell,odmi-controller";
-				interrupt-controller;
-				msi-controller;
-				marvell,odmi-frames = <4>;
-				reg = <0x300000 0x4000>,
-				      <0x304000 0x4000>,
-				      <0x308000 0x4000>,
-				      <0x30C000 0x4000>;
-				marvell,spi-base = <128>, <136>, <144>, <152>;
-			};
-
-			gicp: gicp@3f0040 {
-				compatible = "marvell,ap806-gicp";
-				reg = <0x3f0040 0x10>;
-				marvell,spi-ranges = <64 64>, <288 64>;
-				msi-controller;
-			};
-
-			pic: interrupt-controller@3f0100 {
-				compatible = "marvell,armada-8k-pic";
-				reg = <0x3f0100 0x10>;
-				#interrupt-cells = <1>;
-				interrupt-controller;
-				interrupts = <GIC_PPI 15 IRQ_TYPE_LEVEL_HIGH>;
-			};
-
-			xor@400000 {
-				compatible = "marvell,armada-7k-xor", "marvell,xor-v2";
-				reg = <0x400000 0x1000>,
-				      <0x410000 0x1000>;
-				msi-parent = <&gic_v2m0>;
-				clocks = <&ap_clk 3>;
-				dma-coherent;
-			};
-
-			xor@420000 {
-				compatible = "marvell,armada-7k-xor", "marvell,xor-v2";
-				reg = <0x420000 0x1000>,
-				      <0x430000 0x1000>;
-				msi-parent = <&gic_v2m0>;
-				clocks = <&ap_clk 3>;
-				dma-coherent;
-			};
-
-			xor@440000 {
-				compatible = "marvell,armada-7k-xor", "marvell,xor-v2";
-				reg = <0x440000 0x1000>,
-				      <0x450000 0x1000>;
-				msi-parent = <&gic_v2m0>;
-				clocks = <&ap_clk 3>;
-				dma-coherent;
-			};
-
-			xor@460000 {
-				compatible = "marvell,armada-7k-xor", "marvell,xor-v2";
-				reg = <0x460000 0x1000>,
-				      <0x470000 0x1000>;
-				msi-parent = <&gic_v2m0>;
-				clocks = <&ap_clk 3>;
-				dma-coherent;
-			};
-
-			spi0: spi@510600 {
-				compatible = "marvell,armada-380-spi";
-				reg = <0x510600 0x50>;
-				#address-cells = <1>;
-				#size-cells = <0>;
-				interrupts = <GIC_SPI 21 IRQ_TYPE_LEVEL_HIGH>;
-				clocks = <&ap_clk 3>;
-				status = "disabled";
-			};
-
-			i2c0: i2c@511000 {
-				compatible = "marvell,mv78230-i2c";
-				reg = <0x511000 0x20>;
-				#address-cells = <1>;
-				#size-cells = <0>;
-				interrupts = <GIC_SPI 20 IRQ_TYPE_LEVEL_HIGH>;
-				timeout-ms = <1000>;
-				clocks = <&ap_clk 3>;
-				status = "disabled";
-			};
-
-			uart0: serial@512000 {
-				compatible = "snps,dw-apb-uart";
-				reg = <0x512000 0x100>;
-				reg-shift = <2>;
-				interrupts = <GIC_SPI 19 IRQ_TYPE_LEVEL_HIGH>;
-				reg-io-width = <1>;
-				clocks = <&ap_clk 3>;
-				status = "disabled";
-			};
-
-			uart1: serial@512100 {
-				compatible = "snps,dw-apb-uart";
-				reg = <0x512100 0x100>;
-				reg-shift = <2>;
-				interrupts = <GIC_SPI 29 IRQ_TYPE_LEVEL_HIGH>;
-				reg-io-width = <1>;
-				clocks = <&ap_clk 3>;
-				status = "disabled";
-
-			};
-
-			watchdog: watchdog@610000 {
-				compatible = "arm,sbsa-gwdt";
-				reg = <0x610000 0x1000>, <0x600000 0x1000>;
-				interrupts = <GIC_SPI 2 IRQ_TYPE_LEVEL_HIGH>;
-			};
-
-			ap_sdhci0: sdhci@6e0000 {
-				compatible = "marvell,armada-ap806-sdhci";
-				reg = <0x6e0000 0x300>;
-				interrupts = <GIC_SPI 16 IRQ_TYPE_LEVEL_HIGH>;
-				clock-names = "core";
-				clocks = <&ap_clk 4>;
-				dma-coherent;
-				marvell,xenon-phy-slow-mode;
-				status = "disabled";
-			};
-
-			ap_syscon: system-controller@6f4000 {
-				compatible = "syscon", "simple-mfd";
-				reg = <0x6f4000 0x2000>;
-
+			ap_syscon0: system-controller@6f4000 {
 				ap_clk: clock {
 					compatible = "marvell,ap806-clock";
 					#clock-cells = <1>;
 				};
-
-				ap_pinctrl: pinctrl {
-					compatible = "marvell,ap806-pinctrl";
-
-					uart0_pins: uart0-pins {
-						marvell,pins = "mpp11", "mpp19";
-						marvell,function = "uart0";
-					};
-				};
-
-				ap_gpio: gpio@1040 {
-					compatible = "marvell,armada-8k-gpio";
-					offset = <0x1040>;
-					ngpios = <20>;
-					gpio-controller;
-					#gpio-cells = <2>;
-					gpio-ranges = <&ap_pinctrl 0 0 20>;
-				};
-			};
-
-			ap_thermal: thermal@6f808c {
-				compatible = "marvell,armada-ap806-thermal";
-				reg = <0x6f808c 0x4>,
-				      <0x6f8084 0x8>;
 			};
 		};
 	};
diff --git a/arch/arm64/boot/dts/marvell/armada-ap807-quad.dtsi b/arch/arm64/boot/dts/marvell/armada-ap807-quad.dtsi
new file mode 100644
index 000000000000..1ec2837931a0
--- /dev/null
+++ b/arch/arm64/boot/dts/marvell/armada-ap807-quad.dtsi
@@ -0,0 +1,270 @@
+/*
+ * Copyright (C) 2018 Marvell Technology Group Ltd.
+ *
+ * This file is dual-licensed: you can use it either under the terms
+ * of the GPLv2 or the X11 license, at your option. Note that this dual
+ * licensing only applies to this file, and not this project as a
+ * whole.
+ *
+ *  a) This library is free software; you can redistribute it and/or
+ *     modify it under the terms of the GNU General Public License as
+ *     published by the Free Software Foundation; either version 2 of the
+ *     License, or (at your option) any later version.
+ *
+ *     This library is distributed in the hope that it will be useful,
+ *     but WITHOUT ANY WARRANTY; without even the implied warranty of
+ *     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ *     GNU General Public License for more details.
+ *
+ * Or, alternatively,
+ *
+ *  b) Permission is hereby granted, free of charge, to any person
+ *     obtaining a copy of this software and associated documentation
+ *     files (the "Software"), to deal in the Software without
+ *     restriction, including without limitation the rights to use,
+ *     copy, modify, merge, publish, distribute, sublicense, and/or
+ *     sell copies of the Software, and to permit persons to whom the
+ *     Software is furnished to do so, subject to the following
+ *     conditions:
+ *
+ *     The above copyright notice and this permission notice shall be
+ *     included in all copies or substantial portions of the Software.
+ *
+ *     THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ *     EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES
+ *     OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ *     NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT
+ *     HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,
+ *     WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+ *     FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
+ *     OTHER DEALINGS IN THE SOFTWARE.
+ */
+
+/*
+ * Device Tree file for Marvell Armada AP807.
+ */
+
+#include "armada-ap807.dtsi"
+
+/ {
+	model = "Marvell Armada AP807 Quad";
+	compatible = "marvell,armada-ap807-quad", "marvell,armada-ap807";
+
+	cpus {
+		#address-cells = <1>;
+		#size-cells = <0>;
+
+		cpu0: cpu@0 {
+			device_type = "cpu";
+			compatible = "arm,cortex-a72", "arm,armv8";
+			reg = <0x000>;
+			enable-method = "psci";
+			#cooling-cells = <2>;
+			clocks = <&cpu_clk 0>;
+			cpu-idle-states = <&CPU_SLEEP_0>;
+			i-cache-size = <0xc000>;
+			i-cache-line-size = <64>;
+			i-cache-sets = <256>;
+			d-cache-size = <0x8000>;
+			d-cache-line-size = <64>;
+			d-cache-sets = <256>;
+			next-level-cache = <&l2_0>;
+		};
+		cpu1: cpu@1 {
+			device_type = "cpu";
+			compatible = "arm,cortex-a72", "arm,armv8";
+			reg = <0x001>;
+			enable-method = "psci";
+			#cooling-cells = <2>;
+			clocks = <&cpu_clk 0>;
+			cpu-idle-states = <&CPU_SLEEP_0>;
+			i-cache-size = <0xc000>;
+			i-cache-line-size = <64>;
+			i-cache-sets = <256>;
+			d-cache-size = <0x8000>;
+			d-cache-line-size = <64>;
+			d-cache-sets = <256>;
+			next-level-cache = <&l2_0>;
+		};
+		cpu2: cpu@100 {
+			device_type = "cpu";
+			compatible = "arm,cortex-a72", "arm,armv8";
+			reg = <0x100>;
+			enable-method = "psci";
+			#cooling-cells = <2>;
+			clocks = <&cpu_clk 1>;
+			cpu-idle-states = <&CPU_SLEEP_0>;
+			i-cache-size = <0xc000>;
+			i-cache-line-size = <64>;
+			i-cache-sets = <256>;
+			d-cache-size = <0x8000>;
+			d-cache-line-size = <64>;
+			d-cache-sets = <256>;
+			next-level-cache = <&l2_1>;
+		};
+		cpu3: cpu@101 {
+			device_type = "cpu";
+			compatible = "arm,cortex-a72", "arm,armv8";
+			reg = <0x101>;
+			enable-method = "psci";
+			#cooling-cells = <2>;
+			clocks = <&cpu_clk 1>;
+			cpu-idle-states = <&CPU_SLEEP_0>;
+			i-cache-size = <0xc000>;
+			i-cache-line-size = <64>;
+			i-cache-sets = <256>;
+			d-cache-size = <0x8000>;
+			d-cache-line-size = <64>;
+			d-cache-sets = <256>;
+			next-level-cache = <&l2_1>;
+		};
+
+		l2_0: l2-cache0 {
+			compatible = "cache";
+			cache-size = <0x80000>;
+			cache-line-size = <64>;
+			cache-sets = <512>;
+		};
+
+		l2_1: l2-cache1 {
+			compatible = "cache";
+			cache-size = <0x80000>;
+			cache-line-size = <64>;
+			cache-sets = <512>;
+		};
+	};
+
+	thermal-zones {
+		ap_thermal_cpu0: ap-thermal-cpu0 {
+			polling-delay-passive = <1000>;
+			polling-delay = <1000>;
+
+			thermal-sensors = <&ap_thermal 1>;
+
+			trips {
+				cpu0_hot: cpu0-hot {
+					temperature = <85000>;
+					hysteresis = <2000>;
+					type = "passive";
+				};
+				cpu0_emerg: cpu0-emerg {
+					temperature = <95000>;
+					hysteresis = <2000>;
+					type = "passive";
+				};
+			};
+
+			cooling-maps {
+				map0_hot: map0-hot {
+					trip = <&cpu0_hot>;
+					cooling-device = <&cpu0 1 2>,
+						<&cpu1 1 2>;
+				};
+				map0_emerg: map0-ermerg {
+					trip = <&cpu0_emerg>;
+					cooling-device = <&cpu0 3 3>,
+						<&cpu1 3 3>;
+				};
+			};
+		};
+
+		ap_thermal_cpu1: ap-thermal-cpu1 {
+			polling-delay-passive = <1000>;
+			polling-delay = <1000>;
+
+			thermal-sensors = <&ap_thermal 2>;
+
+			trips {
+				cpu1_hot: cpu1-hot {
+					temperature = <85000>;
+					hysteresis = <2000>;
+					type = "passive";
+				};
+				cpu1_emerg: cpu1-emerg {
+					temperature = <95000>;
+					hysteresis = <2000>;
+					type = "passive";
+				};
+			};
+
+			cooling-maps {
+				map1_hot: map1-hot {
+					trip = <&cpu1_hot>;
+					cooling-device = <&cpu0 1 2>,
+						<&cpu1 1 2>;
+				};
+				map1_emerg: map1-emerg {
+					trip = <&cpu1_emerg>;
+					cooling-device = <&cpu0 3 3>,
+						<&cpu1 3 3>;
+				};
+			};
+		};
+
+		ap_thermal_cpu2: ap-thermal-cpu2 {
+			polling-delay-passive = <1000>;
+			polling-delay = <1000>;
+
+			thermal-sensors = <&ap_thermal 3>;
+
+			trips {
+				cpu2_hot: cpu2-hot {
+					temperature = <85000>;
+					hysteresis = <2000>;
+					type = "passive";
+				};
+				cpu2_emerg: cpu2-emerg {
+					temperature = <95000>;
+					hysteresis = <2000>;
+					type = "passive";
+				};
+			};
+
+			cooling-maps {
+				map2_hot: map2-hot {
+					trip = <&cpu2_hot>;
+					cooling-device = <&cpu2 1 2>,
+						<&cpu3 1 2>;
+				};
+				map2_emerg: map2-emerg {
+					trip = <&cpu2_emerg>;
+					cooling-device = <&cpu2 3 3>,
+						<&cpu3 3 3>;
+				};
+			};
+		};
+
+		ap_thermal_cpu3: ap-thermal-cpu3 {
+			polling-delay-passive = <1000>;
+			polling-delay = <1000>;
+
+			thermal-sensors = <&ap_thermal 4>;
+
+			trips {
+				cpu3_hot: cpu3-hot {
+					temperature = <85000>;
+					hysteresis = <2000>;
+					type = "passive";
+				};
+				cpu3_emerg: cpu3-emerg {
+					temperature = <95000>;
+					hysteresis = <2000>;
+					type = "passive";
+				};
+			};
+
+			cooling-maps {
+				map3_hot: map3-bhot {
+					trip = <&cpu3_hot>;
+					cooling-device = <&cpu2 1 2>,
+						<&cpu3 1 2>;
+				};
+				map3_emerg: map3-emerg {
+					trip = <&cpu3_emerg>;
+					cooling-device = <&cpu2 3 3>,
+						<&cpu3 3 3>;
+				};
+			};
+		};
+	};
+};
diff --git a/arch/arm64/boot/dts/marvell/armada-ap807.dtsi b/arch/arm64/boot/dts/marvell/armada-ap807.dtsi
new file mode 100755
index 000000000000..74223b5b2123
--- /dev/null
+++ b/arch/arm64/boot/dts/marvell/armada-ap807.dtsi
@@ -0,0 +1,75 @@
+/*
+ * Copyright (C) 2018 Marvell Technology Group Ltd.
+ *
+ * This file is dual-licensed: you can use it either under the terms
+ * of the GPLv2 or the X11 license, at your option. Note that this dual
+ * licensing only applies to this file, and not this project as a
+ * whole.
+ *
+ *  a) This library is free software; you can redistribute it and/or
+ *     modify it under the terms of the GNU General Public License as
+ *     published by the Free Software Foundation; either version 2 of the
+ *     License, or (at your option) any later version.
+ *
+ *     This library is distributed in the hope that it will be useful,
+ *     but WITHOUT ANY WARRANTY; without even the implied warranty of
+ *     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ *     GNU General Public License for more details.
+ *
+ * Or, alternatively,
+ *
+ *  b) Permission is hereby granted, free of charge, to any person
+ *     obtaining a copy of this software and associated documentation
+ *     files (the "Software"), to deal in the Software without
+ *     restriction, including without limitation the rights to use,
+ *     copy, modify, merge, publish, distribute, sublicense, and/or
+ *     sell copies of the Software, and to permit persons to whom the
+ *     Software is furnished to do so, subject to the following
+ *     conditions:
+ *
+ *     The above copyright notice and this permission notice shall be
+ *     included in all copies or substantial portions of the Software.
+ *
+ *     THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ *     EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES
+ *     OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ *     NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT
+ *     HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,
+ *     WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+ *     FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
+ *     OTHER DEALINGS IN THE SOFTWARE.
+ */
+
+/*
+ * Device Tree file for Marvell Armada AP807.
+ */
+
+#include <dt-bindings/interrupt-controller/arm-gic.h>
+#define AP_NAME		ap807
+#include "armada-ap80x.dtsi"
+
+/ {
+	model = "Marvell Armada AP807";
+	AP_NAME {
+		config-space@f0000000 {
+			ap_syscon1:system-controller@6f8000 {
+				cpu_clk: clock-cpu {
+					compatible = "marvell,ap807-cpu-clock";
+					clocks = <&ap_clk 0>, <&ap_clk 1>;
+					#clock-cells = <1>;
+				};
+			};
+
+			ap_syscon0: system-controller@6f4000 {
+				ap_clk: clock {
+					compatible = "marvell,ap807-clock";
+					#clock-cells = <1>;
+				};
+			};
+		};
+	};
+};
+
+&ap_sdhci0 {
+	compatible = "marvell,armada-ap807-sdhci";
+};
diff --git a/arch/arm64/boot/dts/marvell/armada-ap80x.dtsi b/arch/arm64/boot/dts/marvell/armada-ap80x.dtsi
new file mode 100644
index 000000000000..b0469d6e6a2a
--- /dev/null
+++ b/arch/arm64/boot/dts/marvell/armada-ap80x.dtsi
@@ -0,0 +1,537 @@
+/*
+ * Copyright (C) 2018 Marvell Technology Group Ltd.
+ *
+ * This file is dual-licensed: you can use it either under the terms
+ * of the GPLv2 or the X11 license, at your option. Note that this dual
+ * licensing only applies to this file, and not this project as a
+ * whole.
+ *
+ *  a) This library is free software; you can redistribute it and/or
+ *     modify it under the terms of the GNU General Public License as
+ *     published by the Free Software Foundation; either version 2 of the
+ *     License, or (at your option) any later version.
+ *
+ *     This library is distributed in the hope that it will be useful,
+ *     but WITHOUT ANY WARRANTY; without even the implied warranty of
+ *     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ *     GNU General Public License for more details.
+ *
+ * Or, alternatively,
+ *
+ *  b) Permission is hereby granted, free of charge, to any person
+ *     obtaining a copy of this software and associated documentation
+ *     files (the "Software"), to deal in the Software without
+ *     restriction, including without limitation the rights to use,
+ *     copy, modify, merge, publish, distribute, sublicense, and/or
+ *     sell copies of the Software, and to permit persons to whom the
+ *     Software is furnished to do so, subject to the following
+ *     conditions:
+ *
+ *     The above copyright notice and this permission notice shall be
+ *     included in all copies or substantial portions of the Software.
+ *
+ *     THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ *     EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES
+ *     OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ *     NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT
+ *     HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,
+ *     WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+ *     FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
+ *     OTHER DEALINGS IN THE SOFTWARE.
+ */
+
+/*
+ * Device Tree file for Marvell Armada AP806/AP807.
+ */
+
+#include <dt-bindings/interrupt-controller/arm-gic.h>
+
+/* GIC-v2m in this AP is the XOR MSI parent for
+ * CPs south-bridges connected to this AP
+ */
+#define XOR_MSI_PARENT(XOR_NUM) <&gic_v2m0>
+
+/dts-v1/;
+
+/ {
+	compatible = "marvell,armada-ap806";
+	#address-cells = <2>;
+	#size-cells = <2>;
+
+	aliases {
+		serial0 = &uart0;
+		serial1 = &uart1;
+		gpio0 = &ap_gpio;
+		spi0 = &spi0;
+	};
+
+	psci {
+		compatible = "arm,psci-0.2";
+		method = "smc";
+	};
+
+	cpus {
+		#address-cells = <1>;
+		#size-cells = <0>;
+
+		idle_states {
+			entry_method = "arm,pcsi";
+
+			CPU_SLEEP_0: cpu-sleep-0 {
+				compatible = "arm,idle-state";
+				local-timer-stop;
+				arm,psci-suspend-param = <0x0010000>;
+				entry-latency-us = <80>;
+				exit-latency-us  = <160>;
+				min-residency-us = <320>;
+			};
+
+			CLUSTER_SLEEP_0: cluster-sleep-0 {
+				compatible = "arm,idle-state";
+				local-timer-stop;
+				arm,psci-suspend-param = <0x1010000>;
+				entry-latency-us = <500>;
+				exit-latency-us = <1000>;
+				min-residency-us = <2500>;
+			};
+		};
+	};
+
+	reserved-memory {
+		#address-cells = <2>;
+		#size-cells = <2>;
+		ranges;
+
+		psci-area@4000000 {
+			reg = <0 0x4000000 0 0x200000>;
+			no-map;
+		};
+
+		tee@4400000 {
+			reg = <0 0x4400000 0 0x1000000>;
+			no-map;
+		};
+	};
+
+	AP_NAME {
+		#address-cells = <2>;
+		#size-cells = <2>;
+		compatible = "simple-bus";
+		interrupt-parent = <&gic>;
+		ranges;
+
+		config-space@f0000000 {
+			#address-cells = <1>;
+			#size-cells = <1>;
+			compatible = "simple-bus";
+			ranges = <0x0 0x0 0xf0000000 0x1000000>;
+
+			smmu: iommu@5000000 {
+				compatible = "marvell,ap806-smmu-500", "arm,mmu-500";
+				reg = <0x100000 0x100000>;
+				dma-coherent;
+				#iommu-cells = <1>;
+				#global-interrupts = <1>;
+				interrupts = <GIC_SPI 6 IRQ_TYPE_LEVEL_HIGH>,
+					     <GIC_SPI 6 IRQ_TYPE_LEVEL_HIGH>,
+					     <GIC_SPI 6 IRQ_TYPE_LEVEL_HIGH>,
+					     <GIC_SPI 6 IRQ_TYPE_LEVEL_HIGH>,
+					     <GIC_SPI 6 IRQ_TYPE_LEVEL_HIGH>,
+					     <GIC_SPI 6 IRQ_TYPE_LEVEL_HIGH>,
+					     <GIC_SPI 6 IRQ_TYPE_LEVEL_HIGH>,
+					     <GIC_SPI 6 IRQ_TYPE_LEVEL_HIGH>,
+					     <GIC_SPI 6 IRQ_TYPE_LEVEL_HIGH>;
+				status = "disabled";
+			};
+
+			gic: interrupt-controller@210000 {
+				compatible = "arm,gic-400";
+				#interrupt-cells = <3>;
+				#address-cells = <1>;
+				#size-cells = <1>;
+				ranges;
+				interrupt-controller;
+				interrupts = <GIC_PPI 9
+					      (GIC_CPU_MASK_SIMPLE(4) |
+					      IRQ_TYPE_LEVEL_HIGH)>;
+				reg = <0x210000 0x10000>,
+				      <0x220000 0x20000>,
+				      <0x240000 0x20000>,
+				      <0x260000 0x20000>;
+
+				gic_v2m0: v2m@280000 {
+					compatible = "arm,gic-v2m-frame";
+					msi-controller;
+					reg = <0x280000 0x1000>;
+					arm,msi-base-spi = <160>;
+					arm,msi-num-spis = <32>;
+				};
+				gic_v2m1: v2m@290000 {
+					compatible = "arm,gic-v2m-frame";
+					msi-controller;
+					reg = <0x290000 0x1000>;
+					arm,msi-base-spi = <192>;
+					arm,msi-num-spis = <32>;
+				};
+				gic_v2m2: v2m@2a0000 {
+					compatible = "arm,gic-v2m-frame";
+					msi-controller;
+					reg = <0x2a0000 0x1000>;
+					arm,msi-base-spi = <224>;
+					arm,msi-num-spis = <32>;
+				};
+				gic_v2m3: v2m@2b0000 {
+					compatible = "arm,gic-v2m-frame";
+					msi-controller;
+					reg = <0x2b0000 0x1000>;
+					arm,msi-base-spi = <256>;
+					arm,msi-num-spis = <32>;
+				};
+			};
+
+			timer {
+				compatible = "arm,armv8-timer";
+				interrupts = <GIC_PPI 13
+					     (GIC_CPU_MASK_SIMPLE(4) |
+					      IRQ_TYPE_LEVEL_LOW)>,
+					     <GIC_PPI 14
+					     (GIC_CPU_MASK_SIMPLE(4) |
+					      IRQ_TYPE_LEVEL_LOW)>,
+					     <GIC_PPI 11
+					     (GIC_CPU_MASK_SIMPLE(4) |
+					      IRQ_TYPE_LEVEL_LOW)>,
+					     <GIC_PPI 10
+					     (GIC_CPU_MASK_SIMPLE(4) |
+					      IRQ_TYPE_LEVEL_LOW)>;
+			};
+
+			pmu {
+				compatible = "arm,cortex-a72-pmu";
+				interrupt-parent = <&pic>;
+				interrupts = <17>;
+			};
+
+			axim-ddr-rd@840000 {
+				compatible = "marvell,coresight-axim",
+					     "arm,primecell";
+				reg = <0x840000 0x1000>;
+				clocks = <&ap_clk 3>, <&ap_clk 5>;
+				clock-names = "apb_pclk", "hclk";
+				bus-width = <40>;
+				port@0 { };
+			};
+
+			axim-ddr-wr@841000 {
+				compatible = "marvell,coresight-axim",
+					     "arm,primecell";
+				reg = <0x841000 0x1000>;
+				clocks = <&ap_clk 3>, <&ap_clk 5>;
+				clock-names = "apb_pclk", "hclk";
+				bus-width = <40>;
+				port@0 { };
+			};
+
+			axim-sb-rd@848000 {
+				compatible = "marvell,coresight-axim",
+					     "arm,primecell";
+				reg = <0x848000 0x1000>;
+				clocks = <&ap_clk 3>, <&ap_clk 5>;
+				clock-names = "apb_pclk", "hclk";
+				bus-width = <40>;
+				port@0 { };
+			};
+
+			axim-sb-wr@849000 {
+				compatible = "marvell,coresight-axim",
+					     "arm,primecell";
+				reg = <0x849000 0x1000>;
+				clocks = <&ap_clk 3>, <&ap_clk 5>;
+				clock-names = "apb_pclk", "hclk";
+				bus-width = <40>;
+				port@0 { };
+			};
+
+
+			odmi: odmi@300000 {
+				compatible = "marvell,odmi-controller";
+				interrupt-controller;
+				msi-controller;
+				marvell,odmi-frames = <4>;
+				reg = <0x300000 0x4000>,
+				      <0x304000 0x4000>,
+				      <0x308000 0x4000>,
+				      <0x30C000 0x4000>;
+				marvell,spi-base = <128>, <136>, <144>, <152>;
+			};
+
+			gicp: gicp@3f0040 {
+				compatible = "marvell,ap806-gicp";
+				reg = <0x3f0040 0x10>;
+				marvell,spi-ranges = <64 64>, <288 64>;
+				msi-controller;
+			};
+
+			pic: interrupt-controller@3f0100 {
+				compatible = "marvell,armada-8k-pic";
+				reg = <0x3f0100 0x10>;
+				#interrupt-cells = <1>;
+				interrupt-controller;
+				interrupts = <GIC_PPI 15 IRQ_TYPE_LEVEL_HIGH>;
+			};
+
+			sei: interrupt-controller@3f0200 {
+				compatible = "marvell,ap806-sei";
+				reg = <0x3f0200 0x40>;
+				interrupts = <GIC_SPI 0 IRQ_TYPE_LEVEL_HIGH>;
+				#interrupt-cells = <1>;
+				interrupt-controller;
+				msi-controller;
+			};
+
+			xor0: xor@400000 {
+				compatible = "marvell,armada-7k-xor",
+					     "marvell,xor-v2";
+				reg = <0x400000 0x1000>,
+				      <0x410000 0x1000>;
+				msi-parent = <&gic_v2m0>;
+				clocks = <&ap_clk 3>;
+				dma-coherent;
+			};
+
+			xor1: xor@420000 {
+				compatible = "marvell,armada-7k-xor",
+					     "marvell,xor-v2";
+				reg = <0x420000 0x1000>,
+				      <0x430000 0x1000>;
+				msi-parent = <&gic_v2m0>;
+				clocks = <&ap_clk 3>;
+				dma-coherent;
+			};
+
+			xor2: xor@440000 {
+				compatible = "marvell,armada-7k-xor",
+					     "marvell,xor-v2";
+				reg = <0x440000 0x1000>,
+				      <0x450000 0x1000>;
+				msi-parent = <&gic_v2m0>;
+				clocks = <&ap_clk 3>;
+				dma-coherent;
+			};
+
+			xor3: xor@460000 {
+				compatible = "marvell,armada-7k-xor",
+					     "marvell,xor-v2";
+				reg = <0x460000 0x1000>,
+				      <0x470000 0x1000>;
+				msi-parent = <&gic_v2m0>;
+				clocks = <&ap_clk 3>;
+				dma-coherent;
+			};
+
+			dma_xor0: dma-xor@400000 {
+				compatible = "marvell,mv-xor-v2-copy-offload";
+				reg = <0x400000 0x1000>,
+				      <0x410000 0x1000>;
+				msi-parent = <&gic_v2m0>;
+				clocks = <&ap_clk 3>;
+				dma-coherent;
+				iommus = <&smmu 0x1>;
+				status = "disabled";
+			};
+
+			dma_xor1: dma-xor@420000 {
+				compatible = "marvell,mv-xor-v2-copy-offload";
+				reg = <0x420000 0x1000>,
+				      <0x430000 0x1000>;
+				msi-parent = <&gic_v2m0>;
+				clocks = <&ap_clk 3>;
+				dma-coherent;
+				iommus = <&smmu 0x2>;
+				status = "disabled";
+			};
+
+			uio_xor0: uio-xor0 {
+				compatible = "marvell,uio-xor-v2";
+				xor_access = <&xor0>;
+			};
+
+			uio_xor1: uio-xor1 {
+				compatible = "marvell,uio-xor-v2";
+				xor_access = <&xor1>;
+			};
+
+			uio_xor2: uio-xor2 {
+				compatible = "marvell,uio-xor-v2";
+				xor_access = <&xor2>;
+			};
+
+			uio_xor3: uio-xor3 {
+				compatible = "marvell,uio-xor-v2";
+				xor_access = <&xor3>;
+			};
+
+			spi0: spi@510600 {
+				compatible = "marvell,armada-380-spi";
+				reg = <0x510600 0x50>;
+				#address-cells = <1>;
+				#size-cells = <0>;
+				interrupts = <GIC_SPI 21 IRQ_TYPE_LEVEL_HIGH>;
+				clocks = <&ap_clk 3>;
+				status = "disabled";
+			};
+
+			i2c0: i2c@511000 {
+				compatible = "marvell,mv78230-i2c";
+				reg = <0x511000 0x20>;
+				#address-cells = <1>;
+				#size-cells = <0>;
+				interrupts = <GIC_SPI 20 IRQ_TYPE_LEVEL_HIGH>;
+				timeout-ms = <1000>;
+				clocks = <&ap_clk 3>;
+				status = "disabled";
+			};
+
+			uart0: serial@512000 {
+				compatible = "snps,dw-apb-uart";
+				reg = <0x512000 0x100>;
+				reg-shift = <2>;
+				interrupts = <GIC_SPI 19 IRQ_TYPE_LEVEL_HIGH>;
+				reg-io-width = <1>;
+				clocks = <&ap_clk 3>;
+				status = "disabled";
+			};
+
+			uart1: serial@512100 {
+				compatible = "snps,dw-apb-uart";
+				reg = <0x512100 0x100>;
+				reg-shift = <2>;
+				interrupts = <GIC_SPI 29 IRQ_TYPE_LEVEL_HIGH>;
+				reg-io-width = <1>;
+				clocks = <&ap_clk 3>;
+				status = "disabled";
+
+			};
+
+			watchdog: watchdog@610000 {
+				compatible = "arm,sbsa-gwdt";
+				reg = <0x610000 0x1000>, <0x600000 0x1000>;
+				interrupts = <GIC_SPI 2 IRQ_TYPE_LEVEL_HIGH>;
+			};
+
+			ap_sdhci0: sdhci@6e0000 {
+				compatible = "marvell,armada-ap806-sdhci";
+				reg = <0x6e0000 0x300>;
+				interrupts = <GIC_SPI 16 IRQ_TYPE_LEVEL_HIGH>;
+				clock-names = "core";
+				clocks = <&ap_clk 4>;
+				dma-coherent;
+				iommus = <&smmu 0x5>;
+				status = "disabled";
+			};
+
+			ap_syscon0: system-controller@6f4000 {
+				compatible = "syscon", "simple-mfd";
+				reg = <0x6f4000 0x2000>;
+
+				ap_pinctrl: pinctrl {
+					compatible = "marvell,ap806-pinctrl";
+
+					uart0_pins: uart0-pins {
+						marvell,pins = "mpp11", "mpp19";
+						marvell,function = "uart0";
+					};
+				};
+
+				ap_gpio: gpio@1040 {
+					compatible = "marvell,armada-8k-gpio";
+					offset = <0x1040>;
+					ngpios = <20>;
+					gpio-controller;
+					#gpio-cells = <2>;
+					gpio-ranges = <&ap_pinctrl 0 0 20>;
+				};
+			};
+
+			ap_syscon1:system-controller@6f8000 {
+				compatible = "syscon", "simple-mfd";
+				reg = <0x6f8000 0x1000>;
+				#address-cells = <1>;
+				#size-cells = <1>;
+
+				ap_thermal: thermal-sensor@80 {
+					compatible = "marvell,armada-ap806-thermal";
+					reg = <0x80 0x10>;
+					interrupt-parent = <&sei>;
+					interrupts = <18>;
+					#thermal-sensor-cells = <1>;
+				};
+			};
+
+			edac_mc: edac-mc@20000 {
+				compatible = "marvell,armada-ap80x-edac-mc";
+				reg = <0x20000 0x1000>;
+				interrupts = <GIC_SPI 5 IRQ_TYPE_LEVEL_HIGH>;
+				status = "disabled";
+			};
+
+			revision-info@610fcc {
+				compatible = "marvell,ap806-rev-info";
+				reg = <0x610fcc 0x4>;
+			};
+
+			musdk_cma {
+				compatible = "marvell,musdk-cma";
+				dma-coherent;
+			};
+
+			agnic-plat {
+				compatible = "marvell,armada-giu-nic";
+				reg = <0x6F00A0 0x8>;
+				msi-parent = <&gic_v2m0>;
+				dma-coherent;
+			};
+
+			uio_agnic_0 {
+				compatible = "marvell,armada-giu-nic-uio";
+				reg = <0x6F0000 0x1000
+				       0x280000 0x1000>;
+				reg-names = "agnic_regs", "msi_regs";
+			};
+		};
+	};
+
+
+	/*
+	 * The thermal IP features one internal sensor plus, if applicable, one
+	 * remote channel wired to one sensor per CPU.
+	 *
+	 * Only one thermal zone per AP/CP may trigger interrupts at a time, the
+	 * first one that will have a critical trip point will be chosen.
+	 */
+	thermal-zones {
+		ap_thermal_ic: ap-thermal-ic {
+			polling-delay-passive = <0>; /* Interrupt driven */
+			polling-delay = <0>; /* Interrupt driven */
+
+			thermal-sensors = <&ap_thermal 0>;
+
+			trips {
+				ap_crit: ap-crit {
+					temperature = <100000>; /* mC degrees */
+					hysteresis = <2000>; /* mC degrees */
+					type = "critical";
+				};
+			};
+
+			cooling-maps { };
+		};
+	};
+
+	firmware {
+		optee {
+			compatible = "linaro,optee-tz";
+			method = "smc";
+			status = "okay";
+		 };
+	};
+};
diff --git a/arch/arm64/boot/dts/marvell/armada-common.dtsi b/arch/arm64/boot/dts/marvell/armada-common.dtsi
old mode 100644
new mode 100755
index d5e8aedec188..cefb26d2f7b7
--- a/arch/arm64/boot/dts/marvell/armada-common.dtsi
+++ b/arch/arm64/boot/dts/marvell/armada-common.dtsi
@@ -6,5 +6,7 @@
 /* Common definitions used by Armada 7K/8K DTs */
 #define PASTER(x, y) x ## y
 #define EVALUATOR(x, y) PASTER(x, y)
+#define CP110_NAME EVALUATOR(cp, CP110_NUM)
 #define CP110_LABEL(name) EVALUATOR(CP110_NAME, EVALUATOR(_, name))
-#define ADDRESSIFY(addr) EVALUATOR(0x, addr)
+#define AP810_NAME EVALUATOR(ap, AP_NUM)
+#define AP810_LABEL(name) EVALUATOR(AP810_NAME, EVALUATOR(_, name))
diff --git a/arch/arm64/boot/dts/marvell/armada-cp110.dtsi b/arch/arm64/boot/dts/marvell/armada-cp110.dtsi
old mode 100644
new mode 100755
index 571bede7bdf6..8801226aedf0
--- a/arch/arm64/boot/dts/marvell/armada-cp110.dtsi
+++ b/arch/arm64/boot/dts/marvell/armada-cp110.dtsi
@@ -6,12 +6,24 @@
  */
 
 #include <dt-bindings/interrupt-controller/mvebu-icu.h>
+#include <dt-bindings/phy/phy-utmi-mvebu.h>
 
 #include "armada-common.dtsi"
 
-#define CP110_PCIEx_IO_BASE(iface)	(CP110_PCIE_IO_BASE + (iface *  0x10000))
-#define CP110_PCIEx_MEM_BASE(iface)	(CP110_PCIE_MEM_BASE + (iface *  0x1000000))
-#define CP110_PCIEx_CONF_BASE(iface)	(CP110_PCIEx_MEM_BASE(iface) + 0xf00000)
+#define U64_TO_U32_H(addr)		(((addr) >> 32) & 0xffffffff)
+#define U64_TO_U32_L(addr)		((addr) & 0xffffffff)
+
+#define CP110_PCIEx_REG0_BASE(iface)	(CP110_BASE + 0x600000 + (iface) * 0x20000)
+#define CP110_PCIEx_REG1_BASE(iface)	(CP110_PCIEx_CPU_MEM_BASE(iface) + \
+					 CP110_PCIE_MEM_SIZE(iface))
+#define CP110_PCIE_EP_REG_BASE(iface)	(CP110_BASE + 0x600000 + \
+					 (iface) * 0x4000)
+
+#define CP110_EIP197_INDEX		CP110_NUM
+#define CP110_TDM_INDEX			CP110_NUM
+#define CP110_SPI_BUS_ID(n)		((CP110_NUM * 2) + (n))
+#define CP110_PCIEx_MAC_RESET_BIT_MASK(n)	\
+					(0x1 << 11 + ((n + 2) % 3))
 
 / {
 	/*
@@ -28,11 +40,11 @@
 	interrupt-parent = <&CP110_LABEL(icu)>;
 	ranges;
 
-	config-space@CP110_BASE {
+	CP110_LABEL(config_space): config-space {
 		#address-cells = <1>;
 		#size-cells = <1>;
 		compatible = "simple-bus";
-		ranges = <0x0 0x0 ADDRESSIFY(CP110_BASE) 0x2000000>;
+		ranges = <0x0 U64_TO_U32_H(CP110_BASE) U64_TO_U32_L(CP110_BASE) 0x2000000>;
 
 		CP110_LABEL(ethernet): ethernet@0 {
 			compatible = "marvell,armada-7k-pp22";
@@ -46,15 +58,22 @@
 			status = "disabled";
 			dma-coherent;
 
+			cm3-mem = <&CP110_LABEL(cm3_sram)>;
+
 			CP110_LABEL(eth0): eth0 {
 				interrupts = <ICU_GRP_NSR 39 IRQ_TYPE_LEVEL_HIGH>,
 					<ICU_GRP_NSR 43 IRQ_TYPE_LEVEL_HIGH>,
 					<ICU_GRP_NSR 47 IRQ_TYPE_LEVEL_HIGH>,
 					<ICU_GRP_NSR 51 IRQ_TYPE_LEVEL_HIGH>,
 					<ICU_GRP_NSR 55 IRQ_TYPE_LEVEL_HIGH>,
+					<ICU_GRP_NSR 59 IRQ_TYPE_LEVEL_HIGH>,
+					<ICU_GRP_NSR 63 IRQ_TYPE_LEVEL_HIGH>,
+					<ICU_GRP_NSR 67 IRQ_TYPE_LEVEL_HIGH>,
+					<ICU_GRP_NSR 71 IRQ_TYPE_LEVEL_HIGH>,
 					<ICU_GRP_NSR 129 IRQ_TYPE_LEVEL_HIGH>;
-				interrupt-names = "tx-cpu0", "tx-cpu1", "tx-cpu2",
-					"tx-cpu3", "rx-shared", "link";
+				interrupt-names = "hif0", "hif1", "hif2",
+					"hif3", "hif4", "hif5", "hif6", "hif7",
+					"hif8", "link";
 				port-id = <0>;
 				gop-port-id = <0>;
 				status = "disabled";
@@ -66,9 +85,14 @@
 					<ICU_GRP_NSR 48 IRQ_TYPE_LEVEL_HIGH>,
 					<ICU_GRP_NSR 52 IRQ_TYPE_LEVEL_HIGH>,
 					<ICU_GRP_NSR 56 IRQ_TYPE_LEVEL_HIGH>,
+					<ICU_GRP_NSR 60 IRQ_TYPE_LEVEL_HIGH>,
+					<ICU_GRP_NSR 64 IRQ_TYPE_LEVEL_HIGH>,
+					<ICU_GRP_NSR 68 IRQ_TYPE_LEVEL_HIGH>,
+					<ICU_GRP_NSR 72 IRQ_TYPE_LEVEL_HIGH>,
 					<ICU_GRP_NSR 128 IRQ_TYPE_LEVEL_HIGH>;
-				interrupt-names = "tx-cpu0", "tx-cpu1", "tx-cpu2",
-					"tx-cpu3", "rx-shared", "link";
+				interrupt-names = "hif0", "hif1", "hif2",
+					"hif3", "hif4", "hif5", "hif6", "hif7",
+					"hif8", "link";
 				port-id = <1>;
 				gop-port-id = <2>;
 				status = "disabled";
@@ -80,18 +104,122 @@
 					<ICU_GRP_NSR 49 IRQ_TYPE_LEVEL_HIGH>,
 					<ICU_GRP_NSR 53 IRQ_TYPE_LEVEL_HIGH>,
 					<ICU_GRP_NSR 57 IRQ_TYPE_LEVEL_HIGH>,
+					<ICU_GRP_NSR 61 IRQ_TYPE_LEVEL_HIGH>,
+					<ICU_GRP_NSR 65 IRQ_TYPE_LEVEL_HIGH>,
+					<ICU_GRP_NSR 69 IRQ_TYPE_LEVEL_HIGH>,
+					<ICU_GRP_NSR 73 IRQ_TYPE_LEVEL_HIGH>,
 					<ICU_GRP_NSR 127 IRQ_TYPE_LEVEL_HIGH>;
-				interrupt-names = "tx-cpu0", "tx-cpu1", "tx-cpu2",
-					"tx-cpu3", "rx-shared", "link";
+				interrupt-names = "hif0", "hif1", "hif2",
+					"hif3", "hif4", "hif5", "hif6", "hif7",
+					"hif8", "link";
 				port-id = <2>;
 				gop-port-id = <3>;
 				status = "disabled";
 			};
 		};
 
-		CP110_LABEL(comphy): phy@120000 {
+		CP110_LABEL(mvpp2x_gop): gop {
+			CP110_LABEL(mvpp2x_emac0): mac0 {
+				interrupts = <ICU_GRP_NSR 129 IRQ_TYPE_LEVEL_HIGH>;  /* Link IRQ */
+				port-id = <0>; /* gop_port_id */
+				status = "disabled";
+			};
+			CP110_LABEL(mvpp2x_emac2): mac2 {
+				interrupts = <ICU_GRP_NSR 128 IRQ_TYPE_LEVEL_HIGH>;  /* Link IRQ */
+				port-id = <2>; /* gop_port_id */
+				status = "disabled";
+			};
+			CP110_LABEL(mvpp2x_emac3): mac3 {
+				interrupts = <ICU_GRP_NSR 127 IRQ_TYPE_LEVEL_HIGH>;  /* Link IRQ */
+				port-id = <3>; /* gop_port_id */
+				status = "disabled";
+			};
+		};
+
+		CP110_LABEL(mvpp2x_ethernet): mvpp2x_ethernet@0 {
+			compatible = "marvell,mv-pp22";
+			reg = <0x000000 0x90000>,/* Packet Processor regs */
+			      <0x129000 0x0600>, /* XMIB regs */
+			      <0x12a000 0x200>,  /* LED regs */
+			      <0x12a200 0x200>,  /* SMI regs */
+			      <0x12a400 0x200>,  /* TAI regs */
+			      <0x12a600 0x200>,  /* XSMI regs */
+			      <0x12b000 0x1000>, /* MG Internal regs */
+			      <0x130000 0x6000>, /* MSPG regs */
+			      <0x130400 0x200>,  /* MSPG - XPCS regs */
+			      <0x130600 0x200>,  /* FCA - flow control regs*/
+			      <0x130e00 0x100>,  /* MSPG - GMAC regs */
+			      <0x130f00 0x100>,  /* MSPG - XLG MAC regs */
+			      <0x441100 0x100>,  /* RFU-1 Regs */
+			      <0x220000 0x800>;  /* CM3 SRAM */
+			reg-names = "pp", "xmib", "led", "smi", "tai", "xsmi",
+				    "mg", "mspg", "xpcs","fca", "gmac", "xlg",
+				    "rfu1", "cm3";
+			clocks = <&CP110_LABEL(clk) 1 3>, <&CP110_LABEL(clk) 1 9>,
+				 <&CP110_LABEL(clk) 1 5>, <&CP110_LABEL(clk) 1 6>,
+				 <&CP110_LABEL(clk) 1 18>;
+			clock-names = "pp_clk", "gop_clk",
+				      "mg_clk", "mg_core_clk", "gop_core_clk";
+			status = "disabled";
+			dma-coherent;
+
+			CP110_LABEL(mvpp2x_eth0): mvpp2x_eth0@010000 {
+				interrupts = <ICU_GRP_NSR 39 IRQ_TYPE_LEVEL_HIGH>,
+					     <ICU_GRP_NSR 43 IRQ_TYPE_LEVEL_HIGH>,
+					     <ICU_GRP_NSR 47 IRQ_TYPE_LEVEL_HIGH>,
+					     <ICU_GRP_NSR 51 IRQ_TYPE_LEVEL_HIGH>,
+					     <ICU_GRP_NSR 55 IRQ_TYPE_LEVEL_HIGH>,
+					     <ICU_GRP_NSR 59 IRQ_TYPE_LEVEL_HIGH>,
+					     <ICU_GRP_NSR 63 IRQ_TYPE_LEVEL_HIGH>,
+					     <ICU_GRP_NSR 67 IRQ_TYPE_LEVEL_HIGH>,
+					     <ICU_GRP_NSR 71 IRQ_TYPE_LEVEL_HIGH>;
+				port-id = <0>; /* pp2_port_id */
+				emac-data = <&CP110_LABEL(mvpp2x_emac0)>;
+				status = "disabled";
+			};
+
+			CP110_LABEL(mvpp2x_eth1): mvpp2x_eth1@020000 {
+				interrupts = <ICU_GRP_NSR 40 IRQ_TYPE_LEVEL_HIGH>,
+					     <ICU_GRP_NSR 44 IRQ_TYPE_LEVEL_HIGH>,
+					     <ICU_GRP_NSR 48 IRQ_TYPE_LEVEL_HIGH>,
+					     <ICU_GRP_NSR 52 IRQ_TYPE_LEVEL_HIGH>,
+					     <ICU_GRP_NSR 56 IRQ_TYPE_LEVEL_HIGH>,
+					     <ICU_GRP_NSR 60 IRQ_TYPE_LEVEL_HIGH>,
+					     <ICU_GRP_NSR 64 IRQ_TYPE_LEVEL_HIGH>,
+					     <ICU_GRP_NSR 68 IRQ_TYPE_LEVEL_HIGH>,
+					     <ICU_GRP_NSR 72 IRQ_TYPE_LEVEL_HIGH>;
+				port-id = <1>; /* pp2_port_id */
+				emac-data = <&CP110_LABEL(mvpp2x_emac2)>;
+				status = "disabled";
+			};
+
+			CP110_LABEL(mvpp2x_eth2): mvpp2x_eth2@030000 {
+				interrupts = <ICU_GRP_NSR 41 IRQ_TYPE_LEVEL_HIGH>,
+					     <ICU_GRP_NSR 45 IRQ_TYPE_LEVEL_HIGH>,
+					     <ICU_GRP_NSR 49 IRQ_TYPE_LEVEL_HIGH>,
+					     <ICU_GRP_NSR 53 IRQ_TYPE_LEVEL_HIGH>,
+					     <ICU_GRP_NSR 57 IRQ_TYPE_LEVEL_HIGH>,
+					     <ICU_GRP_NSR 61 IRQ_TYPE_LEVEL_HIGH>,
+					     <ICU_GRP_NSR 65 IRQ_TYPE_LEVEL_HIGH>,
+					     <ICU_GRP_NSR 69 IRQ_TYPE_LEVEL_HIGH>,
+					     <ICU_GRP_NSR 73 IRQ_TYPE_LEVEL_HIGH>;
+				port-id = <2>; /* pp2_port_id */
+				emac-data = <&CP110_LABEL(mvpp2x_emac3)>;
+				status = "disabled";
+			};
+		};
+
+		CP110_LABEL(uio_ethernet): EVALUATOR(uio_pp_, CP110_NUM)@0 {
+			compatible = "generic-uio";
+			reg = <0x0 0x90000>, <0x130000 0x6000>,
+			      <0x220000 0x1000>;
+			reg-names = "pp", "mspg", "cm3";
+		};
+
+		CP110_LABEL(comphy): phy@441000 {
 			compatible = "marvell,comphy-cp110";
-			reg = <0x120000 0x6000>;
+			reg = <0x441000 0xF4>, <0x120000 0x6000>;
+			reg-names = "comphy";
 			marvell,system-controller = <&CP110_LABEL(syscon0)>;
 			#address-cells = <1>;
 			#size-cells = <0>;
@@ -147,6 +275,18 @@
 			status = "disabled";
 		};
 
+		CP110_LABEL(mdio_uio): mdio_uio {
+			compatible = "marvell,mvmdio-uio";
+			mii-bus = <&CP110_LABEL(mdio)>;
+			status = "disabled";
+		};
+
+		CP110_LABEL(xmdio_uio): xmdio_uio {
+			compatible = "marvell,mvmdio-uio";
+			mii-bus = <&CP110_LABEL(xmdio)>;
+			status = "disabled";
+		};
+
 		CP110_LABEL(icu): interrupt-controller@1e0000 {
 			compatible = "marvell,cp110-icu";
 			reg = <0x1e0000 0x440>;
@@ -155,6 +295,14 @@
 			msi-parent = <&gicp>;
 		};
 
+		CP110_LABEL(cm3_sram): cm3@220000 {
+			compatible = "mmio-sram";
+			reg = <0x220000 0x800>;
+			#address-cells = <1>;
+			#size-cells = <1>;
+			ranges = <0 0x220000 0x800>;
+		};
+
 		CP110_LABEL(rtc): rtc@284000 {
 			compatible = "marvell,armada-8k-rtc";
 			reg = <0x284000 0x20>, <0x284080 0x24>;
@@ -162,6 +310,62 @@
 			interrupts = <ICU_GRP_NSR 77 IRQ_TYPE_LEVEL_HIGH>;
 		};
 
+		CP110_LABEL(axim_cp_rd): axim-cp-rd@3c5000 {
+			compatible = "marvell,coresight-axim", "arm,primecell";
+			reg = <0x3c5000 0x1000>;
+			clocks = <&CP110_LABEL(clk) 1 3>;
+			clock-names = "apb_pclk";
+			bus-width = <40>;
+			port@0 { };
+		};
+
+		CP110_LABEL(axim_cp_wr): axim-cp-wr@3c6000 {
+			compatible = "marvell,coresight-axim", "arm,primecell";
+			reg = <0x3c6000 0x1000>;
+			clocks = <&CP110_LABEL(clk) 1 3>;
+			clock-names = "apb_pclk";
+			bus-width = <40>;
+			port@0 { };
+		};
+
+		CP110_LABEL(axim_ppv2_rd): axim-ppv2-rd@3c0000 {
+			compatible = "marvell,coresight-axim", "arm,primecell";
+			reg = <0x3c0000 0x1000>;
+			clocks = <&CP110_LABEL(clk) 1 3>;
+			clock-names = "apb_pclk";
+			bus-width = <40>;
+			port@0 { };
+		};
+
+		CP110_LABEL(axim_ppv2_wr): axim-ppv2-wr@3c1000 {
+			compatible = "marvell,coresight-axim", "arm,primecell";
+			reg = <0x3c1000 0x1000>;
+			clocks = <&CP110_LABEL(clk) 1 3>;
+			clock-names = "apb_pclk";
+			bus-width = <40>;
+			port@0 { };
+		};
+
+		CP110_LABEL(axim_hb1_rd): axim-hb1-rd@3c8000 {
+			compatible = "marvell,coresight-axim", "arm,primecell";
+			reg = <0x3c8000 0x1000>;
+			clocks = <&CP110_LABEL(clk) 1 3>;
+			clock-names = "apb_pclk";
+			bus-width = <40>;
+			status = "disabled";
+			port@0 { };
+		};
+
+		CP110_LABEL(axim_hb1_wr): axim-hb1-wr@3c9000 {
+			compatible = "marvell,coresight-axim", "arm,primecell";
+			reg = <0x3c9000 0x1000>;
+			clocks = <&CP110_LABEL(clk) 1 3>;
+			clock-names = "apb_pclk";
+			bus-width = <40>;
+			status = "disabled";
+			port@0 { };
+		};
+
 		CP110_LABEL(thermal): thermal@400078 {
 			compatible = "marvell,armada-cp110-thermal";
 			reg = <0x400078 0x4>,
@@ -185,6 +389,7 @@
 				#gpio-cells = <2>;
 				gpio-ranges = <&CP110_LABEL(pinctrl) 0 0 32>;
 				interrupt-controller;
+				#interrupt-cells = <2>;
 				interrupts = <ICU_GRP_NSR 86 IRQ_TYPE_LEVEL_HIGH>,
 					<ICU_GRP_NSR 85 IRQ_TYPE_LEVEL_HIGH>,
 					<ICU_GRP_NSR 84 IRQ_TYPE_LEVEL_HIGH>,
@@ -200,6 +405,7 @@
 				#gpio-cells = <2>;
 				gpio-ranges = <&CP110_LABEL(pinctrl) 0 32 31>;
 				interrupt-controller;
+				#interrupt-cells = <2>;
 				interrupts = <ICU_GRP_NSR 82 IRQ_TYPE_LEVEL_HIGH>,
 					<ICU_GRP_NSR 81 IRQ_TYPE_LEVEL_HIGH>,
 					<ICU_GRP_NSR 80 IRQ_TYPE_LEVEL_HIGH>,
@@ -208,9 +414,32 @@
 			};
 		};
 
+		CP110_LABEL(utmi0): utmi@580000 {
+			compatible = "marvell,cp110-utmi-phy";
+			reg = <0x580000 0x1000>,
+			      <0x440420 0x4>,
+			      <0x440440 0x4>;
+			reg-names = "utmi", "usb-cfg-reg", "utmi-cfg-reg";
+			utmi-port = <UTMI_PHY_TO_USB3_HOST0>;
+			utmi-index = <0>;
+			#phy-cells = <0>;
+			status = "disabled";
+		};
+
+		CP110_LABEL(utmi1): utmi@581000 {
+			compatible = "marvell,cp110-utmi-phy";
+			reg = <0x581000 0x1000>,
+			      <0x440420 0x4>,
+			      <0x440444 0x4>;
+			reg-names = "utmi", "usb-cfg-reg", "utmi-cfg-reg";
+			utmi-port = <UTMI_PHY_TO_USB3_HOST1>;
+			utmi-index = <1>;
+			#phy-cells = <0>;
+			status = "disabled";
+		};
+
 		CP110_LABEL(usb3_0): usb3@500000 {
-			compatible = "marvell,armada-8k-xhci",
-			"generic-xhci";
+			compatible = "generic-xhci";
 			reg = <0x500000 0x4000>;
 			dma-coherent;
 			interrupts = <ICU_GRP_NSR 106 IRQ_TYPE_LEVEL_HIGH>;
@@ -221,8 +450,7 @@
 		};
 
 		CP110_LABEL(usb3_1): usb3@510000 {
-			compatible = "marvell,armada-8k-xhci",
-			"generic-xhci";
+			compatible = "generic-xhci";
 			reg = <0x510000 0x4000>;
 			dma-coherent;
 			interrupts = <ICU_GRP_NSR 105 IRQ_TYPE_LEVEL_HIGH>;
@@ -233,21 +461,31 @@
 		};
 
 		CP110_LABEL(sata0): sata@540000 {
-			compatible = "marvell,armada-8k-ahci",
-			"generic-ahci";
+			compatible = "generic-ahci";
 			reg = <0x540000 0x30000>;
 			dma-coherent;
 			interrupts = <ICU_GRP_NSR 107 IRQ_TYPE_LEVEL_HIGH>;
 			clocks = <&CP110_LABEL(clk) 1 15>,
 				 <&CP110_LABEL(clk) 1 16>;
 			status = "disabled";
+			#address-cells = <1>;
+			#size-cells = <0>;
+
+			sata-port@0 {
+				reg = <0>;
+				satus = "disabled";
+			};
+			sata-port@1 {
+				reg = <1>;
+				status = "disabled";
+			};
 		};
 
 		CP110_LABEL(xor0): xor@6a0000 {
 			compatible = "marvell,armada-7k-xor", "marvell,xor-v2";
 			reg = <0x6a0000 0x1000>, <0x6b0000 0x1000>;
 			dma-coherent;
-			msi-parent = <&gic_v2m0>;
+			msi-parent = XOR_MSI_PARENT(0);
 			clock-names = "core", "reg";
 			clocks = <&CP110_LABEL(clk) 1 8>,
 				 <&CP110_LABEL(clk) 1 14>;
@@ -257,17 +495,28 @@
 			compatible = "marvell,armada-7k-xor", "marvell,xor-v2";
 			reg = <0x6c0000 0x1000>, <0x6d0000 0x1000>;
 			dma-coherent;
-			msi-parent = <&gic_v2m0>;
+			msi-parent = XOR_MSI_PARENT(1);
 			clock-names = "core", "reg";
 			clocks = <&CP110_LABEL(clk) 1 7>,
 				 <&CP110_LABEL(clk) 1 14>;
 		};
 
+		CP110_LABEL(uio_xor0) {
+			compatible = "marvell,uio-xor-v2";
+			xor_access = <&CP110_LABEL(xor0)>;
+		};
+
+		CP110_LABEL(uio_xor1) {
+			compatible = "marvell,uio-xor-v2";
+			xor_access = <&CP110_LABEL(xor1)>;
+		};
+
 		CP110_LABEL(spi0): spi@700600 {
-			compatible = "marvell,armada-380-spi";
+			compatible = "marvell,armada-cp110-spi";
 			reg = <0x700600 0x50>;
 			#address-cells = <0x1>;
 			#size-cells = <0x0>;
+			cell-index = <CP110_SPI_BUS_ID(1)>;
 			clock-names = "core", "axi";
 			clocks = <&CP110_LABEL(clk) 1 21>,
 				 <&CP110_LABEL(clk) 1 17>;
@@ -275,10 +524,11 @@
 		};
 
 		CP110_LABEL(spi1): spi@700680 {
-			compatible = "marvell,armada-380-spi";
+			compatible = "marvell,armada-cp110-spi";
 			reg = <0x700680 0x50>;
 			#address-cells = <1>;
 			#size-cells = <0>;
+			cell-index = <CP110_SPI_BUS_ID(2)>;
 			clock-names = "core", "axi";
 			clocks = <&CP110_LABEL(clk) 1 21>,
 				 <&CP110_LABEL(clk) 1 17>;
@@ -291,9 +541,10 @@
 			#address-cells = <1>;
 			#size-cells = <0>;
 			interrupts = <ICU_GRP_NSR 120 IRQ_TYPE_LEVEL_HIGH>;
-			clock-names = "core", "reg";
+			clock-names = "core", "reg", "axi";
 			clocks = <&CP110_LABEL(clk) 1 21>,
-				 <&CP110_LABEL(clk) 1 17>;
+				 <&CP110_LABEL(clk) 1 17>,
+				 <&CP110_LABEL(clk) 1 18>;
 			status = "disabled";
 		};
 
@@ -303,9 +554,23 @@
 			#address-cells = <1>;
 			#size-cells = <0>;
 			interrupts = <ICU_GRP_NSR 121 IRQ_TYPE_LEVEL_HIGH>;
-			clock-names = "core", "reg";
+			clock-names = "core", "reg", "axi";
 			clocks = <&CP110_LABEL(clk) 1 21>,
-				 <&CP110_LABEL(clk) 1 17>;
+				 <&CP110_LABEL(clk) 1 17>,
+				 <&CP110_LABEL(clk) 1 18>;
+			status = "disabled";
+		};
+
+		CP110_LABEL(mss_i2c): i2c@211000 {
+			compatible = "marvell,mv78230-i2c";
+			reg = <0x211000 0x20>;
+			#address-cells = <1>;
+			#size-cells = <0>;
+			interrupts = <ICU_GRP_NSR 0 IRQ_TYPE_LEVEL_HIGH>;
+			clock-names = "core", "reg", "axi";
+			clocks = <&CP110_LABEL(clk) 1 21>,
+				 <&CP110_LABEL(clk) 1 17>,
+				 <&CP110_LABEL(clk) 1 18>;
 			status = "disabled";
 		};
 
@@ -359,10 +624,10 @@
 
 		CP110_LABEL(nand_controller): nand@720000 {
 			/*
-			 * Due to the limitation of the pins available
-			 * this controller is only usable on the CPM
-			 * for A7K and on the CPS for A8K.
-			 */
+			* Due to the limitation of the pins available
+			* this controller is only usable on the CPM
+			* for A7K and on the CPS for A8K.
+			*/
 			compatible = "marvell,armada-8k-nand-controller",
 				"marvell,armada370-nand-controller";
 			reg = <0x720000 0x54>;
@@ -397,6 +662,20 @@
 			status = "disabled";
 		};
 
+		CP110_LABEL(tdm): tdm@7a0000 {
+			compatible = "marvell,armada-a8k-tdm";
+			reg = <0x7a0000 0x20000>;
+			reg-names = "tdm_regs";
+			interrupts = <ICU_GRP_NSR 111 IRQ_TYPE_LEVEL_HIGH>,
+				     <ICU_GRP_NSR 112 IRQ_TYPE_LEVEL_HIGH>,
+				     <ICU_GRP_NSR 113 IRQ_TYPE_LEVEL_HIGH>;
+			cell-index = <CP110_TDM_INDEX>;
+			clock-names = "core", "axi";
+			clocks = <&CP110_LABEL(clk) 1 1>,
+				 <&CP110_LABEL(clk) 1 17>;
+			status = "disabled";
+		};
+
 		CP110_LABEL(crypto): crypto@800000 {
 			compatible = "inside-secure,safexcel-eip197b";
 			reg = <0x800000 0x200000>;
@@ -411,14 +690,52 @@
 			clock-names = "core", "reg";
 			clocks = <&CP110_LABEL(clk) 1 26>,
 				 <&CP110_LABEL(clk) 1 17>;
+			cell-index = <CP110_EIP197_INDEX>;
 			dma-coherent;
+			status = "disabled";
+		};
+
+		CP110_LABEL(uio_sam): uio_sam@800000 {
+			compatible = "marvell,uio-sam";
+			eip_access = <&CP110_LABEL(crypto)>;
 		};
 	};
 
-	CP110_LABEL(pcie0): pcie@CP110_PCIE0_BASE {
+	CP110_LABEL(armada_ep):armada-ep {
+		compatible = "marvell,armada-ep";
+		msi-parent = <&gic_v2m0>;
+		status = "disabled";
+	};
+
+	CP110_LABEL(pcie_ep): pcie-ep@600000 {
+		compatible = "marvell,armada-pcie-ep", "snps,dw-pcie";
+		reg =	<U64_TO_U32_H(CP110_PCIE_EP_REG_BASE(0))
+			 U64_TO_U32_L(CP110_PCIE_EP_REG_BASE(0)) 0 0x4000>,
+			<U64_TO_U32_H(CP110_PCIE_EP_REG_BASE(2))
+			 U64_TO_U32_L(CP110_PCIE_EP_REG_BASE(2)) 0 0x80000>,
+			<U64_TO_U32_H(CP110_PCIE_EP_REG_BASE(1))
+			 U64_TO_U32_L(CP110_PCIE_EP_REG_BASE(1)) 0 0x1000>;
+		reg-names = "core", "lm", "shadow_core";
+		clocks = <&CP110_LABEL(clk) 1 13>;
+		status = "disabled";
+	};
+
+	CP110_LABEL(pci_ep_uio): pci-ep-uio {
+		compatible = "marvell,pci-ep-uio";
+		reg = <0x00 0x00000000 0x0 0x00100000>,
+		      <0x00 0x3f000000 0x0 0x01000000>,
+		      <0x00 0xf0000000 0x0 0x01000000>,
+		      <0x80 0x00000000 0x8 0x00000000>;
+		reg-names = "bar0", "bar2", "bar4", "host-map";
+		status = "disabled";
+	};
+
+	CP110_LABEL(pcie0): pcie@600000 {
 		compatible = "marvell,armada8k-pcie", "snps,dw-pcie";
-		reg = <0 ADDRESSIFY(CP110_PCIE0_BASE) 0 0x10000>,
-		      <0 CP110_PCIEx_CONF_BASE(0) 0 0x80000>;
+		reg =
+		   <U64_TO_U32_H(CP110_PCIEx_REG0_BASE(0)) U64_TO_U32_L(CP110_PCIEx_REG0_BASE(0)) 0 0x10000>,
+		   /* Last 512KB of mem space */
+		   <U64_TO_U32_H(CP110_PCIEx_REG1_BASE(0)) U64_TO_U32_L(CP110_PCIEx_REG1_BASE(0)) 0 0x80000>;
 		reg-names = "ctrl", "config";
 		#address-cells = <3>;
 		#size-cells = <2>;
@@ -426,26 +743,30 @@
 		device_type = "pci";
 		dma-coherent;
 		msi-parent = <&gic_v2m0>;
-
 		bus-range = <0 0xff>;
 		ranges =
-		/* downstream I/O */
-		<0x81000000 0 CP110_PCIEx_IO_BASE(0) 0  CP110_PCIEx_IO_BASE(0) 0 0x10000
-		/* non-prefetchable memory */
-		0x82000000 0 CP110_PCIEx_MEM_BASE(0) 0  CP110_PCIEx_MEM_BASE(0) 0 0xf00000>;
+			/* non-prefetchable memory */
+			<CP110_PCIE_BUS_MEM_CFG U64_TO_U32_H(CP110_PCIEx_BUS_MEM_BASE(0))
+			U64_TO_U32_L(CP110_PCIEx_BUS_MEM_BASE(0)) U64_TO_U32_H(CP110_PCIEx_CPU_MEM_BASE(0))
+			U64_TO_U32_L(CP110_PCIEx_CPU_MEM_BASE(0))
+			U64_TO_U32_H(CP110_PCIE_MEM_SIZE(0)) U64_TO_U32_L(CP110_PCIE_MEM_SIZE(0))>;
 		interrupt-map-mask = <0 0 0 0>;
 		interrupt-map = <0 0 0 0 &CP110_LABEL(icu) ICU_GRP_NSR 22 IRQ_TYPE_LEVEL_HIGH>;
 		interrupts = <ICU_GRP_NSR 22 IRQ_TYPE_LEVEL_HIGH>;
 		num-lanes = <1>;
 		clock-names = "core", "reg";
 		clocks = <&CP110_LABEL(clk) 1 13>, <&CP110_LABEL(clk) 1 14>;
+		marvell,system-controller = <&CP110_LABEL(syscon0)>;
+		mac-reset-bit-mask = <CP110_PCIEx_MAC_RESET_BIT_MASK(0)>;
 		status = "disabled";
 	};
 
-	CP110_LABEL(pcie1): pcie@CP110_PCIE1_BASE {
+	CP110_LABEL(pcie1): pcie@620000 {
 		compatible = "marvell,armada8k-pcie", "snps,dw-pcie";
-		reg = <0 ADDRESSIFY(CP110_PCIE1_BASE) 0 0x10000>,
-		      <0 CP110_PCIEx_CONF_BASE(1) 0 0x80000>;
+		reg =
+		   <U64_TO_U32_H(CP110_PCIEx_REG0_BASE(1)) U64_TO_U32_L(CP110_PCIEx_REG0_BASE(1)) 0 0x10000>,
+		   /* Last 512KB of mem space */
+		   <U64_TO_U32_H(CP110_PCIEx_REG1_BASE(1)) U64_TO_U32_L(CP110_PCIEx_REG1_BASE(1)) 0 0x80000>;
 		reg-names = "ctrl", "config";
 		#address-cells = <3>;
 		#size-cells = <2>;
@@ -453,27 +774,30 @@
 		device_type = "pci";
 		dma-coherent;
 		msi-parent = <&gic_v2m0>;
-
 		bus-range = <0 0xff>;
 		ranges =
-		/* downstream I/O */
-		<0x81000000 0 CP110_PCIEx_IO_BASE(1) 0  CP110_PCIEx_IO_BASE(1) 0 0x10000
-		/* non-prefetchable memory */
-		0x82000000 0 CP110_PCIEx_MEM_BASE(1) 0  CP110_PCIEx_MEM_BASE(1) 0 0xf00000>;
+			/* non-prefetchable memory */
+			<CP110_PCIE_BUS_MEM_CFG U64_TO_U32_H(CP110_PCIEx_BUS_MEM_BASE(1))
+			U64_TO_U32_L(CP110_PCIEx_BUS_MEM_BASE(1)) U64_TO_U32_H(CP110_PCIEx_CPU_MEM_BASE(1))
+			U64_TO_U32_L(CP110_PCIEx_CPU_MEM_BASE(1))
+			U64_TO_U32_H(CP110_PCIE_MEM_SIZE(1)) U64_TO_U32_L(CP110_PCIE_MEM_SIZE(1))>;
 		interrupt-map-mask = <0 0 0 0>;
 		interrupt-map = <0 0 0 0 &CP110_LABEL(icu) ICU_GRP_NSR 24 IRQ_TYPE_LEVEL_HIGH>;
 		interrupts = <ICU_GRP_NSR 24 IRQ_TYPE_LEVEL_HIGH>;
-
 		num-lanes = <1>;
 		clock-names = "core", "reg";
 		clocks = <&CP110_LABEL(clk) 1 11>, <&CP110_LABEL(clk) 1 14>;
+		marvell,system-controller = <&CP110_LABEL(syscon0)>;
+		mac-reset-bit-mask = <CP110_PCIEx_MAC_RESET_BIT_MASK(1)>;
 		status = "disabled";
 	};
 
-	CP110_LABEL(pcie2): pcie@CP110_PCIE2_BASE {
+	CP110_LABEL(pcie2): pcie@640000 {
 		compatible = "marvell,armada8k-pcie", "snps,dw-pcie";
-		reg = <0 ADDRESSIFY(CP110_PCIE2_BASE) 0 0x10000>,
-		      <0 CP110_PCIEx_CONF_BASE(2) 0 0x80000>;
+		reg =
+		   <U64_TO_U32_H(CP110_PCIEx_REG0_BASE(2)) U64_TO_U32_L(CP110_PCIEx_REG0_BASE(2)) 0 0x10000>,
+		   /* Last 64KB of mem space */
+		   <U64_TO_U32_H(CP110_PCIEx_REG1_BASE(2)) U64_TO_U32_L(CP110_PCIEx_REG1_BASE(2)) 0 0x80000>;
 		reg-names = "ctrl", "config";
 		#address-cells = <3>;
 		#size-cells = <2>;
@@ -481,20 +805,21 @@
 		device_type = "pci";
 		dma-coherent;
 		msi-parent = <&gic_v2m0>;
-
 		bus-range = <0 0xff>;
 		ranges =
-		/* downstream I/O */
-		<0x81000000 0 CP110_PCIEx_IO_BASE(2) 0  CP110_PCIEx_IO_BASE(2) 0 0x10000
-		/* non-prefetchable memory */
-		0x82000000 0 CP110_PCIEx_MEM_BASE(2) 0  CP110_PCIEx_MEM_BASE(2) 0 0xf00000>;
+			/* non-prefetchable memory */
+			<CP110_PCIE_BUS_MEM_CFG U64_TO_U32_H(CP110_PCIEx_BUS_MEM_BASE(2))
+			U64_TO_U32_L(CP110_PCIEx_BUS_MEM_BASE(2)) U64_TO_U32_H(CP110_PCIEx_CPU_MEM_BASE(2))
+			U64_TO_U32_L(CP110_PCIEx_CPU_MEM_BASE(2))
+			U64_TO_U32_H(CP110_PCIE_MEM_SIZE(2)) U64_TO_U32_L(CP110_PCIE_MEM_SIZE(2))>;
 		interrupt-map-mask = <0 0 0 0>;
 		interrupt-map = <0 0 0 0 &CP110_LABEL(icu) ICU_GRP_NSR 23 IRQ_TYPE_LEVEL_HIGH>;
 		interrupts = <ICU_GRP_NSR 23 IRQ_TYPE_LEVEL_HIGH>;
-
 		num-lanes = <1>;
 		clock-names = "core", "reg";
 		clocks = <&CP110_LABEL(clk) 1 12>, <&CP110_LABEL(clk) 1 14>;
+		marvell,system-controller = <&CP110_LABEL(syscon0)>;
+		mac-reset-bit-mask = <CP110_PCIEx_MAC_RESET_BIT_MASK(2)>;
 		status = "disabled";
 	};
 };
diff --git a/arch/arm64/boot/dts/marvell/cn9130-db-A.dts b/arch/arm64/boot/dts/marvell/cn9130-db-A.dts
new file mode 100644
index 000000000000..4d1c03b22663
--- /dev/null
+++ b/arch/arm64/boot/dts/marvell/cn9130-db-A.dts
@@ -0,0 +1,197 @@
+/*
+ * Copyright (C) 2018 Marvell International Ltd.
+ *
+ * SPDX-License-Identifier:    GPL-2.0
+ * https://spdx.org/licenses
+ */
+
+#include "cn9130-db.dtsi"
+
+/ {
+	model = "Model: Marvell CN9130 development board (CP NOR) setup(A)";
+	compatible = "marvell,cn9130-db-A", "marvell,armada-ap807-quad",
+		     "marvell,armada-ap807";
+
+	chosen {
+		stdout-path = "serial0:115200n8";
+	};
+
+	aliases {
+		i2c0 = &cp0_i2c0;
+		ethernet0 = &cp0_eth0;
+		ethernet1 = &cp0_eth1;
+		ethernet2 = &cp0_eth2;
+	};
+
+	memory@00000000 {
+		device_type = "memory";
+		reg = <0x0 0x0 0x0 0x80000000>;
+	};
+};
+
+&uart0 {
+	status = "okay";
+};
+
+/* on-board eMMC - U9 */
+&ap_sdhci0 {
+	pinctrl-names = "default";
+	bus-width = <8>;
+	status = "okay";
+	mmc-ddr-1_8v;
+	mmc-hs400-1_8v;
+	vqmmc-supply = <&ap0_reg_sd_vccq>;
+};
+
+/*
+ * CP related configuration
+ */
+&cp0_i2c0 {
+	pinctrl-names = "default";
+	pinctrl-0 = <&cp0_i2c0_pins>;
+	status = "okay";
+	clock-frequency = <100000>;
+};
+
+&cp0_i2c1 {
+	status = "okay";
+};
+
+/* CON 28 */
+&cp0_sdhci0 {
+	status = "okay";
+};
+
+/* U54 */
+&cp0_nand_controller {
+	pinctrl-names = "default";
+	pinctrl-0 = <&nand_pins>;
+
+	nand@0 {
+		reg = <0>;
+		label = "main-storage";
+		nand-rb = <0>;
+		nand-ecc-mode = "hw";
+		nand-on-flash-bbt;
+		nand-ecc-strength = <8>;
+		nand-ecc-step-size = <512>;
+
+		partitions {
+			compatible = "fixed-partitions";
+			#address-cells = <1>;
+			#size-cells = <1>;
+
+			partition@0 {
+				label = "U-Boot";
+				reg = <0 0x200000>;
+			};
+			partition@200000 {
+				label = "Linux";
+				reg = <0x200000 0xe00000>;
+			};
+			partition@1000000 {
+				label = "Filesystem";
+				reg = <0x1000000 0x3f000000>;
+			};
+		};
+	};
+};
+
+/* U55 */
+&cp0_spi1 {
+	pinctrl-names = "default";
+	pinctrl-0 = <&cp0_spi0_pins>;
+	reg = <0x700680 0x50>,		/* control */
+	      <0x2000000 0x1000000>;	/* CS0 */
+	status = "okay";
+
+	spi-flash@0 {
+		#address-cells = <0x1>;
+		#size-cells = <0x1>;
+		compatible = "jedec,spi-nor";
+		reg = <0x0>;
+		/* On-board MUX does not allow higher frequencies */
+		spi-max-frequency = <40000000>;
+
+		partitions {
+			compatible = "fixed-partitions";
+			#address-cells = <1>;
+			#size-cells = <1>;
+
+			partition@0 {
+				label = "U-Boot";
+				reg = <0x0 0x200000>;
+			};
+
+			partition@400000 {
+				label = "Filesystem";
+				reg = <0x200000 0xe00000>;
+			};
+		};
+	};
+};
+
+/* SLM-1521-V2, CON6 */
+&cp0_pcie0 {
+	status = "okay";
+	num-lanes = <4>;
+	num-viewport = <8>;
+	/* Generic PHY, providing serdes lanes */
+	phys = <&cp0_comphy0 0
+		&cp0_comphy1 0
+		&cp0_comphy2 0
+		&cp0_comphy3 0>;
+	iommu-map =
+		<0x0   &smmu 0x480 0x20>,
+		<0x100 &smmu 0x4a0 0x20>,
+		<0x200 &smmu 0x4c0 0x20>;
+	iommu-map-mask = <0x031f>;
+};
+
+&cp0_sata0 {
+	status = "okay";
+	/* SLM-1521-V2, CON2 */
+	sata-port@1 {
+		status = "okay";
+		/* Generic PHY, providing serdes lanes */
+		phys = <&cp0_comphy5 1>;
+	};
+};
+
+&cp0_mdio {
+	status = "okay";
+	phy0: ethernet-phy@0 {
+		reg = <0>;
+	};
+	phy1: ethernet-phy@1 {
+		reg = <1>;
+	};
+};
+
+&cp0_ethernet {
+	status = "okay";
+};
+
+/* SLM-1521-V2, CON9 */
+&cp0_eth0 {
+	status = "okay";
+	phy-mode = "10gbase-kr";
+	/* Generic PHY, providing serdes lanes */
+	phys = <&cp0_comphy4 0>;
+	managed = "in-band-status";
+	sfp = <&cp0_sfp_eth0>;
+};
+
+/* CON56 */
+&cp0_eth1 {
+	status = "okay";
+	phy = <&phy0>;
+	phy-mode = "rgmii-id";
+};
+
+/* CON57 */
+&cp0_eth2 {
+	status = "okay";
+	phy = <&phy1>;
+	phy-mode = "rgmii-id";
+};
diff --git a/arch/arm64/boot/dts/marvell/cn9130-db.dtsi b/arch/arm64/boot/dts/marvell/cn9130-db.dtsi
new file mode 100644
index 000000000000..d2584a411cca
--- /dev/null
+++ b/arch/arm64/boot/dts/marvell/cn9130-db.dtsi
@@ -0,0 +1,177 @@
+// SPDX-License-Identifier: GPL-2.0+
+/*
+ * Copyright (C) 2018 Marvell International Ltd.
+ */
+
+#include <dt-bindings/gpio/gpio.h>
+#include "cn9130.dtsi" /* include SoC device tree */
+
+/ {
+	model = "DB-CN-9130";
+	compatible = "marvell,cn9130", "marvell,armada-ap807-quad",
+		     "marvell,armada-ap807";
+
+	cp0_reg_usb3_vbus0: cp0_usb3_vbus@0 {
+		compatible = "regulator-fixed";
+		regulator-name = "cp0-xhci0-vbus";
+		regulator-min-microvolt = <5000000>;
+		regulator-max-microvolt = <5000000>;
+		enable-active-high;
+		gpio = <&expander0 0 GPIO_ACTIVE_HIGH>;
+	};
+
+	cp0_usb3_0_phy0: cp0_usb3_phy0 {
+		compatible = "usb-nop-xceiv";
+		vcc-supply = <&cp0_reg_usb3_vbus0>;
+	};
+
+	cp0_reg_usb3_vbus1: cp0_usb3_vbus@1 {
+		compatible = "regulator-fixed";
+		regulator-name = "cp0-xhci1-vbus";
+		regulator-min-microvolt = <5000000>;
+		regulator-max-microvolt = <5000000>;
+		enable-active-high;
+		gpio = <&expander0 1 GPIO_ACTIVE_HIGH>;
+	};
+
+	cp0_usb3_0_phy1: cp0_usb3_phy1 {
+		compatible = "usb-nop-xceiv";
+		vcc-supply = <&cp0_reg_usb3_vbus1>;
+	};
+
+	cp0_reg_sd_vccq: cp0_sd_vccq@0 {
+		compatible = "regulator-gpio";
+		regulator-name = "cp0_sd_vccq";
+		regulator-min-microvolt = <1800000>;
+		regulator-max-microvolt = <3300000>;
+		gpios = <&expander0 15 GPIO_ACTIVE_HIGH>;
+		states = <1800000 0x1
+			  3300000 0x0>;
+	};
+
+	ap0_reg_sd_vccq: ap0_sd_vccq@0 {
+		compatible = "regulator-gpio";
+		regulator-name = "ap0_sd_vccq";
+		regulator-min-microvolt = <1800000>;
+		regulator-max-microvolt = <3300000>;
+		gpios = <&expander0 8 GPIO_ACTIVE_HIGH>;
+		states = <1800000 0x1
+			  3300000 0x0>;
+	};
+
+	cp0_reg_sd_vcc: cp0_sd_vcc@0 {
+		compatible = "regulator-fixed";
+		regulator-name = "cp0_sd_vcc";
+		regulator-min-microvolt = <3300000>;
+		regulator-max-microvolt = <3300000>;
+		gpio = <&expander0 14 GPIO_ACTIVE_HIGH>;
+		enable-active-high;
+		regulator-always-on;
+	};
+
+	cp0_sfp_eth0: sfp-eth0 {
+		compatible = "sff,sfp";
+		i2c-bus = <&cp0_sfpp0_i2c>;
+		los-gpio = <&cp0_moudle_expander1 11 GPIO_ACTIVE_HIGH>;
+		mod-def0-gpio = <&cp0_moudle_expander1 10 GPIO_ACTIVE_LOW>;
+		tx-disable-gpio = <&cp0_moudle_expander1 9 GPIO_ACTIVE_HIGH>;
+		tx-fault-gpio = <&cp0_moudle_expander1 8 GPIO_ACTIVE_HIGH>;
+		status = "disabled";
+	};
+};
+
+/*
+ * CP0
+ */
+&cp0_i2c0 {
+	clock-frequency = <100000>;
+
+	/* U36 */
+	expander0: pca953x@21 {
+		compatible = "nxp,pca9555";
+		pinctrl-names = "default";
+		gpio-controller;
+		#gpio-cells = <2>;
+		reg = <0x21>;
+		status = "okay";
+	};
+
+	/* U42 */
+	eeprom0: eeprom@50 {
+		compatible = "atmel,24c64";
+		reg = <0x50>;
+		pagesize = <0x20>;
+	};
+
+	/* U38 */
+	eeprom1: eeprom@57 {
+		compatible = "atmel,24c64";
+		reg = <0x57>;
+		pagesize = <0x20>;
+	};
+};
+
+&cp0_i2c1 {
+	clock-frequency = <100000>;
+
+	/* SLM-1521-V2 - U3 */
+	i2c-mux@72 { /* verify address - depends on dpr */
+		compatible = "nxp,pca9544";
+		#address-cells = <1>;
+		#size-cells = <0>;
+		reg = <0x72>;
+		cp0_sfpp0_i2c: i2c@0 {
+			#address-cells = <1>;
+			#size-cells = <0>;
+			reg = <0>;
+		};
+
+		i2c@1 {
+			#address-cells = <1>;
+			#size-cells = <0>;
+			reg = <1>;
+			/* U12 */
+			cp0_moudle_expander1: pca9555@21 {
+				compatible = "nxp,pca9555";
+				pinctrl-names = "default";
+				gpio-controller;
+				#gpio-cells = <2>;
+				reg = <0x21>;
+			};
+
+		};
+	};
+};
+
+
+&cp0_sdhci0 {
+	pinctrl-names = "default";
+	pinctrl-0 = <&cp0_sdhci_pins
+		     &cp0_sdhci_cd_pins>;
+	bus-width = <4>;
+	cd-gpios = <&cp0_gpio2 11 GPIO_ACTIVE_LOW>;
+	vqmmc-supply = <&cp0_reg_sd_vccq>;
+	vmmc-supply = <&cp0_reg_sd_vcc>;
+};
+
+&cp0_utmi0 {
+	status = "okay";
+};
+
+&cp0_usb3_0 {
+	status = "okay";
+	usb-phy = <&cp0_usb3_0_phy0>;
+	phys = <&cp0_utmi0>;
+	phy-names = "usb";
+};
+
+&cp0_utmi1 {
+	status = "okay";
+};
+
+&cp0_usb3_1 {
+	status = "okay";
+	usb-phy = <&cp0_usb3_0_phy1>;
+	phys = <&cp0_utmi1>;
+	phy-names = "usb";
+};
diff --git a/arch/arm64/boot/dts/marvell/cn9130.dtsi b/arch/arm64/boot/dts/marvell/cn9130.dtsi
new file mode 100644
index 000000000000..d37cd71c9aff
--- /dev/null
+++ b/arch/arm64/boot/dts/marvell/cn9130.dtsi
@@ -0,0 +1,132 @@
+/*
+ * Copyright (C) 2018 Marvell International Ltd.
+ *
+ * SPDX-License-Identifier:	GPL-2.0
+ * https://spdx.org/licenses
+ */
+
+/*
+ * Device Tree file for the CN 9130 SoC, made of an AP807 Quad and
+ * three CP110.
+ */
+
+#include "armada-ap807-quad.dtsi"
+
+/ {
+	aliases {
+		gpio1 = &cp0_gpio1;
+		gpio2 = &cp0_gpio2;
+		spi1 = &cp0_spi0;
+		spi2 = &cp0_spi1;
+	};
+};
+
+/* This defines used to calculate the base address of each CP */
+#define CP110_BASE_OFFSET		(0xf2000000)
+#define CP110_SPACE_SIZE		(0x02000000)
+#define CP110_BASE			(CP110_BASE_OFFSET + \
+						(CP110_NUM * CP110_SPACE_SIZE))
+
+#define CP110_PCIE_MEM_SIZE(iface)	((iface == 0) ? 0x1ff00000 : 0xf00000)
+#define CP110_PCIE_BUS_MEM_CFG		(0x82000000)
+
+/* CP110-0 Settings */
+#define CP110_NUM			0
+#define CP110_PCIEx_CPU_MEM_BASE(iface)	((iface == 0) ? 0xc0000000 : \
+					 (0xe0000000 + (iface - 1) * 0x1000000))
+#define CP110_PCIEx_BUS_MEM_BASE(iface)	(CP110_PCIEx_CPU_MEM_BASE(iface))
+
+#include "armada-cp110.dtsi"
+
+#undef CP110_NUM
+
+/ {
+	model = "Marvell CN 9130";
+	compatible = "marvell,cn9130", "marvell,armada-ap807-quad",
+		     "marvell,armada-ap806";
+};
+
+&smmu {
+	status = "disabled";
+};
+
+&cp0_sata0 {
+	iommus = <&smmu 0x444>;
+};
+
+&cp0_sdhci0 {
+	iommus = <&smmu 0x445>;
+};
+
+&cp0_usb3_0 {
+	iommus = <&smmu 0x440>;
+};
+
+&cp0_usb3_1 {
+	iommus = <&smmu 0x441>;
+};
+
+&cp0_crypto {
+	status = "okay";
+};
+
+&cp0_gpio1 {
+	status = "okay";
+};
+
+&cp0_gpio2 {
+	status = "okay";
+};
+
+&cp0_syscon0 {
+	cp0_pinctrl: pinctrl {
+		compatible = "marvell,cp115-standalone-pinctrl";
+
+		cp0_i2c0_pins: cp0-i2c-pins-0 {
+			marvell,pins = "mpp37", "mpp38";
+			marvell,function = "i2c0";
+		};
+		cp0_i2c1_pins: cp0-i2c-pins-1 {
+			marvell,pins = "mpp35", "mpp36";
+			marvell,function = "i2c1";
+		};
+		cp0_ge1_rgmii_pins: cp0-ge-rgmii-pins-0 {
+			marvell,pins = "mpp0", "mpp1", "mpp2",
+				       "mpp3", "mpp4", "mpp5",
+				       "mpp6", "mpp7", "mpp8",
+				       "mpp9", "mpp10", "mpp11";
+			marvell,function = "ge0";
+		};
+		cp0_ge2_rgmii_pins: cp0-ge-rgmii-pins-1 {
+			marvell,pins = "mpp44", "mpp45", "mpp46",
+				       "mpp47", "mpp48", "mpp49",
+				       "mpp50", "mpp51", "mpp52",
+				       "mpp53", "mpp54", "mpp55";
+			marvell,function = "ge1";
+		};
+		cp0_sdhci_cd_pins: cp0-sdhci-cd-pins-0 {
+			marvell,pins = "mpp43";
+			marvell,function = "gpio";
+		};
+		cp0_sdhci_pins: cp0-sdhi-pins-0 {
+			marvell,pins = "mpp56", "mpp57", "mpp58",
+				       "mpp59", "mpp60", "mpp61";
+			marvell,function = "sdio";
+		};
+		cp0_spi0_pins: cp0-spi-pins-0 {
+			marvell,pins = "mpp13", "mpp14", "mpp15", "mpp16";
+			marvell,function = "spi1";
+		};
+		nand_pins: nand-pins {
+			marvell,pins =
+			"mpp15", "mpp16", "mpp17", "mpp18", "mpp19",
+			"mpp20", "mpp21", "mpp22", "mpp23", "mpp24",
+			"mpp25", "mpp26", "mpp27";
+			marvell,function = "dev";
+		};
+		nand_rb: nand-rb {
+			marvell,pins = "mpp13";
+			marvell,function = "nf";
+		};
+	};
+};
diff --git a/arch/arm64/include/asm/cputype.h b/arch/arm64/include/asm/cputype.h
old mode 100644
new mode 100755
index 3cd936b1c79c..fea557129b33
--- a/arch/arm64/include/asm/cputype.h
+++ b/arch/arm64/include/asm/cputype.h
@@ -85,9 +85,11 @@
 #define APM_CPU_PART_POTENZA		0x000
 
 #define CAVIUM_CPU_PART_THUNDERX	0x0A1
-#define CAVIUM_CPU_PART_THUNDERX_81XX	0x0A2
-#define CAVIUM_CPU_PART_THUNDERX_83XX	0x0A3
+#define CAVIUM_CPU_PART_T81		0x0A2
+#define CAVIUM_CPU_PART_T83		0x0A3
 #define CAVIUM_CPU_PART_THUNDERX2	0x0AF
+#define MRVL_CPU_PART_OCTEONTX2_96XX	0x0B2
+#define MRVL_CPU_PART_OCTEONTX2_95XX	0x0B3
 
 #define BRCM_CPU_PART_VULCAN		0x516
 
@@ -110,9 +112,11 @@
 #define MIDR_CORTEX_A76 MIDR_CPU_MODEL(ARM_CPU_IMP_ARM, ARM_CPU_PART_CORTEX_A76)
 #define MIDR_NEOVERSE_N1 MIDR_CPU_MODEL(ARM_CPU_IMP_ARM, ARM_CPU_PART_NEOVERSE_N1)
 #define MIDR_THUNDERX	MIDR_CPU_MODEL(ARM_CPU_IMP_CAVIUM, CAVIUM_CPU_PART_THUNDERX)
-#define MIDR_THUNDERX_81XX MIDR_CPU_MODEL(ARM_CPU_IMP_CAVIUM, CAVIUM_CPU_PART_THUNDERX_81XX)
-#define MIDR_THUNDERX_83XX MIDR_CPU_MODEL(ARM_CPU_IMP_CAVIUM, CAVIUM_CPU_PART_THUNDERX_83XX)
+#define MIDR_OCTEON_T81 MIDR_CPU_MODEL(ARM_CPU_IMP_CAVIUM, CAVIUM_CPU_PART_T81)
+#define MIDR_OCTEON_T83 MIDR_CPU_MODEL(ARM_CPU_IMP_CAVIUM, CAVIUM_CPU_PART_T83)
 #define MIDR_CAVIUM_THUNDERX2 MIDR_CPU_MODEL(ARM_CPU_IMP_CAVIUM, CAVIUM_CPU_PART_THUNDERX2)
+#define MIDR_MRVL_OCTEONTX2_96XX MIDR_CPU_MODEL(ARM_CPU_IMP_CAVIUM, MRVL_CPU_PART_OCTEONTX2_96XX)
+#define MIDR_MRVL_OCTEONTX2_95XX MIDR_CPU_MODEL(ARM_CPU_IMP_CAVIUM, MRVL_CPU_PART_OCTEONTX2_95XX)
 #define MIDR_BRCM_VULCAN MIDR_CPU_MODEL(ARM_CPU_IMP_BRCM, BRCM_CPU_PART_VULCAN)
 #define MIDR_QCOM_FALKOR_V1 MIDR_CPU_MODEL(ARM_CPU_IMP_QCOM, QCOM_CPU_PART_FALKOR_V1)
 #define MIDR_QCOM_FALKOR MIDR_CPU_MODEL(ARM_CPU_IMP_QCOM, QCOM_CPU_PART_FALKOR)
diff --git a/arch/arm64/include/asm/io.h b/arch/arm64/include/asm/io.h
index 49bb9a020a09..31999223fac8 100644
--- a/arch/arm64/include/asm/io.h
+++ b/arch/arm64/include/asm/io.h
@@ -55,10 +55,26 @@ static inline void __raw_writel(u32 val, volatile void __iomem *addr)
 }
 
 #define __raw_writeq __raw_writeq
+#ifdef CONFIG_MMIO_64BIT
 static inline void __raw_writeq(u64 val, volatile void __iomem *addr)
 {
 	asm volatile("str %x0, [%1]" : : "rZ" (val), "r" (addr));
 }
+#else
+static inline void __raw_writeq(u64 val, volatile void __iomem *addr)
+{
+	u32 *low, *high;
+
+	low = high = (u32 *)addr;
+#ifdef CONFIG_CPU_BIG_ENDIAN
+	low++;
+#else
+	high++;
+#endif
+	asm volatile("str %w0, [%1]" : : "rZ" (val & U32_MAX), "r" (low));
+	asm volatile("str %w0, [%1]" : : "rZ" (val >> 32), "r" (high));
+}
+#endif
 
 #define __raw_readb __raw_readb
 static inline u8 __raw_readb(const volatile void __iomem *addr)
@@ -95,6 +111,7 @@ static inline u32 __raw_readl(const volatile void __iomem *addr)
 }
 
 #define __raw_readq __raw_readq
+#ifdef CONFIG_MMIO_64BIT
 static inline u64 __raw_readq(const volatile void __iomem *addr)
 {
 	u64 val;
@@ -104,6 +121,35 @@ static inline u64 __raw_readq(const volatile void __iomem *addr)
 		     : "=r" (val) : "r" (addr));
 	return val;
 }
+#else
+static inline u64 __raw_readq(const volatile void __iomem *addr)
+{
+	u64 val = 0;
+	u32 temp;
+	u32 *low, *high;
+
+	low = high = (u32 *)addr;
+#ifdef CONFIG_CPU_BIG_ENDIAN
+	low++;
+#else
+	high++;
+#endif
+
+	asm volatile(ALTERNATIVE("ldr %w0, [%1]",
+				 "ldar %w0, [%1]",
+				 ARM64_WORKAROUND_DEVICE_LOAD_ACQUIRE)
+		     : "=r" (temp) : "r" (high));
+	val = temp;
+	val = val << 32;
+	asm volatile(ALTERNATIVE("ldr %w0, [%1]",
+				 "ldar %w0, [%1]",
+				 ARM64_WORKAROUND_DEVICE_LOAD_ACQUIRE)
+		     : "=r" (temp) : "r" (low));
+	val |= temp;
+
+	return val;
+}
+#endif
 
 /* IO barriers */
 #define __iormb(v)							\
diff --git a/arch/arm64/include/asm/mmu_context.h b/arch/arm64/include/asm/mmu_context.h
index 39ec0b8a689e..6917368b5a6a 100644
--- a/arch/arm64/include/asm/mmu_context.h
+++ b/arch/arm64/include/asm/mmu_context.h
@@ -241,6 +241,12 @@ switch_mm(struct mm_struct *prev, struct mm_struct *next,
 void verify_cpu_asid_bits(void);
 void post_ttbr_update_workaround(void);
 
+#ifdef CONFIG_MRVL_OCTEONTX_EL0_INTR
+int lock_context(struct mm_struct *mm, int index);
+int unlock_context_by_index(int index);
+bool unlock_context_by_mm(struct mm_struct *mm);
+#endif
+
 #endif /* !__ASSEMBLY__ */
 
 #endif /* !__ASM_MMU_CONTEXT_H */
diff --git a/arch/arm64/include/asm/thread_info.h b/arch/arm64/include/asm/thread_info.h
index 69ac5262cccd..5edfdd2e2bcc 100644
--- a/arch/arm64/include/asm/thread_info.h
+++ b/arch/arm64/include/asm/thread_info.h
@@ -76,6 +76,7 @@ void arch_release_task_struct(struct task_struct *tsk);
 #define TIF_FOREIGN_FPSTATE	3	/* CPU's FP state is not current's */
 #define TIF_UPROBE		4	/* uprobe breakpoint or singlestep */
 #define TIF_FSCHECK		5	/* Check FS is USER_DS on return */
+#define TIF_TASK_ISOLATION	6
 #define TIF_NOHZ		7
 #define TIF_SYSCALL_TRACE	8
 #define TIF_SYSCALL_AUDIT	9
@@ -89,11 +90,13 @@ void arch_release_task_struct(struct task_struct *tsk);
 #define TIF_SVE			23	/* Scalable Vector Extension in use */
 #define TIF_SVE_VL_INHERIT	24	/* Inherit sve_vl_onexec across exec */
 #define TIF_SSBD		25	/* Wants SSB mitigation */
+#define TIF_32BIT_AARCH64	26	/* 32 bit process on AArch64(ILP32) */
 
 #define _TIF_SIGPENDING		(1 << TIF_SIGPENDING)
 #define _TIF_NEED_RESCHED	(1 << TIF_NEED_RESCHED)
 #define _TIF_NOTIFY_RESUME	(1 << TIF_NOTIFY_RESUME)
 #define _TIF_FOREIGN_FPSTATE	(1 << TIF_FOREIGN_FPSTATE)
+#define _TIF_TASK_ISOLATION	(1 << TIF_TASK_ISOLATION)
 #define _TIF_NOHZ		(1 << TIF_NOHZ)
 #define _TIF_SYSCALL_TRACE	(1 << TIF_SYSCALL_TRACE)
 #define _TIF_SYSCALL_AUDIT	(1 << TIF_SYSCALL_AUDIT)
@@ -104,10 +107,12 @@ void arch_release_task_struct(struct task_struct *tsk);
 #define _TIF_SINGLESTEP		(1 << TIF_SINGLESTEP)
 #define _TIF_32BIT		(1 << TIF_32BIT)
 #define _TIF_SVE		(1 << TIF_SVE)
+#define _TIF_32BIT_AARCH64	(1 << TIF_32BIT_AARCH64)
 
 #define _TIF_WORK_MASK		(_TIF_NEED_RESCHED | _TIF_SIGPENDING | \
 				 _TIF_NOTIFY_RESUME | _TIF_FOREIGN_FPSTATE | \
-				 _TIF_UPROBE | _TIF_FSCHECK)
+				 _TIF_UPROBE | _TIF_FSCHECK | \
+				 _TIF_TASK_ISOLATION)
 
 #define _TIF_SYSCALL_WORK	(_TIF_SYSCALL_TRACE | _TIF_SYSCALL_AUDIT | \
 				 _TIF_SYSCALL_TRACEPOINT | _TIF_SECCOMP | \
diff --git a/arch/arm64/include/uapi/asm/bitsperlong.h b/arch/arm64/include/uapi/asm/bitsperlong.h
index 485d60bee26c..9a05a9659e76 100644
--- a/arch/arm64/include/uapi/asm/bitsperlong.h
+++ b/arch/arm64/include/uapi/asm/bitsperlong.h
@@ -17,7 +17,14 @@
 #ifndef __ASM_BITSPERLONG_H
 #define __ASM_BITSPERLONG_H
 
-#define __BITS_PER_LONG 64
+#if defined(__LP64__)
+/* Assuming __LP64__ will be defined for native ELF64's and not for ILP32. */
+#  define __BITS_PER_LONG 64
+#elif defined(__ILP32__)
+#  define __BITS_PER_LONG 32
+#else
+#  error "Neither LP64 nor ILP32: unsupported ABI in asm/bitsperlong.h"
+#endif
 
 #include <asm-generic/bitsperlong.h>
 
diff --git a/arch/arm64/include/uapi/asm/unistd.h b/arch/arm64/include/uapi/asm/unistd.h
index 5072cbd15c82..80f1cb4ae2e1 100644
--- a/arch/arm64/include/uapi/asm/unistd.h
+++ b/arch/arm64/include/uapi/asm/unistd.h
@@ -15,6 +15,19 @@
  * along with this program.  If not, see <http://www.gnu.org/licenses/>.
  */
 
+/*
+ * Use AARCH32 interface for sys_sync_file_range() as it passes 64-bit arguments.
+ */
+#if defined(__ILP32__) || defined(__SYSCALL_COMPAT)
+#define __ARCH_WANT_SYNC_FILE_RANGE2
+#endif
+
+/*
+ * AARCH64/ILP32 is introduced after next syscalls were deprecated.
+ */
+#if !(defined(__ILP32__) || defined(__SYSCALL_COMPAT))
 #define __ARCH_WANT_RENAMEAT
+#define __ARCH_WANT_SET_GET_RLIMIT
+#endif
 
 #include <asm-generic/unistd.h>
diff --git a/arch/arm64/kernel/cpu_errata.c b/arch/arm64/kernel/cpu_errata.c
index 76490b0cefce..8e79d366044d 100644
--- a/arch/arm64/kernel/cpu_errata.c
+++ b/arch/arm64/kernel/cpu_errata.c
@@ -744,7 +744,7 @@ const struct arm64_cpu_capabilities arm64_errata[] = {
 	/* Cavium ThunderX, T81 pass 1.0 */
 		.desc = "Cavium erratum 27456",
 		.capability = ARM64_WORKAROUND_CAVIUM_27456,
-		ERRATA_MIDR_REV(MIDR_THUNDERX_81XX, 0, 0),
+		ERRATA_MIDR_REV(MIDR_OCTEON_T81, 0, 0),
 	},
 #endif
 #ifdef CONFIG_CAVIUM_ERRATUM_30115
@@ -760,13 +760,13 @@ const struct arm64_cpu_capabilities arm64_errata[] = {
 	/* Cavium ThunderX, T81 pass 1.0 - 1.2 */
 		.desc = "Cavium erratum 30115",
 		.capability = ARM64_WORKAROUND_CAVIUM_30115,
-		ERRATA_MIDR_REV_RANGE(MIDR_THUNDERX_81XX, 0, 0, 2),
+		ERRATA_MIDR_REV_RANGE(MIDR_OCTEON_T81, 0, 0, 2),
 	},
 	{
 	/* Cavium ThunderX, T83 pass 1.0 */
 		.desc = "Cavium erratum 30115",
 		.capability = ARM64_WORKAROUND_CAVIUM_30115,
-		ERRATA_MIDR_REV(MIDR_THUNDERX_83XX, 0, 0),
+		ERRATA_MIDR_REV(MIDR_OCTEON_T83, 0, 0),
 	},
 #endif
 	{
diff --git a/arch/arm64/mm/context.c b/arch/arm64/mm/context.c
index c127f94da8e2..86b43c58108a 100644
--- a/arch/arm64/mm/context.c
+++ b/arch/arm64/mm/context.c
@@ -35,6 +35,13 @@ static unsigned long *asid_map;
 
 static DEFINE_PER_CPU(atomic64_t, active_asids);
 static DEFINE_PER_CPU(u64, reserved_asids);
+
+#ifdef CONFIG_MRVL_OCTEONTX_EL0_INTR
+#define LOCKED_ASIDS_COUNT	128
+
+static u64 locked_asids[LOCKED_ASIDS_COUNT];
+#endif
+
 static cpumask_t tlb_flush_pending;
 
 #define ASID_MASK		(~GENMASK(asid_bits - 1, 0))
@@ -111,6 +118,15 @@ static void flush_context(unsigned int cpu)
 		per_cpu(reserved_asids, i) = asid;
 	}
 
+#ifdef CONFIG_MRVL_OCTEONTX_EL0_INTR
+	/* Set bits for locked ASIDs. */
+	for (i = 0; i < LOCKED_ASIDS_COUNT; i++) {
+		asid = locked_asids[i];
+		if (asid != 0)
+			__set_bit(asid & ~ASID_MASK, asid_map);
+	}
+#endif
+
 	/*
 	 * Queue a TLB invalidation for each CPU to perform on next
 	 * context-switch
@@ -118,9 +134,61 @@ static void flush_context(unsigned int cpu)
 	cpumask_setall(&tlb_flush_pending);
 }
 
+#ifdef CONFIG_MRVL_OCTEONTX_EL0_INTR
+int lock_context(struct mm_struct *mm, int index)
+{
+	unsigned long flags;
+	u64 asid;
+
+	if ((index < 0) || (index >= LOCKED_ASIDS_COUNT))
+		return -1;
+	raw_spin_lock_irqsave(&cpu_asid_lock, flags);
+	asid = atomic64_read(&mm->context.id);
+	locked_asids[index] = asid;
+	raw_spin_unlock_irqrestore(&cpu_asid_lock, flags);
+	return 0;
+}
+EXPORT_SYMBOL(lock_context);
+
+int unlock_context_by_index(int index)
+{
+	unsigned long flags;
+
+	if ((index < 0) || (index >= LOCKED_ASIDS_COUNT))
+		return -1;
+	raw_spin_lock_irqsave(&cpu_asid_lock, flags);
+	locked_asids[index] = 0;
+	raw_spin_unlock_irqrestore(&cpu_asid_lock, flags);
+	return 0;
+}
+EXPORT_SYMBOL(unlock_context_by_index);
+
+bool unlock_context_by_mm(struct mm_struct *mm)
+{
+	int i;
+	unsigned long flags;
+	bool hit = false;
+	u64 asid;
+
+	raw_spin_lock_irqsave(&cpu_asid_lock, flags);
+	asid = atomic64_read(&mm->context.id);
+
+	for (i = 0; i < LOCKED_ASIDS_COUNT; i++) {
+		if (locked_asids[i] == asid) {
+			hit = true;
+			locked_asids[i] = 0;
+		}
+	}
+
+	raw_spin_unlock_irqrestore(&cpu_asid_lock, flags);
+
+	return hit;
+}
+#endif
+
 static bool check_update_reserved_asid(u64 asid, u64 newasid)
 {
-	int cpu;
+	int i, cpu;
 	bool hit = false;
 
 	/*
@@ -139,6 +207,16 @@ static bool check_update_reserved_asid(u64 asid, u64 newasid)
 		}
 	}
 
+#ifdef CONFIG_MRVL_OCTEONTX_EL0_INTR
+	/* Same mechanism for locked ASIDs */
+	for (i = 0; i < LOCKED_ASIDS_COUNT; i++) {
+		if (locked_asids[i] == asid) {
+			hit = true;
+			locked_asids[i] = newasid;
+		}
+	}
+#endif
+
 	return hit;
 }
 
diff --git a/arch/arm64/mm/mmap.c b/arch/arm64/mm/mmap.c
index 157f2caa1351..ac89686c4af8 100644
--- a/arch/arm64/mm/mmap.c
+++ b/arch/arm64/mm/mmap.c
@@ -54,7 +54,7 @@ unsigned long arch_mmap_rnd(void)
 	unsigned long rnd;
 
 #ifdef CONFIG_COMPAT
-	if (test_thread_flag(TIF_32BIT))
+	if (is_compat_task())
 		rnd = get_random_long() & ((1UL << mmap_rnd_compat_bits) - 1);
 	else
 #endif
diff --git a/drivers/Makefile b/drivers/Makefile
index 578f469f72fb..8fda55a094fc 100644
--- a/drivers/Makefile
+++ b/drivers/Makefile
@@ -38,9 +38,6 @@ obj-y				+= clk/
 # really early.
 obj-$(CONFIG_DMADEVICES)	+= dma/
 
-# SOC specific infrastructure drivers.
-obj-y				+= soc/
-
 obj-$(CONFIG_VIRTIO)		+= virtio/
 obj-$(CONFIG_XEN)		+= xen/
 
@@ -58,6 +55,9 @@ obj-y				+= char/
 # iommu/ comes before gpu as gpu are using iommu controllers
 obj-$(CONFIG_IOMMU_SUPPORT)	+= iommu/
 
+# SOC specific infrastructure drivers.
+obj-y				+= soc/
+
 # gpu/ comes after char for AGP vs DRM startup and after iommu
 obj-y				+= gpu/
 
diff --git a/drivers/ata/libahci_platform.c b/drivers/ata/libahci_platform.c
index 522b543f718d..60e3b14d909e 100644
--- a/drivers/ata/libahci_platform.c
+++ b/drivers/ata/libahci_platform.c
@@ -56,6 +56,12 @@ int ahci_platform_enable_phys(struct ahci_host_priv *hpriv)
 		if (rc)
 			goto disable_phys;
 
+		rc = phy_set_mode(hpriv->phys[i], PHY_MODE_SATA);
+		if (rc) {
+			phy_exit(hpriv->phys[i]);
+			goto disable_phys;
+		}
+
 		rc = phy_power_on(hpriv->phys[i]);
 		if (rc) {
 			phy_exit(hpriv->phys[i]);
diff --git a/drivers/clk/mvebu/Kconfig b/drivers/clk/mvebu/Kconfig
index fddc8ac5faff..cc05b5b9b531 100644
--- a/drivers/clk/mvebu/Kconfig
+++ b/drivers/clk/mvebu/Kconfig
@@ -7,6 +7,9 @@ config MVEBU_CLK_CPU
 config MVEBU_CLK_COREDIV
 	bool
 
+config ARMADA_AP_CP_HELPER
+	bool
+
 config ARMADA_370_CLK
 	bool
 	select MVEBU_CLK_COMMON
@@ -34,9 +37,14 @@ config ARMADA_XP_CLK
 
 config ARMADA_AP806_SYSCON
 	bool
+	select ARMADA_AP_CP_HELPER
+
+config ARMADA_AP810_SYSCON
+	bool
 
 config ARMADA_CP110_SYSCON
 	bool
+	select ARMADA_AP_CP_HELPER
 
 config DOVE_CLK
 	bool
diff --git a/drivers/clk/mvebu/Makefile b/drivers/clk/mvebu/Makefile
index 93ac3685271f..40eb7923649f 100644
--- a/drivers/clk/mvebu/Makefile
+++ b/drivers/clk/mvebu/Makefile
@@ -2,6 +2,7 @@
 obj-$(CONFIG_MVEBU_CLK_COMMON)	+= common.o
 obj-$(CONFIG_MVEBU_CLK_CPU) 	+= clk-cpu.o
 obj-$(CONFIG_MVEBU_CLK_COREDIV)	+= clk-corediv.o
+obj-$(CONFIG_ARMADA_AP_CP_HELPER) += armada_ap_cp_helper.o
 
 obj-$(CONFIG_ARMADA_370_CLK)	+= armada-370.o
 obj-$(CONFIG_ARMADA_375_CLK)	+= armada-375.o
@@ -13,6 +14,7 @@ obj-$(CONFIG_ARMADA_37XX_CLK)	+= armada-37xx-periph.o
 obj-$(CONFIG_ARMADA_XP_CLK)	+= armada-xp.o mv98dx3236.o
 obj-$(CONFIG_ARMADA_AP806_SYSCON) += ap806-system-controller.o
 obj-$(CONFIG_ARMADA_CP110_SYSCON) += cp110-system-controller.o
+obj-$(CONFIG_ARMADA_AP810_SYSCON) += ap810-system-controller.o
 obj-$(CONFIG_DOVE_CLK)		+= dove.o dove-divider.o
 obj-$(CONFIG_KIRKWOOD_CLK)	+= kirkwood.o
 obj-$(CONFIG_ORION_CLK)		+= orion.o
diff --git a/drivers/clk/mvebu/ap806-system-controller.c b/drivers/clk/mvebu/ap806-system-controller.c
index fa2fbd2cef4a..895b9ba99392 100644
--- a/drivers/clk/mvebu/ap806-system-controller.c
+++ b/drivers/clk/mvebu/ap806-system-controller.c
@@ -12,18 +12,19 @@
 
 #define pr_fmt(fmt) "ap806-system-controller: " fmt
 
+#include "armada_ap_cp_helper.h"
 #include <linux/clk-provider.h>
 #include <linux/mfd/syscon.h>
 #include <linux/init.h>
 #include <linux/of.h>
-#include <linux/of_address.h>
 #include <linux/platform_device.h>
 #include <linux/regmap.h>
+#include <stdbool.h>
 
 #define AP806_SAR_REG			0x400
 #define AP806_SAR_CLKFREQ_MODE_MASK	0x1f
 
-#define AP806_CLK_NUM			5
+#define AP806_CLK_NUM			6
 
 static struct clk *ap806_clks[AP806_CLK_NUM];
 
@@ -32,86 +33,157 @@ static struct clk_onecell_data ap806_clk_data = {
 	.clk_num = AP806_CLK_NUM,
 };
 
-static char *ap806_unique_name(struct device *dev, struct device_node *np,
-			       char *name)
+static int ap806_get_sar_clocks(unsigned int freq_mode,
+				  unsigned int *cpuclk_freq,
+				  unsigned int *dclk_freq)
 {
-	const __be32 *reg;
-	u64 addr;
+	int ret = 0;
 
-	reg = of_get_property(np, "reg", NULL);
-	addr = of_translate_address(np, reg);
-	return devm_kasprintf(dev, GFP_KERNEL, "%llx-%s",
-			(unsigned long long)addr, name);
-}
-
-static int ap806_syscon_common_probe(struct platform_device *pdev,
-				     struct device_node *syscon_node)
-{
-	unsigned int freq_mode, cpuclk_freq;
-	const char *name, *fixedclk_name;
-	struct device *dev = &pdev->dev;
-	struct device_node *np = dev->of_node;
-	struct regmap *regmap;
-	u32 reg;
-	int ret;
-
-	regmap = syscon_node_to_regmap(syscon_node);
-	if (IS_ERR(regmap)) {
-		dev_err(dev, "cannot get regmap\n");
-		return PTR_ERR(regmap);
-	}
-
-	ret = regmap_read(regmap, AP806_SAR_REG, &reg);
-	if (ret) {
-		dev_err(dev, "cannot read from regmap\n");
-		return ret;
-	}
-
-	freq_mode = reg & AP806_SAR_CLKFREQ_MODE_MASK;
 	switch (freq_mode) {
 	case 0x0:
+		*cpuclk_freq = 2000;
+		*dclk_freq = 600;
+		break;
 	case 0x1:
-		cpuclk_freq = 2000;
+		*cpuclk_freq = 2000;
+		*dclk_freq = 525;
 		break;
 	case 0x6:
+		*cpuclk_freq = 1800;
+		*dclk_freq = 600;
+		break;
 	case 0x7:
-		cpuclk_freq = 1800;
+		*cpuclk_freq = 1800;
+		*dclk_freq = 525;
 		break;
 	case 0x4:
+		*cpuclk_freq = 1600;
+		*dclk_freq = 400;
+		break;
 	case 0xB:
+		*cpuclk_freq = 1600;
+		*dclk_freq = 450;
+		break;
 	case 0xD:
-		cpuclk_freq = 1600;
+		*cpuclk_freq = 1600;
+		*dclk_freq = 525;
 		break;
 	case 0x1a:
-		cpuclk_freq = 1400;
+		*cpuclk_freq = 1400;
+		*dclk_freq = 400;
 		break;
 	case 0x14:
+		*cpuclk_freq = 1300;
+		*dclk_freq = 400;
+		break;
 	case 0x17:
-		cpuclk_freq = 1300;
+		*cpuclk_freq = 1300;
+		*dclk_freq = 325;
 		break;
 	case 0x19:
-		cpuclk_freq = 1200;
+		*cpuclk_freq = 1200;
+		*dclk_freq = 400;
 		break;
 	case 0x13:
+		*cpuclk_freq = 1000;
+		*dclk_freq = 325;
+		break;
 	case 0x1d:
-		cpuclk_freq = 1000;
+		*cpuclk_freq = 1000;
+		*dclk_freq = 400;
 		break;
 	case 0x1c:
-		cpuclk_freq = 800;
+		*cpuclk_freq = 800;
+		*dclk_freq = 400;
 		break;
 	case 0x1b:
-		cpuclk_freq = 600;
+		*cpuclk_freq = 600;
+		*dclk_freq = 400;
+		break;
+	default:
+		ret = -EINVAL;
+		break;
+	}
+
+	return ret;
+}
+
+static int ap807_get_sar_clocks(unsigned int freq_mode,
+				  unsigned int *cpuclk_freq,
+				  unsigned int *dclk_freq)
+{
+	int ret = 0;
+
+	switch (freq_mode) {
+	case 0x0:
+		*cpuclk_freq = 2000;
+		*dclk_freq = 1200;
+		break;
+	case 0x6:
+		*cpuclk_freq = 2200;
+		*dclk_freq = 1200;
+		break;
+	case 0xD:
+		*cpuclk_freq = 1600;
+		*dclk_freq = 1200;
 		break;
 	default:
-		dev_err(dev, "invalid SAR value\n");
+		ret =  -EINVAL;
+		break;
+	}
+
+	return ret;
+}
+
+static int ap806_syscon_common_probe(struct platform_device *pdev,
+				     struct device_node *syscon_node)
+{
+	unsigned int freq_mode, cpuclk_freq, dclk_freq;
+	const char *name, *fixedclk_name;
+	struct device *dev = &pdev->dev;
+	struct device_node *np = dev->of_node;
+	struct regmap *regmap;
+	u32 reg;
+	int ret;
+
+	regmap = syscon_node_to_regmap(syscon_node);
+	if (IS_ERR(regmap)) {
+		dev_err(dev, "cannot get regmap\n");
+		return PTR_ERR(regmap);
+	}
+
+	ret = regmap_read(regmap, AP806_SAR_REG, &reg);
+	if (ret) {
+		dev_err(dev, "cannot read from regmap\n");
+		return ret;
+	}
+
+	freq_mode = reg & AP806_SAR_CLKFREQ_MODE_MASK;
+
+	if (of_device_is_compatible(pdev->dev.of_node,
+				    "marvell,ap807-clock")) {
+		ret = ap807_get_sar_clocks(freq_mode, &cpuclk_freq,
+					   &dclk_freq);
+	} else if (of_device_is_compatible(pdev->dev.of_node,
+					   "marvell,ap806-clock")) {
+		ret = ap806_get_sar_clocks(freq_mode, &cpuclk_freq,
+					   &dclk_freq);
+	} else {
+		dev_err(dev, "no supported compatible device found\n");
 		return -EINVAL;
 	}
 
+	if (ret) {
+		dev_err(dev, "invalid Sample at Reset value\n");
+		return ret;
+	}
+
 	/* Convert to hertz */
 	cpuclk_freq *= 1000 * 1000;
+	dclk_freq *= 1000 * 1000;
 
 	/* CPU clocks depend on the Sample At Reset configuration */
-	name = ap806_unique_name(dev, syscon_node, "cpu-cluster-0");
+	name = ap_cp_unique_name(dev, syscon_node, "pll-cluster-0");
 	ap806_clks[0] = clk_register_fixed_rate(dev, name, NULL,
 						0, cpuclk_freq);
 	if (IS_ERR(ap806_clks[0])) {
@@ -119,7 +191,7 @@ static int ap806_syscon_common_probe(struct platform_device *pdev,
 		goto fail0;
 	}
 
-	name = ap806_unique_name(dev, syscon_node, "cpu-cluster-1");
+	name = ap_cp_unique_name(dev, syscon_node, "pll-cluster-1");
 	ap806_clks[1] = clk_register_fixed_rate(dev, name, NULL, 0,
 						cpuclk_freq);
 	if (IS_ERR(ap806_clks[1])) {
@@ -128,7 +200,7 @@ static int ap806_syscon_common_probe(struct platform_device *pdev,
 	}
 
 	/* Fixed clock is always 1200 Mhz */
-	fixedclk_name = ap806_unique_name(dev, syscon_node, "fixed");
+	fixedclk_name = ap_cp_unique_name(dev, syscon_node, "fixed");
 	ap806_clks[2] = clk_register_fixed_rate(dev, fixedclk_name, NULL,
 						0, 1200 * 1000 * 1000);
 	if (IS_ERR(ap806_clks[2])) {
@@ -137,7 +209,7 @@ static int ap806_syscon_common_probe(struct platform_device *pdev,
 	}
 
 	/* MSS Clock is fixed clock divided by 6 */
-	name = ap806_unique_name(dev, syscon_node, "mss");
+	name = ap_cp_unique_name(dev, syscon_node, "mss");
 	ap806_clks[3] = clk_register_fixed_factor(NULL, name, fixedclk_name,
 						  0, 1, 6);
 	if (IS_ERR(ap806_clks[3])) {
@@ -146,7 +218,7 @@ static int ap806_syscon_common_probe(struct platform_device *pdev,
 	}
 
 	/* SDIO(/eMMC) Clock is fixed clock divided by 3 */
-	name = ap806_unique_name(dev, syscon_node, "sdio");
+	name = ap_cp_unique_name(dev, syscon_node, "sdio");
 	ap806_clks[4] = clk_register_fixed_factor(NULL, name,
 						  fixedclk_name,
 						  0, 1, 3);
@@ -155,6 +227,16 @@ static int ap806_syscon_common_probe(struct platform_device *pdev,
 		goto fail4;
 	}
 
+	/* AP-DCLK(HCLK) Clock is DDR clock divided by 2 */
+	name = ap_cp_unique_name(dev, syscon_node, "ap-dclk");
+	ap806_clks[5] = clk_register_fixed_rate(dev, name, NULL,
+						0, dclk_freq);
+
+	if (IS_ERR(ap806_clks[5])) {
+		ret = PTR_ERR(ap806_clks[5]);
+		goto fail5;
+	}
+
 	of_clk_add_provider(np, of_clk_src_onecell_get, &ap806_clk_data);
 	ret = of_clk_add_provider(np, of_clk_src_onecell_get, &ap806_clk_data);
 	if (ret)
@@ -163,6 +245,8 @@ static int ap806_syscon_common_probe(struct platform_device *pdev,
 	return 0;
 
 fail_clk_add:
+	clk_unregister_fixed_factor(ap806_clks[5]);
+fail5:
 	clk_unregister_fixed_factor(ap806_clks[4]);
 fail4:
 	clk_unregister_fixed_factor(ap806_clks[3]);
@@ -209,6 +293,7 @@ builtin_platform_driver(ap806_syscon_legacy_driver);
 
 static const struct of_device_id ap806_clock_of_match[] = {
 	{ .compatible = "marvell,ap806-clock", },
+	{ .compatible = "marvell,ap807-clock", },
 	{ }
 };
 
diff --git a/drivers/clk/mvebu/ap810-system-controller.c b/drivers/clk/mvebu/ap810-system-controller.c
new file mode 100644
index 000000000000..f78a0c3cd4cc
--- /dev/null
+++ b/drivers/clk/mvebu/ap810-system-controller.c
@@ -0,0 +1,306 @@
+/*
+ * Marvell Armada AP810 System Controller
+ *
+ * Copyright (C) 2018 Marvell
+ *
+ * Thomas Petazzoni <thomas.petazzoni@free-electrons.com>
+ * Konstantin Porotchkin <kostap@marvell.com>
+ *
+ * This file is licensed under the terms of the GNU General Public
+ * License version 2.  This program is licensed "as is" without any
+ * warranty of any kind, whether express or implied.
+ */
+
+#define pr_fmt(fmt) "ap810-system-controller: " fmt
+
+#include <linux/clk-provider.h>
+#include <linux/mfd/syscon.h>
+#include <linux/init.h>
+#include <linux/of.h>
+#include <linux/of_address.h>
+#include <linux/platform_device.h>
+#include <linux/regmap.h>
+
+/* Clock frequency mode is not shown correctly in SAR status
+ * register of AP810-A0 (offset is 0x400, or 0x6f4400)
+ * Use scratchpad register at offset 0x6f43e4 filled by ATF
+ * for obtaining the real frequency mode
+ */
+#define AP810_SARSR_REG			0x400
+#define AP810_A0_FREQ_MODE_REG		0x3e4
+#define AP810_CLOCK_FREQ_MODE_OFFS	0
+#define AP810_CLOCK_FREQ_MODE_MASK	(0x7 << AP810_CLOCK_FREQ_MODE_OFFS)
+
+#define AP810_EFUSE_STATUS_REG		0x410
+#define AP810_HIGHV_MODE_OFFS		24
+#define AP810_HIGHV_MODE_MASK		(1 << AP810_HIGHV_MODE_OFFS)
+
+#define AP810_SAR_CLK_OPT_NUM		8
+#define AP810_CLK_NUM			8
+
+#define AP810_CPU_CLK_IDX		0
+#define AP810_DDR_CLK_IDX		1
+#define AP810_FAB_CLK_IDX		2
+#define AP810_EIP197_CLK_IDX		3
+#define AP810_MAX_CLK_IDX		4
+
+#define MHZ				(1000 * 1000)
+
+static unsigned int
+	ap810_hp_clk_tbl[AP810_SAR_CLK_OPT_NUM][AP810_MAX_CLK_IDX] = {
+		{ 1600,	1600, 1200, 1200 },	/* 0 */
+		{ 2000,	2400, 1200, 1200 },	/* 1 */
+		{ 2000,	2667, 1400, 1200 },	/* 2 */
+		{ 2200, 2400, 1400, 1200 },	/* 3 */
+		{ 2200, 2667, 1400, 1200 },	/* 4 */
+		{ 2500, 2667, 1400, 1200 },	/* 5 */
+		{ 2500, 2933, 1400, 1200 },	/* 6 */
+		{ 2700, 3200, 1400, 1200 }	/* 7 */
+	};
+
+static unsigned int
+	ap810_lp_clk_tbl[AP810_SAR_CLK_OPT_NUM][AP810_MAX_CLK_IDX] = {
+		{ 1200, 1600, 800,  1000 },	/* 0 */
+		{ 1600, 2400, 800,  1000 },	/* 1 */
+		{ 1600, 2667, 1200, 1000 },	/* 2 */
+		{ 1800, 2400, 1200, 1000 },	/* 3 */
+		{ 1800, 2667, 1300, 1000 },	/* 4 */
+		{ 2000, 2400, 1200, 1000 },	/* 5 */
+		{ 2000, 2667, 1300, 1000 },	/* 6 */
+		{ 2000, 2667, 1300, 1000 }	/* 7 */
+	};
+
+static struct clk *ap810_clks[AP810_CLK_NUM];
+
+static struct clk_onecell_data ap810_clk_data = {
+	.clks = ap810_clks,
+	.clk_num = AP810_CLK_NUM,
+};
+
+static char *ap810_unique_name(struct device *dev, struct device_node *np,
+			       char *name)
+{
+	const __be32 *reg;
+	u64 addr;
+
+	reg = of_get_property(np, "reg", NULL);
+	addr = of_translate_address(np, reg);
+	return devm_kasprintf(dev, GFP_KERNEL, "%llx-%s",
+			(unsigned long long)addr, name);
+}
+
+static int ap810_syscon_common_probe(struct platform_device *pdev,
+				     struct device_node *syscon_node)
+{
+	unsigned int freq_mode, cpuclk_freq;
+	unsigned int ringclk_freq, eipclk_freq;
+	const char *name, *fixedclk_name, *ringclk_name;
+	bool is_hp;
+	struct device *dev = &pdev->dev;
+	struct device_node *np = dev->of_node;
+	struct regmap *regmap;
+	u32 reg, ap810_revision;
+	int ret;
+
+	regmap = syscon_node_to_regmap(syscon_node);
+	if (IS_ERR(regmap)) {
+		dev_err(dev, "cannot get regmap\n");
+		return PTR_ERR(regmap);
+	}
+
+	/* TODO - call the SoC info driver for reading the AP810 revision ID */
+	ap810_revision = 0;
+
+	/* Get the frequuency mode */
+	if (ap810_revision == 0)
+		ret = regmap_read(regmap, AP810_A0_FREQ_MODE_REG, &reg);
+	else
+		ret = regmap_read(regmap, AP810_SARSR_REG, &reg);
+
+	if (ret) {
+		dev_err(dev, "cannot read from regmap\n");
+		return ret;
+	}
+
+	freq_mode = reg & AP810_CLOCK_FREQ_MODE_MASK;
+	freq_mode >>= AP810_CLOCK_FREQ_MODE_OFFS;
+
+
+	/* Get the Low/High SoC power variant */
+	ret = regmap_read(regmap, AP810_EFUSE_STATUS_REG, &reg);
+	if (ret) {
+		dev_err(dev, "cannot read from regmap\n");
+		return ret;
+	}
+
+	is_hp = !!(reg & AP810_HIGHV_MODE_MASK);
+
+	/* Obtain MHz values from HW clocks tables */
+	if (is_hp) {
+		cpuclk_freq = ap810_hp_clk_tbl[freq_mode][AP810_CPU_CLK_IDX];
+		ringclk_freq = ap810_hp_clk_tbl[freq_mode][AP810_FAB_CLK_IDX];
+		eipclk_freq = ap810_hp_clk_tbl[freq_mode][AP810_EIP197_CLK_IDX];
+	} else {
+		cpuclk_freq = ap810_lp_clk_tbl[freq_mode][AP810_CPU_CLK_IDX];
+		ringclk_freq = ap810_lp_clk_tbl[freq_mode][AP810_FAB_CLK_IDX];
+		eipclk_freq = ap810_lp_clk_tbl[freq_mode][AP810_EIP197_CLK_IDX];
+	}
+
+	/* continue in case of a bad SAR value and configure
+	 *  the MSS clock (used to calculate the baudrate of the UART)
+	 */
+	if (cpuclk_freq == 0)
+		pr_err("invalid frequency mode %d in Sample at Reset\n",
+		       freq_mode);
+
+	/* Convert all clocks to hertz (DCLK = 0.5*DDR_CLK) */
+	eipclk_freq *= MHZ;
+	cpuclk_freq *= MHZ;
+	ringclk_freq *= MHZ;
+
+	/* CPU clocks depend on the Sample At Reset configuration */
+	name = ap810_unique_name(dev, syscon_node, "cpu-cluster-0-1");
+	ap810_clks[0] = clk_register_fixed_rate(dev, name, NULL,
+						0, cpuclk_freq);
+	if (IS_ERR(ap810_clks[0])) {
+		ret = PTR_ERR(ap810_clks[0]);
+		goto fail0;
+	}
+
+	name = ap810_unique_name(dev, syscon_node, "cpu-cluster-2-3");
+	ap810_clks[1] = clk_register_fixed_rate(dev, name, NULL, 0,
+						cpuclk_freq);
+	if (IS_ERR(ap810_clks[1])) {
+		ret = PTR_ERR(ap810_clks[1]);
+		goto fail1;
+	}
+
+	/* Ring clocks are derived from Sample At Reset configuration */
+	ringclk_name = ap810_unique_name(dev, syscon_node, "ring");
+	ap810_clks[2] = clk_register_fixed_rate(dev, ringclk_name, NULL, 0,
+						ringclk_freq);
+	if (IS_ERR(ap810_clks[2])) {
+		ret = PTR_ERR(ap810_clks[2]);
+		goto fail2;
+	}
+
+	/* DMA Clock is ring clock divided by 2 */
+	name = ap810_unique_name(dev, syscon_node, "rdma");
+	ap810_clks[3] = clk_register_fixed_factor(NULL, name,
+						  ringclk_name,
+						  0, 1, 2);
+	if (IS_ERR(ap810_clks[3])) {
+		ret = PTR_ERR(ap810_clks[3]);
+		goto fail3;
+	}
+
+	/* EIP197 clocks are derived from Sample At Reset configuration */
+	name = ap810_unique_name(dev, syscon_node, "eip197");
+	ap810_clks[4] = clk_register_fixed_rate(dev, name, NULL, 0,
+						eipclk_freq);
+	if (IS_ERR(ap810_clks[4])) {
+		ret = PTR_ERR(ap810_clks[4]);
+		goto fail4;
+	}
+
+	/* Fixed clock is always 1200 Mhz */
+	fixedclk_name = ap810_unique_name(dev, syscon_node, "fixed");
+	ap810_clks[5] = clk_register_fixed_rate(dev, fixedclk_name, NULL,
+						0, 1200 * 1000 * 1000);
+	if (IS_ERR(ap810_clks[5])) {
+		ret = PTR_ERR(ap810_clks[5]);
+		goto fail5;
+	}
+
+	/* MSS Clock is fixed clock divided by 6 */
+	name = ap810_unique_name(dev, syscon_node, "mss");
+	ap810_clks[6] = clk_register_fixed_factor(NULL, name,
+						  fixedclk_name,
+						  0, 1, 6);
+	if (IS_ERR(ap810_clks[6])) {
+		ret = PTR_ERR(ap810_clks[6]);
+		goto fail6;
+	}
+
+	/* SDIO(/eMMC) Clock is fixed clock divided by 3 */
+	name = ap810_unique_name(dev, syscon_node, "sdio");
+	ap810_clks[7] = clk_register_fixed_factor(NULL, name,
+						  fixedclk_name,
+						  0, 1, 3);
+	if (IS_ERR(ap810_clks[7])) {
+		ret = PTR_ERR(ap810_clks[7]);
+		goto fail7;
+	}
+
+	of_clk_add_provider(np, of_clk_src_onecell_get, &ap810_clk_data);
+	ret = of_clk_add_provider(np, of_clk_src_onecell_get, &ap810_clk_data);
+	if (ret)
+		goto fail_clk_add;
+
+	return 0;
+
+fail_clk_add:
+	clk_unregister_fixed_factor(ap810_clks[7]);	/* sdio */
+fail7:
+	clk_unregister_fixed_factor(ap810_clks[6]);	/* mss */
+fail6:
+	clk_unregister_fixed_rate(ap810_clks[5]);	/* fixed */
+fail5:
+	clk_unregister_fixed_rate(ap810_clks[4]);	/* eip197 */
+fail4:
+	clk_unregister_fixed_factor(ap810_clks[3]);	/* rdma */
+fail3:
+	clk_unregister_fixed_rate(ap810_clks[2]);	/* ring */
+fail2:
+	clk_unregister_fixed_rate(ap810_clks[1]);	/* cpu-cluster-2-3 */
+fail1:
+	clk_unregister_fixed_rate(ap810_clks[0]);	/* cpu-cluster-0-1 */
+fail0:
+	return ret;
+}
+
+static int ap810_syscon_legacy_probe(struct platform_device *pdev)
+{
+	dev_warn(&pdev->dev, FW_WARN "Using legacy device tree binding\n");
+	dev_warn(&pdev->dev, FW_WARN "Update your device tree:\n");
+	dev_warn(&pdev->dev, FW_WARN
+		 "This binding won't be supported in future kernel\n");
+
+	return ap810_syscon_common_probe(pdev, pdev->dev.of_node);
+
+}
+
+static int ap810_clock_probe(struct platform_device *pdev)
+{
+	return ap810_syscon_common_probe(pdev, pdev->dev.of_node->parent);
+}
+
+static const struct of_device_id ap810_syscon_legacy_of_match[] = {
+	{ .compatible = "marvell,ap810-system-controller", },
+	{ }
+};
+
+static struct platform_driver ap810_syscon_legacy_driver = {
+	.probe = ap810_syscon_legacy_probe,
+	.driver		= {
+		.name	= "marvell-ap810-system-controller",
+		.of_match_table = ap810_syscon_legacy_of_match,
+		.suppress_bind_attrs = true,
+	},
+};
+builtin_platform_driver(ap810_syscon_legacy_driver);
+
+static const struct of_device_id ap810_clock_of_match[] = {
+	{ .compatible = "marvell,ap810-clock", },
+	{ }
+};
+
+static struct platform_driver ap810_clock_driver = {
+	.probe = ap810_clock_probe,
+	.driver		= {
+		.name	= "marvell-ap810-clock",
+		.of_match_table = ap810_clock_of_match,
+		.suppress_bind_attrs = true,
+	},
+};
+builtin_platform_driver(ap810_clock_driver);
diff --git a/drivers/clk/mvebu/armada-37xx-xtal.c b/drivers/clk/mvebu/armada-37xx-xtal.c
index 612d65ede10a..5370514959e1 100644
--- a/drivers/clk/mvebu/armada-37xx-xtal.c
+++ b/drivers/clk/mvebu/armada-37xx-xtal.c
@@ -15,8 +15,8 @@
 #include <linux/platform_device.h>
 #include <linux/regmap.h>
 
-#define NB_GPIO1_LATCH	0xC
-#define XTAL_MODE	    BIT(31)
+#define NB_GPIO1_LATCH	0x8
+#define XTAL_MODE	    BIT(9)
 
 static int armada_3700_xtal_clock_probe(struct platform_device *pdev)
 {
diff --git a/drivers/clk/mvebu/armada_ap_cp_helper.c b/drivers/clk/mvebu/armada_ap_cp_helper.c
new file mode 100644
index 000000000000..6a930f697ee5
--- /dev/null
+++ b/drivers/clk/mvebu/armada_ap_cp_helper.c
@@ -0,0 +1,30 @@
+// SPDX-License-Identifier: GPL-2.0+
+/*
+ * Marvell Armada AP and CP110 helper
+ *
+ * Copyright (C) 2018 Marvell
+ *
+ * Gregory Clement <gregory.clement@bootlin.com>
+ *
+ */
+
+#include "armada_ap_cp_helper.h"
+#include <linux/device.h>
+#include <linux/of.h>
+#include <linux/of_address.h>
+
+char *ap_cp_unique_name(struct device *dev, struct device_node *np,
+			const char *name)
+{
+	const __be32 *reg;
+	u64 addr;
+
+	/* Do not create a name if there is no clock */
+	if (!name)
+		return NULL;
+
+	reg = of_get_property(np, "reg", NULL);
+	addr = of_translate_address(np, reg);
+	return devm_kasprintf(dev, GFP_KERNEL, "%llx-%s",
+			      (unsigned long long)addr, name);
+}
diff --git a/drivers/clk/mvebu/armada_ap_cp_helper.h b/drivers/clk/mvebu/armada_ap_cp_helper.h
new file mode 100644
index 000000000000..810af1e5dfa4
--- /dev/null
+++ b/drivers/clk/mvebu/armada_ap_cp_helper.h
@@ -0,0 +1,11 @@
+/* SPDX-License-Identifier: GPL-2.0+ */
+
+#ifndef __ARMADA_AP_CP_HELPER_H
+#define __ARMADA_AP_CP_HELPER_H
+
+struct device;
+struct device_node;
+
+char *ap_cp_unique_name(struct device *dev, struct device_node *np,
+			const char *name);
+#endif
diff --git a/drivers/clk/mvebu/cp110-system-controller.c b/drivers/clk/mvebu/cp110-system-controller.c
index 0153c76d4a20..85fdfdeb4c44 100644
--- a/drivers/clk/mvebu/cp110-system-controller.c
+++ b/drivers/clk/mvebu/cp110-system-controller.c
@@ -28,11 +28,11 @@
 
 #define pr_fmt(fmt) "cp110-system-controller: " fmt
 
+#include "armada_ap_cp_helper.h"
 #include <linux/clk-provider.h>
 #include <linux/mfd/syscon.h>
 #include <linux/init.h>
 #include <linux/of.h>
-#include <linux/of_address.h>
 #include <linux/platform_device.h>
 #include <linux/regmap.h>
 #include <linux/slab.h>
@@ -214,22 +214,6 @@ static struct clk_hw *cp110_of_clk_get(struct of_phandle_args *clkspec,
 	return ERR_PTR(-EINVAL);
 }
 
-static char *cp110_unique_name(struct device *dev, struct device_node *np,
-			       const char *name)
-{
-	const __be32 *reg;
-	u64 addr;
-
-	/* Do not create a name if there is no clock */
-	if (!name)
-		return NULL;
-
-	reg = of_get_property(np, "reg", NULL);
-	addr = of_translate_address(np, reg);
-	return devm_kasprintf(dev, GFP_KERNEL, "%llx-%s",
-			      (unsigned long long)addr, name);
-}
-
 static int cp110_syscon_common_probe(struct platform_device *pdev,
 				     struct device_node *syscon_node)
 {
@@ -263,7 +247,7 @@ static int cp110_syscon_common_probe(struct platform_device *pdev,
 	cp110_clk_data->num = CP110_CLK_NUM;
 
 	/* Register the PLL0 which is the root of the hw tree */
-	pll0_name = cp110_unique_name(dev, syscon_node, "pll0");
+	pll0_name = ap_cp_unique_name(dev, syscon_node, "pll0");
 	hw = clk_hw_register_fixed_rate(NULL, pll0_name, NULL, 0,
 					1000 * 1000 * 1000);
 	if (IS_ERR(hw)) {
@@ -274,7 +258,7 @@ static int cp110_syscon_common_probe(struct platform_device *pdev,
 	cp110_clks[CP110_CORE_PLL0] = hw;
 
 	/* PPv2 is PLL0/3 */
-	ppv2_name = cp110_unique_name(dev, syscon_node, "ppv2-core");
+	ppv2_name = ap_cp_unique_name(dev, syscon_node, "ppv2-core");
 	hw = clk_hw_register_fixed_factor(NULL, ppv2_name, pll0_name, 0, 1, 3);
 	if (IS_ERR(hw)) {
 		ret = PTR_ERR(hw);
@@ -284,7 +268,7 @@ static int cp110_syscon_common_probe(struct platform_device *pdev,
 	cp110_clks[CP110_CORE_PPV2] = hw;
 
 	/* X2CORE clock is PLL0/2 */
-	x2core_name = cp110_unique_name(dev, syscon_node, "x2core");
+	x2core_name = ap_cp_unique_name(dev, syscon_node, "x2core");
 	hw = clk_hw_register_fixed_factor(NULL, x2core_name, pll0_name,
 					  0, 1, 2);
 	if (IS_ERR(hw)) {
@@ -295,7 +279,7 @@ static int cp110_syscon_common_probe(struct platform_device *pdev,
 	cp110_clks[CP110_CORE_X2CORE] = hw;
 
 	/* Core clock is X2CORE/2 */
-	core_name = cp110_unique_name(dev, syscon_node, "core");
+	core_name = ap_cp_unique_name(dev, syscon_node, "core");
 	hw = clk_hw_register_fixed_factor(NULL, core_name, x2core_name,
 					  0, 1, 2);
 	if (IS_ERR(hw)) {
@@ -305,7 +289,7 @@ static int cp110_syscon_common_probe(struct platform_device *pdev,
 
 	cp110_clks[CP110_CORE_CORE] = hw;
 	/* NAND can be either PLL0/2.5 or core clock */
-	nand_name = cp110_unique_name(dev, syscon_node, "nand-core");
+	nand_name = ap_cp_unique_name(dev, syscon_node, "nand-core");
 	if (nand_clk_ctrl & NF_CLOCK_SEL_400_MASK)
 		hw = clk_hw_register_fixed_factor(NULL, nand_name,
 						   pll0_name, 0, 2, 5);
@@ -320,7 +304,7 @@ static int cp110_syscon_common_probe(struct platform_device *pdev,
 	cp110_clks[CP110_CORE_NAND] = hw;
 
 	/* SDIO clock is PLL0/2.5 */
-	sdio_name = cp110_unique_name(dev, syscon_node, "sdio-core");
+	sdio_name = ap_cp_unique_name(dev, syscon_node, "sdio-core");
 	hw = clk_hw_register_fixed_factor(NULL, sdio_name,
 					  pll0_name, 0, 2, 5);
 	if (IS_ERR(hw)) {
@@ -332,7 +316,7 @@ static int cp110_syscon_common_probe(struct platform_device *pdev,
 
 	/* create the unique name for all the gate clocks */
 	for (i = 0; i < ARRAY_SIZE(gate_base_names); i++)
-		gate_name[i] =	cp110_unique_name(dev, syscon_node,
+		gate_name[i] =	ap_cp_unique_name(dev, syscon_node,
 						  gate_base_names[i]);
 
 	for (i = 0; i < ARRAY_SIZE(gate_base_names); i++) {
diff --git a/drivers/gpio/Kconfig b/drivers/gpio/Kconfig
index 2c34e9537f9e..cb24fd1e86da 100644
--- a/drivers/gpio/Kconfig
+++ b/drivers/gpio/Kconfig
@@ -801,6 +801,18 @@ config GPIO_ADNP
 	  enough to represent all pins, but the driver will assume a
 	  register layout for 64 pins (8 registers).
 
+config GPIO_I2C
+	tristate "Generic I2C->GPIO no-irq expander"
+	depends on OF
+	default n
+	help
+	  Select this option to enable GPIO for simple I2C devices,
+	  parameterized by device-tree, and having no interrupts.
+	  Developed to model a custom board's CPLD, but may be useful
+	  for various hardware where i2c-poking flips external pins.
+
+	  If unsure, say N.
+
 config GPIO_MAX7300
 	tristate "Maxim MAX7300 GPIO expander"
 	select GPIO_MAX730X
diff --git a/drivers/gpio/Makefile b/drivers/gpio/Makefile
index c256aff66a65..02050a62c9df 100644
--- a/drivers/gpio/Makefile
+++ b/drivers/gpio/Makefile
@@ -56,6 +56,7 @@ obj-$(CONFIG_GPIO_GPIO_MM)	+= gpio-gpio-mm.o
 obj-$(CONFIG_GPIO_GRGPIO)	+= gpio-grgpio.o
 obj-$(CONFIG_GPIO_HLWD)		+= gpio-hlwd.o
 obj-$(CONFIG_HTC_EGPIO)		+= gpio-htc-egpio.o
+obj-$(CONFIG_GPIO_I2C)		+= gpio-i2c.o
 obj-$(CONFIG_GPIO_ICH)		+= gpio-ich.o
 obj-$(CONFIG_GPIO_INGENIC)	+= gpio-ingenic.o
 obj-$(CONFIG_GPIO_IOP)		+= gpio-iop.o
diff --git a/drivers/gpio/gpio-i2c.c b/drivers/gpio/gpio-i2c.c
new file mode 100644
index 000000000000..a67ed0706995
--- /dev/null
+++ b/drivers/gpio/gpio-i2c.c
@@ -0,0 +1,204 @@
+/*
+ * simple parameterized no-irq of_driven i2c->gpio expander,
+ * cut down from gpio-pcf857x.c to be totally device-tree driven.
+ *
+ * Suitable for any "memory-like" device, where a 1-byte i2c read yields data
+ * which can safely be written back, possibly with a bit changed, with the
+ * effect of changing only the output level of that bit's GPIO pin.
+ *
+ * Copyright (C) 2016 Cavium Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#include <linux/gpio.h>
+#include <linux/i2c.h>
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/of.h>
+#include <linux/of_device.h>
+#include <linux/slab.h>
+#include <linux/spinlock.h>
+
+struct gpio_i2c_platform_data {
+	unsigned int	i2c_addr;
+	unsigned int	pins;
+};
+
+
+static const struct of_device_id gpio_i2c_of_table[] = {
+	{ .compatible = "gpio-i2c" },
+	{ }
+};
+MODULE_DEVICE_TABLE(of, gpio_i2c_of_table);
+
+struct gpio_i2c {
+	unsigned int	i2c_addr;
+	struct gpio_chip	chip;
+	struct i2c_client	*client;
+	struct mutex		lock;		/* protect 'out' */
+	u8			out[];		/* software latch */
+};
+
+/*-------------------------------------------------------------------------*/
+
+static int gpio_i2c_get(struct gpio_chip *chip, unsigned int offset)
+{
+	struct gpio_i2c	*gpio = container_of(chip, struct gpio_i2c, chip);
+	int		value;
+	unsigned int	byte = (offset >> 3);
+	unsigned int	bit = (offset & 7);
+
+	mutex_lock(&gpio->lock);
+	value = i2c_smbus_read_byte_data(gpio->client, byte);
+	mutex_unlock(&gpio->lock);
+	return (value < 0) ? 0 : ((value >> bit) & 1);
+}
+
+static int gpio_i2c_output(struct gpio_chip *chip,
+		unsigned int offset, int value)
+{
+	struct gpio_i2c	*gpio = container_of(chip, struct gpio_i2c, chip);
+	unsigned int	byte = (offset >> 3);
+	unsigned int	bit = (offset & 7);
+	unsigned int	mask = (1 << bit);
+	int		status;
+	u8		was;
+
+	mutex_lock(&gpio->lock);
+	was = i2c_smbus_read_byte_data(gpio->client, byte);
+	if (value)
+		was |= mask;
+	else
+		was &= ~mask;
+	status = i2c_smbus_write_byte_data(gpio->client, byte, was);
+	gpio->out[byte] = was;
+	mutex_unlock(&gpio->lock);
+
+	return status;
+}
+
+static void gpio_i2c_set(struct gpio_chip *chip, unsigned int offset, int value)
+{
+	gpio_i2c_output(chip, offset, value);
+}
+
+/* for open-drain: set as input by letting output go high */
+static int gpio_i2c_input(struct gpio_chip *chip, unsigned int offset)
+{
+	return gpio_i2c_output(chip, offset, 1);
+}
+
+/*-------------------------------------------------------------------------*/
+
+static int gpio_i2c_probe(struct i2c_client *client,
+			 const struct i2c_device_id *id)
+{
+	struct gpio_i2c_platform_data	*pdata = dev_get_platdata(&client->dev);
+	struct device_node		*np = client->dev.of_node;
+	struct gpio_i2c			*gpio;
+	u32				pins;
+	u32				i2c_addr;
+	int				status;
+
+	if (np) {
+		status = of_property_read_u32(np, "reg", &i2c_addr);
+		if (status < 0) {
+			dev_dbg(&client->dev, "missing reg property\n");
+			return status;
+		}
+		status = of_property_read_u32(np, "ngpios", &pins);
+		if (status < 0) {
+			dev_dbg(&client->dev, "missing ngpios property\n");
+			return status;
+		}
+	} else if (pdata) {
+		i2c_addr = pdata->i2c_addr;
+		pins = pdata->pins;
+	} else {
+		dev_dbg(&client->dev, "no platform data\n");
+		return -EPROBE_DEFER;
+	}
+
+	/* Allocate, initialize, and register this gpio_chip. */
+	gpio = devm_kzalloc(&client->dev,
+		sizeof(*gpio) + (pins + 7) / 8, GFP_KERNEL);
+	if (!gpio)
+		return -ENOMEM;
+
+	mutex_init(&gpio->lock);
+
+	gpio->i2c_addr			= i2c_addr;
+	gpio->chip.base			= -1;
+	gpio->chip.can_sleep		= true;
+	gpio->chip.parent		= &client->dev;
+	gpio->chip.owner		= THIS_MODULE;
+	gpio->chip.get			= gpio_i2c_get;
+	gpio->chip.set			= gpio_i2c_set;
+	gpio->chip.direction_input	= gpio_i2c_input;
+	gpio->chip.direction_output	= gpio_i2c_output;
+	gpio->chip.ngpio		= pins;
+	gpio->chip.label		= client->name;
+	gpio->client			= client;
+	gpio->client->addr		= i2c_addr;
+	i2c_set_clientdata(client, gpio);
+
+	status = gpiochip_add(&gpio->chip);
+	if (status < 0)
+		goto fail;
+
+	dev_info(&client->dev, "probed\n");
+
+	return 0;
+
+fail:
+	dev_dbg(&client->dev, "probe error %d for '%s'\n", status,
+		client->name);
+
+	return status;
+}
+
+static int gpio_i2c_remove(struct i2c_client *client)
+{
+	struct gpio_i2c			*gpio = i2c_get_clientdata(client);
+	int				status = 0;
+
+	gpiochip_remove(&gpio->chip);
+	return status;
+}
+
+/* this must _exist_ for i2c_device_probe() to call our probe, may be empty */
+static struct i2c_device_id empty_id_table[] = {
+	{ },
+};
+MODULE_DEVICE_TABLE(i2c, empty_id_table);
+
+static struct i2c_driver gpio_i2c_driver = {
+	.driver = {
+		.name	= "gpio-i2c",
+		.of_match_table = of_match_ptr(gpio_i2c_of_table),
+	},
+	.probe	= gpio_i2c_probe,
+	.remove	= gpio_i2c_remove,
+	.id_table = empty_id_table,
+};
+
+module_i2c_driver(gpio_i2c_driver);
+
+MODULE_LICENSE("GPL");
+MODULE_AUTHOR("David Brownell");
+MODULE_AUTHOR("Peter Swain <pswain@cavium.com>");
+/*
+ * arguably this name defies convention, but correct(?) alias has been
+ * taken by the inverse function in
+ *	drivers/i2c/busses/i2c-gpio.c:MODULE_ALIAS("platform:i2c-gpio");
+ */
+MODULE_ALIAS("platform:gpio-i2c");
diff --git a/drivers/i2c/busses/i2c-mv64xxx.c b/drivers/i2c/busses/i2c-mv64xxx.c
index a5a95ea5b81a..c1269e8de6ac 100644
--- a/drivers/i2c/busses/i2c-mv64xxx.c
+++ b/drivers/i2c/busses/i2c-mv64xxx.c
@@ -17,6 +17,7 @@
 #include <linux/interrupt.h>
 #include <linux/mv643xx_i2c.h>
 #include <linux/platform_device.h>
+#include <linux/pinctrl/consumer.h>
 #include <linux/reset.h>
 #include <linux/io.h>
 #include <linux/of.h>
@@ -136,6 +137,7 @@ struct mv64xxx_i2c_data {
 	u32			freq_n;
 	struct clk              *clk;
 	struct clk              *reg_clk;
+	struct clk              *axi_clk;
 	wait_queue_head_t	waitq;
 	spinlock_t		lock;
 	struct i2c_msg		*msg;
@@ -147,6 +149,7 @@ struct mv64xxx_i2c_data {
 	bool			irq_clear_inverted;
 	/* Clk div is 2 to the power n, not 2 to the power n + 1 */
 	bool			clk_n_base_0;
+	struct i2c_bus_recovery_info	rinfo;
 };
 
 static struct mv64xxx_i2c_regs mv64xxx_i2c_regs_mv64xxx = {
@@ -325,7 +328,8 @@ mv64xxx_i2c_fsm(struct mv64xxx_i2c_data *drv_data, u32 status)
 			 drv_data->msg->flags);
 		drv_data->action = MV64XXX_I2C_ACTION_SEND_STOP;
 		mv64xxx_i2c_hw_init(drv_data);
-		drv_data->rc = -EIO;
+		i2c_recover_bus(&drv_data->adapter);
+		drv_data->rc = -EAGAIN;
 	}
 }
 
@@ -437,6 +441,8 @@ mv64xxx_i2c_read_offload_rx_data(struct mv64xxx_i2c_data *drv_data,
 
 	buf[0] = readl(drv_data->reg_base + MV64XXX_I2C_REG_RX_DATA_LO);
 	buf[1] = readl(drv_data->reg_base + MV64XXX_I2C_REG_RX_DATA_HI);
+	buf[0] = le32_to_cpu(buf[0]);
+	buf[1] = le32_to_cpu(buf[1]);
 
 	memcpy(msg->buf, buf, msg->len);
 }
@@ -563,6 +569,7 @@ mv64xxx_i2c_wait_for_completion(struct mv64xxx_i2c_data *drv_data)
 				"time_left: %d\n", drv_data->block,
 				(int)time_left);
 			mv64xxx_i2c_hw_init(drv_data);
+			i2c_recover_bus(&drv_data->adapter);
 		}
 	} else
 		spin_unlock_irqrestore(&drv_data->lock, flags);
@@ -591,9 +598,11 @@ static void
 mv64xxx_i2c_prepare_tx(struct mv64xxx_i2c_data *drv_data)
 {
 	struct i2c_msg *msg = drv_data->msgs;
-	u32 buf[2];
+	u32 buf[2] = {0};
 
 	memcpy(buf, msg->buf, msg->len);
+	buf[0] = cpu_to_le32(buf[0]);
+	buf[1] = cpu_to_le32(buf[1]);
 
 	writel(buf[0], drv_data->reg_base + MV64XXX_I2C_REG_TX_DATA_LO);
 	writel(buf[1], drv_data->reg_base + MV64XXX_I2C_REG_TX_DATA_HI);
@@ -872,6 +881,25 @@ mv64xxx_of_config(struct mv64xxx_i2c_data *drv_data,
 }
 #endif /* CONFIG_OF */
 
+static int mv64xxx_i2c_init_recovery_info(struct mv64xxx_i2c_data *drv_data,
+					  struct device *dev)
+{
+	struct i2c_bus_recovery_info *rinfo = &drv_data->rinfo;
+
+	rinfo->pinctrl = devm_pinctrl_get(dev);
+	if (IS_ERR(rinfo->pinctrl)) {
+		if (PTR_ERR(rinfo->pinctrl) == -EPROBE_DEFER)
+			return -EPROBE_DEFER;
+		dev_info(dev, "can't get pinctrl, bus recovery not supported\n");
+		return PTR_ERR(rinfo->pinctrl);
+	} else if (!rinfo->pinctrl) {
+		return -ENODEV;
+	}
+
+	drv_data->adapter.bus_recovery_info = rinfo;
+	return 0;
+}
+
 static int
 mv64xxx_i2c_probe(struct platform_device *pd)
 {
@@ -913,6 +941,14 @@ mv64xxx_i2c_probe(struct platform_device *pd)
 	if (!IS_ERR(drv_data->reg_clk))
 		clk_prepare_enable(drv_data->reg_clk);
 
+	drv_data->axi_clk = devm_clk_get(&pd->dev, "axi");
+	if (IS_ERR(drv_data->axi_clk) &&
+	    PTR_ERR(drv_data->axi_clk) == -EPROBE_DEFER) {
+		return -EPROBE_DEFER;
+	}
+	if (!IS_ERR(drv_data->axi_clk))
+		clk_prepare_enable(drv_data->axi_clk);
+
 	drv_data->irq = platform_get_irq(pd, 0);
 
 	if (pdata) {
@@ -931,6 +967,10 @@ mv64xxx_i2c_probe(struct platform_device *pd)
 		goto exit_reset;
 	}
 
+	rc = mv64xxx_i2c_init_recovery_info(drv_data, &pd->dev);
+	if (rc == -EPROBE_DEFER)
+		goto exit_reset;
+
 	drv_data->adapter.dev.parent = &pd->dev;
 	drv_data->adapter.algo = &mv64xxx_i2c_algo;
 	drv_data->adapter.owner = THIS_MODULE;
@@ -962,6 +1002,7 @@ mv64xxx_i2c_probe(struct platform_device *pd)
 exit_reset:
 	reset_control_assert(drv_data->rstc);
 exit_clk:
+	clk_disable_unprepare(drv_data->axi_clk);
 	clk_disable_unprepare(drv_data->reg_clk);
 	clk_disable_unprepare(drv_data->clk);
 
@@ -976,6 +1017,7 @@ mv64xxx_i2c_remove(struct platform_device *dev)
 	i2c_del_adapter(&drv_data->adapter);
 	free_irq(drv_data->irq, drv_data);
 	reset_control_assert(drv_data->rstc);
+	clk_disable_unprepare(drv_data->axi_clk);
 	clk_disable_unprepare(drv_data->reg_clk);
 	clk_disable_unprepare(drv_data->clk);
 
diff --git a/drivers/i2c/i2c-core-base.c b/drivers/i2c/i2c-core-base.c
index f225bef1e043..0df8c4543d84 100644
--- a/drivers/i2c/i2c-core-base.c
+++ b/drivers/i2c/i2c-core-base.c
@@ -40,6 +40,7 @@
 #include <linux/of_device.h>
 #include <linux/of.h>
 #include <linux/of_irq.h>
+#include <linux/pinctrl/consumer.h>
 #include <linux/pm_domain.h>
 #include <linux/pm_runtime.h>
 #include <linux/pm_wakeirq.h>
@@ -189,6 +190,8 @@ int i2c_generic_scl_recovery(struct i2c_adapter *adap)
 
 	if (bri->prepare_recovery)
 		bri->prepare_recovery(adap);
+	if (bri->pinctrl)
+		pinctrl_select_state(bri->pinctrl, bri->pins_gpio);
 
 	/*
 	 * If we can set SDA, we will always create a STOP to ensure additional
@@ -198,6 +201,8 @@ int i2c_generic_scl_recovery(struct i2c_adapter *adap)
 	 * here for simplicity.
 	 */
 	bri->set_scl(adap, scl);
+	if (bri->set_sda)
+		bri->set_sda(adap, 1);
 	ndelay(RECOVERY_NDELAY);
 	if (bri->set_sda)
 		bri->set_sda(adap, scl);
@@ -244,6 +249,8 @@ int i2c_generic_scl_recovery(struct i2c_adapter *adap)
 
 	if (bri->unprepare_recovery)
 		bri->unprepare_recovery(adap);
+	if (bri->pinctrl)
+		pinctrl_select_state(bri->pinctrl, bri->pins_default);
 
 	return ret;
 }
@@ -259,13 +266,135 @@ int i2c_recover_bus(struct i2c_adapter *adap)
 }
 EXPORT_SYMBOL_GPL(i2c_recover_bus);
 
-static void i2c_init_recovery(struct i2c_adapter *adap)
+static void i2c_gpio_init_pinctrl_recovery(struct i2c_adapter *adap)
+{
+	struct i2c_bus_recovery_info *bri = adap->bus_recovery_info;
+	struct device *dev = &adap->dev;
+	struct pinctrl *p = bri->pinctrl;
+
+	/*
+	 * we can't change states without pinctrl, so remove the states if
+	 * populated
+	 */
+	if (!p) {
+		bri->pins_default = NULL;
+		bri->pins_gpio = NULL;
+		return;
+	}
+
+	if (!bri->pins_default) {
+		bri->pins_default = pinctrl_lookup_state(p,
+							 PINCTRL_STATE_DEFAULT);
+		if (IS_ERR(bri->pins_default)) {
+			dev_dbg(dev, PINCTRL_STATE_DEFAULT " state not found for GPIO recovery\n");
+			bri->pins_default = NULL;
+		}
+	}
+	if (!bri->pins_gpio) {
+		bri->pins_gpio = pinctrl_lookup_state(p, "gpio");
+		if (IS_ERR(bri->pins_gpio))
+			bri->pins_gpio = pinctrl_lookup_state(p, "recovery");
+
+		if (IS_ERR(bri->pins_gpio)) {
+			dev_dbg(dev, "no gpio or recovery state found for GPIO recovery\n");
+			bri->pins_gpio = NULL;
+		}
+	}
+
+	/* for pinctrl state changes, we need all the information */
+	if (bri->pins_default && bri->pins_gpio) {
+		dev_info(dev, "using pinctrl states for GPIO recovery");
+	} else {
+		bri->pinctrl = NULL;
+		bri->pins_default = NULL;
+		bri->pins_gpio = NULL;
+	}
+}
+
+static int i2c_gpio_init_generic_recovery(struct i2c_adapter *adap)
+{
+	struct i2c_bus_recovery_info *bri = adap->bus_recovery_info;
+	struct device *dev = &adap->dev;
+	struct gpio_desc *gpiod;
+	int ret = 0;
+
+	/*
+	 * don't touch the recovery information if the driver is not using
+	 * generic SCL recovery
+	 */
+	if (bri->recover_bus && bri->recover_bus != i2c_generic_scl_recovery)
+		return 0;
+
+	/*
+	 * pins might be taken as GPIO, so we should inform pinctrl about
+	 * this and move the state to GPIO
+	 */
+	if (bri->pinctrl)
+		pinctrl_select_state(bri->pinctrl, bri->pins_gpio);
+
+	/*
+	 * if there is incomplete or no recovery information, see if generic
+	 * GPIO recovery is available
+	 */
+	if (!bri->scl_gpiod) {
+		gpiod = devm_gpiod_get(dev, "scl", GPIOD_OUT_HIGH_OPEN_DRAIN);
+		if (PTR_ERR(gpiod) == -EPROBE_DEFER) {
+			ret  = -EPROBE_DEFER;
+			goto cleanup_pinctrl_state;
+		}
+		if (!IS_ERR(gpiod)) {
+			bri->scl_gpiod = gpiod;
+			bri->recover_bus = i2c_generic_scl_recovery;
+			dev_info(dev, "using generic GPIOs for recovery\n");
+		}
+	}
+
+	/* SDA GPIOD line is optional, so we care about DEFER only */
+	if (!bri->sda_gpiod) {
+		/*
+		 * We have SCL. Pull SCL low and wait a bit so that SDA glitches
+		 * have no effect.
+		 */
+		gpiod_direction_output(bri->scl_gpiod, 0);
+		udelay(10);
+		gpiod = devm_gpiod_get(dev, "sda", GPIOD_IN);
+
+		/* Wait a bit in case of a SDA glitch, and then release SCL. */
+		udelay(10);
+		gpiod_direction_output(bri->scl_gpiod, 1);
+
+		if (PTR_ERR(gpiod) == -EPROBE_DEFER) {
+			ret = -EPROBE_DEFER;
+			goto cleanup_pinctrl_state;
+		}
+		if (!IS_ERR(gpiod))
+			bri->sda_gpiod = gpiod;
+	}
+
+cleanup_pinctrl_state:
+	/* change the state of the pins back to their default state */
+	if (bri->pinctrl)
+		pinctrl_select_state(bri->pinctrl, bri->pins_default);
+
+	return ret;
+}
+
+static int i2c_gpio_init_recovery(struct i2c_adapter *adap)
+{
+	i2c_gpio_init_pinctrl_recovery(adap);
+	return i2c_gpio_init_generic_recovery(adap);
+}
+
+static int i2c_init_recovery(struct i2c_adapter *adap)
 {
 	struct i2c_bus_recovery_info *bri = adap->bus_recovery_info;
 	char *err_str;
 
 	if (!bri)
-		return;
+		return 0;
+
+	if (i2c_gpio_init_recovery(adap) == -EPROBE_DEFER)
+		return -EPROBE_DEFER;
 
 	if (!bri->recover_bus) {
 		err_str = "no recover_bus() found";
@@ -296,10 +425,12 @@ static void i2c_init_recovery(struct i2c_adapter *adap)
 		}
 	}
 
-	return;
+	return 0;
  err:
 	dev_err(&adap->dev, "Not using recovery: %s\n", err_str);
 	adap->bus_recovery_info = NULL;
+
+	return -EINVAL;
 }
 
 static int i2c_smbus_host_notify_to_irq(const struct i2c_client *client)
@@ -1280,6 +1411,12 @@ static int i2c_register_adapter(struct i2c_adapter *adap)
 	pm_suspend_ignore_children(&adap->dev, true);
 	pm_runtime_enable(&adap->dev);
 
+	res = i2c_init_recovery(adap);
+	if (res == -EPROBE_DEFER)
+		goto out_reg;
+
+	dev_dbg(&adap->dev, "adapter [%s] registered\n", adap->name);
+
 #ifdef CONFIG_I2C_COMPAT
 	res = class_compat_create_link(i2c_adapter_compat_class, &adap->dev,
 				       adap->dev.parent);
@@ -1288,12 +1425,10 @@ static int i2c_register_adapter(struct i2c_adapter *adap)
 			 "Failed to create compatibility class link\n");
 #endif
 
-	i2c_init_recovery(adap);
-
 	/* create pre-declared device nodes */
 	of_i2c_register_devices(adap);
-	i2c_acpi_register_devices(adap);
 	i2c_acpi_install_space_handler(adap);
+	i2c_acpi_register_devices(adap);
 
 	if (adap->nr < __i2c_first_dynamic_bus_num)
 		i2c_scan_static_board_info(adap);
diff --git a/drivers/irqchip/Kconfig b/drivers/irqchip/Kconfig
index 8cb6800dbdfb..7fb4578cbebe 100644
--- a/drivers/irqchip/Kconfig
+++ b/drivers/irqchip/Kconfig
@@ -310,6 +310,9 @@ config MVEBU_ODMI
 config MVEBU_PIC
 	bool
 
+config MVEBU_SEI
+        bool
+
 config LS_SCFG_MSI
 	def_bool y if SOC_LS1021A || ARCH_LAYERSCAPE
 	depends on PCI && PCI_MSI
diff --git a/drivers/irqchip/Makefile b/drivers/irqchip/Makefile
index fbd1ec8070ef..022d05871c21 100644
--- a/drivers/irqchip/Makefile
+++ b/drivers/irqchip/Makefile
@@ -27,8 +27,8 @@ obj-$(CONFIG_ARM_GIC)			+= irq-gic.o irq-gic-common.o
 obj-$(CONFIG_ARM_GIC_PM)		+= irq-gic-pm.o
 obj-$(CONFIG_ARCH_REALVIEW)		+= irq-gic-realview.o
 obj-$(CONFIG_ARM_GIC_V2M)		+= irq-gic-v2m.o
-obj-$(CONFIG_ARM_GIC_V3)		+= irq-gic-v3.o irq-gic-v3-mbi.o irq-gic-common.o
-obj-$(CONFIG_ARM_GIC_V3_ITS)		+= irq-gic-v3-its.o irq-gic-v3-its-platform-msi.o irq-gic-v4.o
+obj-$(CONFIG_ARM_GIC_V3)		+= irq-gic-v3.o irq-gic-v3-mbi.o irq-gic-common.o irq-gic-v3-quirks.o
+obj-$(CONFIG_ARM_GIC_V3_ITS)		+= irq-gic-v3-its.o irq-gic-v3-its-pci-msi.o irq-gic-v3-its-platform-msi.o irq-gic-v4.o
 obj-$(CONFIG_ARM_GIC_V3_ITS_PCI)	+= irq-gic-v3-its-pci-msi.o
 obj-$(CONFIG_ARM_GIC_V3_ITS_FSL_MC)	+= irq-gic-v3-its-fsl-mc-msi.o
 obj-$(CONFIG_PARTITION_PERCPU)		+= irq-partition-percpu.o
@@ -76,6 +76,7 @@ obj-$(CONFIG_MVEBU_GICP)		+= irq-mvebu-gicp.o
 obj-$(CONFIG_MVEBU_ICU)			+= irq-mvebu-icu.o
 obj-$(CONFIG_MVEBU_ODMI)		+= irq-mvebu-odmi.o
 obj-$(CONFIG_MVEBU_PIC)			+= irq-mvebu-pic.o
+obj-$(CONFIG_MVEBU_SEI)			+= irq-mvebu-sei.o
 obj-$(CONFIG_LS_SCFG_MSI)		+= irq-ls-scfg-msi.o
 obj-$(CONFIG_EZNPS_GIC)			+= irq-eznps.o
 obj-$(CONFIG_ARCH_ASPEED)		+= irq-aspeed-vic.o irq-aspeed-i2c-ic.o
diff --git a/drivers/irqchip/irq-gic-v2m.c b/drivers/irqchip/irq-gic-v2m.c
index f5fe0100f9ff..0f52d44b3f69 100644
--- a/drivers/irqchip/irq-gic-v2m.c
+++ b/drivers/irqchip/irq-gic-v2m.c
@@ -199,7 +199,7 @@ static int gicv2m_irq_domain_alloc(struct irq_domain *domain, unsigned int virq,
 
 fail:
 	irq_domain_free_irqs_parent(domain, virq, nr_irqs);
-	gicv2m_unalloc_msi(v2m, hwirq, nr_irqs);
+	gicv2m_unalloc_msi(v2m, hwirq, get_count_order(nr_irqs));
 	return err;
 }
 
diff --git a/drivers/irqchip/irq-gic-v3-its.c b/drivers/irqchip/irq-gic-v3-its.c
index d5cc32e80f5e..66fe075bde89 100644
--- a/drivers/irqchip/irq-gic-v3-its.c
+++ b/drivers/irqchip/irq-gic-v3-its.c
@@ -1906,6 +1906,11 @@ static int its_alloc_tables(struct its_node *its)
 		/* erratum 24313: ignore memory access type */
 		cache = GITS_BASER_nCnB;
 
+	if (its->flags & ITS_FLAGS_SAVE_SUSPEND_STATE) {
+		shr = GITS_BASER_NonShareable;
+		cache = GITS_BASER_nCnB;
+	}
+
 	for (i = 0; i < GITS_BASER_NR_REGS; i++) {
 		struct its_baser *baser = its->tables + i;
 		u64 val = its_read_baser(its, baser);
@@ -3174,6 +3179,19 @@ static bool __maybe_unused its_enable_quirk_hip07_161600802(void *data)
 	return true;
 }
 
+static bool __maybe_unused its_enable_quirk_mvebu(void *data)
+{
+	struct its_node *its = data;
+
+	/*
+	 * Enable MVEBU workaround to flush the command
+	 * queue & ITS translation table
+	 */
+	its->flags |= ITS_FLAGS_SAVE_SUSPEND_STATE;
+
+	return true;
+}
+
 static const struct gic_quirk its_quirks[] = {
 #ifdef CONFIG_CAVIUM_ERRATUM_22375
 	{
@@ -3221,6 +3239,10 @@ static const struct gic_quirk its_quirks[] = {
 	},
 #endif
 	{
+		.desc	= "ITS: Marvell workaround errata",
+		.iidr	= 0x0201043B, /* r1p0 revision ID for Marvell release */
+		.mask	= 0xffffffff,
+		.init	= its_enable_quirk_mvebu,
 	}
 };
 
@@ -3547,10 +3569,29 @@ static int __init its_probe_one(struct resource *res,
 			baser |= GITS_CBASER_nC;
 			gits_write_cbaser(baser, its->base + GITS_CBASER);
 		}
-		pr_info("ITS: using cache flushing for cmd queue\n");
 		its->flags |= ITS_FLAGS_CMDQ_NEEDS_FLUSHING;
 	}
 
+	/*
+	 * In Marvell case it was architecturally-defined that  GIC
+	 * support Shareability & Cacheability but due to fabric signals
+	 * issue, the HW allows to enable those bits (falsely), which
+	 * will lead to not enabling ITS_FLAGS_CMDQ_NEEDS_FLUSHING.
+	 * but due to that missing fabric signals, Marvell implementation
+	 * requires enabling ITS_FLAGS_CMDQ_NEEDS_FLUSHING.
+	 */
+	if (its->flags & ITS_FLAGS_SAVE_SUSPEND_STATE) {
+		its->flags |= ITS_FLAGS_CMDQ_NEEDS_FLUSHING;
+
+		baser &= ~(GITS_CBASER_SHAREABILITY_MASK |
+			   GITS_CBASER_CACHEABILITY_MASK);
+		baser |= GITS_CBASER_nCnB | GITS_CBASER_NonShareable;
+		writeq_relaxed(baser, its->base + GITS_CBASER);
+	}
+
+	if (its->flags & ITS_FLAGS_CMDQ_NEEDS_FLUSHING)
+		pr_info("ITS: using cache flushing for cmd queue\n");
+
 	gits_write_cwriter(0, its->base + GITS_CWRITER);
 	ctlr = readl_relaxed(its->base + GITS_CTLR);
 	ctlr |= GITS_CTLR_ENABLE;
diff --git a/drivers/irqchip/irq-gic-v3-quirks.c b/drivers/irqchip/irq-gic-v3-quirks.c
new file mode 100644
index 000000000000..d028e4531157
--- /dev/null
+++ b/drivers/irqchip/irq-gic-v3-quirks.c
@@ -0,0 +1,161 @@
+// SPDX-License-Identifier: GPL-2.0
+
+/* GIC quirks
+ *
+ * Copyright (C) 2020 Marvell International Ltd.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ */
+
+#include <linux/delay.h>
+#include <linux/io.h>
+
+#include <linux/irqchip.h>
+#include <linux/irqchip/arm-gic-common.h>
+#include <linux/irqchip/arm-gic-v3.h>
+
+#include "irq-gic-common.h"
+#include "irq-gic-v3-quirks.h"
+
+enum ipi_msg_type {
+	IPI_RESCHEDULE,
+	IPI_CALL_FUNC,
+	IPI_CPU_STOP,
+	IPI_CPU_CRASH_STOP,
+	IPI_TIMER,
+	IPI_IRQ_WORK,
+	IPI_WAKEUP,
+	NR_IPIS
+};
+
+struct gic_ipi_track {
+	atomic_t tx_count;
+	atomic_t rx_count;
+	spinlock_t lock;
+};
+
+static struct gic_ipi_track gic_ipitrack[NR_CPUS][NR_IPIS];
+
+static inline void gic_ipi_txcount_inc(int cpu, int irq)
+{
+	atomic_inc(&gic_ipitrack[cpu][irq].tx_count);
+}
+
+void gic_ipi_rxcount_inc(int cpu, int irq)
+{
+	atomic_inc(&gic_ipitrack[cpu][irq].rx_count);
+}
+
+static inline void gic_ipi_count_reset(int cpu, int irq)
+{
+	atomic_set(&gic_ipitrack[cpu][irq].tx_count, 0x0);
+	atomic_set(&gic_ipitrack[cpu][irq].rx_count, 0x0);
+}
+
+static inline bool is_gic_ipi_received(int dest_cpu, int irq)
+{
+	int retry_count = 0xf;
+
+retry:
+	if (gic_rdist_pend_reg(dest_cpu, 0x0) & (1 << irq))
+		return true;
+
+	if (gic_rdist_active_reg(dest_cpu, 0x0) & (1 << irq))
+		return true;
+	smp_rmb(); /* Ensure pend/active reg read happens first */
+
+	if (atomic_read(&gic_ipitrack[dest_cpu][irq].tx_count) ==
+		atomic_read(&gic_ipitrack[dest_cpu][irq].rx_count))
+		return true;
+
+	if (!retry_count)
+		return false;
+
+	retry_count--;
+	goto retry;
+}
+
+void gic_write_sgi1r_retry(int dest_cpu, int irq, u64 val)
+{
+	unsigned long flags;
+
+	spin_lock_irqsave(&gic_ipitrack[dest_cpu][irq].lock, flags);
+	wmb(); /* Ensure lock is acquired before we generate an IPI */
+retry:
+	gic_write_sgi1r(val);
+	isb(); /* Ensure sgi write is completed before pending/active read */
+	gic_ipi_txcount_inc(dest_cpu, irq);
+	if (is_gic_ipi_received(dest_cpu, irq))
+		goto out;
+
+	/* Seems we have lost an interrupt
+	 * Reset and start again
+	 */
+	gic_ipi_count_reset(dest_cpu, irq);
+	wmb(); /* Ensure the write is completed before we start again */
+	goto retry;
+out:
+	spin_unlock_irqrestore(&gic_ipitrack[dest_cpu][irq].lock, flags);
+}
+
+static bool gicv3_enable_quirk_otx2(void *data)
+{
+	int cpu, ipi;
+
+	gic_v3_enable_ipimiss_quirk();
+
+	/* Initialize necessary lock */
+	for_each_possible_cpu(cpu)
+		for (ipi = 0; ipi < NR_IPIS; ipi++)
+			spin_lock_init(&gic_ipitrack[cpu][ipi].lock);
+
+	return true;
+}
+
+static const struct gic_quirk gicv3_quirks[] = {
+	{
+		.desc	= "GIC V3: IPI Miss",
+		.iidr	= 0xb100034c,
+		.mask	= 0xff000fff,
+		.init	= gicv3_enable_quirk_otx2,
+	},
+	{
+		.desc	= "GIC V3: IPI Miss",
+		.iidr	= 0xb200034c,
+		.mask	= 0xff000fff,
+		.init	= gicv3_enable_quirk_otx2,
+	},
+	{
+		.desc	= "GIC V3: IPI Miss",
+		.iidr	= 0xb300034c,
+		.mask	= 0xff000fff,
+		.init	= gicv3_enable_quirk_otx2,
+	},
+	{
+		.desc	= "GIC V3: IPI Miss",
+		.iidr	= 0xb400034c,
+		.mask	= 0xff000fff,
+		.init	= gicv3_enable_quirk_otx2,
+	},
+	{
+		.desc	= "GIC V3: IPI Miss",
+		.iidr	= 0xb500034c,
+		.mask	= 0xff000fff,
+		.init	= gicv3_enable_quirk_otx2,
+	},
+	{ /* NULL entry */
+		0,
+		0,
+		0,
+		0,
+	}
+};
+
+void gic_v3_enable_quirks(void __iomem *base)
+{
+	u32 iidr = readl_relaxed(base + GICD_IIDR);
+
+	gic_enable_quirks(iidr, gicv3_quirks, NULL);
+}
diff --git a/drivers/irqchip/irq-gic-v3-quirks.h b/drivers/irqchip/irq-gic-v3-quirks.h
new file mode 100644
index 000000000000..bb2548c161d7
--- /dev/null
+++ b/drivers/irqchip/irq-gic-v3-quirks.h
@@ -0,0 +1,25 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+
+/* GIC quirks
+ *
+ * Copyright (C) 2020 Marvell International Ltd.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ */
+
+#ifndef __IRQCHIP_IRQ_GIC_V3_QUIRKS__
+#define __IRQCHIP_IRQ_GIC_V3_QUIRKS__
+
+#define GICV3_QUIRK_IPI_MISS	(1 << 0)
+
+u32 gic_rdist_pend_reg(int cpu, int offset);
+u32 gic_rdist_active_reg(int cpu, int offset);
+
+void gic_ipi_rxcount_inc(int cpu, int irq);
+void gic_write_sgi1r_retry(int dest_cpu, int irq, u64 val);
+void gic_v3_enable_quirks(void __iomem *base);
+void gic_v3_enable_ipimiss_quirk(void);
+
+#endif
diff --git a/drivers/irqchip/irq-gic-v3.c b/drivers/irqchip/irq-gic-v3.c
index ac888d7a0b00..2d351aa30998 100644
--- a/drivers/irqchip/irq-gic-v3.c
+++ b/drivers/irqchip/irq-gic-v3.c
@@ -40,6 +40,7 @@
 #include <asm/virt.h>
 
 #include "irq-gic-common.h"
+#include "irq-gic-v3-quirks.h"
 
 struct redist_region {
 	void __iomem		*redist_base;
@@ -61,6 +62,8 @@ struct gic_chip_data {
 };
 
 static struct gic_chip_data gic_data __read_mostly;
+static struct static_key supports_deactivate = STATIC_KEY_INIT_TRUE;
+DEFINE_STATIC_KEY_FALSE(gic_ipimiss_quirk);
 static DEFINE_STATIC_KEY_TRUE(supports_deactivate_key);
 
 static struct gic_kvm_info gic_v3_kvm_info;
@@ -71,9 +74,39 @@ static DEFINE_PER_CPU(bool, has_rss);
 #define gic_data_rdist_rd_base()	(gic_data_rdist()->rd_base)
 #define gic_data_rdist_sgi_base()	(gic_data_rdist_rd_base() + SZ_64K)
 
+#define gic_data_rdist_cpu(cpu)		\
+				(per_cpu_ptr(gic_data.rdists.rdist, cpu))
+#define gic_data_rdist_rd_base_cpu(cpu)	\
+				(gic_data_rdist_cpu(cpu)->rd_base)
+#define gic_data_rdist_sgi_base_cpu(cpu)\
+				(gic_data_rdist_rd_base_cpu(cpu) + SZ_64K)
+
 /* Our default, arbitrary priority value. Linux only uses one anyway. */
 #define DEFAULT_PMR_VALUE	0xf0
 
+void gic_v3_enable_ipimiss_quirk(void)
+{
+	static_branch_enable(&gic_ipimiss_quirk);
+}
+
+u32 gic_rdist_pend_reg(int cpu, int offset)
+{
+	void __iomem *base;
+
+	base = gic_data_rdist_sgi_base_cpu(cpu);
+
+	return readl_relaxed(base + GICR_ISPENDR0 + offset);
+}
+
+u32 gic_rdist_active_reg(int cpu, int offset)
+{
+	void __iomem *base;
+
+	base = gic_data_rdist_sgi_base_cpu(cpu);
+
+	return readl_relaxed(base + GICR_ISACTIVER0 + offset);
+}
+
 static inline unsigned int gic_irq(struct irq_data *d)
 {
 	return d->hwirq;
@@ -372,6 +405,11 @@ static asmlinkage void __exception_irq_entry gic_handle_irq(struct pt_regs *regs
 			continue;
 		}
 		if (irqnr < 16) {
+			if (static_branch_likely(&gic_ipimiss_quirk)) {
+				gic_ipi_rxcount_inc(smp_processor_id(), irqnr);
+				/* Force increment is done before deactivate */
+				wmb();
+			}
 			gic_write_eoir(irqnr);
 			if (static_branch_likely(&supports_deactivate_key))
 				gic_write_dir(irqnr);
@@ -398,6 +436,8 @@ static void __init gic_dist_init(void)
 	u64 affinity;
 	void __iomem *base = gic_data.dist_base;
 
+	gic_v3_enable_quirks(base);
+
 	/* Disable the distributor */
 	writel_relaxed(0, base + GICD_CTLR);
 	gic_dist_wait_for_rwp();
@@ -702,6 +742,10 @@ static u16 gic_compute_target_list(int *base_cpu, const struct cpumask *mask,
 	while (cpu < nr_cpu_ids) {
 		tlist |= 1 << (mpidr & 0xf);
 
+		if (static_branch_likely(&gic_ipimiss_quirk))
+			/* Force only one target at a time */
+			goto out;
+
 		next_cpu = cpumask_next(cpu, mask);
 		if (next_cpu >= nr_cpu_ids)
 			goto out;
@@ -722,8 +766,8 @@ static u16 gic_compute_target_list(int *base_cpu, const struct cpumask *mask,
 #define MPIDR_TO_SGI_AFFINITY(cluster_id, level) \
 	(MPIDR_AFFINITY_LEVEL(cluster_id, level) \
 		<< ICC_SGI1R_AFFINITY_## level ##_SHIFT)
-
-static void gic_send_sgi(u64 cluster_id, u16 tlist, unsigned int irq)
+static void gic_send_sgi(int dest_cpu, u64 cluster_id, u16 tlist,
+			 unsigned int irq)
 {
 	u64 val;
 
@@ -735,7 +779,10 @@ static void gic_send_sgi(u64 cluster_id, u16 tlist, unsigned int irq)
 	       tlist << ICC_SGI1R_TARGET_LIST_SHIFT);
 
 	pr_devel("CPU%d: ICC_SGI1R_EL1 %llx\n", smp_processor_id(), val);
-	gic_write_sgi1r(val);
+	if (static_branch_likely(&gic_ipimiss_quirk))
+		gic_write_sgi1r_retry(dest_cpu, irq, val);
+	else
+		gic_write_sgi1r(val);
 }
 
 static void gic_raise_softirq(const struct cpumask *mask, unsigned int irq)
@@ -756,9 +803,12 @@ static void gic_raise_softirq(const struct cpumask *mask, unsigned int irq)
 		u16 tlist;
 
 		tlist = gic_compute_target_list(&cpu, mask, cluster_id);
-		gic_send_sgi(cluster_id, tlist, irq);
+		gic_send_sgi(cpu, cluster_id, tlist, irq);
 	}
 
+	if (static_branch_likely(&gic_ipimiss_quirk))
+		return;
+
 	/* Force the above writes to ICC_SGI1R_EL1 to be executed */
 	isb();
 }
diff --git a/drivers/irqchip/irq-mvebu-icu.c b/drivers/irqchip/irq-mvebu-icu.c
index a2a3acd74491..5732bc6be808 100644
--- a/drivers/irqchip/irq-mvebu-icu.c
+++ b/drivers/irqchip/irq-mvebu-icu.c
@@ -36,6 +36,9 @@
 #define ICU_SATA0_ICU_ID	109
 #define ICU_SATA1_ICU_ID	107
 
+/* AP810 ICU entries from CP110 are consecutive */
+#define ICU_GIC_SPI_AP810_BASE		160
+
 struct mvebu_icu {
 	struct irq_chip irq_chip;
 	void __iomem *base;
@@ -74,6 +77,27 @@ static void mvebu_icu_write_msg(struct msi_desc *desc, struct msi_msg *msg)
 		mvebu_icu_init(icu, msg);
 		/* Configure the ICU with irq number & type */
 		icu_int = msg->data | ICU_INT_ENABLE;
+		/*
+		 * identify if it's a CP110 connected to AP810 or CP110
+		 * connected to AP806, since they differ in relevance to how
+		 * they are connected to AP GIC entries.
+		 * ICU interrupts in AP806 are written to GIC-P,
+		 * by writing only source ID, than the GIC-P remaps these
+		 * interrupt IDs, according to AP806 GIC assignments:
+		 * - 0-31 : PPI/SGI
+		 * - 32-64: AP interrupts
+		 * So the remap was done internally by HW.
+		 *
+		 * For AP810, there is no GIC-P in between, and the ICU writes
+		 * the message directly to the GIC, so the differences are:
+		 * 1. AP810 GIC has 92 interrupt entries, pre-assigned to:
+		 * 0-31 : PPI/SGI
+		 * 32-92: AP interrupts
+		 * 2. ICU need to write message ID directly to GIC, hence it
+		 * should also increase the GIC entries ID by 92, by SW
+		 */
+		if (of_machine_is_compatible("marvell,armada-ap810"))
+			icu_int += ICU_GIC_SPI_AP810_BASE;
 		if (icu_irqd->type & IRQ_TYPE_EDGE_RISING)
 			icu_int |= ICU_IS_EDGE;
 		icu_int |= icu_irqd->icu_group << ICU_GROUP_SHIFT;
diff --git a/drivers/irqchip/irq-mvebu-pic.c b/drivers/irqchip/irq-mvebu-pic.c
index eec63951129a..eca1a6edf49c 100644
--- a/drivers/irqchip/irq-mvebu-pic.c
+++ b/drivers/irqchip/irq-mvebu-pic.c
@@ -188,7 +188,19 @@ static struct platform_driver mvebu_pic_driver = {
 		.of_match_table = mvebu_pic_of_match,
 	},
 };
-module_platform_driver(mvebu_pic_driver);
+
+static int __init mvebu_pic_driver_init(void)
+{
+	return platform_driver_register(&mvebu_pic_driver);
+}
+
+static void __exit mvebu_pic_driver_exit(void)
+{
+	return platform_driver_unregister(&mvebu_pic_driver);
+}
+
+arch_initcall(mvebu_pic_driver_init)
+module_exit(mvebu_pic_driver_exit)
 
 MODULE_AUTHOR("Yehuda Yitschak <yehuday@marvell.com>");
 MODULE_AUTHOR("Thomas Petazzoni <thomas.petazzoni@free-electrons.com>");
diff --git a/drivers/irqchip/irq-mvebu-sei.c b/drivers/irqchip/irq-mvebu-sei.c
new file mode 100644
index 000000000000..18832ccc8ff8
--- /dev/null
+++ b/drivers/irqchip/irq-mvebu-sei.c
@@ -0,0 +1,507 @@
+// SPDX-License-Identifier: GPL-2.0
+
+#define pr_fmt(fmt) "mvebu-sei: " fmt
+
+#include <linux/interrupt.h>
+#include <linux/irq.h>
+#include <linux/irqchip.h>
+#include <linux/irqchip/chained_irq.h>
+#include <linux/irqdomain.h>
+#include <linux/kernel.h>
+#include <linux/msi.h>
+#include <linux/platform_device.h>
+#include <linux/of_address.h>
+#include <linux/of_irq.h>
+#include <linux/of_platform.h>
+
+/* Cause register */
+#define GICP_SECR(idx)		(0x0  + ((idx) * 0x4))
+/* Mask register */
+#define GICP_SEMR(idx)		(0x20 + ((idx) * 0x4))
+#define GICP_SET_SEI_OFFSET	0x30
+
+#define SEI_IRQ_COUNT_PER_REG	32
+#define SEI_IRQ_REG_COUNT	2
+#define SEI_IRQ_COUNT		(SEI_IRQ_COUNT_PER_REG * SEI_IRQ_REG_COUNT)
+#define SEI_IRQ_REG_IDX(irq_id)	((irq_id) / SEI_IRQ_COUNT_PER_REG)
+#define SEI_IRQ_REG_BIT(irq_id)	((irq_id) % SEI_IRQ_COUNT_PER_REG)
+
+struct mvebu_sei_interrupt_range {
+	u32 first;
+	u32 size;
+};
+
+struct mvebu_sei_caps {
+	struct mvebu_sei_interrupt_range ap_range;
+	struct mvebu_sei_interrupt_range cp_range;
+};
+
+struct mvebu_sei {
+	struct device *dev;
+	void __iomem *base;
+	struct resource *res;
+	struct irq_domain *sei_domain;
+	struct irq_domain *ap_domain;
+	struct irq_domain *cp_domain;
+	const struct mvebu_sei_caps *caps;
+
+	/* Lock on MSI allocations/releases */
+	struct mutex cp_msi_lock;
+	DECLARE_BITMAP(cp_msi_bitmap, SEI_IRQ_COUNT);
+
+	/* Lock on IRQ masking register */
+	raw_spinlock_t mask_lock;
+};
+
+static void mvebu_sei_ack_irq(struct irq_data *d)
+{
+	struct mvebu_sei *sei = irq_data_get_irq_chip_data(d);
+	u32 reg_idx = SEI_IRQ_REG_IDX(d->hwirq);
+
+	writel_relaxed(BIT(SEI_IRQ_REG_BIT(d->hwirq)),
+		       sei->base + GICP_SECR(reg_idx));
+}
+
+static void mvebu_sei_mask_irq(struct irq_data *d)
+{
+	struct mvebu_sei *sei = irq_data_get_irq_chip_data(d);
+	u32 reg, reg_idx = SEI_IRQ_REG_IDX(d->hwirq);
+	unsigned long flags;
+
+	/* 1 disables the interrupt */
+	raw_spin_lock_irqsave(&sei->mask_lock, flags);
+	reg = readl_relaxed(sei->base + GICP_SEMR(reg_idx));
+	reg |= BIT(SEI_IRQ_REG_BIT(d->hwirq));
+	writel_relaxed(reg, sei->base + GICP_SEMR(reg_idx));
+	raw_spin_unlock_irqrestore(&sei->mask_lock, flags);
+}
+
+static void mvebu_sei_unmask_irq(struct irq_data *d)
+{
+	struct mvebu_sei *sei = irq_data_get_irq_chip_data(d);
+	u32 reg, reg_idx = SEI_IRQ_REG_IDX(d->hwirq);
+	unsigned long flags;
+
+	/* 0 enables the interrupt */
+	raw_spin_lock_irqsave(&sei->mask_lock, flags);
+	reg = readl_relaxed(sei->base + GICP_SEMR(reg_idx));
+	reg &= ~BIT(SEI_IRQ_REG_BIT(d->hwirq));
+	writel_relaxed(reg, sei->base + GICP_SEMR(reg_idx));
+	raw_spin_unlock_irqrestore(&sei->mask_lock, flags);
+}
+
+static int mvebu_sei_set_affinity(struct irq_data *d,
+				  const struct cpumask *mask_val,
+				  bool force)
+{
+	return -EINVAL;
+}
+
+static int mvebu_sei_set_irqchip_state(struct irq_data *d,
+				       enum irqchip_irq_state which,
+				       bool state)
+{
+	/* We can only clear the pending state by acking the interrupt */
+	if (which != IRQCHIP_STATE_PENDING || state)
+		return -EINVAL;
+
+	mvebu_sei_ack_irq(d);
+	return 0;
+}
+
+static struct irq_chip mvebu_sei_irq_chip = {
+	.name			= "SEI",
+	.irq_ack		= mvebu_sei_ack_irq,
+	.irq_mask		= mvebu_sei_mask_irq,
+	.irq_unmask		= mvebu_sei_unmask_irq,
+	.irq_set_affinity       = mvebu_sei_set_affinity,
+	.irq_set_irqchip_state	= mvebu_sei_set_irqchip_state,
+};
+
+static int mvebu_sei_ap_set_type(struct irq_data *data, unsigned int type)
+{
+	if ((type & IRQ_TYPE_SENSE_MASK) != IRQ_TYPE_LEVEL_HIGH)
+		return -EINVAL;
+
+	return 0;
+}
+
+static struct irq_chip mvebu_sei_ap_irq_chip = {
+	.name			= "AP SEI",
+	.irq_ack		= irq_chip_ack_parent,
+	.irq_mask		= irq_chip_mask_parent,
+	.irq_unmask		= irq_chip_unmask_parent,
+	.irq_set_affinity       = irq_chip_set_affinity_parent,
+	.irq_set_type		= mvebu_sei_ap_set_type,
+};
+
+static void mvebu_sei_cp_compose_msi_msg(struct irq_data *data,
+					 struct msi_msg *msg)
+{
+	struct mvebu_sei *sei = data->chip_data;
+	phys_addr_t set = sei->res->start + GICP_SET_SEI_OFFSET;
+
+	msg->data = data->hwirq + sei->caps->cp_range.first;
+	msg->address_lo = lower_32_bits(set);
+	msg->address_hi = upper_32_bits(set);
+}
+
+static int mvebu_sei_cp_set_type(struct irq_data *data, unsigned int type)
+{
+	if ((type & IRQ_TYPE_SENSE_MASK) != IRQ_TYPE_EDGE_RISING)
+		return -EINVAL;
+
+	return 0;
+}
+
+static struct irq_chip mvebu_sei_cp_irq_chip = {
+	.name			= "CP SEI",
+	.irq_ack		= irq_chip_ack_parent,
+	.irq_mask		= irq_chip_mask_parent,
+	.irq_unmask		= irq_chip_unmask_parent,
+	.irq_set_affinity       = irq_chip_set_affinity_parent,
+	.irq_set_type		= mvebu_sei_cp_set_type,
+	.irq_compose_msi_msg	= mvebu_sei_cp_compose_msi_msg,
+};
+
+static int mvebu_sei_domain_alloc(struct irq_domain *domain, unsigned int virq,
+				  unsigned int nr_irqs, void *arg)
+{
+	struct mvebu_sei *sei = domain->host_data;
+	struct irq_fwspec *fwspec = arg;
+
+	/* Not much to do, just setup the irqdata */
+	irq_domain_set_hwirq_and_chip(domain, virq, fwspec->param[0],
+				      &mvebu_sei_irq_chip, sei);
+
+	return 0;
+}
+
+static void mvebu_sei_domain_free(struct irq_domain *domain, unsigned int virq,
+				  unsigned int nr_irqs)
+{
+	int i;
+
+	for (i = 0; i < nr_irqs; i++) {
+		struct irq_data *d = irq_domain_get_irq_data(domain, virq + i);
+		irq_set_handler(virq + i, NULL);
+		irq_domain_reset_irq_data(d);
+	}
+}
+
+static const struct irq_domain_ops mvebu_sei_domain_ops = {
+	.alloc	= mvebu_sei_domain_alloc,
+	.free	= mvebu_sei_domain_free,
+};
+
+static int mvebu_sei_ap_translate(struct irq_domain *domain,
+				  struct irq_fwspec *fwspec,
+				  unsigned long *hwirq,
+				  unsigned int *type)
+{
+	*hwirq = fwspec->param[0];
+	*type  = IRQ_TYPE_LEVEL_HIGH;
+
+	return 0;
+}
+
+static int mvebu_sei_ap_alloc(struct irq_domain *domain, unsigned int virq,
+			      unsigned int nr_irqs, void *arg)
+{
+	struct mvebu_sei *sei = domain->host_data;
+	struct irq_fwspec fwspec;
+	unsigned long hwirq;
+	unsigned int type;
+	int err;
+
+	mvebu_sei_ap_translate(domain, arg, &hwirq, &type);
+
+	fwspec.fwnode = domain->parent->fwnode;
+	fwspec.param_count = 1;
+	fwspec.param[0] = hwirq + sei->caps->ap_range.first;
+
+	err = irq_domain_alloc_irqs_parent(domain, virq, 1, &fwspec);
+	if (err)
+		return err;
+
+	irq_domain_set_info(domain, virq, hwirq,
+			    &mvebu_sei_ap_irq_chip, sei,
+			    handle_level_irq, NULL, NULL);
+	irq_set_probe(virq);
+
+	return 0;
+}
+
+static const struct irq_domain_ops mvebu_sei_ap_domain_ops = {
+	.translate	= mvebu_sei_ap_translate,
+	.alloc		= mvebu_sei_ap_alloc,
+	.free		= irq_domain_free_irqs_parent,
+};
+
+static void mvebu_sei_cp_release_irq(struct mvebu_sei *sei, unsigned long hwirq)
+{
+	mutex_lock(&sei->cp_msi_lock);
+	clear_bit(hwirq, sei->cp_msi_bitmap);
+	mutex_unlock(&sei->cp_msi_lock);
+}
+
+static int mvebu_sei_cp_domain_alloc(struct irq_domain *domain,
+				     unsigned int virq, unsigned int nr_irqs,
+				     void *args)
+{
+	struct mvebu_sei *sei = domain->host_data;
+	struct irq_fwspec fwspec;
+	unsigned long hwirq;
+	int ret;
+
+	/* The software only supports single allocations for now */
+	if (nr_irqs != 1)
+		return -ENOTSUPP;
+
+	mutex_lock(&sei->cp_msi_lock);
+	hwirq = find_first_zero_bit(sei->cp_msi_bitmap,
+				    sei->caps->cp_range.size);
+	if (hwirq < sei->caps->cp_range.size)
+		set_bit(hwirq, sei->cp_msi_bitmap);
+	mutex_unlock(&sei->cp_msi_lock);
+
+	if (hwirq == sei->caps->cp_range.size)
+		return -ENOSPC;
+
+	fwspec.fwnode = domain->parent->fwnode;
+	fwspec.param_count = 1;
+	fwspec.param[0] = hwirq + sei->caps->cp_range.first;
+
+	ret = irq_domain_alloc_irqs_parent(domain, virq, 1, &fwspec);
+	if (ret)
+		goto free_irq;
+
+	irq_domain_set_info(domain, virq, hwirq,
+			    &mvebu_sei_cp_irq_chip, sei,
+			    handle_edge_irq, NULL, NULL);
+
+	return 0;
+
+free_irq:
+	mvebu_sei_cp_release_irq(sei, hwirq);
+	return ret;
+}
+
+static void mvebu_sei_cp_domain_free(struct irq_domain *domain,
+				     unsigned int virq, unsigned int nr_irqs)
+{
+	struct mvebu_sei *sei = domain->host_data;
+	struct irq_data *d = irq_domain_get_irq_data(domain, virq);
+
+	if (nr_irqs != 1 || d->hwirq >= sei->caps->cp_range.size) {
+		dev_err(sei->dev, "Invalid hwirq %lu\n", d->hwirq);
+		return;
+	}
+
+	mvebu_sei_cp_release_irq(sei, d->hwirq);
+	irq_domain_free_irqs_parent(domain, virq, 1);
+}
+
+static const struct irq_domain_ops mvebu_sei_cp_domain_ops = {
+	.alloc	= mvebu_sei_cp_domain_alloc,
+	.free	= mvebu_sei_cp_domain_free,
+};
+
+static struct irq_chip mvebu_sei_msi_irq_chip = {
+	.name		= "SEI pMSI",
+	.irq_ack	= irq_chip_ack_parent,
+	.irq_set_type	= irq_chip_set_type_parent,
+};
+
+static struct msi_domain_ops mvebu_sei_msi_ops = {
+};
+
+static struct msi_domain_info mvebu_sei_msi_domain_info = {
+	.flags	= MSI_FLAG_USE_DEF_DOM_OPS | MSI_FLAG_USE_DEF_CHIP_OPS,
+	.ops	= &mvebu_sei_msi_ops,
+	.chip	= &mvebu_sei_msi_irq_chip,
+};
+
+static void mvebu_sei_handle_cascade_irq(struct irq_desc *desc)
+{
+	struct mvebu_sei *sei = irq_desc_get_handler_data(desc);
+	struct irq_chip *chip = irq_desc_get_chip(desc);
+	u32 idx;
+
+	chained_irq_enter(chip, desc);
+
+	for (idx = 0; idx < SEI_IRQ_REG_COUNT; idx++) {
+		unsigned long irqmap;
+		int bit;
+
+		irqmap = readl_relaxed(sei->base + GICP_SECR(idx));
+		for_each_set_bit(bit, &irqmap, SEI_IRQ_COUNT_PER_REG) {
+			unsigned long hwirq;
+			unsigned int virq;
+
+			hwirq = idx * SEI_IRQ_COUNT_PER_REG + bit;
+			virq = irq_find_mapping(sei->sei_domain, hwirq);
+			if (likely(virq)) {
+				generic_handle_irq(virq);
+				continue;
+			}
+
+			dev_warn(sei->dev,
+				 "Spurious IRQ detected (hwirq %lu)\n", hwirq);
+		}
+	}
+
+	chained_irq_exit(chip, desc);
+}
+
+static void mvebu_sei_reset(struct mvebu_sei *sei)
+{
+	u32 reg_idx;
+
+	/* Clear IRQ cause registers, mask all interrupts */
+	for (reg_idx = 0; reg_idx < SEI_IRQ_REG_COUNT; reg_idx++) {
+		writel_relaxed(0xFFFFFFFF, sei->base + GICP_SECR(reg_idx));
+		writel_relaxed(0xFFFFFFFF, sei->base + GICP_SEMR(reg_idx));
+	}
+}
+
+static int mvebu_sei_probe(struct platform_device *pdev)
+{
+	struct device_node *node = pdev->dev.of_node;
+	struct irq_domain *plat_domain;
+	struct mvebu_sei *sei;
+	u32 parent_irq;
+	int ret;
+
+	sei = devm_kzalloc(&pdev->dev, sizeof(*sei), GFP_KERNEL);
+	if (!sei)
+		return -ENOMEM;
+
+	sei->dev = &pdev->dev;
+
+	mutex_init(&sei->cp_msi_lock);
+	raw_spin_lock_init(&sei->mask_lock);
+
+	sei->res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	sei->base = devm_ioremap_resource(sei->dev, sei->res);
+	if (IS_ERR(sei->base)) {
+		dev_err(sei->dev, "Failed to remap SEI resource\n");
+		return PTR_ERR(sei->base);
+	}
+
+	/* Retrieve the SEI capabilities with the interrupt ranges */
+	sei->caps = of_device_get_match_data(&pdev->dev);
+	if (!sei->caps) {
+		dev_err(sei->dev,
+			"Could not retrieve controller capabilities\n");
+		return -EINVAL;
+	}
+
+	/*
+	 * Reserve the single (top-level) parent SPI IRQ from which all the
+	 * interrupts handled by this driver will be signaled.
+	 */
+	parent_irq = irq_of_parse_and_map(node, 0);
+	if (parent_irq <= 0) {
+		dev_err(sei->dev, "Failed to retrieve top-level SPI IRQ\n");
+		return -ENODEV;
+	}
+
+	/* Create the root SEI domain */
+	sei->sei_domain = irq_domain_create_linear(of_node_to_fwnode(node),
+						   (sei->caps->ap_range.size +
+						    sei->caps->cp_range.size),
+						   &mvebu_sei_domain_ops,
+						   sei);
+	if (!sei->sei_domain) {
+		dev_err(sei->dev, "Failed to create SEI IRQ domain\n");
+		ret = -ENOMEM;
+		goto dispose_irq;
+	}
+
+	irq_domain_update_bus_token(sei->sei_domain, DOMAIN_BUS_NEXUS);
+
+	/* Create the 'wired' domain */
+	sei->ap_domain = irq_domain_create_hierarchy(sei->sei_domain, 0,
+						     sei->caps->ap_range.size,
+						     of_node_to_fwnode(node),
+						     &mvebu_sei_ap_domain_ops,
+						     sei);
+	if (!sei->ap_domain) {
+		dev_err(sei->dev, "Failed to create AP IRQ domain\n");
+		ret = -ENOMEM;
+		goto remove_sei_domain;
+	}
+
+	irq_domain_update_bus_token(sei->ap_domain, DOMAIN_BUS_WIRED);
+
+	/* Create the 'MSI' domain */
+	sei->cp_domain = irq_domain_create_hierarchy(sei->sei_domain, 0,
+						     sei->caps->cp_range.size,
+						     of_node_to_fwnode(node),
+						     &mvebu_sei_cp_domain_ops,
+						     sei);
+	if (!sei->cp_domain) {
+		pr_err("Failed to create CPs IRQ domain\n");
+		ret = -ENOMEM;
+		goto remove_ap_domain;
+	}
+
+	irq_domain_update_bus_token(sei->cp_domain, DOMAIN_BUS_GENERIC_MSI);
+
+	plat_domain = platform_msi_create_irq_domain(of_node_to_fwnode(node),
+						     &mvebu_sei_msi_domain_info,
+						     sei->cp_domain);
+	if (!plat_domain) {
+		pr_err("Failed to create CPs MSI domain\n");
+		ret = -ENOMEM;
+		goto remove_cp_domain;
+	}
+
+	mvebu_sei_reset(sei);
+
+	irq_set_chained_handler_and_data(parent_irq,
+					 mvebu_sei_handle_cascade_irq,
+					 sei);
+
+	return 0;
+
+remove_cp_domain:
+	irq_domain_remove(sei->cp_domain);
+remove_ap_domain:
+	irq_domain_remove(sei->ap_domain);
+remove_sei_domain:
+	irq_domain_remove(sei->sei_domain);
+dispose_irq:
+	irq_dispose_mapping(parent_irq);
+
+	return ret;
+}
+
+static struct mvebu_sei_caps mvebu_sei_ap806_caps = {
+	.ap_range = {
+		.first = 0,
+		.size = 21,
+	},
+	.cp_range = {
+		.first = 21,
+		.size = 43,
+	},
+};
+
+static const struct of_device_id mvebu_sei_of_match[] = {
+	{
+		.compatible = "marvell,ap806-sei",
+		.data = &mvebu_sei_ap806_caps,
+	},
+	{},
+};
+
+static struct platform_driver mvebu_sei_driver = {
+	.probe  = mvebu_sei_probe,
+	.driver = {
+		.name = "mvebu-sei",
+		.of_match_table = mvebu_sei_of_match,
+	},
+};
+builtin_platform_driver(mvebu_sei_driver);
diff --git a/drivers/misc/Kconfig b/drivers/misc/Kconfig
index 3726eacdf65d..c1ae6d9b31b8 100644
--- a/drivers/misc/Kconfig
+++ b/drivers/misc/Kconfig
@@ -509,10 +509,20 @@ config PCI_ENDPOINT_TEST
            Enable this configuration option to enable the host side test driver
            for PCI Endpoint.
 
+
+config MVEBU_SOC_INFO
+	bool "Marvell Aramda-8K SoC information driver"
+	depends on ARCH_MVEBU
+	default y
+	help
+	  Marvell A8K SoC information driver
+
+
 config MISC_RTSX
 	tristate
 	default MISC_RTSX_PCI || MISC_RTSX_USB
 
+source "drivers/misc/mvebu/Kconfig"
 source "drivers/misc/c2port/Kconfig"
 source "drivers/misc/eeprom/Kconfig"
 source "drivers/misc/cb710/Kconfig"
diff --git a/drivers/misc/Makefile b/drivers/misc/Makefile
index af22bbc3d00c..e56ea1435a45 100644
--- a/drivers/misc/Makefile
+++ b/drivers/misc/Makefile
@@ -56,5 +56,6 @@ obj-$(CONFIG_CXL_BASE)		+= cxl/
 obj-$(CONFIG_ASPEED_LPC_CTRL)	+= aspeed-lpc-ctrl.o
 obj-$(CONFIG_ASPEED_LPC_SNOOP)	+= aspeed-lpc-snoop.o
 obj-$(CONFIG_PCI_ENDPOINT_TEST)	+= pci_endpoint_test.o
+obj-y				+= mvebu/
 obj-$(CONFIG_OCXL)		+= ocxl/
 obj-$(CONFIG_MISC_RTSX)		+= cardreader/
diff --git a/drivers/misc/mvebu/Kconfig b/drivers/misc/mvebu/Kconfig
new file mode 100644
index 000000000000..9f9bcf92f284
--- /dev/null
+++ b/drivers/misc/mvebu/Kconfig
@@ -0,0 +1,17 @@
+# MISC MVEBU
+
+config MVEBU_SOC_INFO
+	bool "Marvell Aramda-8K SoC information driver"
+	depends on ARCH_MVEBU
+	default y
+	help
+	  Marvell A8K SoC information driver
+
+config MVEBU_A8K_DEBUGFS
+	bool "Marvell Aramda-8K debugfs driver"
+	depends on ARCH_MVEBU && ARM64
+	default y
+	help
+	  Debugfs interface for Marvell's Armada-8K SoCs.
+	  This drivers provide access (status and configuration) to
+	  some SoC status and configuration registers.
diff --git a/drivers/misc/mvebu/Makefile b/drivers/misc/mvebu/Makefile
new file mode 100644
index 000000000000..cffbbe10342b
--- /dev/null
+++ b/drivers/misc/mvebu/Makefile
@@ -0,0 +1,2 @@
+obj-$(CONFIG_MVEBU_SOC_INFO)	+= mv_soc_info.o
+obj-$(CONFIG_MVEBU_A8K_DEBUGFS)	+= mvebu-a8k-debugfs.o
diff --git a/drivers/misc/mvebu/mv_soc_info.c b/drivers/misc/mvebu/mv_soc_info.c
new file mode 100644
index 000000000000..6d2779bc16ba
--- /dev/null
+++ b/drivers/misc/mvebu/mv_soc_info.c
@@ -0,0 +1,78 @@
+/*
+ * Copyright (C) 2015-2018 Marvell International Ltd.
+
+ * This program is free software: you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License as
+ * published by the Free Software Foundation, either version 2 of the
+ * License, or any later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * General Public License for more details.
+ */
+
+#include <linux/mv_soc_info.h>
+#include <linux/of_address.h>
+
+int soc_revision_id = -1;
+
+/* Get SoC revision ID */
+int mv_soc_info_get_ap_revision(void)
+{
+	void __iomem *ap_rev_info_reg;
+	const unsigned int *reg;
+	struct device_node *node;
+	phys_addr_t paddr;
+
+	/* if soc_revision_id was already initialized,
+	 * no need to read it again
+	 */
+	if (soc_revision_id != -1)
+		return soc_revision_id;
+
+	/* TODO add support for CP110, CP115, AP807 and AP810 revisions */
+	node = of_find_compatible_node(NULL, NULL, "marvell,ap806-rev-info");
+	if (!node) {
+		pr_err("Read soc-rev-info node failed\n");
+		goto free_node;
+	}
+
+	/* Read the offset of the register */
+	reg = of_get_property(node, "reg", NULL);
+	if (!reg) {
+		pr_err("Read reg property failed from soc-rev-info node\n");
+		goto free_node;
+	}
+
+	/* Translate the offset to physical address */
+	paddr = of_translate_address(node, reg);
+	if (paddr == OF_BAD_ADDR) {
+		pr_err("of_translate_address failed for soc-rev-info\n");
+		goto free_node;
+	}
+
+	ap_rev_info_reg = ioremap(paddr, reg[1]);
+	if (!ap_rev_info_reg) {
+		pr_err("ioremap() failed for soc-rev-info register\n");
+		goto free_node;
+	}
+
+	/* read gwd_iidr2 register and set the revision global*/
+	soc_revision_id = (readl(ap_rev_info_reg) >>
+			   GWD_IIDR2_REV_ID_OFFSET) &
+			   GWD_IIDR2_REV_ID_MASK;
+
+	pr_debug("%s: Detected SoC revision A%d\n",
+		 __func__, soc_revision_id == APN806_REV_ID_A0 ? 0 : 1);
+
+	/* Release resources */
+	iounmap(ap_rev_info_reg);
+	of_node_put(node);
+
+	return soc_revision_id;
+
+free_node:
+	of_node_put(node);
+	return -EINVAL;
+}
diff --git a/drivers/misc/mvebu/mvebu-a8k-debugfs.c b/drivers/misc/mvebu/mvebu-a8k-debugfs.c
new file mode 100644
index 000000000000..4254ca15f6f7
--- /dev/null
+++ b/drivers/misc/mvebu/mvebu-a8k-debugfs.c
@@ -0,0 +1,312 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * Copyright (C) 2018 Marvell
+ */
+
+#define pr_fmt(fmt) KBUILD_MODNAME ": " fmt
+
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/debugfs.h>
+#include <linux/uaccess.h>
+#include <linux/ioctl.h>
+
+struct mvebu_a8k_state {
+	struct dentry *debugfs_root;
+	struct dentry *debugfs_ap;
+	struct dentry *debugfs_sysregs;
+	struct dentry *debugfs_debug;
+};
+
+struct sysreg_entry {
+	char name[32];
+	char desc[128];
+	u64 (*read_func)(void);
+	void (*write_func)(u64);
+};
+
+/* Control structure */
+static struct mvebu_a8k_state a8k_state;
+
+/*
+ * The below macros provide a generic way for creating system registers
+ * read / write function, without the need to explicitly write them.
+ */
+#define SYSREG_READ_ASM(v, code)		\
+		asm volatile("mrs %0, " __stringify(code) : "=r" (v))
+
+#define SYSREG_WRITE_ASM(v, code)		\
+		asm volatile("msr " __stringify(code) ", %0" : : "r" (v))
+
+#define DECLARE_RD_WR_FUNC(code)		\
+	static u64 read_##code(void)		\
+	{					\
+		u64 v;				\
+		SYSREG_READ_ASM(v, code);	\
+		return v;			\
+	}					\
+	static void write_##code(u64 v)		\
+	{					\
+		SYSREG_WRITE_ASM(v, code);	\
+	}
+
+/*
+ * This will result in definining a read / write function for
+ * each of the system registers below.
+ */
+DECLARE_RD_WR_FUNC(midr_el1);
+DECLARE_RD_WR_FUNC(mpidr_el1);
+DECLARE_RD_WR_FUNC(sctlr_el1);
+DECLARE_RD_WR_FUNC(s3_1_c15_c0_0);
+DECLARE_RD_WR_FUNC(s3_1_c11_c0_2);
+DECLARE_RD_WR_FUNC(s3_1_c11_c0_3);
+DECLARE_RD_WR_FUNC(s3_1_c15_c2_1);
+DECLARE_RD_WR_FUNC(s3_1_c15_c2_0);
+
+
+#define SYSREG_ENTRY(code, _desc)		\
+	{					\
+		.name = __stringify(code),	\
+		.desc = _desc,			\
+		.read_func = &read_##code,	\
+		.write_func = &write_##code	\
+	}
+
+static struct sysreg_entry sysregs_list[] = {
+	SYSREG_ENTRY(midr_el1, "Main ID"),
+	SYSREG_ENTRY(mpidr_el1, "Multiprocessor Affinity"),
+	SYSREG_ENTRY(sctlr_el1, "System Ctrl"),
+	SYSREG_ENTRY(s3_1_c15_c0_0, "L2 Aux Ctrl"),
+	SYSREG_ENTRY(s3_1_c11_c0_2, "L2 Ctrl"),
+	SYSREG_ENTRY(s3_1_c11_c0_3, "L2 Ext Ctrl"),
+	SYSREG_ENTRY(s3_1_c15_c2_1, "CPU Ext Ctrl"),
+	SYSREG_ENTRY(s3_1_c15_c2_0, "CPU Aux Ctrl"),
+};
+
+
+static int mvebu_ap806_sysregs_debug_show(struct seq_file *seq, void *v)
+{
+	u64 val;
+	int i;
+
+	seq_puts(seq, "System Registers Dump:\n");
+	for (i = 0; i < ARRAY_SIZE(sysregs_list); i++) {
+		seq_printf(seq, "%s\t\t- ", sysregs_list[i].name);
+		val = sysregs_list[i].read_func();
+		seq_printf(seq, "0x%016llx", val);
+		seq_printf(seq, " (%s).\n", sysregs_list[i].desc);
+	}
+
+	return 0;
+}
+
+/*
+ * Write to a specific system register:
+ * e.g.
+ * # echo s3_1_c15_c0_0 0x42 > ap806/sysregs
+ */
+static ssize_t mvebu_ap806_sysregs_debug_write(struct file *f,
+		const char __user *user_buf, size_t count, loff_t *ppos)
+{
+	char buf[64];
+	u32 val32;
+	u64 val64;
+	char *start, *end;
+	int len, found, i;
+	size_t cnt = min(count, sizeof(buf)-1);
+
+	if (copy_from_user(buf, user_buf, cnt))
+		return -EFAULT;
+	buf[cnt] = '\0';
+
+	start = buf;
+	/* Get sysreg name */
+	end = memscan(start, ' ', cnt);
+	len = end - start;
+	if (len > cnt) {
+		pr_err("Bad command.\n");
+		return count;
+	}
+
+	found = 0;
+	for (i = 0; i < ARRAY_SIZE(sysregs_list); i++) {
+		if (strncmp(sysregs_list[i].name, start, len))
+			continue;
+		found = 1;
+		break;
+	}
+
+	start = end;
+	/* Skip all spaces between sysreg name and value. */
+	while (start[0] == ' ')
+		start++;
+
+	if (found) {
+		if (kstrtou32(start, 16, &val32)) {
+			pr_err("Bad value.\n");
+			return count;
+		}
+
+		pr_info("Writing 0x%08x to %s.\n", val32, sysregs_list[i].name);
+		val64 = (u64)val32;
+
+		sysregs_list[i].write_func(val64);
+
+		pr_info("New value %s - 0x%016llx.\n", sysregs_list[i].name,
+				sysregs_list[i].read_func());
+	} else {
+		pr_err("Bad system register name.\n");
+	}
+
+	return count;
+}
+
+
+static int mvebu_ap806_sysregs_debug_open(struct inode *inode,
+		struct file *file)
+{
+	return single_open(file, mvebu_ap806_sysregs_debug_show,
+			inode->i_private);
+}
+
+static const struct file_operations mvebu_ap806_sysregs_debug_fops = {
+	.open = mvebu_ap806_sysregs_debug_open,
+	.read = seq_read,
+	.write = mvebu_ap806_sysregs_debug_write,
+	.llseek = seq_lseek,
+	.release = single_release,
+};
+
+#define MVEBU_DBG_VA2PA		_IOWR('q', 1, struct va2pa_args *)
+
+#define VA2PA_TYPE_USER		0
+#define VA2PA_TYPE_KERNEL	1
+
+#define BMVAL(val, lsb, msb)	((val & GENMASK(msb, lsb)) >> lsb)
+#define BMVAL_64(val, lsb, msb)	((val & GENMASK_ULL(msb, lsb)) >> lsb)
+
+#define PAR_EL1_FAULT_BIT	0
+#define PAR_EL1_FST_START	1
+#define PAR_EL1_FST_END		6
+#define PAR_EL1_SHA_START	7
+#define PAR_EL1_SHA_END		8
+#define PAR_EL1_NS_BIT		9
+#define PAR_EL1_PA_START	12
+#define PAR_EL1_PA_END		47
+#define PAR_EL1_MAIR_START	56
+#define PAR_EL1_MAIR_END	63
+
+struct va2pa_args {
+	void *va;
+	void *pa;
+	int type;
+	u8  esr_fault;
+	bool non_secure;
+	u8   sharability;
+	u8   mair;
+};
+
+static long _mvebu_debug_va2pa(struct va2pa_args *va2pa)
+{
+	u64 pa, par_el1;
+
+	switch (va2pa->type) {
+	case VA2PA_TYPE_USER:
+		asm volatile("at s1e0r, %0" :: "r" (va2pa->va));
+		goto translate;
+
+	case VA2PA_TYPE_KERNEL:
+		asm volatile("at s1e1r, %0" :: "r" (va2pa->va));
+		goto translate;
+
+	default:
+		pr_err("bad translation type %d\n", va2pa->type);
+		return -EINVAL;
+	}
+
+translate:
+	asm volatile("mrs %0, par_el1" : "=r" (par_el1));
+
+	/* Check if translation was sucessfull */
+	if (BMVAL(par_el1, PAR_EL1_FAULT_BIT, PAR_EL1_FAULT_BIT)) {
+		va2pa->pa = (void *)~0ULL;
+		va2pa->esr_fault =
+			BMVAL(par_el1, PAR_EL1_FST_START, PAR_EL1_FST_END);
+		return -EFAULT;
+	}
+
+	/* lowest 12 bits are offset inside page so
+	 * take them from the virtual address
+	 */
+	pa = BMVAL_64(par_el1, PAR_EL1_PA_START, PAR_EL1_PA_END) << 12;
+	va2pa->pa = (void *)(pa | BMVAL((u64)va2pa->va, 0, 11));
+
+	/* Figure out the attributes */
+	va2pa->sharability = BMVAL(par_el1, PAR_EL1_SHA_START, PAR_EL1_SHA_END);
+	va2pa->non_secure = BMVAL(par_el1, PAR_EL1_NS_BIT, PAR_EL1_NS_BIT);
+	va2pa->mair = BMVAL(par_el1, PAR_EL1_MAIR_START, PAR_EL1_MAIR_END);
+
+	return 0;
+}
+
+static long mvebu_debug_va2pa(unsigned long arg)
+{
+	struct va2pa_args va2pa;
+	char __user *argp = (char __user *)arg;
+	int ret;
+
+	if (copy_from_user(&va2pa, argp, sizeof(struct va2pa_args))) {
+		pr_err("Failed to copy from user\n");
+		return -EFAULT;
+	}
+
+	ret = _mvebu_debug_va2pa(&va2pa);
+	if (ret)
+		return ret;
+
+	if (copy_to_user(argp, &va2pa, sizeof(struct va2pa_args))) {
+		pr_err("Failed to copy to user\n");
+		return -EFAULT;
+	}
+
+	return 0;
+}
+
+static long mvebu_debug_ioctl(struct file *file,
+		unsigned int cmd, unsigned long arg)
+{
+
+	switch (cmd) {
+
+	case MVEBU_DBG_VA2PA:
+		return mvebu_debug_va2pa(arg);
+
+	default:
+		pr_err("unknown debug ioctl\n");
+		return -EINVAL;
+	}
+
+}
+static const struct file_operations mvebu_debug_fops = {
+	.unlocked_ioctl = mvebu_debug_ioctl,
+};
+
+static __init int mvebu_a8k_debugfs_init(void)
+{
+	struct mvebu_a8k_state *s = &a8k_state;
+
+	s->debugfs_root = debugfs_create_dir("mvebu", NULL);
+	s->debugfs_debug = debugfs_create_file("debug", 0660,
+			s->debugfs_root, NULL, &mvebu_debug_fops);
+	if (s->debugfs_root) {
+		s->debugfs_ap = debugfs_create_dir("ap806", s->debugfs_root);
+		s->debugfs_sysregs =
+			debugfs_create_file("sysregs", 0660, s->debugfs_ap,
+					NULL, &mvebu_ap806_sysregs_debug_fops);
+	}
+
+	return 0;
+}
+fs_initcall(mvebu_a8k_debugfs_init);
+
diff --git a/drivers/mmc/host/sdhci-xenon-phy.c b/drivers/mmc/host/sdhci-xenon-phy.c
index caccedc836dc..0987f217e453 100644
--- a/drivers/mmc/host/sdhci-xenon-phy.c
+++ b/drivers/mmc/host/sdhci-xenon-phy.c
@@ -14,6 +14,7 @@
 #include <linux/slab.h>
 #include <linux/delay.h>
 #include <linux/ktime.h>
+#include <linux/mv_soc_info.h>
 #include <linux/of_address.h>
 
 #include "sdhci-pltfm.h"
@@ -219,6 +220,24 @@ static int xenon_alloc_emmc_phy(struct sdhci_host *host)
 	return 0;
 }
 
+static int xenon_check_stability_internal_clk(struct sdhci_host *host)
+{
+	u32 reg;
+	ktime_t timeout;
+
+	/* Wait max 20 ms */
+	timeout = ktime_add_ms(ktime_get(), 20);
+	while (!((reg = sdhci_readw(host, SDHCI_CLOCK_CONTROL))
+		& SDHCI_CLOCK_INT_STABLE)) {
+		if (ktime_after(ktime_get(), timeout)) {
+			dev_err(mmc_dev(host->mmc), "phy_init: Internal clock never stabilised.\n");
+			return -ETIMEDOUT;
+		}
+		usleep_range(900, 1100);
+	}
+	return 0;
+}
+
 /*
  * eMMC 5.0/5.1 PHY init/re-init.
  * eMMC PHY init should be executed after:
@@ -229,12 +248,16 @@ static int xenon_alloc_emmc_phy(struct sdhci_host *host)
  */
 static int xenon_emmc_phy_init(struct sdhci_host *host)
 {
-	u32 reg;
-	u32 wait, clock;
+	int ret;
+	u32 reg, wait, clock;
 	struct sdhci_pltfm_host *pltfm_host = sdhci_priv(host);
 	struct xenon_priv *priv = sdhci_pltfm_priv(pltfm_host);
 	struct xenon_emmc_phy_regs *phy_regs = priv->emmc_phy_regs;
 
+	ret = xenon_check_stability_internal_clk(host);
+	if (ret)
+		return ret;
+
 	reg = sdhci_readl(host, phy_regs->timing_adj);
 	reg |= XENON_PHY_INITIALIZAION;
 	sdhci_writel(host, reg, phy_regs->timing_adj);
@@ -699,7 +722,12 @@ static int xenon_emmc_phy_parse_param_dt(struct sdhci_host *host,
 	u32 value;
 
 	params->slow_mode = false;
-	if (of_property_read_bool(np, "marvell,xenon-phy-slow-mode"))
+	/* Activate slow mode unconditionally for AP806 A0 and A1, but not B0.
+	 * For any revision honor the explicit request for the slow mode
+	 */
+	if ((of_device_is_compatible(np, "marvell,armada-ap806-sdhci") &&
+	    mv_soc_info_get_ap_revision() < APN806_REV_ID_B0) ||
+	    of_property_read_bool(np, "marvell,xenon-phy-slow-mode"))
 		params->slow_mode = true;
 
 	params->znr = XENON_ZNR_DEF_VALUE;
diff --git a/drivers/mmc/host/sdhci-xenon.c b/drivers/mmc/host/sdhci-xenon.c
index fafb02644efd..03f893b9a5f1 100644
--- a/drivers/mmc/host/sdhci-xenon.c
+++ b/drivers/mmc/host/sdhci-xenon.c
@@ -17,6 +17,7 @@
 #include <linux/delay.h>
 #include <linux/ktime.h>
 #include <linux/module.h>
+#include <linux/mv_soc_info.h>
 #include <linux/of.h>
 #include <linux/pm.h>
 #include <linux/pm_runtime.h>
@@ -170,7 +171,12 @@ static void xenon_reset_exit(struct sdhci_host *host,
 	/* Disable tuning request and auto-retuning again */
 	xenon_retune_setup(host);
 
-	xenon_set_acg(host, true);
+	/*
+	 * The ACG should be turned off at init time, in order to solve
+	 * 1.8v regulator stability problem. it turned On in later stage.
+	 * ACG is Automatic Clock Gating used for Power Reduction.
+	 */
+	xenon_set_acg(host, false);
 
 	xenon_set_sdclk_off_idle(host, sdhc_id, false);
 
@@ -328,8 +334,11 @@ static int xenon_start_signal_voltage_switch(struct mmc_host *mmc,
 	 * If Vqmmc is fixed on platform, vqmmc regulator should be unavailable.
 	 * Thus SDHCI_CTRL_VDD_180 bit might not work then.
 	 * Skip the standard voltage switch to avoid any issue.
+	 *
+	 * When oops_in_progress skip voltage switching since it may required
+	 * i2c blocking operation in case when vqmmc is routed via io-expanders.
 	 */
-	if (PTR_ERR(mmc->supply.vqmmc) == -ENODEV)
+	if (PTR_ERR(mmc->supply.vqmmc) == -ENODEV || oops_in_progress)
 		return 0;
 
 	return sdhci_start_signal_voltage_switch(mmc, ios);
@@ -420,9 +429,12 @@ static int xenon_probe_dt(struct platform_device *pdev)
 	u32 sdhc_id, nr_sdhc;
 	u32 tuning_count;
 
-	/* Disable HS200 on Armada AP806 */
-	if (of_device_is_compatible(np, "marvell,armada-ap806-sdhci"))
+	/* Disable HS200 on Armada AP806 A0 and A1, but not B0 */
+	if (of_device_is_compatible(np, "marvell,armada-ap806-sdhci") &&
+	    mv_soc_info_get_ap_revision() < APN806_REV_ID_B0) {
+		dev_err(mmc_dev(mmc), "AP SDHC is running in slow mode\n");
 		host->quirks2 |= SDHCI_QUIRK2_BROKEN_HS200;
+	}
 
 	sdhc_id = 0x0;
 	if (!of_property_read_u32(np, "marvell,xenon-sdhc-id", &sdhc_id)) {
@@ -671,8 +683,10 @@ static const struct dev_pm_ops sdhci_xenon_dev_pm_ops = {
 
 static const struct of_device_id sdhci_xenon_dt_ids[] = {
 	{ .compatible = "marvell,armada-ap806-sdhci",},
+	{ .compatible = "marvell,armada-ap807-sdhci",},
 	{ .compatible = "marvell,armada-cp110-sdhci",},
 	{ .compatible = "marvell,armada-3700-sdhci",},
+	{ .compatible = "marvell,armada-ap810-sdhci",},
 	{}
 };
 MODULE_DEVICE_TABLE(of, sdhci_xenon_dt_ids);
diff --git a/drivers/mtd/spi-nor/spi-nor.c b/drivers/mtd/spi-nor/spi-nor.c
index ff641c06003a..a8c30465a1aa 100644
--- a/drivers/mtd/spi-nor/spi-nor.c
+++ b/drivers/mtd/spi-nor/spi-nor.c
@@ -1088,12 +1088,14 @@ static const struct flash_info spi_nor_ids[] = {
 	{ "mx25u6435f",  INFO(0xc22537, 0, 64 * 1024, 128, SECT_4K) },
 	{ "mx25l12805d", INFO(0xc22018, 0, 64 * 1024, 256, 0) },
 	{ "mx25l12855e", INFO(0xc22618, 0, 64 * 1024, 256, 0) },
-	{ "mx25l25635e", INFO(0xc22019, 0, 64 * 1024, 512, SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ) },
+	{ "mx25l25635e", INFO(0xc22019, 0, 64 * 1024, 512, SPI_NOR_DUAL_READ |
+				 SPI_NOR_QUAD_READ | SPI_NOR_4B_OPCODES) },
 	{ "mx25u25635f", INFO(0xc22539, 0, 64 * 1024, 512, SECT_4K | SPI_NOR_4B_OPCODES) },
 	{ "mx25l25655e", INFO(0xc22619, 0, 64 * 1024, 512, 0) },
 	{ "mx66l51235l", INFO(0xc2201a, 0, 64 * 1024, 1024, SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ | SPI_NOR_4B_OPCODES) },
 	{ "mx66u51235f", INFO(0xc2253a, 0, 64 * 1024, 1024, SECT_4K | SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ | SPI_NOR_4B_OPCODES) },
-	{ "mx66l1g45g",  INFO(0xc2201b, 0, 64 * 1024, 2048, SECT_4K | SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ) },
+	{ "mx66l1g45g",  INFO(0xc2201b, 0, 64 * 1024, 2048, SECT_4K | SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ | SPI_NOR_4B_OPCODES) },
+	{ "mx66l2g45g",  INFO(0xc2201c, 0, 64 * 1024, 4096, SECT_4K | SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ | SPI_NOR_4B_OPCODES) },
 	{ "mx66l1g55g",  INFO(0xc2261b, 0, 64 * 1024, 2048, SPI_NOR_QUAD_READ) },
 
 	/* Micron */
@@ -1104,12 +1106,15 @@ static const struct flash_info spi_nor_ids[] = {
 	{ "n25q064a",    INFO(0x20bb17, 0, 64 * 1024,  128, SECT_4K | SPI_NOR_QUAD_READ) },
 	{ "n25q128a11",  INFO(0x20bb18, 0, 64 * 1024,  256, SECT_4K | SPI_NOR_QUAD_READ) },
 	{ "n25q128a13",  INFO(0x20ba18, 0, 64 * 1024,  256, SECT_4K | SPI_NOR_QUAD_READ) },
-	{ "n25q256a",    INFO(0x20ba19, 0, 64 * 1024,  512, SECT_4K | SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ) },
+	{ "n25q256a",    INFO(0x20ba19, 0, 64 * 1024,  512, SECT_4K |
+				  SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ |
+				  SPI_NOR_4B_OPCODES) },
 	{ "n25q256ax1",  INFO(0x20bb19, 0, 64 * 1024,  512, SECT_4K | SPI_NOR_QUAD_READ) },
 	{ "n25q512a",    INFO(0x20bb20, 0, 64 * 1024, 1024, SECT_4K | USE_FSR | SPI_NOR_QUAD_READ) },
 	{ "n25q512ax3",  INFO(0x20ba20, 0, 64 * 1024, 1024, SECT_4K | USE_FSR | SPI_NOR_QUAD_READ) },
-	{ "n25q00",      INFO(0x20ba21, 0, 64 * 1024, 2048, SECT_4K | USE_FSR | SPI_NOR_QUAD_READ | NO_CHIP_ERASE) },
+	{ "n25q00",      INFO(0x20ba21, 0, 64 * 1024, 2048, SECT_4K | USE_FSR | SPI_NOR_QUAD_READ | NO_CHIP_ERASE | SPI_NOR_4B_OPCODES) },
 	{ "n25q00a",     INFO(0x20bb21, 0, 64 * 1024, 2048, SECT_4K | USE_FSR | SPI_NOR_QUAD_READ | NO_CHIP_ERASE) },
+	{ "mt25ql02g",   INFO(0x20ba22, 0, 64 * 1024, 4096, SECT_4K | USE_FSR | SPI_NOR_QUAD_READ | SPI_NOR_4B_OPCODES | NO_CHIP_ERASE) },
 	{ "mt25qu02g",   INFO(0x20bb22, 0, 64 * 1024, 4096, SECT_4K | USE_FSR | SPI_NOR_QUAD_READ | NO_CHIP_ERASE) },
 
 	/* PMC */
@@ -1123,7 +1128,9 @@ static const struct flash_info spi_nor_ids[] = {
 	{ "s25sl032p",  INFO(0x010215, 0x4d00,  64 * 1024,  64, SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ) },
 	{ "s25sl064p",  INFO(0x010216, 0x4d00,  64 * 1024, 128, SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ) },
 	{ "s25fl256s0", INFO(0x010219, 0x4d00, 256 * 1024, 128, USE_CLSR) },
-	{ "s25fl256s1", INFO(0x010219, 0x4d01,  64 * 1024, 512, SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ | USE_CLSR) },
+	{ "s25fl256s1", INFO(0x010219, 0x4d01,  64 * 1024, 512,
+			  SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ |
+			  USE_CLSR | SPI_NOR_4B_OPCODES) },
 	{ "s25fl512s",  INFO(0x010220, 0x4d00, 256 * 1024, 256, SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ | USE_CLSR) },
 	{ "s70fl01gs",  INFO(0x010221, 0x4d00, 256 * 1024, 256, 0) },
 	{ "s25sl12800", INFO(0x012018, 0x0300, 256 * 1024,  64, 0) },
@@ -1242,7 +1249,9 @@ static const struct flash_info spi_nor_ids[] = {
 	{ "w25q80", INFO(0xef5014, 0, 64 * 1024,  16, SECT_4K) },
 	{ "w25q80bl", INFO(0xef4014, 0, 64 * 1024,  16, SECT_4K) },
 	{ "w25q128", INFO(0xef4018, 0, 64 * 1024, 256, SECT_4K) },
-	{ "w25q256", INFO(0xef4019, 0, 64 * 1024, 512, SECT_4K | SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ) },
+	{ "w25q256", INFO(0xef4019, 0, 64 * 1024, 512, SECT_4K |
+			SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ |
+			SPI_NOR_4B_OPCODES) },
 	{ "w25m512jv", INFO(0xef7119, 0, 64 * 1024, 1024,
 			SECT_4K | SPI_NOR_QUAD_READ | SPI_NOR_DUAL_READ) },
 
diff --git a/drivers/net/ethernet/marvell/mv643xx_eth.c b/drivers/net/ethernet/marvell/mv643xx_eth.c
index 59007d6cd36d..2434409f84b2 100644
--- a/drivers/net/ethernet/marvell/mv643xx_eth.c
+++ b/drivers/net/ethernet/marvell/mv643xx_eth.c
@@ -1346,9 +1346,9 @@ static void mib_counters_update(struct mv643xx_eth_private *mp)
 	spin_unlock_bh(&mp->mib_counters_lock);
 }
 
-static void mib_counters_timer_wrapper(struct timer_list *t)
+static void mib_counters_timer_wrapper(unsigned long _mp)
 {
-	struct mv643xx_eth_private *mp = from_timer(mp, t, mib_counters_timer);
+	struct mv643xx_eth_private *mp = (void *)_mp;
 	mib_counters_update(mp);
 	mod_timer(&mp->mib_counters_timer, jiffies + 30 * HZ);
 }
@@ -2321,9 +2321,9 @@ static int mv643xx_eth_poll(struct napi_struct *napi, int budget)
 	return work_done;
 }
 
-static inline void oom_timer_wrapper(struct timer_list *t)
+static inline void oom_timer_wrapper(unsigned long data)
 {
-	struct mv643xx_eth_private *mp = from_timer(mp, t, rx_oom);
+	struct mv643xx_eth_private *mp = (void *)data;
 
 	napi_schedule(&mp->napi);
 }
@@ -3183,7 +3183,8 @@ static int mv643xx_eth_probe(struct platform_device *pdev)
 
 	mib_counters_clear(mp);
 
-	timer_setup(&mp->mib_counters_timer, mib_counters_timer_wrapper, 0);
+	setup_timer(&mp->mib_counters_timer, mib_counters_timer_wrapper,
+		    (unsigned long)mp);
 	mp->mib_counters_timer.expires = jiffies + 30 * HZ;
 
 	spin_lock_init(&mp->mib_counters_lock);
@@ -3192,7 +3193,7 @@ static int mv643xx_eth_probe(struct platform_device *pdev)
 
 	netif_napi_add(dev, &mp->napi, mv643xx_eth_poll, NAPI_POLL_WEIGHT);
 
-	timer_setup(&mp->rx_oom, oom_timer_wrapper, 0);
+	setup_timer(&mp->rx_oom, oom_timer_wrapper, (unsigned long)mp);
 
 
 	res = platform_get_resource(pdev, IORESOURCE_IRQ, 0);
diff --git a/drivers/net/ethernet/marvell/mvmdio.c b/drivers/net/ethernet/marvell/mvmdio.c
index ee7857298361..024688c90aa9 100644
--- a/drivers/net/ethernet/marvell/mvmdio.c
+++ b/drivers/net/ethernet/marvell/mvmdio.c
@@ -319,15 +319,25 @@ static int orion_mdio_probe(struct platform_device *pdev)
 
 	init_waitqueue_head(&dev->smi_busy_wait);
 
-	for (i = 0; i < ARRAY_SIZE(dev->clk); i++) {
-		dev->clk[i] = of_clk_get(pdev->dev.of_node, i);
-		if (PTR_ERR(dev->clk[i]) == -EPROBE_DEFER) {
+	if (pdev->dev.of_node) {
+		for (i = 0; i < ARRAY_SIZE(dev->clk); i++) {
+			dev->clk[i] = of_clk_get(pdev->dev.of_node, i);
+			if (PTR_ERR(dev->clk[i]) == -EPROBE_DEFER) {
+				ret = -EPROBE_DEFER;
+				goto out_clk;
+			}
+			if (IS_ERR(dev->clk[i]))
+				break;
+			clk_prepare_enable(dev->clk[i]);
+		}
+	} else {
+		dev->clk[0] = clk_get(&pdev->dev, NULL);
+		if (PTR_ERR(dev->clk[0]) == -EPROBE_DEFER) {
 			ret = -EPROBE_DEFER;
 			goto out_clk;
 		}
-		if (IS_ERR(dev->clk[i]))
-			break;
-		clk_prepare_enable(dev->clk[i]);
+		if (!IS_ERR(dev->clk[0]))
+			clk_prepare_enable(dev->clk[0]);
 	}
 
 	dev->err_interrupt = platform_get_irq(pdev, 0);
@@ -352,7 +362,10 @@ static int orion_mdio_probe(struct platform_device *pdev)
 		goto out_mdio;
 	}
 
-	ret = of_mdiobus_register(bus, pdev->dev.of_node);
+	if (pdev->dev.of_node)
+		ret = of_mdiobus_register(bus, pdev->dev.of_node);
+	else
+		ret = mdiobus_register(bus);
 	if (ret < 0) {
 		dev_err(&pdev->dev, "Cannot register MDIO bus (%d)\n", ret);
 		goto out_mdio;
diff --git a/drivers/net/ethernet/marvell/mvneta.c b/drivers/net/ethernet/marvell/mvneta.c
index 30a16cf796c7..bf020d7a1767 100644
--- a/drivers/net/ethernet/marvell/mvneta.c
+++ b/drivers/net/ethernet/marvell/mvneta.c
@@ -29,6 +29,7 @@
 #include <linux/of_net.h>
 #include <linux/phy.h>
 #include <linux/phylink.h>
+#include <linux/phy/phy.h>
 #include <linux/platform_device.h>
 #include <linux/skbuff.h>
 #include <net/hwbm.h>
@@ -221,6 +222,8 @@
 #define      MVNETA_GMAC_AN_FLOW_CTRL_EN         BIT(11)
 #define      MVNETA_GMAC_CONFIG_FULL_DUPLEX      BIT(12)
 #define      MVNETA_GMAC_AN_DUPLEX_EN            BIT(13)
+#define MVNETA_GMAC_CTRL_4                       0x2c90
+#define      MVNETA_GMAC4_SHORT_PREAMBLE_ENABLE  BIT(1)
 #define MVNETA_MIB_COUNTERS_BASE                 0x3000
 #define      MVNETA_MIB_LATE_COLLISION           0x7c
 #define MVNETA_DA_FILT_SPEC_MCAST                0x3400
@@ -295,10 +298,14 @@
 #define MVNETA_RSS_LU_TABLE_SIZE	1
 
 /* Max number of Rx descriptors */
-#define MVNETA_MAX_RXD 512
+#define MVNETA_MAX_RXD 4096
+/* Default number of Rx descriptors */
+#define MVNETA_RXD_NUM 512
 
 /* Max number of Tx descriptors */
-#define MVNETA_MAX_TXD 1024
+#define MVNETA_MAX_TXD 4096
+/* Default number of Tx descriptors */
+#define MVNETA_TXD_NUM 1024
 
 /* Max number of allowed TCP segments for software TSO */
 #define MVNETA_MAX_TSO_SEGS 100
@@ -333,6 +340,13 @@ enum {
 	ETHTOOL_MAX_STATS,
 };
 
+enum mvneta_type {
+	MVNETA_TYPE_XP,
+	MVNETA_TYPE_370,
+	MVNETA_TYPE_3700,
+	MVNETA_TYPE_AC5
+};
+
 struct mvneta_statistic {
 	unsigned short offset;
 	unsigned short type;
@@ -385,8 +399,6 @@ struct mvneta_pcpu_stats {
 	struct	u64_stats_sync syncp;
 	u64	rx_packets;
 	u64	rx_bytes;
-	u64	rx_dropped;
-	u64	rx_errors;
 	u64	tx_packets;
 	u64	tx_bytes;
 };
@@ -436,6 +448,7 @@ struct mvneta_port {
 	struct device_node *dn;
 	unsigned int tx_csum_limit;
 	struct phylink *phylink;
+	struct phy *comphy;
 
 	struct mvneta_bm *bm_priv;
 	struct mvneta_bm_pool *pool_long;
@@ -451,7 +464,8 @@ struct mvneta_port {
 	u32 indir[MVNETA_RSS_LU_TABLE_SIZE];
 
 	/* Flags for special SoC configurations */
-	bool neta_armada3700;
+	bool musdk_port;
+	enum mvneta_type neta_type;
 	u16 rx_offset_correction;
 	const struct mbus_dram_target_info *dram_target_info;
 };
@@ -643,9 +657,14 @@ static int rx_header_size __read_mostly = 128;
 /* HW BM need that each port be identify by a unique ID */
 static int global_port_id;
 
+/* Branch prediction switches */
+DEFINE_STATIC_KEY_FALSE(a3700_variant);
+
 #define MVNETA_DRIVER_NAME "mvneta"
 #define MVNETA_DRIVER_VERSION "1.0"
 
+#define MVNETA_MUSDK_QUEUE_MASK		1
+
 /* Utility/helper methods */
 
 /* Write helper method */
@@ -703,8 +722,6 @@ mvneta_get_stats64(struct net_device *dev,
 		struct mvneta_pcpu_stats *cpu_stats;
 		u64 rx_packets;
 		u64 rx_bytes;
-		u64 rx_dropped;
-		u64 rx_errors;
 		u64 tx_packets;
 		u64 tx_bytes;
 
@@ -713,20 +730,19 @@ mvneta_get_stats64(struct net_device *dev,
 			start = u64_stats_fetch_begin_irq(&cpu_stats->syncp);
 			rx_packets = cpu_stats->rx_packets;
 			rx_bytes   = cpu_stats->rx_bytes;
-			rx_dropped = cpu_stats->rx_dropped;
-			rx_errors  = cpu_stats->rx_errors;
 			tx_packets = cpu_stats->tx_packets;
 			tx_bytes   = cpu_stats->tx_bytes;
 		} while (u64_stats_fetch_retry_irq(&cpu_stats->syncp, start));
 
 		stats->rx_packets += rx_packets;
 		stats->rx_bytes   += rx_bytes;
-		stats->rx_dropped += rx_dropped;
-		stats->rx_errors  += rx_errors;
 		stats->tx_packets += tx_packets;
 		stats->tx_bytes   += tx_bytes;
 	}
 
+	stats->rx_errors	= dev->stats.rx_errors;
+	stats->rx_dropped	= dev->stats.rx_dropped;
+
 	stats->tx_dropped	= dev->stats.tx_dropped;
 }
 
@@ -763,8 +779,8 @@ static void mvneta_rxq_non_occup_desc_add(struct mvneta_port *pp,
 }
 
 /* Get number of RX descriptors occupied by received packets */
-static int mvneta_rxq_busy_desc_num_get(struct mvneta_port *pp,
-					struct mvneta_rx_queue *rxq)
+static inline int mvneta_rxq_busy_desc_num_get(struct mvneta_port *pp,
+					       struct mvneta_rx_queue *rxq)
 {
 	u32 val;
 
@@ -775,9 +791,9 @@ static int mvneta_rxq_busy_desc_num_get(struct mvneta_port *pp,
 /* Update num of rx desc called upon return from rx path or
  * from mvneta_rxq_drop_pkts().
  */
-static void mvneta_rxq_desc_num_update(struct mvneta_port *pp,
-				       struct mvneta_rx_queue *rxq,
-				       int rx_done, int rx_filled)
+static inline void mvneta_rxq_desc_num_update(struct mvneta_port *pp,
+					      struct mvneta_rx_queue *rxq,
+					      int rx_done, int rx_filled)
 {
 	u32 val;
 
@@ -1048,7 +1064,7 @@ static int mvneta_bm_port_init(struct platform_device *pdev,
 	struct device_node *dn = pdev->dev.of_node;
 	u32 long_pool_id, short_pool_id;
 
-	if (!pp->neta_armada3700) {
+	if ((pp->neta_type != MVNETA_TYPE_3700) && (pp->neta_type != MVNETA_TYPE_AC5)) {
 		int ret;
 
 		ret = mvneta_bm_port_mbus_init(pp);
@@ -1145,21 +1161,30 @@ static void mvneta_port_up(struct mvneta_port *pp)
 	u32 q_map;
 
 	/* Enable all initialized TXs. */
-	q_map = 0;
-	for (queue = 0; queue < txq_number; queue++) {
-		struct mvneta_tx_queue *txq = &pp->txqs[queue];
-		if (txq->descs)
-			q_map |= (1 << queue);
+	if (pp->musdk_port) {
+		q_map = MVNETA_MUSDK_QUEUE_MASK;
+	} else {
+		q_map = 0;
+		for (queue = 0; queue < txq_number; queue++) {
+			struct mvneta_tx_queue *txq = &pp->txqs[queue];
+
+			if (txq->descs)
+				q_map |= (1 << queue);
+		}
 	}
 	mvreg_write(pp, MVNETA_TXQ_CMD, q_map);
 
-	q_map = 0;
-	/* Enable all initialized RXQs. */
-	for (queue = 0; queue < rxq_number; queue++) {
-		struct mvneta_rx_queue *rxq = &pp->rxqs[queue];
+	if (pp->musdk_port) {
+		q_map = MVNETA_MUSDK_QUEUE_MASK;
+	} else {
+		q_map = 0;
+		/* Enable all initialized RXQs. */
+		for (queue = 0; queue < rxq_number; queue++) {
+			struct mvneta_rx_queue *rxq = &pp->rxqs[queue];
 
-		if (rxq->descs)
-			q_map |= (1 << queue);
+			if (rxq->descs)
+				q_map |= (1 << queue);
+		}
 	}
 	mvreg_write(pp, MVNETA_RXQ_CMD, q_map);
 }
@@ -1172,7 +1197,6 @@ static void mvneta_port_down(struct mvneta_port *pp)
 
 	/* Stop Rx port activity. Check port Rx activity. */
 	val = mvreg_read(pp, MVNETA_RXQ_CMD) & MVNETA_RXQ_ENABLE_MASK;
-
 	/* Issue stop command for active channels only */
 	if (val != 0)
 		mvreg_write(pp, MVNETA_RXQ_CMD,
@@ -1196,7 +1220,6 @@ static void mvneta_port_down(struct mvneta_port *pp)
 	 * command for active channels only
 	 */
 	val = (mvreg_read(pp, MVNETA_TXQ_CMD)) & MVNETA_TXQ_ENABLE_MASK;
-
 	if (val != 0)
 		mvreg_write(pp, MVNETA_TXQ_CMD,
 			    (val << MVNETA_TXQ_DISABLE_SHIFT));
@@ -1214,7 +1237,6 @@ static void mvneta_port_down(struct mvneta_port *pp)
 
 		/* Check TX Command reg that all Txqs are stopped */
 		val = mvreg_read(pp, MVNETA_TXQ_CMD);
-
 	} while (val & MVNETA_TXQ_ENABLE_MASK);
 
 	/* Double check to verify that TX FIFO is empty */
@@ -1386,7 +1408,7 @@ static void mvneta_defaults_set(struct mvneta_port *pp)
 	for_each_present_cpu(cpu) {
 		int rxq_map = 0, txq_map = 0;
 		int rxq, txq;
-		if (!pp->neta_armada3700) {
+		if ((pp->neta_type != MVNETA_TYPE_3700) && (pp->neta_type != MVNETA_TYPE_AC5)) {
 			for (rxq = 0; rxq < rxq_number; rxq++)
 				if ((rxq % max_cpu) == cpu)
 					rxq_map |= MVNETA_CPU_RXQ_ACCESS(rxq);
@@ -1609,9 +1631,9 @@ static void mvneta_tx_done_pkts_coal_set(struct mvneta_port *pp,
 }
 
 /* Handle rx descriptor fill by setting buf_cookie and buf_phys_addr */
-static void mvneta_rx_desc_fill(struct mvneta_rx_desc *rx_desc,
-				u32 phys_addr, void *virt_addr,
-				struct mvneta_rx_queue *rxq)
+static inline void mvneta_rx_desc_fill(struct mvneta_rx_desc *rx_desc,
+				       u32 phys_addr, void *virt_addr,
+				       struct mvneta_rx_queue *rxq)
 {
 	int i;
 
@@ -1703,14 +1725,8 @@ static u32 mvneta_txq_desc_csum(int l3_offs, int l3_proto,
 static void mvneta_rx_error(struct mvneta_port *pp,
 			    struct mvneta_rx_desc *rx_desc)
 {
-	struct mvneta_pcpu_stats *stats = this_cpu_ptr(pp->stats);
 	u32 status = rx_desc->status;
 
-	/* update per-cpu counter */
-	u64_stats_update_begin(&stats->syncp);
-	stats->rx_errors++;
-	u64_stats_update_end(&stats->syncp);
-
 	switch (status & MVNETA_RXD_ERR_CODE_MASK) {
 	case MVNETA_RXD_ERR_CRC:
 		netdev_err(pp->dev, "bad rx status %08x (crc error), size=%d\n",
@@ -1813,10 +1829,10 @@ static void mvneta_txq_done(struct mvneta_port *pp,
 
 /* Refill processing for SW buffer management */
 /* Allocate page per descriptor */
-static int mvneta_rx_refill(struct mvneta_port *pp,
-			    struct mvneta_rx_desc *rx_desc,
-			    struct mvneta_rx_queue *rxq,
-			    gfp_t gfp_mask)
+static inline int mvneta_rx_refill(struct mvneta_port *pp,
+				   struct mvneta_rx_desc *rx_desc,
+				   struct mvneta_rx_queue *rxq,
+				   gfp_t gfp_mask)
 {
 	dma_addr_t phys_addr;
 	struct page *page;
@@ -1911,12 +1927,13 @@ int mvneta_rx_refill_queue(struct mvneta_port *pp, struct mvneta_rx_queue *rxq)
 {
 	struct mvneta_rx_desc *rx_desc;
 	int curr_desc = rxq->first_to_refill;
-	int i;
+	int i, err;
 
 	for (i = 0; (i < rxq->refill_num) && (i < 64); i++) {
 		rx_desc = rxq->descs + curr_desc;
 		if (!(rx_desc->buf_phys_addr)) {
-			if (mvneta_rx_refill(pp, rx_desc, rxq, GFP_ATOMIC)) {
+			err = mvneta_rx_refill(pp, rx_desc, rxq, GFP_ATOMIC);
+			if (unlikely(err)) {
 				pr_err("Can't refill queue %d. Done %d from %d\n",
 				       rxq->id, i, rxq->refill_num);
 				rxq->refill_err++;
@@ -1936,9 +1953,10 @@ static int mvneta_rx_swbm(struct napi_struct *napi,
 			  struct mvneta_port *pp, int budget,
 			  struct mvneta_rx_queue *rxq)
 {
+	struct sk_buff *rcvd_skbs[budget];
 	struct net_device *dev = pp->dev;
 	int rx_todo, rx_proc;
-	int refill = 0;
+	int refill = 0, i = 0;
 	u32 rcvd_pkts = 0;
 	u32 rcvd_bytes = 0;
 
@@ -1969,8 +1987,9 @@ static int mvneta_rx_swbm(struct napi_struct *napi,
 
 		if (rx_status & MVNETA_RXD_FIRST_DESC) {
 			/* Check errors only for FIRST descriptor */
-			if (rx_status & MVNETA_RXD_ERR_SUMMARY) {
+			if (unlikely(rx_status & MVNETA_RXD_ERR_SUMMARY)) {
 				mvneta_rx_error(pp, rx_desc);
+				dev->stats.rx_errors++;
 				/* leave the descriptor untouched */
 				continue;
 			}
@@ -1981,20 +2000,17 @@ static int mvneta_rx_swbm(struct napi_struct *napi,
 			skb_size = max(rx_copybreak, rx_header_size);
 			rxq->skb = netdev_alloc_skb_ip_align(dev, skb_size);
 			if (unlikely(!rxq->skb)) {
-				struct mvneta_pcpu_stats *stats = this_cpu_ptr(pp->stats);
-
 				netdev_err(dev,
 					   "Can't allocate skb on queue %d\n",
 					   rxq->id);
-
+				dev->stats.rx_dropped++;
 				rxq->skb_alloc_err++;
-
-				u64_stats_update_begin(&stats->syncp);
-				stats->rx_dropped++;
-				u64_stats_update_end(&stats->syncp);
 				continue;
 			}
-			copy_size = min(skb_size, rx_bytes);
+			if (skb_size > rx_bytes)
+				copy_size = rx_bytes;
+			else
+				copy_size = rx_header_size;
 
 			/* Copy data from buffer to SKB, skip Marvell header */
 			memcpy(rxq->skb->data, data + MVNETA_MH_SIZE,
@@ -2065,7 +2081,7 @@ static int mvneta_rx_swbm(struct napi_struct *napi,
 			/* no last descriptor this time */
 			continue;
 
-		if (rxq->left_size) {
+		if (unlikely(rxq->left_size)) {
 			pr_err("get last desc, but left_size (%d) != 0\n",
 			       rxq->left_size);
 			dev_kfree_skb_any(rxq->skb);
@@ -2073,23 +2089,21 @@ static int mvneta_rx_swbm(struct napi_struct *napi,
 			rxq->skb = NULL;
 			continue;
 		}
-		rcvd_pkts++;
 		rcvd_bytes += rxq->skb->len;
+		rcvd_skbs[rcvd_pkts++] = rxq->skb;
 
 		/* Linux processing */
 		rxq->skb->protocol = eth_type_trans(rxq->skb, dev);
 
-		if (dev->features & NETIF_F_GRO)
-			napi_gro_receive(napi, rxq->skb);
-		else
-			netif_receive_skb(rxq->skb);
-
 		/* clean uncomplete skb pointer in queue */
 		rxq->skb = NULL;
 		rxq->left_size = 0;
 	}
 
-	if (rcvd_pkts) {
+	while (likely(i < rcvd_pkts))
+		napi_gro_receive(napi, rcvd_skbs[i++]);
+
+	if (likely(rcvd_pkts)) {
 		struct mvneta_pcpu_stats *stats = this_cpu_ptr(pp->stats);
 
 		u64_stats_update_begin(&stats->syncp);
@@ -2151,6 +2165,7 @@ static int mvneta_rx_hwbm(struct napi_struct *napi,
 			mvneta_bm_pool_put_bp(pp->bm_priv, bm_pool,
 					      rx_desc->buf_phys_addr);
 err_drop_frame:
+			dev->stats.rx_errors++;
 			mvneta_rx_error(pp, rx_desc);
 			/* leave the descriptor untouched */
 			continue;
@@ -2162,7 +2177,7 @@ static int mvneta_rx_hwbm(struct napi_struct *napi,
 			if (unlikely(!skb))
 				goto err_drop_frame_ret_pool;
 
-			dma_sync_single_range_for_cpu(&pp->bm_priv->pdev->dev,
+			dma_sync_single_range_for_cpu(dev->dev.parent,
 			                              rx_desc->buf_phys_addr,
 			                              MVNETA_MH_SIZE + NET_SKB_PAD,
 			                              rx_bytes,
@@ -2419,6 +2434,9 @@ static netdev_tx_t mvneta_tx(struct sk_buff *skb, struct net_device *dev)
 	int frags = 0;
 	u32 tx_cmd;
 
+	if (pp->musdk_port)
+		return NETDEV_TX_OK;
+
 	if (!netif_running(dev))
 		goto out;
 
@@ -2801,13 +2819,22 @@ static int mvneta_poll(struct napi_struct *napi, int budget)
 	/* For the case where the last mvneta_poll did not process all
 	 * RX packets
 	 */
-	cause_rx_tx |= pp->neta_armada3700 ? pp->cause_rx_tx :
+	rx_queue = fls(((cause_rx_tx >> 8) & 0xff));
+
+	cause_rx_tx |= static_branch_likely(&a3700_variant) ? pp->cause_rx_tx :
 		port->cause_rx_tx;
 
-	rx_queue = fls(((cause_rx_tx >> 8) & 0xff));
 	if (rx_queue) {
 		rx_queue = rx_queue - 1;
+#if defined(CONFIG_ARM64)
+		/* Hardcode branch prediction for 64-bit variant,
+		 * which is a workaround for generic issues with using
+		 * static_branch array.
+		 */
+		if (unlikely(pp->bm_priv))
+#else
 		if (pp->bm_priv)
+#endif
 			rx_done = mvneta_rx_hwbm(napi, pp, budget,
 						 &pp->rxqs[rx_queue]);
 		else
@@ -2819,7 +2846,7 @@ static int mvneta_poll(struct napi_struct *napi, int budget)
 		cause_rx_tx = 0;
 		napi_complete_done(napi, rx_done);
 
-		if (pp->neta_armada3700) {
+		if (static_branch_likely(&a3700_variant)) {
 			unsigned long flags;
 
 			local_irq_save(flags);
@@ -2833,7 +2860,7 @@ static int mvneta_poll(struct napi_struct *napi, int budget)
 		}
 	}
 
-	if (pp->neta_armada3700)
+	if (static_branch_likely(&a3700_variant))
 		pp->cause_rx_tx = cause_rx_tx;
 	else
 		port->cause_rx_tx = cause_rx_tx;
@@ -2841,6 +2868,33 @@ static int mvneta_poll(struct napi_struct *napi, int budget)
 	return rx_done;
 }
 
+static int mvneta_poll_musdk(struct napi_struct *napi, int budget)
+{
+	struct mvneta_port *pp = netdev_priv(napi->dev);
+
+	/* Read cause register */
+	if (mvreg_read(pp, MVNETA_INTR_NEW_CAUSE) & MVNETA_MISCINTR_INTR_MASK) {
+		unsigned long flags;
+		u32 cause_misc = mvreg_read(pp, MVNETA_INTR_MISC_CAUSE);
+
+		mvreg_write(pp, MVNETA_INTR_MISC_CAUSE, 0);
+
+		if (cause_misc & (MVNETA_CAUSE_PHY_STATUS_CHANGE |
+				  MVNETA_CAUSE_LINK_CHANGE))
+			mvneta_link_change(pp);
+		local_irq_save(flags);
+		mvreg_write(pp, MVNETA_INTR_NEW_MASK,
+			    MVNETA_MISCINTR_INTR_MASK);
+		local_irq_restore(flags);
+	}
+
+	/* We always want trigger this function by interrupt.
+	 * This is why '0' is return to napi_complete and as return value
+	 */
+	napi_complete_done(napi, 0);
+	return 0;
+}
+
 /* Handle rxq fill: allocates rxq skbs; called when initializing a port */
 static int mvneta_rxq_fill(struct mvneta_port *pp, struct mvneta_rx_queue *rxq,
 			   int num)
@@ -3135,7 +3189,6 @@ static int mvneta_setup_rxqs(struct mvneta_port *pp)
 		if (err) {
 			netdev_err(pp->dev, "%s: can't create rxq=%d\n",
 				   __func__, queue);
-			mvneta_cleanup_rxqs(pp);
 			return err;
 		}
 	}
@@ -3161,6 +3214,32 @@ static int mvneta_setup_txqs(struct mvneta_port *pp)
 	return 0;
 }
 
+/* Sets the PHY mode of the COMPHY (which configures the serdes lanes).
+ *
+ * The PHY mode used by the mvneta driver comes from the network subsystem,
+ * while the one given to the COMPHY comes from the generic PHY subsystem. Hence
+ * they differ.
+ *
+ * The COMPHY configures the serdes lanes regardless of the actual use of the
+ * lanes by the physical layer. This is why configurations like
+ * "mvneta (1000BaseX) - COMPHY (SGMII)" or
+ * "mvneta (2500BaseX) - COMPHY (2500SGMII)" are valid.
+ */
+static int mvneta_comphy_init(struct mvneta_port *pp)
+{
+	int ret;
+
+	if (!pp->comphy)
+		return 0;
+
+	ret = phy_set_mode_ext(pp->comphy, PHY_MODE_ETHERNET,
+			       pp->phy_interface);
+	if (ret)
+		return ret;
+
+	return phy_power_on(pp->comphy);
+}
+
 static void mvneta_start_dev(struct mvneta_port *pp)
 {
 	int cpu;
@@ -3168,10 +3247,12 @@ static void mvneta_start_dev(struct mvneta_port *pp)
 	mvneta_max_rx_size_set(pp, pp->pkt_size);
 	mvneta_txq_max_tx_size_set(pp, pp->pkt_size);
 
+	mvneta_comphy_init(pp);
+
 	/* start the Rx/Tx activity */
 	mvneta_port_enable(pp);
 
-	if (!pp->neta_armada3700) {
+	if ((pp->neta_type != MVNETA_TYPE_3700) && (pp->neta_type != MVNETA_TYPE_AC5)) {
 		/* Enable polling on the port */
 		for_each_online_cpu(cpu) {
 			struct mvneta_pcpu_port *port =
@@ -3200,7 +3281,7 @@ static void mvneta_stop_dev(struct mvneta_port *pp)
 
 	phylink_stop(pp->phylink);
 
-	if (!pp->neta_armada3700) {
+	if ((pp->neta_type != MVNETA_TYPE_3700) && (pp->neta_type != MVNETA_TYPE_AC5)) {
 		for_each_online_cpu(cpu) {
 			struct mvneta_pcpu_port *port =
 				per_cpu_ptr(pp->ports, cpu);
@@ -3227,6 +3308,9 @@ static void mvneta_stop_dev(struct mvneta_port *pp)
 
 	mvneta_tx_reset(pp);
 	mvneta_rx_reset(pp);
+
+	if (pp->comphy)
+		phy_power_off(pp->comphy);
 }
 
 static void mvneta_percpu_enable(void *arg)
@@ -3249,6 +3333,11 @@ static int mvneta_change_mtu(struct net_device *dev, int mtu)
 	struct mvneta_port *pp = netdev_priv(dev);
 	int ret;
 
+	if (pp->musdk_port) {
+		netdev_warn(dev, "ndo_change_mtu not supported on MUSDK port\n");
+		return 0;
+	}
+
 	if (!IS_ALIGNED(MVNETA_RX_PKT_SIZE(mtu), 8)) {
 		netdev_info(dev, "Illegal MTU value %d, rounding to %d\n",
 			    mtu, ALIGN(MVNETA_RX_PKT_SIZE(mtu), 8));
@@ -3358,6 +3447,7 @@ static void mvneta_validate(struct net_device *ndev, unsigned long *supported,
 	if (state->interface != PHY_INTERFACE_MODE_NA &&
 	    state->interface != PHY_INTERFACE_MODE_QSGMII &&
 	    state->interface != PHY_INTERFACE_MODE_SGMII &&
+	    state->interface != PHY_INTERFACE_MODE_2500BASEX &&
 	    !phy_interface_mode_is_8023z(state->interface) &&
 	    !phy_interface_mode_is_rgmii(state->interface)) {
 		bitmap_zero(supported, __ETHTOOL_LINK_MODE_MASK_NBITS);
@@ -3370,9 +3460,15 @@ static void mvneta_validate(struct net_device *ndev, unsigned long *supported,
 
 	/* Asymmetric pause is unsupported */
 	phylink_set(mask, Pause);
-	/* Half-duplex at speeds higher than 100Mbit is unsupported */
-	phylink_set(mask, 1000baseT_Full);
-	phylink_set(mask, 1000baseX_Full);
+
+	/* We cannot use 1Gbps when using the 2.5G interface. */
+	if (state->interface == PHY_INTERFACE_MODE_2500BASEX) {
+		phylink_set(mask, 2500baseT_Full);
+		phylink_set(mask, 2500baseX_Full);
+	} else {
+		phylink_set(mask, 1000baseT_Full);
+		phylink_set(mask, 1000baseX_Full);
+	}
 
 	if (!phy_interface_mode_is_8023z(state->interface)) {
 		/* 10M and 100M are only supported in non-802.3z mode */
@@ -3396,7 +3492,9 @@ static int mvneta_mac_link_state(struct net_device *ndev,
 
 	gmac_stat = mvreg_read(pp, MVNETA_GMAC_STATUS);
 
-	if (gmac_stat & MVNETA_GMAC_SPEED_1000)
+	if (pp->phy_interface == PHY_INTERFACE_MODE_2500BASEX)
+		state->speed = SPEED_2500;
+	else if (gmac_stat & MVNETA_GMAC_SPEED_1000)
 		state->speed = SPEED_1000;
 	else if (gmac_stat & MVNETA_GMAC_SPEED_100)
 		state->speed = SPEED_100;
@@ -3419,8 +3517,11 @@ static int mvneta_mac_link_state(struct net_device *ndev,
 static void mvneta_mac_an_restart(struct net_device *ndev)
 {
 	struct mvneta_port *pp = netdev_priv(ndev);
-	u32 gmac_an = mvreg_read(pp, MVNETA_GMAC_AUTONEG_CONFIG);
+	u32 gmac_an;
 
+	if (pp->phy_interface == PHY_INTERFACE_MODE_2500BASEX)
+		return;
+	gmac_an = mvreg_read(pp, MVNETA_GMAC_AUTONEG_CONFIG);
 	mvreg_write(pp, MVNETA_GMAC_AUTONEG_CONFIG,
 		    gmac_an | MVNETA_GMAC_INBAND_RESTART_AN);
 	mvreg_write(pp, MVNETA_GMAC_AUTONEG_CONFIG,
@@ -3431,14 +3532,25 @@ static void mvneta_mac_config(struct net_device *ndev, unsigned int mode,
 	const struct phylink_link_state *state)
 {
 	struct mvneta_port *pp = netdev_priv(ndev);
-	u32 new_ctrl0, gmac_ctrl0 = mvreg_read(pp, MVNETA_GMAC_CTRL_0);
-	u32 new_ctrl2, gmac_ctrl2 = mvreg_read(pp, MVNETA_GMAC_CTRL_2);
-	u32 new_clk, gmac_clk = mvreg_read(pp, MVNETA_GMAC_CLOCK_DIVIDER);
-	u32 new_an, gmac_an = mvreg_read(pp, MVNETA_GMAC_AUTONEG_CONFIG);
+	u32 new_ctrl0, gmac_ctrl0, new_ctrl2, gmac_ctrl2, new_clk, gmac_clk;
+	u32 new_an, gmac_an, gmac_ctrl4, new_ctrl4;
+
+	/* Reconfigure the serdes lanes */
+	if (pp->comphy)
+		phy_power_off(pp->comphy);
+
+	mvneta_comphy_init(pp);
+
+	gmac_ctrl0 = mvreg_read(pp, MVNETA_GMAC_CTRL_0);
+	gmac_ctrl2 = mvreg_read(pp, MVNETA_GMAC_CTRL_2);
+	gmac_ctrl4 = mvreg_read(pp, MVNETA_GMAC_CTRL_4);
+	gmac_clk = mvreg_read(pp, MVNETA_GMAC_CLOCK_DIVIDER);
+	gmac_an = mvreg_read(pp, MVNETA_GMAC_AUTONEG_CONFIG);
 
 	new_ctrl0 = gmac_ctrl0 & ~MVNETA_GMAC0_PORT_1000BASE_X;
 	new_ctrl2 = gmac_ctrl2 & ~(MVNETA_GMAC2_INBAND_AN_ENABLE |
 				   MVNETA_GMAC2_PORT_RESET);
+	new_ctrl4 = gmac_ctrl4 & ~(MVNETA_GMAC4_SHORT_PREAMBLE_ENABLE);
 	new_clk = gmac_clk & ~MVNETA_GMAC_1MS_CLOCK_ENABLE;
 	new_an = gmac_an & ~(MVNETA_GMAC_INBAND_AN_ENABLE |
 			     MVNETA_GMAC_INBAND_RESTART_AN |
@@ -3458,6 +3570,7 @@ static void mvneta_mac_config(struct net_device *ndev, unsigned int mode,
 
 	if (state->interface == PHY_INTERFACE_MODE_QSGMII ||
 	    state->interface == PHY_INTERFACE_MODE_SGMII ||
+	    state->interface == PHY_INTERFACE_MODE_2500BASEX ||
 	    phy_interface_mode_is_8023z(state->interface))
 		new_ctrl2 |= MVNETA_GMAC2_PCS_ENABLE;
 
@@ -3471,7 +3584,7 @@ static void mvneta_mac_config(struct net_device *ndev, unsigned int mode,
 		if (state->duplex)
 			new_an |= MVNETA_GMAC_CONFIG_FULL_DUPLEX;
 
-		if (state->speed == SPEED_1000)
+		if (state->speed == SPEED_1000 || state->speed == SPEED_2500)
 			new_an |= MVNETA_GMAC_CONFIG_GMII_SPEED;
 		else if (state->speed == SPEED_100)
 			new_an |= MVNETA_GMAC_CONFIG_MII_SPEED;
@@ -3490,11 +3603,12 @@ static void mvneta_mac_config(struct net_device *ndev, unsigned int mode,
 		new_clk |= MVNETA_GMAC_1MS_CLOCK_ENABLE;
 		new_an = (new_an & ~(MVNETA_GMAC_FORCE_LINK_DOWN |
 				     MVNETA_GMAC_FORCE_LINK_PASS)) |
-			 MVNETA_GMAC_INBAND_AN_ENABLE |
 			 MVNETA_GMAC_CONFIG_GMII_SPEED |
 			 /* The MAC only supports FD mode */
 			 MVNETA_GMAC_CONFIG_FULL_DUPLEX;
 
+		if (state->interface != PHY_INTERFACE_MODE_2500BASEX)
+			new_an |= MVNETA_GMAC_INBAND_AN_ENABLE;
 		if (state->pause & MLO_PAUSE_AN && state->an_enabled)
 			new_an |= MVNETA_GMAC_AN_FLOW_CTRL_EN;
 	}
@@ -3502,28 +3616,37 @@ static void mvneta_mac_config(struct net_device *ndev, unsigned int mode,
 	/* Armada 370 documentation says we can only change the port mode
 	 * and in-band enable when the link is down, so force it down
 	 * while making these changes. We also do this for GMAC_CTRL2 */
-	if ((new_ctrl0 ^ gmac_ctrl0) & MVNETA_GMAC0_PORT_1000BASE_X ||
-	    (new_ctrl2 ^ gmac_ctrl2) & MVNETA_GMAC2_INBAND_AN_ENABLE ||
-	    (new_an  ^ gmac_an) & MVNETA_GMAC_INBAND_AN_ENABLE) {
-		mvreg_write(pp, MVNETA_GMAC_AUTONEG_CONFIG,
-			    (gmac_an & ~MVNETA_GMAC_FORCE_LINK_PASS) |
-			    MVNETA_GMAC_FORCE_LINK_DOWN);
+	/* Also set the GMAC in a reset to clear port on new link-up */
+	if ((new_ctrl0 ^ gmac_ctrl0) || (new_ctrl2 ^ gmac_ctrl2) ||
+	    (new_an  ^ gmac_an)) {
+		gmac_an &= ~MVNETA_GMAC_FORCE_LINK_PASS;
+		gmac_an |= MVNETA_GMAC_FORCE_LINK_DOWN;
+		mvreg_write(pp, MVNETA_GMAC_AUTONEG_CONFIG, gmac_an);
+
+		if (state->interface == PHY_INTERFACE_MODE_2500BASEX) {
+			gmac_ctrl2 |= MVNETA_GMAC2_PORT_RESET;
+			mvreg_write(pp, MVNETA_GMAC_CTRL_2, gmac_ctrl2);
+		}
 	}
 
+	/* When at 2.5G, the link partner can send frames with shortened
+	 * preambles.
+	 */
+	if (state->speed == SPEED_2500)
+		new_ctrl4 |= MVNETA_GMAC4_SHORT_PREAMBLE_ENABLE;
+
 	if (new_ctrl0 != gmac_ctrl0)
 		mvreg_write(pp, MVNETA_GMAC_CTRL_0, new_ctrl0);
 	if (new_ctrl2 != gmac_ctrl2)
 		mvreg_write(pp, MVNETA_GMAC_CTRL_2, new_ctrl2);
+	while (mvreg_read(pp, MVNETA_GMAC_CTRL_2) & MVNETA_GMAC2_PORT_RESET)
+		continue;
+	if (new_ctrl4 != gmac_ctrl4)
+		mvreg_write(pp, MVNETA_GMAC_CTRL_4, new_ctrl4);
 	if (new_clk != gmac_clk)
 		mvreg_write(pp, MVNETA_GMAC_CLOCK_DIVIDER, new_clk);
 	if (new_an != gmac_an)
 		mvreg_write(pp, MVNETA_GMAC_AUTONEG_CONFIG, new_an);
-
-	if (gmac_ctrl2 & MVNETA_GMAC2_PORT_RESET) {
-		while ((mvreg_read(pp, MVNETA_GMAC_CTRL_2) &
-			MVNETA_GMAC2_PORT_RESET) != 0)
-			continue;
-	}
 }
 
 static void mvneta_set_eee(struct mvneta_port *pp, bool enable)
@@ -3763,6 +3886,38 @@ static int mvneta_open(struct net_device *dev)
 	struct mvneta_port *pp = netdev_priv(dev);
 	int ret;
 
+	if (pp->musdk_port) {
+		/* Connect to port interrupt line */
+		ret = request_irq(pp->dev->irq, mvneta_isr, 0,
+				  dev->name, pp);
+		if (ret) {
+			netdev_err(pp->dev, "cannot request irq %d\n",
+				   pp->dev->irq);
+			return ret;
+		}
+
+		ret = mvneta_mdio_probe(pp);
+		if (ret < 0) {
+			netdev_err(dev, "cannot probe MDIO bus\n");
+			free_irq(pp->dev->irq, pp);
+			return ret;
+		}
+
+		/* Only mask phy-status and link-state interrupts */
+		mvreg_write(pp, MVNETA_INTR_NEW_MASK,
+			    MVNETA_MISCINTR_INTR_MASK);
+
+		mvreg_write(pp, MVNETA_INTR_MISC_MASK,
+			    MVNETA_CAUSE_PHY_STATUS_CHANGE |
+			    MVNETA_CAUSE_LINK_CHANGE);
+
+		napi_enable(&pp->napi);
+
+		phylink_start(pp->phylink);
+		netdev_info(dev, "skipping ndo_open as this port is User Space port\n");
+		return 0;
+	}
+
 	pp->pkt_size = MVNETA_RX_PKT_SIZE(pp->dev->mtu);
 
 	ret = mvneta_setup_rxqs(pp);
@@ -3774,7 +3929,7 @@ static int mvneta_open(struct net_device *dev)
 		goto err_cleanup_rxqs;
 
 	/* Connect to port interrupt line */
-	if (pp->neta_armada3700)
+	if ((pp->neta_type == MVNETA_TYPE_3700) || (pp->neta_type == MVNETA_TYPE_AC5))
 		ret = request_irq(pp->dev->irq, mvneta_isr, 0,
 				  dev->name, pp);
 	else
@@ -3785,7 +3940,7 @@ static int mvneta_open(struct net_device *dev)
 		goto err_cleanup_txqs;
 	}
 
-	if (!pp->neta_armada3700) {
+	if ((pp->neta_type != MVNETA_TYPE_3700) && (pp->neta_type != MVNETA_TYPE_AC5)) {
 		/* Enable per-CPU interrupt on all the CPU to handle our RX
 		 * queue interrupts
 		 */
@@ -3806,9 +3961,6 @@ static int mvneta_open(struct net_device *dev)
 			goto err_free_online_hp;
 	}
 
-	/* In default link is down */
-	netif_carrier_off(pp->dev);
-
 	ret = mvneta_mdio_probe(pp);
 	if (ret < 0) {
 		netdev_err(dev, "cannot probe MDIO bus\n");
@@ -3820,15 +3972,15 @@ static int mvneta_open(struct net_device *dev)
 	return 0;
 
 err_free_dead_hp:
-	if (!pp->neta_armada3700)
+	if ((pp->neta_type != MVNETA_TYPE_3700) && (pp->neta_type != MVNETA_TYPE_AC5))
 		cpuhp_state_remove_instance_nocalls(CPUHP_NET_MVNETA_DEAD,
 						    &pp->node_dead);
 err_free_online_hp:
-	if (!pp->neta_armada3700)
+	if ((pp->neta_type != MVNETA_TYPE_3700) && (pp->neta_type != MVNETA_TYPE_AC5))
 		cpuhp_state_remove_instance_nocalls(online_hpstate,
 						    &pp->node_online);
 err_free_irq:
-	if (pp->neta_armada3700) {
+	if ((pp->neta_type != MVNETA_TYPE_3700) && (pp->neta_type != MVNETA_TYPE_AC5)) {
 		free_irq(pp->dev->irq, pp);
 	} else {
 		on_each_cpu(mvneta_percpu_disable, pp, true);
@@ -3846,7 +3998,12 @@ static int mvneta_stop(struct net_device *dev)
 {
 	struct mvneta_port *pp = netdev_priv(dev);
 
-	if (!pp->neta_armada3700) {
+	if (pp->musdk_port) {
+		netdev_warn(dev, "ndo_stop not supported on MUSDK port\n");
+		return 0;
+	}
+
+	if ((pp->neta_type != MVNETA_TYPE_3700) && (pp->neta_type != MVNETA_TYPE_AC5)) {
 		/* Inform that we are stopping so we don't want to setup the
 		 * driver for new CPUs in the notifiers. The code of the
 		 * notifier for CPU online is protected by the same spinlock,
@@ -3893,6 +4050,19 @@ mvneta_ethtool_set_link_ksettings(struct net_device *ndev,
 {
 	struct mvneta_port *pp = netdev_priv(ndev);
 
+	if (!pp->phylink)
+		return -1;
+
+	phylink_stop(pp->phylink);
+
+	if (cmd->base.speed == 1000)
+		pp->phy_interface = PHY_INTERFACE_MODE_SGMII;
+
+	if (cmd->base.speed == 2500)
+		pp->phy_interface = PHY_INTERFACE_MODE_2500BASEX;
+
+	phylink_start(pp->phylink);
+
 	return phylink_ethtool_ksettings_set(pp->phylink, cmd);
 }
 
@@ -4120,7 +4290,7 @@ static int  mvneta_config_rss(struct mvneta_port *pp)
 
 	on_each_cpu(mvneta_percpu_mask_interrupt, pp, true);
 
-	if (!pp->neta_armada3700) {
+	if ((pp->neta_type != MVNETA_TYPE_3700) && (pp->neta_type != MVNETA_TYPE_AC5)) {
 		/* We have to synchronise on the napi of each CPU */
 		for_each_online_cpu(cpu) {
 			struct mvneta_pcpu_port *pcpu_port =
@@ -4148,7 +4318,7 @@ static int  mvneta_config_rss(struct mvneta_port *pp)
 	mvneta_percpu_elect(pp);
 	spin_unlock(&pp->lock);
 
-	if (!pp->neta_armada3700) {
+	if ((pp->neta_type != MVNETA_TYPE_3700) && (pp->neta_type != MVNETA_TYPE_AC5)) {
 		/* We have to synchronise on the napi of each CPU */
 		for_each_online_cpu(cpu) {
 			struct mvneta_pcpu_port *pcpu_port =
@@ -4171,7 +4341,7 @@ static int mvneta_ethtool_set_rxfh(struct net_device *dev, const u32 *indir,
 	struct mvneta_port *pp = netdev_priv(dev);
 
 	/* Current code for Armada 3700 doesn't support RSS features yet */
-	if (pp->neta_armada3700)
+	if ((pp->neta_type != MVNETA_TYPE_3700) && (pp->neta_type != MVNETA_TYPE_AC5))
 		return -EOPNOTSUPP;
 
 	/* We require at least one supported parameter to be changed
@@ -4195,7 +4365,7 @@ static int mvneta_ethtool_get_rxfh(struct net_device *dev, u32 *indir, u8 *key,
 	struct mvneta_port *pp = netdev_priv(dev);
 
 	/* Current code for Armada 3700 doesn't support RSS features yet */
-	if (pp->neta_armada3700)
+	if ((pp->neta_type == MVNETA_TYPE_3700) || (pp->neta_type == MVNETA_TYPE_AC5))
 		return -EOPNOTSUPP;
 
 	if (hfunc)
@@ -4254,8 +4424,7 @@ static int mvneta_ethtool_set_eee(struct net_device *dev,
 
 	/* The Armada 37x documents do not give limits for this other than
 	 * it being an 8-bit register. */
-	if (eee->tx_lpi_enabled &&
-	    (eee->tx_lpi_timer < 0 || eee->tx_lpi_timer > 255))
+	if (eee->tx_lpi_enabled && eee->tx_lpi_timer > 255)
 		return -EINVAL;
 
 	lpi_ctl0 = mvreg_read(pp, MVNETA_LPI_CTRL_0);
@@ -4344,7 +4513,7 @@ static int mvneta_init(struct device *dev, struct mvneta_port *pp)
 		rxq->time_coal = MVNETA_RX_COAL_USEC;
 		rxq->buf_virt_addr
 			= devm_kmalloc_array(pp->dev->dev.parent,
-					     rxq->size,
+					     MVNETA_MAX_RXD,
 					     sizeof(*rxq->buf_virt_addr),
 					     GFP_KERNEL);
 		if (!rxq->buf_virt_addr)
@@ -4411,7 +4580,8 @@ static int mvneta_port_power_up(struct mvneta_port *pp, int phy_mode)
 	if (phy_mode == PHY_INTERFACE_MODE_QSGMII)
 		mvreg_write(pp, MVNETA_SERDES_CFG, MVNETA_QSGMII_SERDES_PROTO);
 	else if (phy_mode == PHY_INTERFACE_MODE_SGMII ||
-		 phy_mode == PHY_INTERFACE_MODE_1000BASEX)
+		 phy_mode == PHY_INTERFACE_MODE_1000BASEX ||
+		 phy_mode == PHY_INTERFACE_MODE_2500BASEX)
 		mvreg_write(pp, MVNETA_SERDES_CFG, MVNETA_SGMII_SERDES_PROTO);
 	else if (!phy_interface_mode_is_rgmii(phy_mode))
 		return -EINVAL;
@@ -4422,6 +4592,7 @@ static int mvneta_port_power_up(struct mvneta_port *pp, int phy_mode)
 /* Device initialization routine */
 static int mvneta_probe(struct platform_device *pdev)
 {
+	struct phy *comphy = NULL;
 	struct resource *res;
 	struct device_node *dn = pdev->dev.of_node;
 	struct device_node *bm_node;
@@ -4435,6 +4606,8 @@ static int mvneta_probe(struct platform_device *pdev)
 	int phy_mode;
 	int err;
 	int cpu;
+	const char *musdk_status;
+	int statlen;
 
 	dev = alloc_etherdev_mqs(sizeof(struct mvneta_port), txq_number, rxq_number);
 	if (!dev)
@@ -4453,6 +4626,15 @@ static int mvneta_probe(struct platform_device *pdev)
 		goto err_free_irq;
 	}
 
+	comphy = devm_of_phy_get(&pdev->dev, dn, NULL);
+	if (IS_ERR(comphy)) {
+		if (PTR_ERR(comphy) == -EPROBE_DEFER) {
+			err = -EPROBE_DEFER;
+			goto err_free_irq;
+		}
+		comphy = NULL;
+	}
+
 	phylink = phylink_create(dev, pdev->dev.fwnode, phy_mode,
 				 &mvneta_phylink_ops);
 	if (IS_ERR(phylink)) {
@@ -4460,7 +4642,7 @@ static int mvneta_probe(struct platform_device *pdev)
 		goto err_free_irq;
 	}
 
-	dev->tx_queue_len = MVNETA_MAX_TXD;
+	dev->tx_queue_len = MVNETA_TXD_NUM;
 	dev->watchdog_timeo = 5 * HZ;
 	dev->netdev_ops = &mvneta_netdev_ops;
 
@@ -4470,14 +4652,22 @@ static int mvneta_probe(struct platform_device *pdev)
 	spin_lock_init(&pp->lock);
 	pp->phylink = phylink;
 	pp->phy_interface = phy_mode;
+	pp->comphy = comphy;
 	pp->dn = dn;
 
 	pp->rxq_def = rxq_def;
 	pp->indir[0] = rxq_def;
 
 	/* Get special SoC configurations */
-	if (of_device_is_compatible(dn, "marvell,armada-3700-neta"))
-		pp->neta_armada3700 = true;
+	if (of_device_is_compatible(dn, "marvell,armada-3700-neta")) {
+		pp->neta_type = MVNETA_TYPE_3700;
+		static_branch_enable(&a3700_variant);
+	} else if (of_device_is_compatible(dn, "marvell,armada-ac5-neta")) {
+		pp->neta_type = MVNETA_TYPE_AC5;
+		static_branch_enable(&a3700_variant);
+	} else {
+		pp->neta_type = MVNETA_TYPE_XP;
+	}
 
 	pp->clk = devm_clk_get(&pdev->dev, "core");
 	if (IS_ERR(pp->clk))
@@ -4500,6 +4690,13 @@ static int mvneta_probe(struct platform_device *pdev)
 		goto err_clk;
 	}
 
+	/* check MUSDK port status */
+	musdk_status = of_get_property(dn, "musdk-status", &statlen);
+
+	/* Set musdk_flag, only if status is "private" */
+	if (musdk_status && !strcmp(musdk_status, "private"))
+		pp->musdk_port = true;
+
 	/* Alloc per-cpu port structure */
 	pp->ports = alloc_percpu(struct mvneta_pcpu_port);
 	if (!pp->ports) {
@@ -4544,17 +4741,16 @@ static int mvneta_probe(struct platform_device *pdev)
 	}
 
 	pp->tx_csum_limit = tx_csum_limit;
-
 	pp->dram_target_info = mv_mbus_dram_info();
 	/* Armada3700 requires setting default configuration of Mbus
 	 * windows, however without using filled mbus_dram_target_info
 	 * structure.
 	 */
-	if (pp->dram_target_info || pp->neta_armada3700)
+	if (pp->dram_target_info || (pp->neta_type == MVNETA_TYPE_3700))
 		mvneta_conf_mbus_windows(pp, pp->dram_target_info);
 
-	pp->tx_ring_size = MVNETA_MAX_TXD;
-	pp->rx_ring_size = MVNETA_MAX_RXD;
+	pp->tx_ring_size = MVNETA_TXD_NUM;
+	pp->rx_ring_size = MVNETA_RXD_NUM;
 
 	pp->dev = dev;
 	SET_NETDEV_DEV(dev, &pdev->dev);
@@ -4598,8 +4794,13 @@ static int mvneta_probe(struct platform_device *pdev)
 	/* Armada3700 network controller does not support per-cpu
 	 * operation, so only single NAPI should be initialized.
 	 */
-	if (pp->neta_armada3700) {
-		netif_napi_add(dev, &pp->napi, mvneta_poll, NAPI_POLL_WEIGHT);
+	if ((pp->neta_type == MVNETA_TYPE_3700) || (pp->neta_type == MVNETA_TYPE_AC5)) {
+		if (pp->musdk_port)
+			netif_napi_add(dev, &pp->napi, mvneta_poll_musdk,
+				       NAPI_POLL_WEIGHT);
+		else
+			netif_napi_add(dev, &pp->napi, mvneta_poll,
+				       NAPI_POLL_WEIGHT);
 	} else {
 		for_each_present_cpu(cpu) {
 			struct mvneta_pcpu_port *port =
@@ -4611,7 +4812,8 @@ static int mvneta_probe(struct platform_device *pdev)
 		}
 	}
 
-	dev->features = NETIF_F_SG | NETIF_F_IP_CSUM | NETIF_F_IPV6_CSUM | NETIF_F_TSO;
+	dev->features = NETIF_F_SG | NETIF_F_IP_CSUM | NETIF_F_IPV6_CSUM |
+			NETIF_F_TSO | NETIF_F_RXCSUM;
 	dev->hw_features |= dev->features;
 	dev->vlan_features |= dev->features;
 	dev->priv_flags |= IFF_LIVE_ADDR_CHANGE;
@@ -4625,7 +4827,7 @@ static int mvneta_probe(struct platform_device *pdev)
 	err = register_netdev(dev);
 	if (err < 0) {
 		dev_err(&pdev->dev, "failed to register\n");
-		goto err_netdev;
+		goto err_free_stats;
 	}
 
 	netdev_info(dev, "Using %s mac address %pM\n", mac_from,
@@ -4633,15 +4835,35 @@ static int mvneta_probe(struct platform_device *pdev)
 
 	platform_set_drvdata(pdev, pp->dev);
 
+	/* Port may be configured by Uboot to transmit IDLE, so a remote side
+	 * feels the link as UP. Stop TX in same way as in mvneta_start/stop.
+	 */
+	if (pp->phylink) {
+		if (rtnl_is_locked()) {
+			if (!mvneta_mdio_probe(pp))
+				mvneta_mdio_remove(pp);
+		} else {
+			rtnl_lock();
+			if (!mvneta_mdio_probe(pp))
+				mvneta_mdio_remove(pp);
+			rtnl_unlock();
+		}
+	}
+
+	if (pp->musdk_port)
+		netdev_info(dev, "Port belong to User Space (MUSDK)\n");
+
 	return 0;
 
 err_netdev:
+	unregister_netdev(dev);
 	if (pp->bm_priv) {
 		mvneta_bm_pool_destroy(pp->bm_priv, pp->pool_long, 1 << pp->id);
 		mvneta_bm_pool_destroy(pp->bm_priv, pp->pool_short,
 				       1 << pp->id);
 		mvneta_bm_put(pp->bm_priv);
 	}
+err_free_stats:
 	free_percpu(pp->stats);
 err_free_ports:
 	free_percpu(pp->ports);
@@ -4693,7 +4915,7 @@ static int mvneta_suspend(struct device *device)
 	if (!netif_running(dev))
 		goto clean_exit;
 
-	if (!pp->neta_armada3700) {
+	if ((pp->neta_type != MVNETA_TYPE_3700) && (pp->neta_type != MVNETA_TYPE_AC5)) {
 		spin_lock(&pp->lock);
 		pp->is_stopped = true;
 		spin_unlock(&pp->lock);
@@ -4738,7 +4960,7 @@ static int mvneta_resume(struct device *device)
 	clk_prepare_enable(pp->clk);
 	if (!IS_ERR(pp->clk_bus))
 		clk_prepare_enable(pp->clk_bus);
-	if (pp->dram_target_info || pp->neta_armada3700)
+	if (pp->dram_target_info || (pp->neta_type == MVNETA_TYPE_3700))
 		mvneta_conf_mbus_windows(pp, pp->dram_target_info);
 	if (pp->bm_priv) {
 		err = mvneta_bm_port_init(pdev, pp);
@@ -4773,7 +4995,7 @@ static int mvneta_resume(struct device *device)
 		mvneta_txq_hw_init(pp, txq);
 	}
 
-	if (!pp->neta_armada3700) {
+	if ((pp->neta_type != MVNETA_TYPE_3700) && (pp->neta_type != MVNETA_TYPE_AC5)) {
 		spin_lock(&pp->lock);
 		pp->is_stopped = false;
 		spin_unlock(&pp->lock);
@@ -4798,6 +5020,7 @@ static const struct of_device_id mvneta_match[] = {
 	{ .compatible = "marvell,armada-370-neta" },
 	{ .compatible = "marvell,armada-xp-neta" },
 	{ .compatible = "marvell,armada-3700-neta" },
+	{ .compatible = "marvell,armada-ac5-neta" },
 	{ }
 };
 MODULE_DEVICE_TABLE(of, mvneta_match);
diff --git a/drivers/net/ethernet/marvell/mvpp2/mvpp2.h b/drivers/net/ethernet/marvell/mvpp2/mvpp2.h
index 46911b67b039..e544daba4bc4 100644
--- a/drivers/net/ethernet/marvell/mvpp2/mvpp2.h
+++ b/drivers/net/ethernet/marvell/mvpp2/mvpp2.h
@@ -15,6 +15,10 @@
 #include <linux/phy.h>
 #include <linux/phylink.h>
 
+#ifndef CACHE_LINE_MASK
+#define CACHE_LINE_MASK            (~(L1_CACHE_BYTES - 1))
+#endif
+
 /* Fifo Registers */
 #define MVPP2_RX_DATA_FIFO_SIZE_REG(port)	(0x00 + 4 * (port))
 #define MVPP2_RX_ATTR_FIFO_SIZE_REG(port)	(0x20 + 4 * (port))
@@ -41,10 +45,16 @@
 #define     MVPP2_RXQ_PACKET_OFFSET_OFFS	28
 #define     MVPP2_RXQ_PACKET_OFFSET_MASK	0x70000000
 #define     MVPP2_RXQ_DISABLE_MASK		BIT(31)
+/* Total max number of hw RX queues */
+#define MVPP2_RXQ_MAX_NUM			128
 
 /* Top Registers */
 #define MVPP2_MH_REG(port)			(0x5040 + 4 * (port))
+#define MVPP2_DSA_NON_EXTENDED			BIT(4)
 #define MVPP2_DSA_EXTENDED			BIT(5)
+#define MVPP2_VER_ID_REG			0x50b0
+#define MVPP2_VER_PP22				0x10
+#define MVPP2_VER_PP23				0x11
 
 /* Parser Registers */
 #define MVPP2_PRS_INIT_LOOKUP_REG		0x1000
@@ -101,6 +111,8 @@
 #define MVPP2_CLS_FLOW_TBL1_REG			0x1828
 #define     MVPP2_CLS_FLOW_TBL1_N_FIELDS_MASK	0x7
 #define     MVPP2_CLS_FLOW_TBL1_N_FIELDS(x)	(x)
+#define     MVPP2_CLS_FLOW_TBL1_LKP_TYPE_MASK	0x3f
+#define     MVPP2_CLS_FLOW_TBL1_LKP_TYPE(x)	((x) << 3)
 #define     MVPP2_CLS_FLOW_TBL1_PRIO_MASK	0x3f
 #define     MVPP2_CLS_FLOW_TBL1_PRIO(x)		((x) << 9)
 #define     MVPP2_CLS_FLOW_TBL1_SEQ_MASK	0x7
@@ -124,6 +136,10 @@
 #define MVPP22_CLS_C2_TCAM_DATA3		0x1b1c
 #define MVPP22_CLS_C2_TCAM_DATA4		0x1b20
 #define     MVPP22_CLS_C2_PORT_ID(port)		((port) << 8)
+#define MVPP2_CLS2_TCAM_INV_REG			0x1b24
+#define     MVPP2_CLS2_TCAM_INV_INVALID		31
+#define     MVPP22_CLS_C2_LKP_TYPE(type)	(type)
+#define     MVPP22_CLS_C2_LKP_TYPE_MASK		(0x3f)
 #define MVPP22_CLS_C2_HIT_CTR			0x1b50
 #define MVPP22_CLS_C2_ACT			0x1b60
 #define     MVPP22_CLS_C2_ACT_RSS_EN(act)	(((act) & 0x3) << 19)
@@ -141,6 +157,8 @@
 #define MVPP22_CLS_C2_ATTR2			0x1b6c
 #define     MVPP22_CLS_C2_ATTR2_RSS_EN		BIT(30)
 #define MVPP22_CLS_C2_ATTR3			0x1b70
+#define MVPP2_CLS2_TCAM_CTRL_REG		0x1b90
+#define     MVPP2_CLS2_TCAM_CTRL_BYPASS_FIFO_STAGES	BIT(0)
 
 /* Descriptor Manager Top Registers */
 #define MVPP2_RXQ_NUM_REG			0x2040
@@ -209,6 +227,7 @@
 #define MVPP22_AXI_RXQ_DESCR_WR_ATTR_REG	0x411c
 #define MVPP22_AXI_RX_DATA_WR_ATTR_REG		0x4120
 #define MVPP22_AXI_TX_DATA_RD_ATTR_REG		0x4130
+#define     MVPP22_AXI_TX_DATA_RD_QOS_ATTRIBUTE (0x3 << 4)
 #define MVPP22_AXI_RD_NORMAL_CODE_REG		0x4150
 #define MVPP22_AXI_RD_SNOOP_CODE_REG		0x4154
 #define MVPP22_AXI_WR_NORMAL_CODE_REG		0x4160
@@ -253,8 +272,8 @@
 #define     MVPP2_ISR_ENABLE_INTERRUPT(mask)	((mask) & 0xffff)
 #define     MVPP2_ISR_DISABLE_INTERRUPT(mask)	(((mask) << 16) & 0xffff0000)
 #define MVPP2_ISR_RX_TX_CAUSE_REG(port)		(0x5480 + 4 * (port))
-#define     MVPP2_CAUSE_RXQ_OCCUP_DESC_ALL_MASK(version) \
-					((version) == MVPP21 ? 0xffff : 0xff)
+#define     MVPP2_CAUSE_RXQ_OCCUP_DESC_ALL_MASK(variant) \
+			(static_branch_unlikely(&variant) ? 0xffff : 0xff)
 #define     MVPP2_CAUSE_TXQ_OCCUP_DESC_ALL_MASK	0xff0000
 #define     MVPP2_CAUSE_TXQ_OCCUP_DESC_ALL_OFFSET	16
 #define     MVPP2_CAUSE_RX_FIFO_OVERRUN_MASK	BIT(24)
@@ -269,6 +288,8 @@
 #define     MVPP2_PON_CAUSE_TXP_OCCUP_DESC_ALL_MASK	0x3fc00000
 #define     MVPP2_PON_CAUSE_MISC_SUM_MASK		BIT(31)
 #define MVPP2_ISR_MISC_CAUSE_REG		0x55b0
+#define MVPP2_ISR_RX_ERR_CAUSE_REG(port)	(0x5520 + 4 * (port))
+#define	    MVPP2_ISR_RX_ERR_CAUSE_NONOCC_MASK	0x00ff
 
 /* Buffer Manager registers */
 #define MVPP2_BM_POOL_BASE_REG(pool)		(0x6000 + ((pool) * 4))
@@ -296,6 +317,10 @@
 #define     MVPP2_BM_HIGH_THRESH_MASK		0x7f0000
 #define     MVPP2_BM_HIGH_THRESH_VALUE(val)	((val) << \
 						MVPP2_BM_HIGH_THRESH_OFFS)
+#define     MVPP2_BM_BPPI_HIGH_THRESH		0x1E
+#define     MVPP2_BM_BPPI_LOW_THRESH		0x1C
+#define     MVPP23_BM_BPPI_HIGH_THRESH		0x34
+#define     MVPP23_BM_BPPI_LOW_THRESH		0x28
 #define MVPP2_BM_INTR_CAUSE_REG(pool)		(0x6240 + ((pool) * 4))
 #define     MVPP2_BM_RELEASED_DELAY_MASK	BIT(0)
 #define     MVPP2_BM_ALLOC_FAILED_MASK		BIT(1)
@@ -320,6 +345,10 @@
 #define     MVPP22_BM_ADDR_HIGH_VIRT_RLS_MASK	0xff00
 #define     MVPP22_BM_ADDR_HIGH_VIRT_RLS_SHIFT	8
 
+#define MVPP22_BM_POOL_BASE_ADDR_HIGH_REG	0x6310
+#define     MVPP22_BM_POOL_BASE_ADDR_HIGH_MASK	0xff
+#define     MVPP23_BM_8POOL_MODE		BIT(8)
+
 /* Hit counters registers */
 #define MVPP2_CTRS_IDX				0x7040
 #define MVPP2_CLS_DEC_TBL_HIT_CTR		0x7700
@@ -331,6 +360,7 @@
 #define     MVPP2_TXP_SCHED_ENQ_MASK		0xff
 #define     MVPP2_TXP_SCHED_DISQ_OFFSET		8
 #define MVPP2_TXP_SCHED_CMD_1_REG		0x8010
+#define MVPP2_TXP_SCHED_FIXED_PRIO_REG		0x8014
 #define MVPP2_TXP_SCHED_PERIOD_REG		0x8018
 #define MVPP2_TXP_SCHED_MTU_REG			0x801c
 #define     MVPP2_TXP_MTU_MAX			0x7FFFF
@@ -388,7 +418,7 @@
 #define     MVPP2_GMAC_IN_BAND_AUTONEG		BIT(2)
 #define     MVPP2_GMAC_IN_BAND_AUTONEG_BYPASS	BIT(3)
 #define     MVPP2_GMAC_IN_BAND_RESTART_AN	BIT(4)
-#define     MVPP2_GMAC_CONFIG_MII_SPEED	BIT(5)
+#define     MVPP2_GMAC_CONFIG_MII_SPEED		BIT(5)
 #define     MVPP2_GMAC_CONFIG_GMII_SPEED	BIT(6)
 #define     MVPP2_GMAC_AN_SPEED_EN		BIT(7)
 #define     MVPP2_GMAC_FC_ADV_EN		BIT(9)
@@ -404,9 +434,12 @@
 #define     MVPP2_GMAC_STATUS0_RX_PAUSE		BIT(6)
 #define     MVPP2_GMAC_STATUS0_TX_PAUSE		BIT(7)
 #define     MVPP2_GMAC_STATUS0_AN_COMPLETE	BIT(11)
+#define MVPP2_GMAC_PORT_FIFO_CFG_0_REG		0x18
+#define     MVPP2_GMAC_TX_FIFO_WM_MASK		0xffff
+#define     MVPP2_GMAC_TX_FIFO_WM_LOW_OFFSET	8
 #define MVPP2_GMAC_PORT_FIFO_CFG_1_REG		0x1c
 #define     MVPP2_GMAC_TX_FIFO_MIN_TH_OFFS	6
-#define     MVPP2_GMAC_TX_FIFO_MIN_TH_ALL_MASK	0x1fc0
+#define     MVPP2_GMAC_TX_FIFO_MIN_TH_ALL_MASK	0x3fc0
 #define     MVPP2_GMAC_TX_FIFO_MIN_TH_MASK(v)	(((v) << 6) & \
 					MVPP2_GMAC_TX_FIFO_MIN_TH_ALL_MASK)
 #define MVPP22_GMAC_INT_STAT			0x20
@@ -423,7 +456,7 @@
 #define MVPP22_GMAC_INT_SUM_MASK		0xa4
 #define     MVPP22_GMAC_INT_SUM_MASK_LINK_STAT	BIT(1)
 
-/* Per-port XGMAC registers. PPv2.2 only, only for GOP port 0,
+/* Per-port XGMAC registers. PPv2.2 and PPv2.3, only for GOP port 0,
  * relative to port->base.
  */
 #define MVPP22_XLG_CTRL0_REG			0x100
@@ -451,10 +484,11 @@
 #define MVPP22_XLG_CTRL4_REG			0x184
 #define     MVPP22_XLG_CTRL4_FWD_FC		BIT(5)
 #define     MVPP22_XLG_CTRL4_FWD_PFC		BIT(6)
+#define     MVPP22_XLG_CTRL4_USE_XPCS		BIT(8)
 #define     MVPP22_XLG_CTRL4_MACMODSELECT_GMAC	BIT(12)
 #define     MVPP22_XLG_CTRL4_EN_IDLE_CHECK	BIT(14)
 
-/* SMI registers. PPv2.2 only, relative to priv->iface_base. */
+/* SMI registers. PPv2.2 and PPv2.3, relative to priv->iface_base. */
 #define MVPP22_SMI_MISC_CFG_REG			0x1204
 #define     MVPP22_SMI_POLLING_EN		BIT(10)
 
@@ -466,7 +500,7 @@
 #define MVPP2_QUEUE_NEXT_DESC(q, index) \
 	(((index) < (q)->last_desc) ? ((index) + 1) : 0)
 
-/* XPCS registers. PPv2.2 only */
+/* XPCS registers.PPv2.2 and PPv2.3 */
 #define MVPP22_MPCS_BASE(port)			(0x7000 + (port) * 0x1000)
 #define MVPP22_MPCS_CTRL			0x14
 #define     MVPP22_MPCS_CTRL_FWD_ERR_CONN	BIT(10)
@@ -477,9 +511,19 @@
 #define     MVPP22_MPCS_CLK_RESET_DIV_RATIO(n)	((n) << 4)
 #define     MVPP22_MPCS_CLK_RESET_DIV_SET	BIT(11)
 
-/* XPCS registers. PPv2.2 only */
+/* FCA registers. PPv2.2 and PPv2.3 */
+#define MVPP22_FCA_BASE(port)			(0x7600 + (port) * 0x1000)
+#define MVPP22_FCA_REG_SIZE			16
+#define MVPP22_FCA_REG_MASK			0xFFFF
+#define MVPP22_FCA_CONTROL_REG			0x0
+#define MVPP22_FCA_ENABLE_PERIODIC		BIT(11)
+#define MVPP22_PERIODIC_COUNTER_LSB_REG		(0x110)
+#define MVPP22_PERIODIC_COUNTER_MSB_REG		(0x114)
+
+/* XPCS registers. PPv2.2 and PPv2.3 */
 #define MVPP22_XPCS_BASE(port)			(0x7400 + (port) * 0x1000)
 #define MVPP22_XPCS_CFG0			0x0
+#define     MVPP22_XPCS_CFG0_RESET_DIS		BIT(0)
 #define     MVPP22_XPCS_CFG0_PCS_MODE(n)	((n) << 3)
 #define     MVPP22_XPCS_CFG0_ACTIVE_LANE(n)	((n) << 5)
 
@@ -501,11 +545,14 @@
 /* Various constants */
 
 /* Coalescing */
-#define MVPP2_TXDONE_COAL_PKTS_THRESH	64
+#define MVPP2_TXDONE_COAL_PKTS_THRESH	32
 #define MVPP2_TXDONE_HRTIMER_PERIOD_NS	1000000UL
+#define MVPP2_GUARD_TXDONE_HRTIMER_NS	(10 * NSEC_PER_MSEC)
 #define MVPP2_TXDONE_COAL_USEC		1000
 #define MVPP2_RX_COAL_PKTS		32
 #define MVPP2_RX_COAL_USEC		64
+#define MVPP2_TX_BULK_TIME		(50 * NSEC_PER_USEC)
+#define MVPP2_TX_BULK_MAX_PACKETS	(MVPP2_AGGR_TXQ_SIZE / MVPP2_MAX_PORTS)
 
 /* The two bytes Marvell header. Either contains a special value used
  * by Marvell switches when a specific hardware mode is enabled (not
@@ -538,32 +585,47 @@
 /* Maximum number of supported ports */
 #define MVPP2_MAX_PORTS			4
 
+/* Loopback port index */
+#define MVPP2_LOOPBACK_PORT_INDEX	3
+
 /* Maximum number of TXQs used by single port */
 #define MVPP2_MAX_TXQ			8
 
-/* MVPP2_MAX_TSO_SEGS is the maximum number of fragments to allow in the GSO
- * skb. As we need a maxium of two descriptors per fragments (1 header, 1 data),
- * multiply this value by two to count the maximum number of skb descs needed.
+/* SKB/TSO/TX-ring-size/pause-wakeup constatnts depend upon the
+ *  MAX_TSO_SEGS - the max number of fragments to allow in the GSO skb.
+ *  Min-Min requirement for it = maxPacket(64kB)/stdMTU(1500)=44 fragments
+ *  and MVPP2_MAX_TSO_SEGS=max(MVPP2_MAX_TSO_SEGS, MAX_SKB_FRAGS).
+ * MAX_SKB_DESCS: we need 2 descriptors per TSO fragment (1 header, 1 data)
+ *  + per-cpu-reservation MVPP2_CPU_DESC_CHUNK*CPUs for optimization.
+ * TX stop activation threshold (e.g. Queue is full) is MAX_SKB_DESCS
+ * TX stop-to-wake hysteresis is MAX_TSO_SEGS
+ * The Tx ring size cannot be smaller than TSO_SEGS + HYSTERESIS + SKBs
+ * The numbers depend upon num cpus (online) used by the driver
  */
-#define MVPP2_MAX_TSO_SEGS		300
-#define MVPP2_MAX_SKB_DESCS		(MVPP2_MAX_TSO_SEGS * 2 + MAX_SKB_FRAGS)
+#define MVPP2_MAX_TSO_SEGS		44
+#define MVPP2_MAX_SKB_DESCS(ncpus)	(MVPP2_MAX_TSO_SEGS * 2 + \
+					MVPP2_CPU_DESC_CHUNK * ncpus)
+#define MVPP2_TX_PAUSE_HYSTERESIS	(MVPP2_MAX_TSO_SEGS * 2)
 
-/* Dfault number of RXQs in use */
-#define MVPP2_DEFAULT_RXQ		1
+/* Max number of RXQs per port */
+#define MVPP2_PORT_MAX_RXQ		32
 
 /* Max number of Rx descriptors */
-#define MVPP2_MAX_RXD_MAX		1024
-#define MVPP2_MAX_RXD_DFLT		128
+#define MVPP2_MAX_RXD_MAX		2048
+#define MVPP2_MAX_RXD_DFLT		MVPP2_MAX_RXD_MAX
 
 /* Max number of Tx descriptors */
 #define MVPP2_MAX_TXD_MAX		2048
-#define MVPP2_MAX_TXD_DFLT		1024
+#define MVPP2_MAX_TXD_DFLT		MVPP2_MAX_TXD_MAX
+#define MVPP2_MIN_TXD(ncpus)	ALIGN(MVPP2_MAX_TSO_SEGS + \
+				      MVPP2_MAX_SKB_DESCS(ncpus) + \
+				      MVPP2_TX_PAUSE_HYSTERESIS, 32)
 
 /* Amount of Tx descriptors that can be reserved at once by CPU */
 #define MVPP2_CPU_DESC_CHUNK		64
 
 /* Max number of Tx descriptors in each aggregated queue */
-#define MVPP2_AGGR_TXQ_SIZE		256
+#define MVPP2_AGGR_TXQ_SIZE		512
 
 /* Descriptor aligned size */
 #define MVPP2_DESC_ALIGNED_SIZE		32
@@ -572,33 +634,57 @@
 #define MVPP2_TX_DESC_ALIGN		(MVPP2_DESC_ALIGNED_SIZE - 1)
 
 /* RX FIFO constants */
+#define MVPP2_RX_FIFO_PORT_DATA_SIZE_44KB	0xb000
 #define MVPP2_RX_FIFO_PORT_DATA_SIZE_32KB	0x8000
 #define MVPP2_RX_FIFO_PORT_DATA_SIZE_8KB	0x2000
 #define MVPP2_RX_FIFO_PORT_DATA_SIZE_4KB	0x1000
-#define MVPP2_RX_FIFO_PORT_ATTR_SIZE_32KB	0x200
-#define MVPP2_RX_FIFO_PORT_ATTR_SIZE_8KB	0x80
+#define MVPP2_RX_FIFO_PORT_ATTR_SIZE(data_size)	(data_size >> 6)
 #define MVPP2_RX_FIFO_PORT_ATTR_SIZE_4KB	0x40
 #define MVPP2_RX_FIFO_PORT_MIN_PKT		0x80
 
 /* TX FIFO constants */
-#define MVPP22_TX_FIFO_DATA_SIZE_10KB		0xa
-#define MVPP22_TX_FIFO_DATA_SIZE_3KB		0x3
-#define MVPP2_TX_FIFO_THRESHOLD_MIN		256
-#define MVPP2_TX_FIFO_THRESHOLD_10KB	\
-	(MVPP22_TX_FIFO_DATA_SIZE_10KB * 1024 - MVPP2_TX_FIFO_THRESHOLD_MIN)
-#define MVPP2_TX_FIFO_THRESHOLD_3KB	\
-	(MVPP22_TX_FIFO_DATA_SIZE_3KB * 1024 - MVPP2_TX_FIFO_THRESHOLD_MIN)
+#define MVPP22_TX_FIFO_DATA_SIZE_18KB		18
+#define MVPP22_TX_FIFO_DATA_SIZE_10KB		10
+#define MVPP22_TX_FIFO_DATA_SIZE_1KB		1
+#define MVPP22_TX_FIFO_DATA_SIZE_MIN		3
+#define MVPP22_TX_FIFO_DATA_SIZE_MAX		15
+#define MVPP2_TX_FIFO_THRESHOLD_MIN		256 /* Bytes */
+#define MVPP2_TX_FIFO_THRESHOLD(kb)		\
+		(kb * 1024 - MVPP2_TX_FIFO_THRESHOLD_MIN)
+#define MVPP22_TX_FIFO_EXTRA_PARAM_MASK		0xF
+#define MVPP22_TX_FIFO_EXTRA_PARAM_OFFS(port)	(4 * (port))
+#define MVPP22_TX_FIFO_EXTRA_PARAM_SIZE(port, val)		\
+	(((val) >> MVPP22_TX_FIFO_EXTRA_PARAM_OFFS(port)) &	\
+	 MVPP22_TX_FIFO_EXTRA_PARAM_MASK)
+
+/* RX FIFO threshold in 1KB granularity */
+#define MVPP23_PORT0_FIFO_TRSH	(9 * 1024)
+#define MVPP23_PORT1_FIFO_TRSH	(4 * 1024)
+#define MVPP23_PORT2_FIFO_TRSH	(2 * 1024)
+
+/* RX Flow Control Registers */
+#define MVPP2_RX_FC_REG(port)		(0x150 + 4 * (port))
+#define     MVPP2_RX_FC_EN		BIT(24)
+#define     MVPP2_RX_FC_TRSH_OFFS	16
+#define     MVPP2_RX_FC_TRSH_MASK	(0xFF << MVPP2_RX_FC_TRSH_OFFS)
+#define     MVPP2_RX_FC_TRSH_UNIT	256
+
+/* GMAC TX FIFO configuration */
+#define MVPP2_GMAC_TX_FIFO_MIN_TH	\
+	MVPP2_GMAC_TX_FIFO_MIN_TH_MASK(50)
+#define MVPP2_GMAC_TX_FIFO_LOW_WM		75
+#define MVPP2_GMAC_TX_FIFO_HI_WM		77
 
 /* RX buffer constants */
 #define MVPP2_SKB_SHINFO_SIZE \
 	SKB_DATA_ALIGN(sizeof(struct skb_shared_info))
 
+#define MVPP2_MTU_OVERHEAD_SIZE \
+	(MVPP2_MH_SIZE + MVPP2_VLAN_TAG_LEN + ETH_HLEN + ETH_FCS_LEN)
 #define MVPP2_RX_PKT_SIZE(mtu) \
-	ALIGN((mtu) + MVPP2_MH_SIZE + MVPP2_VLAN_TAG_LEN + \
-	      ETH_HLEN + ETH_FCS_LEN, cache_line_size())
+	ALIGN((mtu) + MVPP2_MTU_OVERHEAD_SIZE, cache_line_size())
 
 #define MVPP2_RX_BUF_SIZE(pkt_size)	((pkt_size) + NET_SKB_PAD)
-#define MVPP2_RX_TOTAL_SIZE(buf_size)	((buf_size) + MVPP2_SKB_SHINFO_SIZE)
 #define MVPP2_RX_MAX_PKT_SIZE(total_size) \
 	((total_size) - NET_SKB_PAD - MVPP2_SKB_SHINFO_SIZE)
 
@@ -614,6 +700,10 @@
 
 /* Port flags */
 #define MVPP2_F_LOOPBACK		BIT(0)
+#define MVPP2_F_DT_COMPAT		BIT(1)
+#define MVPP22_F_IF_MUSDK		BIT(2) /* musdk port */
+/* BIT(1 and 2) are reserved */
+#define MVPP2_F_IF_TX_ON		BIT(3)
 
 /* Marvell tag types */
 enum mvpp2_tag_type {
@@ -639,8 +729,8 @@ enum mvpp2_prs_l3_cast {
 };
 
 /* BM constants */
-#define MVPP2_BM_JUMBO_BUF_NUM		512
-#define MVPP2_BM_LONG_BUF_NUM		1024
+#define MVPP2_BM_JUMBO_BUF_NUM		2048
+#define MVPP2_BM_LONG_BUF_NUM		2048
 #define MVPP2_BM_SHORT_BUF_NUM		2048
 #define MVPP2_BM_POOL_SIZE_MAX		(16*1024 - MVPP2_BM_POOL_PTR_ALIGN/4)
 #define MVPP2_BM_POOL_PTR_ALIGN		128
@@ -649,7 +739,7 @@ enum mvpp2_prs_l3_cast {
 #define MVPP2_BM_COOKIE_POOL_OFFS	8
 #define MVPP2_BM_COOKIE_CPU_OFFS	24
 
-#define MVPP2_BM_SHORT_FRAME_SIZE		512
+#define MVPP2_BM_SHORT_FRAME_SIZE		1024
 #define MVPP2_BM_LONG_FRAME_SIZE		2048
 #define MVPP2_BM_JUMBO_FRAME_SIZE		10240
 /* BM short pool packet size
@@ -663,7 +753,7 @@ enum mvpp2_prs_l3_cast {
 #define MVPP21_ADDR_SPACE_SZ		0
 #define MVPP22_ADDR_SPACE_SZ		SZ_64K
 
-#define MVPP2_MAX_THREADS		8
+#define MVPP2_MAX_THREADS		9
 #define MVPP2_MAX_QVECS			MVPP2_MAX_THREADS
 
 /* GMAC MIB Counters register definitions */
@@ -692,7 +782,7 @@ enum mvpp2_prs_l3_cast {
 #define MVPP2_MIB_FC_RCVD			0x58
 #define MVPP2_MIB_RX_FIFO_OVERRUN		0x5c
 #define MVPP2_MIB_UNDERSIZE_RCVD		0x60
-#define MVPP2_MIB_FRAGMENTS_RCVD		0x64
+#define MVPP2_MIB_FRAGMENTS_ERR_RCVD		0x64
 #define MVPP2_MIB_OVERSIZE_RCVD			0x68
 #define MVPP2_MIB_JABBER_RCVD			0x6c
 #define MVPP2_MIB_MAC_RCV_ERROR			0x70
@@ -702,8 +792,72 @@ enum mvpp2_prs_l3_cast {
 
 #define MVPP2_MIB_COUNTERS_STATS_DELAY		(1 * HZ)
 
+/* Other counters */
+#define MVPP2_OVERRUN_DROP_REG(port)		(0x7000 + 4 * (port))
+#define MVPP2_CLS_DROP_REG(port)		(0x7020 + 4 * (port))
+#define MVPP2_CNT_IDX_REG			0x7040
+#define MVPP2_TX_PKT_FULLQ_DROP_REG		0x7200
+#define MVPP2_TX_PKT_EARLY_DROP_REG		0x7204
+#define MVPP2_TX_PKT_BM_DROP_REG		0x7208
+#define MVPP2_TX_PKT_BM_MC_DROP_REG		0x720c
+#define MVPP2_RX_PKT_FULLQ_DROP_REG		0x7220
+#define MVPP2_RX_PKT_EARLY_DROP_REG		0x7224
+#define MVPP2_RX_PKT_BM_DROP_REG		0x7228
+
 #define MVPP2_DESC_DMA_MASK	DMA_BIT_MASK(40)
 
+/* MSS Flow control */
+#define MSS_SRAM_SIZE			0x800
+#define MSS_FC_COM_REG			0
+#define FLOW_CONTROL_ENABLE_BIT		BIT(0)
+#define FLOW_CONTROL_UPDATE_COMMAND_BIT	BIT(31)
+#define FC_QUANTA			0xFFFF
+#define FC_CLK_DIVIDER			0x140
+
+#define MSS_BUF_POOL_BASE		0x40
+#define MSS_BUF_POOL_OFFS		4
+#define MSS_BUF_POOL_REG(id)		(MSS_BUF_POOL_BASE		\
+					+ (id) * MSS_BUF_POOL_OFFS)
+
+#define MSS_BUF_POOL_STOP_MASK		0xFFF
+#define MSS_BUF_POOL_START_MASK		(0xFFF << MSS_BUF_POOL_START_OFFS)
+#define MSS_BUF_POOL_START_OFFS		12
+#define MSS_BUF_POOL_PORTS_MASK		(0xF << MSS_BUF_POOL_PORTS_OFFS)
+#define MSS_BUF_POOL_PORTS_OFFS		24
+#define MSS_BUF_POOL_PORT_OFFS(id)	(0x1 <<				\
+					((id) + MSS_BUF_POOL_PORTS_OFFS))
+
+#define MSS_RXQ_TRESH_BASE		0x200
+#define MSS_RXQ_TRESH_OFFS		4
+#define MSS_RXQ_TRESH_REG(q, fq)	(MSS_RXQ_TRESH_BASE + (((q) + (fq)) \
+					* MSS_RXQ_TRESH_OFFS))
+
+#define MSS_RXQ_TRESH_START_MASK	0xFFFF
+#define MSS_RXQ_TRESH_STOP_MASK		(0xFFFF << MSS_RXQ_TRESH_STOP_OFFS)
+#define MSS_RXQ_TRESH_STOP_OFFS		16
+
+#define MSS_RXQ_ASS_BASE	0x80
+#define MSS_RXQ_ASS_OFFS	4
+#define MSS_RXQ_ASS_PER_REG	4
+#define MSS_RXQ_ASS_PER_OFFS	8
+#define MSS_RXQ_ASS_PORTID_OFFS	0
+#define MSS_RXQ_ASS_PORTID_MASK	0x3
+#define MSS_RXQ_ASS_HOSTID_OFFS	2
+#define MSS_RXQ_ASS_HOSTID_MASK	0x3F
+
+#define MSS_RXQ_ASS_Q_BASE(q, fq) ((((q) + (fq)) % MSS_RXQ_ASS_PER_REG)	 \
+				  * MSS_RXQ_ASS_PER_OFFS)
+#define MSS_RXQ_ASS_PQ_BASE(q, fq) ((((q) + (fq)) / MSS_RXQ_ASS_PER_REG) \
+				   * MSS_RXQ_ASS_OFFS)
+#define MSS_RXQ_ASS_REG(q, fq) (MSS_RXQ_ASS_BASE + MSS_RXQ_ASS_PQ_BASE(q, fq))
+
+#define MSS_THRESHOLD_STOP	768
+#define MSS_THRESHOLD_START	1024
+#define MSS_FC_MAX_TIMEOUT	5000
+
+#define MVPP2_PRS_TCAM_SRAM_SIZE        256
+#define MVPP2_N_FLOWS   52
+
 /* Definitions */
 
 /* Shared Packet Processor resources */
@@ -711,16 +865,18 @@ struct mvpp2 {
 	/* Shared registers' base addresses */
 	void __iomem *lms_base;
 	void __iomem *iface_base;
+	void __iomem *cm3_base;
 
-	/* On PPv2.2, each "software thread" can access the base
+	/* On PPv2.2 and PPv2.3, each "software thread" can access the base
 	 * register through a separate address space, each 64 KB apart
 	 * from each other. Typically, such address spaces will be
 	 * used per CPU.
 	 */
 	void __iomem *swth_base[MVPP2_MAX_THREADS];
 
-	/* On PPv2.2, some port control registers are located into the system
-	 * controller space. These registers are accessible through a regmap.
+	/* On PPv2.2 and PPv2.3, some port control registers are located into
+	 * the system controller space. These registers are accessible
+	 * through a regmap.
 	 */
 	struct regmap *sysctrl_base;
 
@@ -734,12 +890,20 @@ struct mvpp2 {
 	/* List of pointers to port structures */
 	int port_count;
 	struct mvpp2_port *port_list[MVPP2_MAX_PORTS];
+	/* Map of enabled ports */
+	unsigned long port_map;
+
+	/* Number of Tx threads used */
+	unsigned int nthreads;
+	/* Map of threads needing locking */
+	unsigned long lock_map;
 
 	/* Aggregated TXQs */
 	struct mvpp2_tx_queue *aggr_txqs;
 
 	/* BM pools */
 	struct mvpp2_bm_pool *bm_pools;
+	struct mvpp2_bm_pool **pools_pcpu;
 
 	/* PRS shadow table */
 	struct mvpp2_prs_shadow *prs_shadow;
@@ -750,7 +914,7 @@ struct mvpp2 {
 	u32 tclk;
 
 	/* HW version */
-	enum { MVPP21, MVPP22 } hw_version;
+	enum { MVPP21, MVPP22, MVPP23 } hw_version;
 
 	/* Maximum number of RXQs per port */
 	unsigned int max_port_rxqs;
@@ -761,6 +925,36 @@ struct mvpp2 {
 
 	/* Debugfs root entry */
 	struct dentry *dbgfs_dir;
+	struct mvpp2_dbgfs_prs_entry *dbgfs_prs_entry[MVPP2_PRS_TCAM_SRAM_SIZE];
+	struct mvpp2_dbgfs_flow_entry *dbgfs_flow_entry[MVPP2_N_FLOWS];
+
+	/* CM3 SRAM pool */
+	struct gen_pool *sram_pool;
+
+	/* Global TX Flow Control config */
+	bool global_tx_fc;
+
+	bool custom_dma_mask;
+
+	/* Spinlocks for CM3 shared memory configuration */
+	spinlock_t mss_spinlock;
+
+	int cp_id;
+};
+
+struct mvpp2_dbgfs_prs_entry {
+	int tid;
+	struct mvpp2 *priv;
+};
+
+struct mvpp2_dbgfs_flow_entry {
+	int flow;
+	struct mvpp2 *priv;
+};
+
+struct mvpp2_dbgfs_port_flow_entry {
+	struct mvpp2_port *port;
+	struct mvpp2_dbgfs_flow_entry *dbg_fe;
 };
 
 struct mvpp2_pcpu_stats {
@@ -773,10 +967,24 @@ struct mvpp2_pcpu_stats {
 
 /* Per-CPU port control */
 struct mvpp2_port_pcpu {
+	/* Timer & Tasklet for bulk-tx optimization */
+	struct hrtimer bulk_timer;
+	bool bulk_timer_scheduled;
+	bool bulk_timer_restart_req;
+	struct tasklet_struct bulk_tasklet;
+
+	/* Timer & Tasklet for egress finalization */
 	struct hrtimer tx_done_timer;
-	bool timer_scheduled;
-	/* Tasklet for egress finalization */
+	bool tx_done_timer_scheduled;
+	bool guard_timer_scheduled;
 	struct tasklet_struct tx_done_tasklet;
+
+	/* tx-done guard timer fields */
+	struct mvpp2_port *port; /* reference to get from tx_done_timer */
+	bool tx_done_passed;	/* tx-done passed since last guard-check */
+	u8 txq_coal_is_zero_map; /* map tx queues (max=8) forced coal=Zero */
+	u8 txq_busy_suspect_map; /* map suspect txq to be forced */
+	u32 tx_guard_cntr;	/* statistic */
 };
 
 struct mvpp2_queue_vector {
@@ -789,13 +997,14 @@ struct mvpp2_queue_vector {
 	int nrxqs;
 	u32 pending_cause_rx;
 	struct mvpp2_port *port;
+	struct cpumask *mask;
 };
 
 struct mvpp2_port {
 	u8 id;
 
 	/* Index of the port from the "group of ports" complex point
-	 * of view
+	 * of view. This is specific to PPv2.2.
 	 */
 	int gop_id;
 
@@ -824,6 +1033,12 @@ struct mvpp2_port {
 	/* Per-CPU port control */
 	struct mvpp2_port_pcpu __percpu *pcpu;
 
+	/* Protect the BM refills and the Tx paths when a thread is used on more
+	 * than a single CPU.
+	 */
+	spinlock_t bm_lock[MVPP2_MAX_THREADS];
+	spinlock_t tx_lock[MVPP2_MAX_THREADS];
+
 	/* Flags */
 	unsigned long flags;
 
@@ -856,6 +1071,23 @@ struct mvpp2_port {
 
 	/* RSS indirection table */
 	u32 indir[MVPP22_RSS_TABLE_ENTRIES];
+
+	/* us private storage, allocated/used by User/Kernel mode toggling */
+	void *us_cfg;
+
+	/* Coherency-update for TX-ON from link_status_irq */
+	struct tasklet_struct txqs_on_tasklet;
+
+	/* Firmware TX flow control */
+	bool tx_fc;
+
+	/* Indication, whether port is connected to XLG MAC */
+	bool has_xlg_mac;
+
+	/* Notifier required when the port is connected to the switch */
+	struct notifier_block dsa_notifier;
+
+	struct mvpp2_dbgfs_port_flow_entry *dbgfs_port_flow_entry;
 };
 
 /* The mvpp2_tx_desc and mvpp2_rx_desc structures describe the
@@ -876,7 +1108,7 @@ struct mvpp2_port {
 
 #define MVPP2_RXD_ERR_SUMMARY		BIT(15)
 #define MVPP2_RXD_ERR_CODE_MASK		(BIT(13) | BIT(14))
-#define MVPP2_RXD_ERR_CRC		0x0
+#define MVPP2_RXD_ERR_MAC		0x0
 #define MVPP2_RXD_ERR_OVERRUN		BIT(13)
 #define MVPP2_RXD_ERR_RESOURCE		(BIT(13) | BIT(14))
 #define MVPP2_RXD_BM_POOL_ID_OFFS	16
@@ -918,7 +1150,7 @@ struct mvpp21_rx_desc {
 	__le32 reserved8;
 };
 
-/* HW TX descriptor for PPv2.2 */
+/* HW TX descriptor for PPv2.2 and PPv2.3 */
 struct mvpp22_tx_desc {
 	__le32 command;
 	u8  packet_offset;
@@ -929,7 +1161,7 @@ struct mvpp22_tx_desc {
 	__le64 buf_cookie_misc;
 };
 
-/* HW RX descriptor for PPv2.2 */
+/* HW RX descriptor for PPv2.2 and PPv2.3 */
 struct mvpp22_rx_desc {
 	__le32 status;
 	__le16 reserved1;
@@ -970,7 +1202,7 @@ struct mvpp2_txq_pcpu_buf {
 
 /* Per-CPU Tx queue control */
 struct mvpp2_txq_pcpu {
-	int cpu;
+	unsigned int thread;
 
 	/* Number of Tx DMA descriptors in the descriptor ring */
 	int size;
@@ -980,8 +1212,10 @@ struct mvpp2_txq_pcpu {
 	 */
 	int count;
 
-	int wake_threshold;
-	int stop_threshold;
+	u16 wake_threshold;
+	u16 stop_threshold;
+	/* TXQ-number above stop_threshold to be wake-up */
+	u16 stopped_on_txq_id;
 
 	/* Number of Tx DMA descriptors reserved for each CPU */
 	int reserved_num;
@@ -1012,6 +1246,7 @@ struct mvpp2_tx_queue {
 
 	/* Number of currently used Tx DMA descriptor in the descriptor ring */
 	int count;
+	int pending;
 
 	/* Per-CPU control of physical Tx queues */
 	struct mvpp2_txq_pcpu __percpu *pcpu;
@@ -1029,35 +1264,43 @@ struct mvpp2_tx_queue {
 
 	/* Index of the next Tx DMA descriptor to process */
 	int next_desc_to_proc;
-};
+} __aligned(L1_CACHE_BYTES);
 
 struct mvpp2_rx_queue {
+	/* Virtual address of the RX DMA descriptors array */
+	struct mvpp2_rx_desc *descs;
+
+	/* Index of the next-to-process and last RX DMA descriptor */
+	int next_desc_to_proc;
+	int last_desc;
+
 	/* RX queue number, in the range 0-31 for physical RXQs */
 	u8 id;
 
+	/* Port's logic RXQ number to which physical RXQ is mapped */
+	u8 logic_rxq;
+
+	/* Num of RXed packets seen in HW but meanwhile not handled by SW */
+	u16 rx_pending;
+
 	/* Num of rx descriptors in the rx descriptor ring */
 	int size;
 
 	u32 pkts_coal;
 	u32 time_coal;
 
-	/* Virtual address of the RX DMA descriptors array */
-	struct mvpp2_rx_desc *descs;
-
 	/* DMA address of the RX DMA descriptors array */
 	dma_addr_t descs_dma;
 
-	/* Index of the last RX DMA descriptor */
-	int last_desc;
-
-	/* Index of the next RX DMA descriptor to process */
-	int next_desc_to_proc;
-
 	/* ID of port to which physical RXQ is mapped */
 	int port;
 
-	/* Port's logic RXQ number to which physical RXQ is mapped */
-	int logic_rxq;
+} __aligned(L1_CACHE_BYTES);
+
+enum mvpp2_bm_pool_type {
+	MVPP2_BM_SHORT,
+	MVPP2_BM_JUMBO,
+	MVPP2_BM_LONG,
 };
 
 struct mvpp2_bm_pool {
@@ -1076,6 +1319,9 @@ struct mvpp2_bm_pool {
 	int pkt_size;
 	int frag_size;
 
+	/* Pool type (short/long/jumbo) */
+	enum mvpp2_bm_pool_type type;
+
 	/* BPPE virtual base address */
 	u32 *virt_addr;
 	/* BPPE DMA base address */
@@ -1085,27 +1331,120 @@ struct mvpp2_bm_pool {
 	u32 port_map;
 };
 
+#define MVPP2_BM_POOLS_NUM	(recycle ? (2 + num_present_cpus()) : 3)
+#define MVPP2_BM_POOLS_NUM_MAX	8
+
 #define IS_TSO_HEADER(txq_pcpu, addr) \
 	((addr) >= (txq_pcpu)->tso_headers_dma && \
 	 (addr) < (txq_pcpu)->tso_headers_dma + \
 	 (txq_pcpu)->size * TSO_HEADER_SIZE)
+#define TSO_HEADER_MARK		((void *)BIT(0))
 
 #define MVPP2_DRIVER_NAME "mvpp2"
 #define MVPP2_DRIVER_VERSION "1.0"
 
-void mvpp2_write(struct mvpp2 *priv, u32 offset, u32 data);
-u32 mvpp2_read(struct mvpp2 *priv, u32 offset);
-
-u32 mvpp2_read_relaxed(struct mvpp2 *priv, u32 offset);
-
-void mvpp2_percpu_write(struct mvpp2 *priv, int cpu, u32 offset, u32 data);
-u32 mvpp2_percpu_read(struct mvpp2 *priv, int cpu, u32 offset);
-
-void mvpp2_percpu_write_relaxed(struct mvpp2 *priv, int cpu, u32 offset,
-				u32 data);
+/* Run-time critical Utility/helper methods */
+static inline
+void mvpp2_write(struct mvpp2 *priv, u32 offset, u32 data)
+{
+	writel(data, priv->swth_base[0] + offset);
+}
+
+static inline
+u32 mvpp2_read(struct mvpp2 *priv, u32 offset)
+{
+	return readl(priv->swth_base[0] + offset);
+}
+
+static inline
+u32 mvpp2_read_relaxed(struct mvpp2 *priv, u32 offset)
+{
+	return readl_relaxed(priv->swth_base[0] + offset);
+}
+
+static inline
+u32 mvpp2_cpu_to_thread(struct mvpp2 *priv, int cpu)
+{
+	return cpu % priv->nthreads;
+}
+
+static inline
+void mvpp2_cm3_write(struct mvpp2 *priv, u32 offset, u32 data)
+{
+	writel(data, priv->cm3_base + offset);
+}
+
+static inline
+u32 mvpp2_cm3_read(struct mvpp2 *priv, u32 offset)
+{
+	return readl(priv->cm3_base + offset);
+}
+
+/* These accessors should be used to access:
+ *
+ * - per-thread registers, where each thread has its own copy of the
+ *   register.
+ *
+ *   MVPP2_BM_VIRT_ALLOC_REG
+ *   MVPP2_BM_ADDR_HIGH_ALLOC
+ *   MVPP22_BM_ADDR_HIGH_RLS_REG
+ *   MVPP2_BM_VIRT_RLS_REG
+ *   MVPP2_ISR_RX_TX_CAUSE_REG
+ *   MVPP2_ISR_RX_TX_MASK_REG
+ *   MVPP2_TXQ_NUM_REG
+ *   MVPP2_AGGR_TXQ_UPDATE_REG
+ *   MVPP2_TXQ_RSVD_REQ_REG
+ *   MVPP2_TXQ_RSVD_RSLT_REG
+ *   MVPP2_TXQ_SENT_REG
+ *   MVPP2_RXQ_NUM_REG
+ *
+ * - global registers that must be accessed through a specific thread
+ *   window, because they are related to an access to a per-thread
+ *   register
+ *
+ *   MVPP2_BM_PHY_ALLOC_REG    (related to MVPP2_BM_VIRT_ALLOC_REG)
+ *   MVPP2_BM_PHY_RLS_REG      (related to MVPP2_BM_VIRT_RLS_REG)
+ *   MVPP2_RXQ_THRESH_REG      (related to MVPP2_RXQ_NUM_REG)
+ *   MVPP2_RXQ_DESC_ADDR_REG   (related to MVPP2_RXQ_NUM_REG)
+ *   MVPP2_RXQ_DESC_SIZE_REG   (related to MVPP2_RXQ_NUM_REG)
+ *   MVPP2_RXQ_INDEX_REG       (related to MVPP2_RXQ_NUM_REG)
+ *   MVPP2_TXQ_PENDING_REG     (related to MVPP2_TXQ_NUM_REG)
+ *   MVPP2_TXQ_DESC_ADDR_REG   (related to MVPP2_TXQ_NUM_REG)
+ *   MVPP2_TXQ_DESC_SIZE_REG   (related to MVPP2_TXQ_NUM_REG)
+ *   MVPP2_TXQ_INDEX_REG       (related to MVPP2_TXQ_NUM_REG)
+ *   MVPP2_TXQ_PENDING_REG     (related to MVPP2_TXQ_NUM_REG)
+ *   MVPP2_TXQ_PREF_BUF_REG    (related to MVPP2_TXQ_NUM_REG)
+ *   MVPP2_TXQ_PREF_BUF_REG    (related to MVPP2_TXQ_NUM_REG)
+ */
+static inline
+void mvpp2_thread_write(struct mvpp2 *priv, unsigned int thread,
+			u32 offset, u32 data)
+{
+	writel(data, priv->swth_base[thread] + offset);
+}
+
+static inline
+u32 mvpp2_thread_read(struct mvpp2 *priv, unsigned int thread, u32 offset)
+{
+	return readl(priv->swth_base[thread] + offset);
+}
+
+static inline
+void mvpp2_thread_write_relaxed(struct mvpp2 *priv, unsigned int thread,
+				u32 offset, u32 data)
+{
+	writel_relaxed(data, priv->swth_base[thread] + offset);
+}
+
+static inline
+u32 mvpp2_thread_read_relaxed(struct mvpp2 *priv, unsigned int thread,
+			      u32 offset)
+{
+	return readl_relaxed(priv->swth_base[thread] + offset);
+}
 
 void mvpp2_dbgfs_init(struct mvpp2 *priv, const char *name);
-
 void mvpp2_dbgfs_cleanup(struct mvpp2 *priv);
+void mvpp23_rx_fifo_fc_en(struct mvpp2 *priv, int port, bool en);
 
 #endif
diff --git a/drivers/net/ethernet/marvell/mvpp2/mvpp2_cls.c b/drivers/net/ethernet/marvell/mvpp2/mvpp2_cls.c
index efdb7a656835..103c4a4fc8dc 100644
--- a/drivers/net/ethernet/marvell/mvpp2/mvpp2_cls.c
+++ b/drivers/net/ethernet/marvell/mvpp2/mvpp2_cls.c
@@ -429,12 +429,6 @@ static void mvpp2_cls_flow_port_id_sel(struct mvpp2_cls_flow_entry *fe,
 		fe->data[0] &= ~MVPP2_CLS_FLOW_TBL0_PORT_ID_SEL;
 }
 
-static void mvpp2_cls_flow_seq_set(struct mvpp2_cls_flow_entry *fe, u32 seq)
-{
-	fe->data[1] &= ~MVPP2_CLS_FLOW_TBL1_SEQ(MVPP2_CLS_FLOW_TBL1_SEQ_MASK);
-	fe->data[1] |= MVPP2_CLS_FLOW_TBL1_SEQ(seq);
-}
-
 static void mvpp2_cls_flow_last_set(struct mvpp2_cls_flow_entry *fe,
 				    bool is_last)
 {
@@ -442,6 +436,19 @@ static void mvpp2_cls_flow_last_set(struct mvpp2_cls_flow_entry *fe,
 	fe->data[0] |= !!is_last;
 }
 
+static bool mvpp2_cls_flow_last_get(struct mvpp2_cls_flow_entry *fe)
+{
+	return (fe->data[0] & MVPP2_CLS_FLOW_TBL0_LAST);
+}
+
+static void mvpp2_cls_flow_lkp_type_set(struct mvpp2_cls_flow_entry *fe,
+					int lkp_type)
+{
+	fe->data[1] &= ~MVPP2_CLS_FLOW_TBL1_LKP_TYPE(
+			MVPP2_CLS_FLOW_TBL1_LKP_TYPE_MASK);
+	fe->data[1] |= MVPP2_CLS_FLOW_TBL1_LKP_TYPE(lkp_type);
+}
+
 static void mvpp2_cls_flow_pri_set(struct mvpp2_cls_flow_entry *fe, int prio)
 {
 	fe->data[1] &= ~MVPP2_CLS_FLOW_TBL1_PRIO(MVPP2_CLS_FLOW_TBL1_PRIO_MASK);
@@ -454,6 +461,11 @@ static void mvpp2_cls_flow_port_add(struct mvpp2_cls_flow_entry *fe,
 	fe->data[0] |= MVPP2_CLS_FLOW_TBL0_PORT_ID(port);
 }
 
+static int mvpp2_cls_flow_port_get(struct mvpp2_cls_flow_entry *fe)
+{
+	return ((fe->data[0] >> 4) & MVPP2_CLS_FLOW_TBL0_PORT_ID_MASK);
+}
+
 /* Initialize the parser entry for the given flow */
 static void mvpp2_cls_flow_prs_init(struct mvpp2 *priv,
 				    struct mvpp2_cls_flow *flow)
@@ -499,7 +511,7 @@ static void mvpp2_cls_flow_init(struct mvpp2 *priv, struct mvpp2_cls_flow *flow)
 	mvpp2_cls_flow_port_id_sel(&fe, true);
 	mvpp2_cls_flow_last_set(&fe, 0);
 	mvpp2_cls_flow_pri_set(&fe, 0);
-	mvpp2_cls_flow_seq_set(&fe, MVPP2_CLS_FLOW_SEQ_FIRST1);
+	mvpp2_cls_flow_lkp_type_set(&fe, MVPP2_CLS_LKP_DEFAULT);
 
 	/* Add all ports */
 	for (i = 0; i < MVPP2_MAX_PORTS; i++)
@@ -510,19 +522,19 @@ static void mvpp2_cls_flow_init(struct mvpp2 *priv, struct mvpp2_cls_flow *flow)
 	/* C3Hx lookups */
 	for (i = 0; i < MVPP2_MAX_PORTS; i++) {
 		memset(&fe, 0, sizeof(fe));
-		fe.index = MVPP2_PORT_FLOW_HASH_ENTRY(i, flow->flow_id);
+		fe.index = MVPP2_PORT_FLOW_INDEX(i, flow->flow_id);
 
+		mvpp2_cls_flow_eng_set(&fe, MVPP22_CLS_ENGINE_C3HA);
 		mvpp2_cls_flow_port_id_sel(&fe, true);
 		mvpp2_cls_flow_pri_set(&fe, i + 1);
-		mvpp2_cls_flow_seq_set(&fe, MVPP2_CLS_FLOW_SEQ_MIDDLE);
 		mvpp2_cls_flow_port_add(&fe, BIT(i));
+		mvpp2_cls_flow_lkp_type_set(&fe, MVPP2_CLS_LKP_HASH);
 
 		mvpp2_cls_flow_write(priv, &fe);
 	}
 
 	/* Update the last entry */
 	mvpp2_cls_flow_last_set(&fe, 1);
-	mvpp2_cls_flow_seq_set(&fe, MVPP2_CLS_FLOW_SEQ_LAST);
 
 	mvpp2_cls_flow_write(priv, &fe);
 }
@@ -543,6 +555,20 @@ static int mvpp2_flow_add_hek_field(struct mvpp2_cls_flow_entry *fe,
 	return 0;
 }
 
+static void mvpp2_cls_c2_inv_set(struct mvpp2 *priv,
+				 int index)
+{
+	/* write index reg */
+	mvpp2_write(priv, MVPP22_CLS_C2_TCAM_IDX, index);
+
+	/* set invalid bit */
+	mvpp2_write(priv, MVPP2_CLS2_TCAM_INV_REG,
+		    (1 << MVPP2_CLS2_TCAM_INV_INVALID));
+
+	/* trigger */
+	mvpp2_write(priv, MVPP22_CLS_C2_TCAM_DATA4, 0);
+}
+
 static int mvpp2_flow_set_hek_fields(struct mvpp2_cls_flow_entry *fe,
 				     unsigned long hash_opts)
 {
@@ -594,6 +620,36 @@ struct mvpp2_cls_flow *mvpp2_cls_flow_get(int flow)
 	return &cls_flows[flow];
 }
 
+int mvpp2_cls_flow_hash_find(struct mvpp2_port *port,
+			     struct mvpp2_cls_flow *flow,
+			     struct mvpp2_cls_flow_entry *fe,
+			     int *flow_index)
+{
+	int engine, flow_offset, port_bm, idx = 0, is_last = 0;
+
+	flow_offset = 0;
+	do {
+		idx = MVPP2_PORT_FLOW_INDEX(flow_offset, flow->flow_id);
+		if (idx >= MVPP2_CLS_FLOWS_TBL_SIZE)
+			break;
+		mvpp2_cls_flow_read(port->priv, idx, fe);
+		engine = mvpp2_cls_flow_eng_get(fe);
+		port_bm = mvpp2_cls_flow_port_get(fe);
+		is_last = mvpp2_cls_flow_last_get(fe);
+		if ((engine == MVPP22_CLS_ENGINE_C3HA ||
+		     engine == MVPP22_CLS_ENGINE_C3HB) &&
+		    (port_bm & BIT(port->id)))
+			break;
+		flow_offset++;
+	} while (!is_last);
+
+	*flow_index = idx;
+	if (is_last)
+		return -EINVAL;
+
+	return 0;
+}
+
 /* Set the hash generation options for the given traffic flow.
  * One traffic flow (in the ethtool sense) has multiple classification flows,
  * to handle specific cases such as fragmentation, or the presence of a
@@ -621,8 +677,8 @@ static int mvpp2_port_rss_hash_opts_set(struct mvpp2_port *port, int flow_type,
 		if (flow->flow_type != flow_type)
 			continue;
 
-		flow_index = MVPP2_PORT_FLOW_HASH_ENTRY(port->id,
-							flow->flow_id);
+		if (mvpp2_cls_flow_hash_find(port, flow, &fe, &flow_index))
+			return -EINVAL;
 
 		mvpp2_cls_flow_read(port->priv, flow_index, &fe);
 
@@ -710,8 +766,8 @@ static u16 mvpp2_port_rss_hash_opts_get(struct mvpp2_port *port, int flow_type)
 		if (flow->flow_type != flow_type)
 			continue;
 
-		flow_index = MVPP2_PORT_FLOW_HASH_ENTRY(port->id,
-							flow->flow_id);
+		if (mvpp2_cls_flow_hash_find(port, flow, &fe, &flow_index))
+			return 0;
 
 		mvpp2_cls_flow_read(port->priv, flow_index, &fe);
 
@@ -742,19 +798,23 @@ static void mvpp2_cls_c2_write(struct mvpp2 *priv,
 {
 	mvpp2_write(priv, MVPP22_CLS_C2_TCAM_IDX, c2->index);
 
-	/* Write TCAM */
-	mvpp2_write(priv, MVPP22_CLS_C2_TCAM_DATA0, c2->tcam[0]);
-	mvpp2_write(priv, MVPP22_CLS_C2_TCAM_DATA1, c2->tcam[1]);
-	mvpp2_write(priv, MVPP22_CLS_C2_TCAM_DATA2, c2->tcam[2]);
-	mvpp2_write(priv, MVPP22_CLS_C2_TCAM_DATA3, c2->tcam[3]);
-	mvpp2_write(priv, MVPP22_CLS_C2_TCAM_DATA4, c2->tcam[4]);
-
 	mvpp2_write(priv, MVPP22_CLS_C2_ACT, c2->act);
 
 	mvpp2_write(priv, MVPP22_CLS_C2_ATTR0, c2->attr[0]);
 	mvpp2_write(priv, MVPP22_CLS_C2_ATTR1, c2->attr[1]);
 	mvpp2_write(priv, MVPP22_CLS_C2_ATTR2, c2->attr[2]);
 	mvpp2_write(priv, MVPP22_CLS_C2_ATTR3, c2->attr[3]);
+
+	/* write valid bit*/
+	mvpp2_write(priv, MVPP2_CLS2_TCAM_INV_REG,
+		    (0 << MVPP2_CLS2_TCAM_INV_INVALID));
+
+	/* Write TCAM */
+	mvpp2_write(priv, MVPP22_CLS_C2_TCAM_DATA0, c2->tcam[0]);
+	mvpp2_write(priv, MVPP22_CLS_C2_TCAM_DATA1, c2->tcam[1]);
+	mvpp2_write(priv, MVPP22_CLS_C2_TCAM_DATA2, c2->tcam[2]);
+	mvpp2_write(priv, MVPP22_CLS_C2_TCAM_DATA3, c2->tcam[3]);
+	mvpp2_write(priv, MVPP22_CLS_C2_TCAM_DATA4, c2->tcam[4]);
 }
 
 void mvpp2_cls_c2_read(struct mvpp2 *priv, int index,
@@ -791,6 +851,10 @@ static void mvpp2_port_c2_cls_init(struct mvpp2_port *port)
 	c2.tcam[4] = MVPP22_CLS_C2_PORT_ID(pmap);
 	c2.tcam[4] |= MVPP22_CLS_C2_TCAM_EN(MVPP22_CLS_C2_PORT_ID(pmap));
 
+	/* Set lkp_type */
+	c2.tcam[4] |= MVPP22_CLS_C2_LKP_TYPE(MVPP2_CLS_LKP_DEFAULT);
+	c2.tcam[4] |= MVPP22_CLS_C2_TCAM_EN(MVPP22_CLS_C2_LKP_TYPE_MASK);
+
 	/* Update RSS status after matching this entry */
 	c2.act = MVPP22_CLS_C2_ACT_RSS_EN(MVPP22_C2_UPD_LOCK);
 
@@ -812,6 +876,19 @@ static void mvpp2_port_c2_cls_init(struct mvpp2_port *port)
 	mvpp2_cls_c2_write(port->priv, &c2);
 }
 
+static void mvpp2_cls_c2_init(struct mvpp2 *priv)
+{
+	int index;
+
+	/* Toggle C2 from Built-In Self-Test mode to Functional mode */
+	mvpp2_write(priv, MVPP2_CLS2_TCAM_CTRL_REG,
+		    MVPP2_CLS2_TCAM_CTRL_BYPASS_FIFO_STAGES);
+
+	/* Invalidate all C2 entries */
+	for (index = 0; index < MVPP22_CLS_C2_MAX_ENTRIES; index++)
+		mvpp2_cls_c2_inv_set(priv, index);
+}
+
 /* Classifier default initialization */
 void mvpp2_cls_init(struct mvpp2 *priv)
 {
@@ -840,7 +917,15 @@ void mvpp2_cls_init(struct mvpp2 *priv)
 		mvpp2_cls_lookup_write(priv, &le);
 	}
 
+	/* Clear CLS_SWFWD_PCTRL register - value of QueueHigh is defined by
+	 * the Classifier
+	 */
+	mvpp2_write(priv, MVPP2_CLS_SWFWD_PCTRL_REG, 0);
+
 	mvpp2_cls_port_init_flows(priv);
+
+	/* Initialize C2 */
+	mvpp2_cls_c2_init(priv);
 }
 
 void mvpp2_cls_port_config(struct mvpp2_port *port)
@@ -915,17 +1000,8 @@ void mvpp22_rss_disable(struct mvpp2_port *port)
 /* Set CPU queue number for oversize packets */
 void mvpp2_cls_oversize_rxq_set(struct mvpp2_port *port)
 {
-	u32 val;
-
 	mvpp2_write(port->priv, MVPP2_CLS_OVERSIZE_RXQ_LOW_REG(port->id),
 		    port->first_rxq & MVPP2_CLS_OVERSIZE_RXQ_LOW_MASK);
-
-	mvpp2_write(port->priv, MVPP2_CLS_SWFWD_P2HQ_REG(port->id),
-		    (port->first_rxq >> MVPP2_CLS_OVERSIZE_RXQ_LOW_BITS));
-
-	val = mvpp2_read(port->priv, MVPP2_CLS_SWFWD_PCTRL_REG);
-	val |= MVPP2_CLS_SWFWD_PCTRL_MASK(port->id);
-	mvpp2_write(port->priv, MVPP2_CLS_SWFWD_PCTRL_REG, val);
 }
 
 static inline u32 mvpp22_rxfh_indir(struct mvpp2_port *port, u32 rxq)
diff --git a/drivers/net/ethernet/marvell/mvpp2/mvpp2_cls.h b/drivers/net/ethernet/marvell/mvpp2/mvpp2_cls.h
index 089f05f29891..e5b7d28abc07 100644
--- a/drivers/net/ethernet/marvell/mvpp2/mvpp2_cls.h
+++ b/drivers/net/ethernet/marvell/mvpp2/mvpp2_cls.h
@@ -71,6 +71,11 @@ enum mvpp2_cls_field_id {
 	MVPP22_CLS_FIELD_L4DIP = 0x1e,
 };
 
+enum mvpp2_cls_lkp_type {
+	MVPP2_CLS_LKP_HASH = 0,
+	MVPP2_CLS_LKP_DEFAULT = 3,
+	MVPP2_CLS_LKP_MAX,
+};
 enum mvpp2_cls_flow_seq {
 	MVPP2_CLS_FLOW_SEQ_NORMAL = 0,
 	MVPP2_CLS_FLOW_SEQ_FIRST1,
@@ -111,6 +116,7 @@ struct mvpp2_cls_c2_entry {
 };
 
 /* Classifier C2 engine entries */
+#define MVPP22_CLS_C2_MAX_ENTRIES	256
 #define MVPP22_CLS_C2_RSS_ENTRY(port)	(port)
 #define MVPP22_CLS_C2_N_ENTRIES		MVPP2_MAX_PORTS
 
@@ -179,9 +185,11 @@ struct mvpp2_cls_flow {
 #define MVPP2_N_FLOWS	52
 
 #define MVPP2_ENTRIES_PER_FLOW			(MVPP2_MAX_PORTS + 1)
-#define MVPP2_FLOW_C2_ENTRY(id)			((id) * MVPP2_ENTRIES_PER_FLOW)
-#define MVPP2_PORT_FLOW_HASH_ENTRY(port, id)	((id) * MVPP2_ENTRIES_PER_FLOW + \
-						(port) + 1)
+#define MVPP2_FLOW_C2_ENTRY(id)			((((id) - MVPP2_FL_START) * \
+						 MVPP2_ENTRIES_PER_FLOW) + 1)
+#define MVPP2_PORT_FLOW_INDEX(offset, id)	(MVPP2_FLOW_C2_ENTRY(id) + \
+						 1 + (offset))
+
 struct mvpp2_cls_flow_entry {
 	u32 index;
 	u32 data[MVPP2_CLS_FLOWS_TBL_DATA_WORDS];
@@ -230,4 +238,9 @@ u32 mvpp2_cls_c2_hit_count(struct mvpp2 *priv, int c2_index);
 void mvpp2_cls_c2_read(struct mvpp2 *priv, int index,
 		       struct mvpp2_cls_c2_entry *c2);
 
+int mvpp2_cls_flow_hash_find(struct mvpp2_port *port,
+			     struct mvpp2_cls_flow *flow,
+			     struct mvpp2_cls_flow_entry *fe,
+			     int *flow_index);
+
 #endif
diff --git a/drivers/net/ethernet/marvell/mvpp2/mvpp2_debugfs.c b/drivers/net/ethernet/marvell/mvpp2/mvpp2_debugfs.c
index f9744a61e5dd..1e614771f3a1 100644
--- a/drivers/net/ethernet/marvell/mvpp2/mvpp2_debugfs.c
+++ b/drivers/net/ethernet/marvell/mvpp2/mvpp2_debugfs.c
@@ -13,21 +13,6 @@
 #include "mvpp2_prs.h"
 #include "mvpp2_cls.h"
 
-struct mvpp2_dbgfs_prs_entry {
-	int tid;
-	struct mvpp2 *priv;
-};
-
-struct mvpp2_dbgfs_flow_entry {
-	int flow;
-	struct mvpp2 *priv;
-};
-
-struct mvpp2_dbgfs_port_flow_entry {
-	struct mvpp2_port *port;
-	struct mvpp2_dbgfs_flow_entry *dbg_fe;
-};
-
 static int mvpp2_dbgfs_flow_flt_hits_show(struct seq_file *s, void *unused)
 {
 	struct mvpp2_dbgfs_flow_entry *entry = s->private;
@@ -98,19 +83,10 @@ static int mvpp2_dbgfs_flow_type_open(struct inode *inode, struct file *file)
 	return single_open(file, mvpp2_dbgfs_flow_type_show, inode->i_private);
 }
 
-static int mvpp2_dbgfs_flow_type_release(struct inode *inode, struct file *file)
-{
-	struct seq_file *seq = file->private_data;
-	struct mvpp2_dbgfs_flow_entry *flow_entry = seq->private;
-
-	kfree(flow_entry);
-	return single_release(inode, file);
-}
-
 static const struct file_operations mvpp2_dbgfs_flow_type_fops = {
 	.open = mvpp2_dbgfs_flow_type_open,
 	.read = seq_read,
-	.release = mvpp2_dbgfs_flow_type_release,
+	.release = single_release,
 };
 
 static int mvpp2_dbgfs_flow_id_show(struct seq_file *s, void *unused)
@@ -142,7 +118,8 @@ static int mvpp2_dbgfs_port_flow_hash_opt_show(struct seq_file *s, void *unused)
 	if (!f)
 		return -EINVAL;
 
-	flow_index = MVPP2_PORT_FLOW_HASH_ENTRY(entry->port->id, f->flow_id);
+	if (mvpp2_cls_flow_hash_find(port, f, &fe, &flow_index))
+		return -EINVAL;
 
 	mvpp2_cls_flow_read(port->priv, flow_index, &fe);
 
@@ -160,20 +137,10 @@ static int mvpp2_dbgfs_port_flow_hash_opt_open(struct inode *inode,
 			   inode->i_private);
 }
 
-static int mvpp2_dbgfs_port_flow_hash_opt_release(struct inode *inode,
-						  struct file *file)
-{
-	struct seq_file *seq = file->private_data;
-	struct mvpp2_dbgfs_port_flow_entry *flow_entry = seq->private;
-
-	kfree(flow_entry);
-	return single_release(inode, file);
-}
-
 static const struct file_operations mvpp2_dbgfs_port_flow_hash_opt_fops = {
 	.open = mvpp2_dbgfs_port_flow_hash_opt_open,
 	.read = seq_read,
-	.release = mvpp2_dbgfs_port_flow_hash_opt_release,
+	.release = single_release,
 };
 
 static int mvpp2_dbgfs_port_flow_engine_show(struct seq_file *s, void *unused)
@@ -188,7 +155,8 @@ static int mvpp2_dbgfs_port_flow_engine_show(struct seq_file *s, void *unused)
 	if (!f)
 		return -EINVAL;
 
-	flow_index = MVPP2_PORT_FLOW_HASH_ENTRY(entry->port->id, f->flow_id);
+	if (mvpp2_cls_flow_hash_find(port, f, &fe, &flow_index))
+		return -EINVAL;
 
 	mvpp2_cls_flow_read(port->priv, flow_index, &fe);
 
@@ -289,6 +257,41 @@ static int mvpp2_dbgfs_port_vid_show(struct seq_file *s, void *unused)
 
 DEFINE_SHOW_ATTRIBUTE(mvpp2_dbgfs_port_vid);
 
+static int mvpp2_prs_hw_hits_dump(struct seq_file *s,
+				  struct mvpp2_prs_entry *pe)
+{
+	struct mvpp2 *priv = ((struct mvpp2_port *)s->private)->priv;
+	unsigned int cnt;
+
+	cnt = mvpp2_prs_hits(priv, pe->index);
+	if (cnt != 0)
+		seq_printf(s, "----- HITS: %d ------\n", cnt);
+	return 0;
+}
+
+static int mvpp2_dbgfs_port_parser_dump(struct seq_file *s,
+					struct mvpp2_prs_entry *pe)
+{
+	int i;
+
+	/* hw entry id */
+	seq_printf(s, "   [%4d] ", pe->index);
+
+	i = MVPP2_PRS_TCAM_WORDS - 1;
+	seq_printf(s, "%1.1x ", pe->tcam[i--] & MVPP2_PRS_LU_MASK);
+
+	while (i >= 0)
+		seq_printf(s, "%4.4x ", (pe->tcam[i--]) & MVPP2_PRS_WORD_MASK);
+
+	seq_printf(s, "| %4.4x %8.8x %8.8x %8.8x\n",
+		   pe->sram[3] & MVPP2_PRS_WORD_MASK,
+		   pe->sram[2],  pe->sram[1],  pe->sram[0]);
+
+	mvpp2_prs_hw_hits_dump(s, pe);
+
+	return 0;
+}
+
 static int mvpp2_dbgfs_port_parser_show(struct seq_file *s, void *unused)
 {
 	struct mvpp2_port *port = s->private;
@@ -302,7 +305,7 @@ static int mvpp2_dbgfs_port_parser_show(struct seq_file *s, void *unused)
 
 		pmap = mvpp2_prs_tcam_port_map_get(&pe);
 		if (priv->prs_shadow[i].valid && test_bit(port->id, &pmap))
-			seq_printf(s, "%03d\n", i);
+			mvpp2_dbgfs_port_parser_dump(s, &pe);
 	}
 
 	return 0;
@@ -461,19 +464,10 @@ static int mvpp2_dbgfs_prs_valid_open(struct inode *inode, struct file *file)
 	return single_open(file, mvpp2_dbgfs_prs_valid_show, inode->i_private);
 }
 
-static int mvpp2_dbgfs_prs_valid_release(struct inode *inode, struct file *file)
-{
-	struct seq_file *seq = file->private_data;
-	struct mvpp2_dbgfs_prs_entry *entry = seq->private;
-
-	kfree(entry);
-	return single_release(inode, file);
-}
-
 static const struct file_operations mvpp2_dbgfs_prs_valid_fops = {
 	.open = mvpp2_dbgfs_prs_valid_open,
 	.read = seq_read,
-	.release = mvpp2_dbgfs_prs_valid_release,
+	.release = single_release,
 };
 
 static int mvpp2_dbgfs_flow_port_init(struct dentry *parent,
@@ -487,13 +481,13 @@ static int mvpp2_dbgfs_flow_port_init(struct dentry *parent,
 	if (IS_ERR(port_dir))
 		return PTR_ERR(port_dir);
 
-	/* This will be freed by 'hash_opts' release op */
 	port_entry = kmalloc(sizeof(*port_entry), GFP_KERNEL);
 	if (!port_entry)
 		return -ENOMEM;
 
 	port_entry->port = port;
 	port_entry->dbg_fe = entry;
+	port->dbgfs_port_flow_entry = port_entry;
 
 	debugfs_create_file("hash_opts", 0444, port_dir, port_entry,
 			    &mvpp2_dbgfs_port_flow_hash_opt_fops);
@@ -518,13 +512,13 @@ static int mvpp2_dbgfs_flow_entry_init(struct dentry *parent,
 	if (!flow_entry_dir)
 		return -ENOMEM;
 
-	/* This will be freed by 'type' release op */
 	entry = kmalloc(sizeof(*entry), GFP_KERNEL);
 	if (!entry)
 		return -ENOMEM;
 
 	entry->flow = flow;
 	entry->priv = priv;
+	priv->dbgfs_flow_entry[flow] = entry;
 
 	debugfs_create_file("flow_hits", 0444, flow_entry_dir, entry,
 			    &mvpp2_dbgfs_flow_flt_hits_fops);
@@ -582,13 +576,13 @@ static int mvpp2_dbgfs_prs_entry_init(struct dentry *parent,
 	if (!prs_entry_dir)
 		return -ENOMEM;
 
-	/* The 'valid' entry's ops will free that */
 	entry = kmalloc(sizeof(*entry), GFP_KERNEL);
 	if (!entry)
 		return -ENOMEM;
 
 	entry->tid = tid;
 	entry->priv = priv;
+	priv->dbgfs_prs_entry[tid] = entry;
 
 	/* Create each attr */
 	debugfs_create_file("sram", 0444, prs_entry_dir, entry,
@@ -662,6 +656,14 @@ static int mvpp2_dbgfs_port_init(struct dentry *parent,
 
 void mvpp2_dbgfs_cleanup(struct mvpp2 *priv)
 {
+	int i;
+
+	for (i = 0; i < MVPP2_PRS_TCAM_SRAM_SIZE; i++)
+		kfree(priv->dbgfs_prs_entry[i]);
+
+	for (i = 0; i < MVPP2_N_FLOWS; i++)
+		kfree(priv->dbgfs_flow_entry[i]);
+
 	debugfs_remove_recursive(priv->dbgfs_dir);
 }
 
diff --git a/drivers/net/ethernet/marvell/mvpp2/mvpp2_main.c b/drivers/net/ethernet/marvell/mvpp2/mvpp2_main.c
index 04bee450eb3d..2c5d0b38f729 100644
--- a/drivers/net/ethernet/marvell/mvpp2/mvpp2_main.c
+++ b/drivers/net/ethernet/marvell/mvpp2/mvpp2_main.c
@@ -17,6 +17,7 @@
 #include <linux/mbus.h>
 #include <linux/module.h>
 #include <linux/mfd/syscon.h>
+#include <linux/if_vlan.h>
 #include <linux/interrupt.h>
 #include <linux/cpumask.h>
 #include <linux/of.h>
@@ -25,6 +26,8 @@
 #include <linux/of_net.h>
 #include <linux/of_address.h>
 #include <linux/of_device.h>
+#include <linux/of_reserved_mem.h>
+#include <linux/genalloc.h>
 #include <linux/phy.h>
 #include <linux/phylink.h>
 #include <linux/phy/phy.h>
@@ -32,26 +35,80 @@
 #include <linux/hrtimer.h>
 #include <linux/ktime.h>
 #include <linux/regmap.h>
+#include <linux/if_vlan.h>
+#include <linux/dma-direct.h>
+#include <linux/dma-mapping.h>
 #include <uapi/linux/ppp_defs.h>
+#include <net/dsa.h>
 #include <net/ip.h>
 #include <net/ipv6.h>
 #include <net/tso.h>
+#include <net/busy_poll.h>
 
 #include "mvpp2.h"
 #include "mvpp2_prs.h"
 #include "mvpp2_cls.h"
 
-enum mvpp2_bm_pool_log_num {
-	MVPP2_BM_SHORT,
-	MVPP2_BM_LONG,
-	MVPP2_BM_JUMBO,
-	MVPP2_BM_POOLS_NUM
+/* RX-TX fast-forwarding path optimization */
+#define MVPP2_RXTX_HASH			0xbac0
+#define MVPP2_RXTX_HASH_CONST_MASK	0xfff0
+#define MVPP2_RXTX_HASH_BMID_MASK	0xf
+/* HashBits[31..16] contain skb->head[22..7], the head is aligned and [6..0]=0,
+ * so skb->head is shifted left for (16-7) bits.
+ * This hash permits to detect 2 non-recyclable cases:
+ * - new skb with old hash inside
+ * - same skb but NET-stack has replaced the data-buffer with another one
+ */
+#define MVPP2_HEAD_HASH_SHIFT	(16 - 7)
+#define MVPP2_RXTX_HASH_GENER(skb, bm_pool_id) \
+	(((u32)(phys_addr_t)skb->head << MVPP2_HEAD_HASH_SHIFT) | \
+					MVPP2_RXTX_HASH | bm_pool_id)
+#define MVPP2_RXTX_HASH_IS_OK(skb, hash) \
+	(MVPP2_RXTX_HASH_GENER(skb, 0) == (hash & ~MVPP2_RXTX_HASH_BMID_MASK))
+#define MVPP2_RXTX_HASH_IS_OK_TX(skb, hash) \
+	(((((u32)(phys_addr_t)skb->head << MVPP2_HEAD_HASH_SHIFT) | \
+			MVPP2_RXTX_HASH) ^ hash) <= MVPP2_RXTX_HASH_BMID_MASK)
+
+/* The recycle pool size should be "effectively big" but limited (to eliminate
+ * memory-wasting on TX-pick). It should be >8 (Net-stack-forwarding-buffer)
+ * and >pkt-coalescing. For "effective" >=NAPI_POLL_WEIGHT.
+ * For 4 ports we need more buffers but not x4, statistically it is enough x3.
+ * SKB-pool is shared for Small/Large/Jumbo buffers so we need more SKBs,
+ * statistically it is enough x5.
+ */
+#define MVPP2_RECYCLE_FULL	(NAPI_POLL_WEIGHT * 3)
+#define MVPP2_RECYCLE_FULL_SKB	(NAPI_POLL_WEIGHT * 5)
+
+struct mvpp2_recycle_pool {
+	void *pbuf[MVPP2_RECYCLE_FULL_SKB];
 };
 
-static struct {
-	int pkt_size;
-	int buf_num;
-} mvpp2_pools[MVPP2_BM_POOLS_NUM];
+struct mvpp2_recycle_pcpu {
+	/* All pool-indexes are in 1 cache-line */
+	short int idx[MVPP2_BM_POOLS_NUM_MAX];
+	/* BM/SKB-buffer pools */
+	struct mvpp2_recycle_pool pool[MVPP2_BM_POOLS_NUM_MAX];
+} __aligned(L1_CACHE_BYTES);
+
+struct mvpp2_share {
+	struct mvpp2_recycle_pcpu *recycle;
+	void *recycle_base;
+
+	/* Counters set by Probe/Init/Open */
+	int num_open_ports;
+} __aligned(L1_CACHE_BYTES);
+
+struct mvpp2_share mvpp2_share;
+
+static inline void mvpp2_recycle_put(struct mvpp2_port *port,
+				     struct mvpp2_txq_pcpu *txq_pcpu,
+				     struct mvpp2_txq_pcpu_buf *tx_buf);
+
+static void mvpp2_tx_done_guard_force_irq(struct mvpp2_port *port,
+					  int sw_thread, u8 to_zero_map);
+static inline void mvpp2_tx_done_guard_timer_set(struct mvpp2_port *port,
+						 int sw_thread);
+static u32 mvpp2_tx_done_guard_get_stats(struct mvpp2_port *port, int cpu);
 
 /* The prototype is added here to be used in start_dev when using ACPI. This
  * will be removed once phylink is used for all modes (dt+ACPI).
@@ -61,95 +118,39 @@ static void mvpp2_mac_config(struct net_device *dev, unsigned int mode,
 static void mvpp2_mac_link_up(struct net_device *dev, unsigned int mode,
 			      phy_interface_t interface, struct phy_device *phy);
 
+/* Branch prediction switches */
+DEFINE_STATIC_KEY_FALSE(mvpp21_variant);
+DEFINE_STATIC_KEY_FALSE(mvpp2_recycle_ena);
+
 /* Queue modes */
 #define MVPP2_QDIST_SINGLE_MODE	0
 #define MVPP2_QDIST_MULTI_MODE	1
 
 static int queue_mode = MVPP2_QDIST_MULTI_MODE;
+static int tx_fifo_protection;
+static int bm_underrun_protect = 1;
+static int recycle;
+static u32 tx_fifo_map;
 
 module_param(queue_mode, int, 0444);
 MODULE_PARM_DESC(queue_mode, "Set queue_mode (single=0, multi=1)");
 
-/* Utility/helper methods */
-
-void mvpp2_write(struct mvpp2 *priv, u32 offset, u32 data)
-{
-	writel(data, priv->swth_base[0] + offset);
-}
-
-u32 mvpp2_read(struct mvpp2 *priv, u32 offset)
-{
-	return readl(priv->swth_base[0] + offset);
-}
-
-u32 mvpp2_read_relaxed(struct mvpp2 *priv, u32 offset)
-{
-	return readl_relaxed(priv->swth_base[0] + offset);
-}
-/* These accessors should be used to access:
- *
- * - per-CPU registers, where each CPU has its own copy of the
- *   register.
- *
- *   MVPP2_BM_VIRT_ALLOC_REG
- *   MVPP2_BM_ADDR_HIGH_ALLOC
- *   MVPP22_BM_ADDR_HIGH_RLS_REG
- *   MVPP2_BM_VIRT_RLS_REG
- *   MVPP2_ISR_RX_TX_CAUSE_REG
- *   MVPP2_ISR_RX_TX_MASK_REG
- *   MVPP2_TXQ_NUM_REG
- *   MVPP2_AGGR_TXQ_UPDATE_REG
- *   MVPP2_TXQ_RSVD_REQ_REG
- *   MVPP2_TXQ_RSVD_RSLT_REG
- *   MVPP2_TXQ_SENT_REG
- *   MVPP2_RXQ_NUM_REG
- *
- * - global registers that must be accessed through a specific CPU
- *   window, because they are related to an access to a per-CPU
- *   register
- *
- *   MVPP2_BM_PHY_ALLOC_REG    (related to MVPP2_BM_VIRT_ALLOC_REG)
- *   MVPP2_BM_PHY_RLS_REG      (related to MVPP2_BM_VIRT_RLS_REG)
- *   MVPP2_RXQ_THRESH_REG      (related to MVPP2_RXQ_NUM_REG)
- *   MVPP2_RXQ_DESC_ADDR_REG   (related to MVPP2_RXQ_NUM_REG)
- *   MVPP2_RXQ_DESC_SIZE_REG   (related to MVPP2_RXQ_NUM_REG)
- *   MVPP2_RXQ_INDEX_REG       (related to MVPP2_RXQ_NUM_REG)
- *   MVPP2_TXQ_PENDING_REG     (related to MVPP2_TXQ_NUM_REG)
- *   MVPP2_TXQ_DESC_ADDR_REG   (related to MVPP2_TXQ_NUM_REG)
- *   MVPP2_TXQ_DESC_SIZE_REG   (related to MVPP2_TXQ_NUM_REG)
- *   MVPP2_TXQ_INDEX_REG       (related to MVPP2_TXQ_NUM_REG)
- *   MVPP2_TXQ_PENDING_REG     (related to MVPP2_TXQ_NUM_REG)
- *   MVPP2_TXQ_PREF_BUF_REG    (related to MVPP2_TXQ_NUM_REG)
- *   MVPP2_TXQ_PREF_BUF_REG    (related to MVPP2_TXQ_NUM_REG)
- */
-void mvpp2_percpu_write(struct mvpp2 *priv, int cpu,
-			       u32 offset, u32 data)
-{
-	writel(data, priv->swth_base[cpu] + offset);
-}
+module_param(tx_fifo_protection, int, 0444);
+MODULE_PARM_DESC(tx_fifo_protection, "Set tx_fifo_protection (off=0, on=1)");
 
-u32 mvpp2_percpu_read(struct mvpp2 *priv, int cpu,
-			     u32 offset)
-{
-	return readl(priv->swth_base[cpu] + offset);
-}
+module_param(bm_underrun_protect, int, 0444);
+MODULE_PARM_DESC(bm_underrun_protect, "Set BM underrun protect feature (0-1), def=1");
 
-void mvpp2_percpu_write_relaxed(struct mvpp2 *priv, int cpu,
-				       u32 offset, u32 data)
-{
-	writel_relaxed(data, priv->swth_base[cpu] + offset);
-}
+module_param(recycle, int, 0444);
+MODULE_PARM_DESC(recycle, "Recycle: 0:disable(default), >=1:enable");
 
-static u32 mvpp2_percpu_read_relaxed(struct mvpp2 *priv, int cpu,
-				     u32 offset)
-{
-	return readl_relaxed(priv->swth_base[cpu] + offset);
-}
+module_param(tx_fifo_map, uint, 0444);
+MODULE_PARM_DESC(tx_fifo_map, "Set PPv2 TX FIFO ports map");
 
 static dma_addr_t mvpp2_txdesc_dma_addr_get(struct mvpp2_port *port,
 					    struct mvpp2_tx_desc *tx_desc)
 {
-	if (port->priv->hw_version == MVPP21)
+	if (static_branch_unlikely(&mvpp21_variant))
 		return le32_to_cpu(tx_desc->pp21.buf_dma_addr);
 	else
 		return le64_to_cpu(tx_desc->pp22.buf_dma_addr_ptp) &
@@ -165,7 +166,7 @@ static void mvpp2_txdesc_dma_addr_set(struct mvpp2_port *port,
 	addr = dma_addr & ~MVPP2_TX_DESC_ALIGN;
 	offset = dma_addr & MVPP2_TX_DESC_ALIGN;
 
-	if (port->priv->hw_version == MVPP21) {
+	if (static_branch_unlikely(&mvpp21_variant)) {
 		tx_desc->pp21.buf_dma_addr = cpu_to_le32(addr);
 		tx_desc->pp21.packet_offset = offset;
 	} else {
@@ -180,7 +181,7 @@ static void mvpp2_txdesc_dma_addr_set(struct mvpp2_port *port,
 static size_t mvpp2_txdesc_size_get(struct mvpp2_port *port,
 				    struct mvpp2_tx_desc *tx_desc)
 {
-	if (port->priv->hw_version == MVPP21)
+	if (static_branch_unlikely(&mvpp21_variant))
 		return le16_to_cpu(tx_desc->pp21.data_size);
 	else
 		return le16_to_cpu(tx_desc->pp22.data_size);
@@ -190,7 +191,7 @@ static void mvpp2_txdesc_size_set(struct mvpp2_port *port,
 				  struct mvpp2_tx_desc *tx_desc,
 				  size_t size)
 {
-	if (port->priv->hw_version == MVPP21)
+	if (static_branch_unlikely(&mvpp21_variant))
 		tx_desc->pp21.data_size = cpu_to_le16(size);
 	else
 		tx_desc->pp22.data_size = cpu_to_le16(size);
@@ -200,7 +201,7 @@ static void mvpp2_txdesc_txq_set(struct mvpp2_port *port,
 				 struct mvpp2_tx_desc *tx_desc,
 				 unsigned int txq)
 {
-	if (port->priv->hw_version == MVPP21)
+	if (static_branch_unlikely(&mvpp21_variant))
 		tx_desc->pp21.phys_txq = txq;
 	else
 		tx_desc->pp22.phys_txq = txq;
@@ -210,7 +211,7 @@ static void mvpp2_txdesc_cmd_set(struct mvpp2_port *port,
 				 struct mvpp2_tx_desc *tx_desc,
 				 unsigned int command)
 {
-	if (port->priv->hw_version == MVPP21)
+	if (static_branch_unlikely(&mvpp21_variant))
 		tx_desc->pp21.command = cpu_to_le32(command);
 	else
 		tx_desc->pp22.command = cpu_to_le32(command);
@@ -219,7 +220,7 @@ static void mvpp2_txdesc_cmd_set(struct mvpp2_port *port,
 static unsigned int mvpp2_txdesc_offset_get(struct mvpp2_port *port,
 					    struct mvpp2_tx_desc *tx_desc)
 {
-	if (port->priv->hw_version == MVPP21)
+	if (static_branch_unlikely(&mvpp21_variant))
 		return tx_desc->pp21.packet_offset;
 	else
 		return tx_desc->pp22.packet_offset;
@@ -228,27 +229,17 @@ static unsigned int mvpp2_txdesc_offset_get(struct mvpp2_port *port,
 static dma_addr_t mvpp2_rxdesc_dma_addr_get(struct mvpp2_port *port,
 					    struct mvpp2_rx_desc *rx_desc)
 {
-	if (port->priv->hw_version == MVPP21)
+	if (static_branch_unlikely(&mvpp21_variant))
 		return le32_to_cpu(rx_desc->pp21.buf_dma_addr);
 	else
 		return le64_to_cpu(rx_desc->pp22.buf_dma_addr_key_hash) &
 		       MVPP2_DESC_DMA_MASK;
 }
 
-static unsigned long mvpp2_rxdesc_cookie_get(struct mvpp2_port *port,
-					     struct mvpp2_rx_desc *rx_desc)
-{
-	if (port->priv->hw_version == MVPP21)
-		return le32_to_cpu(rx_desc->pp21.buf_cookie);
-	else
-		return le64_to_cpu(rx_desc->pp22.buf_cookie_misc) &
-		       MVPP2_DESC_DMA_MASK;
-}
-
 static size_t mvpp2_rxdesc_size_get(struct mvpp2_port *port,
 				    struct mvpp2_rx_desc *rx_desc)
 {
-	if (port->priv->hw_version == MVPP21)
+	if (static_branch_unlikely(&mvpp21_variant))
 		return le16_to_cpu(rx_desc->pp21.data_size);
 	else
 		return le16_to_cpu(rx_desc->pp22.data_size);
@@ -257,7 +248,7 @@ static size_t mvpp2_rxdesc_size_get(struct mvpp2_port *port,
 static u32 mvpp2_rxdesc_status_get(struct mvpp2_port *port,
 				   struct mvpp2_rx_desc *rx_desc)
 {
-	if (port->priv->hw_version == MVPP21)
+	if (static_branch_unlikely(&mvpp21_variant))
 		return le32_to_cpu(rx_desc->pp21.status);
 	else
 		return le32_to_cpu(rx_desc->pp22.status);
@@ -272,12 +263,12 @@ static void mvpp2_txq_inc_get(struct mvpp2_txq_pcpu *txq_pcpu)
 
 static void mvpp2_txq_inc_put(struct mvpp2_port *port,
 			      struct mvpp2_txq_pcpu *txq_pcpu,
-			      struct sk_buff *skb,
+			      void *skb_or_tso_mark,
 			      struct mvpp2_tx_desc *tx_desc)
 {
 	struct mvpp2_txq_pcpu_buf *tx_buf =
 		txq_pcpu->buffs + txq_pcpu->txq_put_index;
-	tx_buf->skb = skb;
+	tx_buf->skb = (struct sk_buff *)skb_or_tso_mark;
 	tx_buf->size = mvpp2_txdesc_size_get(port, tx_desc);
 	tx_buf->dma = mvpp2_txdesc_dma_addr_get(port, tx_desc) +
 		mvpp2_txdesc_offset_get(port, tx_desc);
@@ -316,6 +307,82 @@ static void mvpp2_frag_free(const struct mvpp2_bm_pool *pool, void *data)
 
 /* Buffer Manager configuration routines */
 
+/* Get default packet size for given BM pool type */
+static int mvpp2_bm_pool_default_pkt_size(enum mvpp2_bm_pool_type bm_pool_type)
+{
+	switch (bm_pool_type) {
+	case MVPP2_BM_SHORT:
+		return MVPP2_BM_SHORT_PKT_SIZE;
+	case MVPP2_BM_JUMBO:
+		return MVPP2_BM_JUMBO_PKT_SIZE;
+	case MVPP2_BM_LONG:
+		return MVPP2_BM_LONG_PKT_SIZE;
+	default:
+		return -EINVAL;
+	}
+}
+
+/* Get default buffer count for given BM pool type */
+static int mvpp2_bm_pool_default_buf_num(enum mvpp2_bm_pool_type bm_pool_type)
+{
+	switch (bm_pool_type) {
+	case MVPP2_BM_SHORT:
+		return MVPP2_BM_SHORT_BUF_NUM;
+	case MVPP2_BM_JUMBO:
+		return MVPP2_BM_JUMBO_BUF_NUM;
+	case MVPP2_BM_LONG:
+		return MVPP2_BM_LONG_BUF_NUM;
+	default:
+		return -EINVAL;
+	}
+}
+
+/* Get BM pool type mapping - return the hardware Buffer Manager pools
+ * type according to the mapping to its ID:
+ * POOL#0 - short packets
+ * POOL#1 - jumbo packets
+ * POOL#2 - long packets
+ * In case the KS recycling feature is enabled, ID = 2 is
+ * the first (CPU#0) out of the per-CPU pools for long packets.
+ */
+static enum mvpp2_bm_pool_type mvpp2_bm_pool_get_type(int id)
+{
+	switch (id) {
+	case 0:
+		return MVPP2_BM_SHORT;
+	case 1:
+		return MVPP2_BM_JUMBO;
+	case 2:
+		return MVPP2_BM_LONG;
+	default:
+		if (recycle)
+			return MVPP2_BM_LONG;
+		return -EINVAL;
+	}
+}
+
+/* Get BM pool ID mapping - return the hardware Buffer Manager pools
+ * ID according to the mapping to its type:
+ * Short packets - POOL#0
+ * Jumbo packets - POOL#1
+ * Long packets - POOL#2
+ * In case the KS recycling feature is enabled, ID = 2 is
+ * the first (CPU#0) out of the per-CPU pools for long packets.
+ */
+static int mvpp2_bm_pool_get_id(enum mvpp2_bm_pool_type bm_pool_type)
+{
+	switch (bm_pool_type) {
+	case MVPP2_BM_SHORT:
+		return 0;
+	case MVPP2_BM_JUMBO:
+		return 1;
+	case MVPP2_BM_LONG:
+		return 2;
+	default:
+		return -EINVAL;
+	}
+}
+
 /* Create pool */
 static int mvpp2_bm_pool_create(struct platform_device *pdev,
 				struct mvpp2 *priv,
@@ -329,7 +396,7 @@ static int mvpp2_bm_pool_create(struct platform_device *pdev,
 	if (!IS_ALIGNED(size, 16))
 		return -EINVAL;
 
-	/* PPv2.1 needs 8 bytes per buffer pointer, PPv2.2 needs 16
+	/* PPv2.1 needs 8 bytes per buffer pointer, PPv2.2 and PPv2.3 needs 16
 	 * bytes per buffer pointer
 	 */
 	if (priv->hw_version == MVPP21)
@@ -358,11 +425,27 @@ static int mvpp2_bm_pool_create(struct platform_device *pdev,
 
 	val = mvpp2_read(priv, MVPP2_BM_POOL_CTRL_REG(bm_pool->id));
 	val |= MVPP2_BM_START_MASK;
+
+	val &= ~MVPP2_BM_LOW_THRESH_MASK;
+	val &= ~MVPP2_BM_HIGH_THRESH_MASK;
+
+	/* Set 8 Pools BPPI threshold if BM underrun protection feature
+	 * were enabled
+	 */
+	if (priv->hw_version == MVPP23 && bm_underrun_protect) {
+		val |= MVPP2_BM_LOW_THRESH_VALUE(MVPP23_BM_BPPI_LOW_THRESH);
+		val |= MVPP2_BM_HIGH_THRESH_VALUE(MVPP23_BM_BPPI_HIGH_THRESH);
+	} else {
+		val |= MVPP2_BM_LOW_THRESH_VALUE(MVPP2_BM_BPPI_LOW_THRESH);
+		val |= MVPP2_BM_HIGH_THRESH_VALUE(MVPP2_BM_BPPI_HIGH_THRESH);
+	}
+
 	mvpp2_write(priv, MVPP2_BM_POOL_CTRL_REG(bm_pool->id), val);
 
 	bm_pool->size = size;
 	bm_pool->pkt_size = 0;
 	bm_pool->buf_num = 0;
+	bm_pool->type = mvpp2_bm_pool_get_type(bm_pool->id);
 
 	return 0;
 }
@@ -385,27 +468,20 @@ static void mvpp2_bm_bufs_get_addrs(struct device *dev, struct mvpp2 *priv,
 				    dma_addr_t *dma_addr,
 				    phys_addr_t *phys_addr)
 {
-	int cpu = get_cpu();
+	unsigned int thread = mvpp2_cpu_to_thread(priv, get_cpu());
 
-	*dma_addr = mvpp2_percpu_read(priv, cpu,
+	*dma_addr = mvpp2_thread_read(priv, thread,
 				      MVPP2_BM_PHY_ALLOC_REG(bm_pool->id));
-	*phys_addr = mvpp2_percpu_read(priv, cpu, MVPP2_BM_VIRT_ALLOC_REG);
 
-	if (priv->hw_version == MVPP22) {
+	if (priv->hw_version != MVPP21 && sizeof(dma_addr_t) == 8) {
 		u32 val;
-		u32 dma_addr_highbits, phys_addr_highbits;
+		u32 dma_addr_highbits;
 
-		val = mvpp2_percpu_read(priv, cpu, MVPP22_BM_ADDR_HIGH_ALLOC);
+		val = mvpp2_thread_read(priv, thread, MVPP22_BM_ADDR_HIGH_ALLOC);
 		dma_addr_highbits = (val & MVPP22_BM_ADDR_HIGH_PHYS_MASK);
-		phys_addr_highbits = (val & MVPP22_BM_ADDR_HIGH_VIRT_MASK) >>
-			MVPP22_BM_ADDR_HIGH_VIRT_SHIFT;
-
-		if (sizeof(dma_addr_t) == 8)
-			*dma_addr |= (u64)dma_addr_highbits << 32;
-
-		if (sizeof(phys_addr_t) == 8)
-			*phys_addr |= (u64)phys_addr_highbits << 32;
+		*dma_addr |= (u64)dma_addr_highbits << 32;
 	}
+	*phys_addr = dma_to_phys(dev, *dma_addr);
 
 	put_cpu();
 }
@@ -493,9 +569,22 @@ static int mvpp2_bm_pool_destroy(struct platform_device *pdev,
 static int mvpp2_bm_pools_init(struct platform_device *pdev,
 			       struct mvpp2 *priv)
 {
-	int i, err, size;
+	int i, err, size, cpu;
 	struct mvpp2_bm_pool *bm_pool;
 
+	if (recycle) {
+		/* Allocate per-CPU long pools array */
+		priv->pools_pcpu = devm_kcalloc(&pdev->dev, num_present_cpus(),
+						sizeof(*priv->pools_pcpu),
+						GFP_KERNEL);
+		if (!priv->pools_pcpu)
+			return -ENOMEM;
+	}
+
+	/* Initialize Virtual with 0x0 */
+	for_each_present_cpu(cpu)
+		mvpp2_thread_write(priv, cpu, MVPP2_BM_VIRT_RLS_REG, 0x0);
+
 	/* Create all pools with maximum size */
 	size = MVPP2_BM_POOL_SIZE_MAX;
 	for (i = 0; i < MVPP2_BM_POOLS_NUM; i++) {
@@ -515,15 +604,46 @@ static int mvpp2_bm_pools_init(struct platform_device *pdev,
 	return err;
 }
 
+/* Routine enable PPv23 8 pool mode */
+static void mvpp23_bm_set_8pool_mode(struct mvpp2 *priv)
+{
+	int val;
+
+	val = mvpp2_read(priv, MVPP22_BM_POOL_BASE_ADDR_HIGH_REG);
+	val |= MVPP23_BM_8POOL_MODE;
+	mvpp2_write(priv, MVPP22_BM_POOL_BASE_ADDR_HIGH_REG, val);
+}
+
+/* Cleanup pool before actual initialization in the OS */
+static void mvpp2_bm_pool_cleanup(struct mvpp2 *priv, int pool_id)
+{
+	u32 val;
+	int i;
+
+	/* Drain the BM from all possible residues left by firmware */
+	for (i = 0; i < MVPP2_BM_POOL_SIZE_MAX; i++)
+		mvpp2_read(priv, MVPP2_BM_PHY_ALLOC_REG(pool_id));
+
+	/* Stop the BM pool */
+	val = mvpp2_read(priv, MVPP2_BM_POOL_CTRL_REG(pool_id));
+	val |= MVPP2_BM_STOP_MASK;
+	mvpp2_write(priv, MVPP2_BM_POOL_CTRL_REG(pool_id), val);
+
+	/* Mask BM all interrupts */
+	mvpp2_write(priv, MVPP2_BM_INTR_MASK_REG(pool_id), 0);
+	/* Clear BM cause register */
+	mvpp2_write(priv, MVPP2_BM_INTR_CAUSE_REG(pool_id), 0);
+}
+
 static int mvpp2_bm_init(struct platform_device *pdev, struct mvpp2 *priv)
 {
 	int i, err;
 
 	for (i = 0; i < MVPP2_BM_POOLS_NUM; i++) {
-		/* Mask BM all interrupts */
-		mvpp2_write(priv, MVPP2_BM_INTR_MASK_REG(i), 0);
-		/* Clear BM cause register */
-		mvpp2_write(priv, MVPP2_BM_INTR_CAUSE_REG(i), 0);
+		/* Make sure about the pool state in case it was
+		 * used by firmware.
+		 */
+		mvpp2_bm_pool_cleanup(priv, i);
 	}
 
 	/* Allocate and initialize BM pools */
@@ -532,27 +652,15 @@ static int mvpp2_bm_init(struct platform_device *pdev, struct mvpp2 *priv)
 	if (!priv->bm_pools)
 		return -ENOMEM;
 
+	if (priv->hw_version == MVPP23 && bm_underrun_protect)
+		mvpp23_bm_set_8pool_mode(priv);
+
 	err = mvpp2_bm_pools_init(pdev, priv);
 	if (err < 0)
 		return err;
 	return 0;
 }
 
-static void mvpp2_setup_bm_pool(void)
-{
-	/* Short pool */
-	mvpp2_pools[MVPP2_BM_SHORT].buf_num  = MVPP2_BM_SHORT_BUF_NUM;
-	mvpp2_pools[MVPP2_BM_SHORT].pkt_size = MVPP2_BM_SHORT_PKT_SIZE;
-
-	/* Long pool */
-	mvpp2_pools[MVPP2_BM_LONG].buf_num  = MVPP2_BM_LONG_BUF_NUM;
-	mvpp2_pools[MVPP2_BM_LONG].pkt_size = MVPP2_BM_LONG_PKT_SIZE;
-
-	/* Jumbo pool */
-	mvpp2_pools[MVPP2_BM_JUMBO].buf_num  = MVPP2_BM_JUMBO_BUF_NUM;
-	mvpp2_pools[MVPP2_BM_JUMBO].pkt_size = MVPP2_BM_JUMBO_PKT_SIZE;
-}
-
 /* Attach long pool to rxq */
 static void mvpp2_rxq_long_pool_set(struct mvpp2_port *port,
 				    int lrxq, int long_pool)
@@ -595,65 +703,254 @@ static void mvpp2_rxq_short_pool_set(struct mvpp2_port *port,
 	mvpp2_write(port->priv, MVPP2_RXQ_CONFIG_REG(prxq), val);
 }
 
-static void *mvpp2_buf_alloc(struct mvpp2_port *port,
-			     struct mvpp2_bm_pool *bm_pool,
-			     dma_addr_t *buf_dma_addr,
-			     phys_addr_t *buf_phys_addr,
-			     gfp_t gfp_mask)
+static dma_addr_t mvpp2_buf_alloc(struct mvpp2_port *port,
+				  struct mvpp2_bm_pool *bm_pool,
+				  gfp_t gfp_mask)
 {
 	dma_addr_t dma_addr;
 	void *data;
 
 	data = mvpp2_frag_alloc(bm_pool);
 	if (!data)
-		return NULL;
+		return (dma_addr_t)data;
 
 	dma_addr = dma_map_single(port->dev->dev.parent, data,
-				  MVPP2_RX_BUF_SIZE(bm_pool->pkt_size),
-				  DMA_FROM_DEVICE);
+				  bm_pool->buf_size, DMA_FROM_DEVICE);
 	if (unlikely(dma_mapping_error(port->dev->dev.parent, dma_addr))) {
 		mvpp2_frag_free(bm_pool, data);
-		return NULL;
+		dma_addr = 0;
+	}
+	return dma_addr;
+}
+
+/* Routine calculate single queue shares address space */
+static int mvpp22_calc_shared_addr_space(struct mvpp2_port *port)
+{
+	/* If number of CPU's greater than number of threads, return last
+	 * address space
+	 */
+	if (num_active_cpus() >= MVPP2_MAX_THREADS)
+		return MVPP2_MAX_THREADS - 1;
+
+	return num_active_cpus();
+}
+
+/* Routine enable flow control for RXQs conditon */
+void mvpp2_rxq_enable_fc(struct mvpp2_port *port)
+{
+	int val, cm3_state, host_id, q;
+	int fq = port->first_rxq;
+	unsigned long flags;
+
+	spin_lock_irqsave(&port->priv->mss_spinlock, flags);
+
+	/* Remove Flow control enable bit to prevent race between FW and Kernel
+	 * If Flow control were enabled, it would be re-enabled.
+	 */
+	val = mvpp2_cm3_read(port->priv, MSS_FC_COM_REG);
+	cm3_state = (val & FLOW_CONTROL_ENABLE_BIT);
+	val &= ~FLOW_CONTROL_ENABLE_BIT;
+	mvpp2_cm3_write(port->priv, MSS_FC_COM_REG, val);
+
+	/* Set same Flow control for all RXQs */
+	for (q = 0; q < port->nrxqs; q++) {
+		/* Set stop and start Flow control RXQ thresholds */
+		val = MSS_THRESHOLD_START;
+		val |= (MSS_THRESHOLD_STOP << MSS_RXQ_TRESH_STOP_OFFS);
+		mvpp2_cm3_write(port->priv, MSS_RXQ_TRESH_REG(q, fq), val);
+
+		val = mvpp2_cm3_read(port->priv, MSS_RXQ_ASS_REG(q, fq));
+		/* Set RXQ port ID */
+		val &= ~(MSS_RXQ_ASS_PORTID_MASK << MSS_RXQ_ASS_Q_BASE(q, fq));
+		val |= (port->id << MSS_RXQ_ASS_Q_BASE(q, fq));
+		val &= ~(MSS_RXQ_ASS_HOSTID_MASK << (MSS_RXQ_ASS_Q_BASE(q, fq)
+			+ MSS_RXQ_ASS_HOSTID_OFFS));
+
+		/* Calculate RXQ host ID:
+		 * In Single queue mode: Host ID equal to Host ID used for
+		 *			 shared RX interrupt
+		 * In Multi queue mode: Host ID equal to number of
+		 *			RXQ ID / number of CoS queues
+		 * In Single resource mode: Host ID always equal to 0
+		 */
+		if (queue_mode == MVPP2_QDIST_SINGLE_MODE)
+			host_id = mvpp22_calc_shared_addr_space(port);
+		else if (queue_mode == MVPP2_QDIST_MULTI_MODE)
+			host_id = q;
+		else
+			host_id = 0;
+
+		/* Set RXQ host ID */
+		val |= (host_id << (MSS_RXQ_ASS_Q_BASE(q, fq)
+			+ MSS_RXQ_ASS_HOSTID_OFFS));
+
+		mvpp2_cm3_write(port->priv, MSS_RXQ_ASS_REG(q, fq), val);
+	}
+
+	/* Notify Firmware that Flow control config space ready for update */
+	val = mvpp2_cm3_read(port->priv, MSS_FC_COM_REG);
+	val |= FLOW_CONTROL_UPDATE_COMMAND_BIT;
+	val |= cm3_state;
+	mvpp2_cm3_write(port->priv, MSS_FC_COM_REG, val);
+
+	spin_unlock_irqrestore(&port->priv->mss_spinlock, flags);
+}
+
+/* Routine disable flow control for RXQs conditon */
+void mvpp2_rxq_disable_fc(struct mvpp2_port *port)
+{
+	int val, cm3_state, q;
+	unsigned long flags;
+	int fq = port->first_rxq;
+
+	spin_lock_irqsave(&port->priv->mss_spinlock, flags);
+
+	/* Remove Flow control enable bit to prevent race between FW and Kernel
+	 * If Flow control were enabled, it would be re-enabled.
+	 */
+	val = mvpp2_cm3_read(port->priv, MSS_FC_COM_REG);
+	cm3_state = (val & FLOW_CONTROL_ENABLE_BIT);
+	val &= ~FLOW_CONTROL_ENABLE_BIT;
+	mvpp2_cm3_write(port->priv, MSS_FC_COM_REG, val);
+
+	/* Disable Flow control for all RXQs */
+	for (q = 0; q < port->nrxqs; q++) {
+		/* Set threshold 0 to disable Flow control */
+		val = 0;
+		val |= (0 << MSS_RXQ_TRESH_STOP_OFFS);
+		mvpp2_cm3_write(port->priv, MSS_RXQ_TRESH_REG(q, fq), val);
+
+		val = mvpp2_cm3_read(port->priv, MSS_RXQ_ASS_REG(q, fq));
+
+		val &= ~(MSS_RXQ_ASS_PORTID_MASK << MSS_RXQ_ASS_Q_BASE(q, fq));
+
+		val &= ~(MSS_RXQ_ASS_HOSTID_MASK << (MSS_RXQ_ASS_Q_BASE(q, fq)
+			+ MSS_RXQ_ASS_HOSTID_OFFS));
+
+		mvpp2_cm3_write(port->priv, MSS_RXQ_ASS_REG(q, fq), val);
+	}
+
+	/* Notify Firmware that Flow control config space ready for update */
+	val = mvpp2_cm3_read(port->priv, MSS_FC_COM_REG);
+	val |= FLOW_CONTROL_UPDATE_COMMAND_BIT;
+	val |= cm3_state;
+	mvpp2_cm3_write(port->priv, MSS_FC_COM_REG, val);
+
+	spin_unlock_irqrestore(&port->priv->mss_spinlock, flags);
+}
+
+/* Routine disable/enable flow control for BM pool conditon */
+void mvpp2_bm_pool_update_fc(struct mvpp2_port *port,
+			     struct mvpp2_bm_pool *pool,
+			     bool en)
+{
+	int val, cm3_state;
+	unsigned long flags;
+
+	spin_lock_irqsave(&port->priv->mss_spinlock, flags);
+
+	/* Remove Flow control enable bit to prevent race between FW and Kernel
+	 * If Flow control were enabled, it would be re-enabled.
+	 */
+	val = mvpp2_cm3_read(port->priv, MSS_FC_COM_REG);
+	cm3_state = (val & FLOW_CONTROL_ENABLE_BIT);
+	val &= ~FLOW_CONTROL_ENABLE_BIT;
+	mvpp2_cm3_write(port->priv, MSS_FC_COM_REG, val);
+
+	/* Check if BM pool should be enabled/disable */
+	if (en) {
+		/* Set BM pool start and stop thresholds per port */
+		val = mvpp2_cm3_read(port->priv, MSS_BUF_POOL_REG(pool->id));
+		val |= MSS_BUF_POOL_PORT_OFFS(port->id);
+		val &= ~MSS_BUF_POOL_START_MASK;
+		val |= (MSS_THRESHOLD_START << MSS_BUF_POOL_START_OFFS);
+		val &= ~MSS_BUF_POOL_STOP_MASK;
+		val |= MSS_THRESHOLD_STOP;
+		mvpp2_cm3_write(port->priv, MSS_BUF_POOL_REG(pool->id), val);
+	} else {
+		/* Remove BM pool from the port */
+		val = mvpp2_cm3_read(port->priv, MSS_BUF_POOL_REG(pool->id));
+		val &= ~MSS_BUF_POOL_PORT_OFFS(port->id);
+
+		/* Zero BM pool start and stop thresholds to disable pool
+		 * flow control if pool empty (not used by any port)
+		 */
+		if (!pool->buf_num) {
+			val &= ~MSS_BUF_POOL_START_MASK;
+			val &= ~MSS_BUF_POOL_STOP_MASK;
+		}
+
+		mvpp2_cm3_write(port->priv, MSS_BUF_POOL_REG(pool->id), val);
+	}
+
+	/* Notify Firmware that Flow control config space ready for update */
+	val = mvpp2_cm3_read(port->priv, MSS_FC_COM_REG);
+	val |= FLOW_CONTROL_UPDATE_COMMAND_BIT;
+	val |= cm3_state;
+	mvpp2_cm3_write(port->priv, MSS_FC_COM_REG, val);
+
+	spin_unlock_irqrestore(&port->priv->mss_spinlock, flags);
+}
+
+static int mvpp2_enable_global_fc(struct mvpp2 *priv)
+{
+	int val, timeout = 0;
+
+	/* Enable global flow control. In this stage global
+	 * flow control enabled, but still disabled per port.
+	 */
+	val = mvpp2_cm3_read(priv, MSS_FC_COM_REG);
+	val |= FLOW_CONTROL_ENABLE_BIT;
+	mvpp2_cm3_write(priv, MSS_FC_COM_REG, val);
+
+	/* Check if Firmware running and disable FC if not*/
+	val |= FLOW_CONTROL_UPDATE_COMMAND_BIT;
+	mvpp2_cm3_write(priv, MSS_FC_COM_REG, val);
+
+	while (timeout < MSS_FC_MAX_TIMEOUT) {
+		val = mvpp2_cm3_read(priv, MSS_FC_COM_REG);
+
+		if (!(val & FLOW_CONTROL_UPDATE_COMMAND_BIT))
+			return 0;
+		usleep_range(10, 20);
+		timeout++;
 	}
-	*buf_dma_addr = dma_addr;
-	*buf_phys_addr = virt_to_phys(data);
 
-	return data;
+	priv->global_tx_fc = false;
+	return -ENOTSUPP;
 }
 
 /* Release buffer to BM */
 static inline void mvpp2_bm_pool_put(struct mvpp2_port *port, int pool,
-				     dma_addr_t buf_dma_addr,
-				     phys_addr_t buf_phys_addr)
+				     dma_addr_t buf_dma_addr)
 {
-	int cpu = get_cpu();
+	unsigned int thread = mvpp2_cpu_to_thread(port->priv, get_cpu());
+	unsigned long flags = 0;
 
-	if (port->priv->hw_version == MVPP22) {
-		u32 val = 0;
+	if (test_bit(thread, &port->priv->lock_map))
+		spin_lock_irqsave(&port->bm_lock[thread], flags);
 
-		if (sizeof(dma_addr_t) == 8)
-			val |= upper_32_bits(buf_dma_addr) &
+	/* MVPP2_BM_VIRT_RLS_REG is not interpreted by HW, and simply
+	 * returned in the "cookie" field of the RX descriptor.
+	 * For performance reasons don't store VA|PA and don't use "cookie".
+	 * VA/PA obtained faster from dma_to_phys(dma-addr) and phys_to_virt.
+	 */
+#if defined(CONFIG_ARCH_DMA_ADDR_T_64BIT) && defined(CONFIG_PHYS_ADDR_T_64BIT)
+	if (!static_branch_unlikely(&mvpp21_variant)) {
+		u32 val = upper_32_bits(buf_dma_addr) &
 				MVPP22_BM_ADDR_HIGH_PHYS_RLS_MASK;
 
-		if (sizeof(phys_addr_t) == 8)
-			val |= (upper_32_bits(buf_phys_addr)
-				<< MVPP22_BM_ADDR_HIGH_VIRT_RLS_SHIFT) &
-				MVPP22_BM_ADDR_HIGH_VIRT_RLS_MASK;
-
-		mvpp2_percpu_write_relaxed(port->priv, cpu,
+		mvpp2_thread_write_relaxed(port->priv, thread,
 					   MVPP22_BM_ADDR_HIGH_RLS_REG, val);
 	}
+#endif
 
-	/* MVPP2_BM_VIRT_RLS_REG is not interpreted by HW, and simply
-	 * returned in the "cookie" field of the RX
-	 * descriptor. Instead of storing the virtual address, we
-	 * store the physical address
-	 */
-	mvpp2_percpu_write_relaxed(port->priv, cpu,
-				   MVPP2_BM_VIRT_RLS_REG, buf_phys_addr);
-	mvpp2_percpu_write_relaxed(port->priv, cpu,
+	mvpp2_thread_write_relaxed(port->priv, thread,
 				   MVPP2_BM_PHY_RLS_REG(pool), buf_dma_addr);
 
+	if (test_bit(thread, &port->priv->lock_map))
+		spin_unlock_irqrestore(&port->bm_lock[thread], flags);
+
 	put_cpu();
 }
 
@@ -661,13 +958,8 @@ static inline void mvpp2_bm_pool_put(struct mvpp2_port *port, int pool,
 static int mvpp2_bm_bufs_add(struct mvpp2_port *port,
 			     struct mvpp2_bm_pool *bm_pool, int buf_num)
 {
-	int i, buf_size, total_size;
+	int i;
 	dma_addr_t dma_addr;
-	phys_addr_t phys_addr;
-	void *buf;
-
-	buf_size = MVPP2_RX_BUF_SIZE(bm_pool->pkt_size);
-	total_size = MVPP2_RX_TOTAL_SIZE(buf_size);
 
 	if (buf_num < 0 ||
 	    (buf_num + bm_pool->buf_num > bm_pool->size)) {
@@ -678,13 +970,11 @@ static int mvpp2_bm_bufs_add(struct mvpp2_port *port,
 	}
 
 	for (i = 0; i < buf_num; i++) {
-		buf = mvpp2_buf_alloc(port, bm_pool, &dma_addr,
-				      &phys_addr, GFP_KERNEL);
-		if (!buf)
+		dma_addr = mvpp2_buf_alloc(port, bm_pool, GFP_KERNEL);
+		if (!dma_addr)
 			break;
 
-		mvpp2_bm_pool_put(port, bm_pool->id, dma_addr,
-				  phys_addr);
+		mvpp2_bm_pool_put(port, bm_pool->id, dma_addr);
 	}
 
 	/* Update BM driver with number of buffers added to pool */
@@ -692,7 +982,9 @@ static int mvpp2_bm_bufs_add(struct mvpp2_port *port,
 
 	netdev_dbg(port->dev,
 		   "pool %d: pkt_size=%4d, buf_size=%4d, total_size=%4d\n",
-		   bm_pool->id, bm_pool->pkt_size, buf_size, total_size);
+		   bm_pool->id, bm_pool->pkt_size,
+		   MVPP2_RX_BUF_SIZE(bm_pool->pkt_size),
+		   bm_pool->frag_size);
 
 	netdev_dbg(port->dev,
 		   "pool %d: %d of %d buffers added\n",
@@ -707,6 +999,7 @@ static struct mvpp2_bm_pool *
 mvpp2_bm_pool_use(struct mvpp2_port *port, unsigned pool, int pkt_size)
 {
 	struct mvpp2_bm_pool *new_pool = &port->priv->bm_pools[pool];
+	enum mvpp2_bm_pool_type pool_type = mvpp2_bm_pool_get_type(pool);
 	int num;
 
 	if (pool >= MVPP2_BM_POOLS_NUM) {
@@ -724,16 +1017,20 @@ mvpp2_bm_pool_use(struct mvpp2_port *port, unsigned pool, int pkt_size)
 		 * the pool is not empty
 		 */
 		pkts_num = new_pool->buf_num;
-		if (pkts_num == 0)
-			pkts_num = mvpp2_pools[pool].buf_num;
-		else
+		if (pkts_num == 0) {
+			pkts_num = mvpp2_bm_pool_default_buf_num(pool_type);
+			if (pkts_num < 0)
+				return NULL;
+		} else {
 			mvpp2_bm_bufs_free(port->dev->dev.parent,
 					   port->priv, new_pool, pkts_num);
+		}
 
 		new_pool->pkt_size = pkt_size;
 		new_pool->frag_size =
-			SKB_DATA_ALIGN(MVPP2_RX_BUF_SIZE(pkt_size)) +
-			MVPP2_SKB_SHINFO_SIZE;
+			SKB_DATA_ALIGN(MVPP2_RX_BUF_SIZE(pkt_size +
+						MVPP2_VLAN_TAG_EDSA_LEN)) +
+						MVPP2_SKB_SHINFO_SIZE;
 
 		/* Allocate buffers for this pool */
 		num = mvpp2_bm_bufs_add(port, new_pool, pkts_num);
@@ -750,28 +1047,125 @@ mvpp2_bm_pool_use(struct mvpp2_port *port, unsigned pool, int pkt_size)
 	return new_pool;
 }
 
+/* Create long pool per-CPU */
+static void mvpp2_bm_pool_pcpu_use(void *arg)
+{
+	struct mvpp2_port *port = arg;
+	struct mvpp2_bm_pool **pools_pcpu = port->priv->pools_pcpu;
+	int cpu = smp_processor_id();
+	int pool_id, pkt_size;
+
+	if (pools_pcpu[cpu])
+		return;
+
+	pool_id = mvpp2_bm_pool_get_id(MVPP2_BM_LONG) + cpu,
+	pkt_size = mvpp2_bm_pool_default_pkt_size(MVPP2_BM_LONG);
+
+	pools_pcpu[cpu] = mvpp2_bm_pool_use(port, pool_id, pkt_size);
+}
+
+/* Initialize pools for swf */
+static int mvpp2_swf_bm_pool_pcpu_init(struct mvpp2_port *port)
+{
+	enum mvpp2_bm_pool_type long_pool_type, short_pool_type;
+	int rxq, pkt_size, pool_id, cpu;
+
+	/* If port pkt_size is higher than 1518B:
+	 * HW Long pool - SW Jumbo pool, HW Short pool - SW Long pool
+	 * else: HW Long pool - SW Long pool, HW Short pool - SW Short pool
+	 */
+	if (port->pkt_size > MVPP2_BM_LONG_PKT_SIZE) {
+		long_pool_type = MVPP2_BM_JUMBO;
+		short_pool_type = MVPP2_BM_LONG;
+	} else {
+		long_pool_type = MVPP2_BM_LONG;
+		short_pool_type = MVPP2_BM_SHORT;
+	}
+
+	/* First handle the per-CPU long pools,
+	 * as they are used in both cases.
+	 */
+	on_each_cpu(mvpp2_bm_pool_pcpu_use, port, 1);
+	/* Sanity check */
+	for_each_present_cpu(cpu) {
+		if (!port->priv->pools_pcpu[cpu])
+			return -ENOMEM;
+	}
+
+	if (!port->pool_long && long_pool_type == MVPP2_BM_JUMBO) {
+		/* HW Long pool - SW Jumbo pool */
+		pool_id = mvpp2_bm_pool_get_id(long_pool_type);
+		pkt_size = mvpp2_bm_pool_default_pkt_size(long_pool_type);
+
+		port->pool_long = mvpp2_bm_pool_use(port, pool_id, pkt_size);
+		if (!port->pool_long)
+			return -ENOMEM;
+
+		port->pool_long->port_map |= BIT(port->id);
+
+		for (rxq = 0; rxq < port->nrxqs; rxq++)
+			mvpp2_rxq_long_pool_set(port, rxq, port->pool_long->id);
+
+		/* HW Short pool - SW Long pool (per-CPU) */
+		port->pool_short = port->priv->pools_pcpu[0];
+		for (rxq = 0; rxq < port->nrxqs; rxq++)
+			mvpp2_rxq_short_pool_set(port, rxq,
+						 port->pool_short->id + rxq);
+
+	} else if (!port->pool_long) {
+		/* HW Long pool - SW Long pool (per-CPU) */
+		port->pool_long = port->priv->pools_pcpu[0];
+		for (rxq = 0; rxq < port->nrxqs; rxq++)
+			mvpp2_rxq_long_pool_set(port, rxq,
+						port->pool_long->id + rxq);
+	}
+
+	if (!port->pool_short) {
+		/* HW Short pool - SW Short pool */
+		pool_id = mvpp2_bm_pool_get_id(short_pool_type);
+		pkt_size = mvpp2_bm_pool_default_pkt_size(short_pool_type);
+
+		port->pool_short = mvpp2_bm_pool_use(port, pool_id, pkt_size);
+		if (!port->pool_short)
+			return -ENOMEM;
+
+		port->pool_short->port_map |= BIT(port->id);
+
+		for (rxq = 0; rxq < port->nrxqs; rxq++)
+			mvpp2_rxq_short_pool_set(port, rxq,
+						 port->pool_short->id);
+	}
+
+	/* Fill per-CPU Long pools' port map */
+	for_each_present_cpu(cpu)
+		port->priv->pools_pcpu[cpu]->port_map |= BIT(port->id);
+
+	return 0;
+}
+
 /* Initialize pools for swf */
 static int mvpp2_swf_bm_pool_init(struct mvpp2_port *port)
 {
+	enum mvpp2_bm_pool_type long_pool_type, short_pool_type;
 	int rxq;
-	enum mvpp2_bm_pool_log_num long_log_pool, short_log_pool;
 
 	/* If port pkt_size is higher than 1518B:
 	 * HW Long pool - SW Jumbo pool, HW Short pool - SW Long pool
 	 * else: HW Long pool - SW Long pool, HW Short pool - SW Short pool
 	 */
 	if (port->pkt_size > MVPP2_BM_LONG_PKT_SIZE) {
-		long_log_pool = MVPP2_BM_JUMBO;
-		short_log_pool = MVPP2_BM_LONG;
+		long_pool_type = MVPP2_BM_JUMBO;
+		short_pool_type = MVPP2_BM_LONG;
 	} else {
-		long_log_pool = MVPP2_BM_LONG;
-		short_log_pool = MVPP2_BM_SHORT;
+		long_pool_type = MVPP2_BM_LONG;
+		short_pool_type = MVPP2_BM_SHORT;
 	}
 
 	if (!port->pool_long) {
 		port->pool_long =
-			mvpp2_bm_pool_use(port, long_log_pool,
-					  mvpp2_pools[long_log_pool].pkt_size);
+			mvpp2_bm_pool_use(port,
+					  mvpp2_bm_pool_get_id(long_pool_type),
+				mvpp2_bm_pool_default_pkt_size(long_pool_type));
 		if (!port->pool_long)
 			return -ENOMEM;
 
@@ -783,8 +1177,9 @@ static int mvpp2_swf_bm_pool_init(struct mvpp2_port *port)
 
 	if (!port->pool_short) {
 		port->pool_short =
-			mvpp2_bm_pool_use(port, short_log_pool,
-					  mvpp2_pools[short_log_pool].pkt_size);
+			mvpp2_bm_pool_use(port,
+					  mvpp2_bm_pool_get_id(short_pool_type),
+			       mvpp2_bm_pool_default_pkt_size(short_pool_type));
 		if (!port->pool_short)
 			return -ENOMEM;
 
@@ -801,37 +1196,72 @@ static int mvpp2_swf_bm_pool_init(struct mvpp2_port *port)
 static int mvpp2_bm_update_mtu(struct net_device *dev, int mtu)
 {
 	struct mvpp2_port *port = netdev_priv(dev);
-	enum mvpp2_bm_pool_log_num new_long_pool;
+	enum mvpp2_bm_pool_type new_long_pool_type;
+	struct mvpp2_bm_pool **pools_pcpu = port->priv->pools_pcpu;
 	int pkt_size = MVPP2_RX_PKT_SIZE(mtu);
+	int err, cpu;
 
 	/* If port MTU is higher than 1518B:
 	 * HW Long pool - SW Jumbo pool, HW Short pool - SW Long pool
 	 * else: HW Long pool - SW Long pool, HW Short pool - SW Short pool
 	 */
 	if (pkt_size > MVPP2_BM_LONG_PKT_SIZE)
-		new_long_pool = MVPP2_BM_JUMBO;
+		new_long_pool_type = MVPP2_BM_JUMBO;
 	else
-		new_long_pool = MVPP2_BM_LONG;
+		new_long_pool_type = MVPP2_BM_LONG;
+
+	if (new_long_pool_type != port->pool_long->type) {
+		if (port->tx_fc) {
+			if (recycle) {
+				for_each_present_cpu(cpu)
+					mvpp2_bm_pool_update_fc(port,
+								pools_pcpu[cpu],
+								false);
+			} else if (pkt_size > MVPP2_BM_LONG_PKT_SIZE)
+				mvpp2_bm_pool_update_fc(port,
+							port->pool_short,
+							false);
+			else
+				mvpp2_bm_pool_update_fc(port, port->pool_long,
+							false);
+		}
 
-	if (new_long_pool != port->pool_long->id) {
 		/* Remove port from old short & long pool */
-		port->pool_long = mvpp2_bm_pool_use(port, port->pool_long->id,
-						    port->pool_long->pkt_size);
 		port->pool_long->port_map &= ~BIT(port->id);
 		port->pool_long = NULL;
 
-		port->pool_short = mvpp2_bm_pool_use(port, port->pool_short->id,
-						     port->pool_short->pkt_size);
 		port->pool_short->port_map &= ~BIT(port->id);
 		port->pool_short = NULL;
 
 		port->pkt_size =  pkt_size;
 
 		/* Add port to new short & long pool */
-		mvpp2_swf_bm_pool_init(port);
+		if (recycle) {
+			for_each_present_cpu(cpu)
+				pools_pcpu[cpu]->port_map &= ~BIT(port->id);
+			err = mvpp2_swf_bm_pool_pcpu_init(port);
+		} else {
+			err = mvpp2_swf_bm_pool_init(port);
+		}
+		if (err)
+			return err;
+
+		if (port->tx_fc) {
+			if (recycle) {
+				for_each_present_cpu(cpu)
+					mvpp2_bm_pool_update_fc(port,
+								pools_pcpu[cpu],
+								false);
+			} else if (pkt_size > MVPP2_BM_LONG_PKT_SIZE)
+				mvpp2_bm_pool_update_fc(port, port->pool_long,
+							true);
+			else
+				mvpp2_bm_pool_update_fc(port, port->pool_short,
+							true);
+		}
 
 		/* Update L4 checksum when jumbo enable/disable on port */
-		if (new_long_pool == MVPP2_BM_JUMBO && port->id != 0) {
+		if (new_long_pool_type == MVPP2_BM_JUMBO && port->id != 0) {
 			dev->features &= ~(NETIF_F_IP_CSUM | NETIF_F_IPV6_CSUM);
 			dev->hw_features &= ~(NETIF_F_IP_CSUM |
 					      NETIF_F_IPV6_CSUM);
@@ -886,7 +1316,7 @@ static inline void mvpp2_qvec_interrupt_disable(struct mvpp2_queue_vector *qvec)
 		    MVPP2_ISR_DISABLE_INTERRUPT(qvec->sw_thread_mask));
 }
 
-/* Mask the current CPU's Rx/Tx interrupts
+/* Mask the current thread's Rx/Tx interrupts
  * Called by on_each_cpu(), guaranteed to run with migration disabled,
  * using smp_processor_id() is OK.
  */
@@ -894,11 +1324,19 @@ static void mvpp2_interrupts_mask(void *arg)
 {
 	struct mvpp2_port *port = arg;
 
-	mvpp2_percpu_write(port->priv, smp_processor_id(),
+	/* If the thread isn't used, don't do anything */
+	if (smp_processor_id() > port->priv->nthreads)
+		return;
+
+	mvpp2_thread_write(port->priv,
+			   mvpp2_cpu_to_thread(port->priv, smp_processor_id()),
 			   MVPP2_ISR_RX_TX_MASK_REG(port->id), 0);
+	mvpp2_thread_write(port->priv,
+			   mvpp2_cpu_to_thread(port->priv, smp_processor_id()),
+			   MVPP2_ISR_RX_ERR_CAUSE_REG(port->id), 0);
 }
 
-/* Unmask the current CPU's Rx/Tx interrupts.
+/* Unmask the current thread's Rx/Tx interrupts.
  * Called by on_each_cpu(), guaranteed to run with migration disabled,
  * using smp_processor_id() is OK.
  */
@@ -907,13 +1345,24 @@ static void mvpp2_interrupts_unmask(void *arg)
 	struct mvpp2_port *port = arg;
 	u32 val;
 
-	val = MVPP2_CAUSE_MISC_SUM_MASK |
-		MVPP2_CAUSE_RXQ_OCCUP_DESC_ALL_MASK(port->priv->hw_version);
+	/* If the thread isn't used, don't do anything */
+	if (smp_processor_id() > port->priv->nthreads)
+		return;
+
+	if (port->flags & MVPP22_F_IF_MUSDK)
+		return;
+
+	val = MVPP2_CAUSE_RXQ_OCCUP_DESC_ALL_MASK(mvpp21_variant);
 	if (port->has_tx_irqs)
 		val |= MVPP2_CAUSE_TXQ_OCCUP_DESC_ALL_MASK;
 
-	mvpp2_percpu_write(port->priv, smp_processor_id(),
+	mvpp2_thread_write(port->priv,
+			   mvpp2_cpu_to_thread(port->priv, smp_processor_id()),
 			   MVPP2_ISR_RX_TX_MASK_REG(port->id), val);
+	mvpp2_thread_write(port->priv,
+			   mvpp2_cpu_to_thread(port->priv, smp_processor_id()),
+			   MVPP2_ISR_RX_ERR_CAUSE_REG(port->id),
+			   MVPP2_ISR_RX_ERR_CAUSE_NONOCC_MASK);
 }
 
 static void
@@ -922,13 +1371,13 @@ mvpp2_shared_interrupt_mask_unmask(struct mvpp2_port *port, bool mask)
 	u32 val;
 	int i;
 
-	if (port->priv->hw_version != MVPP22)
+	if (port->priv->hw_version == MVPP21)
 		return;
 
 	if (mask)
 		val = 0;
 	else
-		val = MVPP2_CAUSE_RXQ_OCCUP_DESC_ALL_MASK(MVPP22);
+		val = MVPP2_CAUSE_RXQ_OCCUP_DESC_ALL_MASK(mvpp21_variant);
 
 	for (i = 0; i < port->nqvecs; i++) {
 		struct mvpp2_queue_vector *v = port->qvecs + i;
@@ -936,8 +1385,11 @@ mvpp2_shared_interrupt_mask_unmask(struct mvpp2_port *port, bool mask)
 		if (v->type != MVPP2_QUEUE_VECTOR_SHARED)
 			continue;
 
-		mvpp2_percpu_write(port->priv, v->sw_thread_id,
+		mvpp2_thread_write(port->priv, v->sw_thread_id,
 				   MVPP2_ISR_RX_TX_MASK_REG(port->id), val);
+		mvpp2_thread_write(port->priv, v->sw_thread_id,
+				   MVPP2_ISR_RX_ERR_CAUSE_REG(port->id),
+				   MVPP2_ISR_RX_ERR_CAUSE_NONOCC_MASK);
 	}
 }
 
@@ -954,39 +1406,57 @@ static void mvpp22_gop_init_rgmii(struct mvpp2_port *port)
 
 	regmap_read(priv->sysctrl_base, GENCONF_CTRL0, &val);
 	if (port->gop_id == 2)
-		val |= GENCONF_CTRL0_PORT0_RGMII | GENCONF_CTRL0_PORT1_RGMII;
+		val |= GENCONF_CTRL0_PORT0_RGMII;
 	else if (port->gop_id == 3)
 		val |= GENCONF_CTRL0_PORT1_RGMII_MII;
 	regmap_write(priv->sysctrl_base, GENCONF_CTRL0, val);
 }
 
-static void mvpp22_gop_init_sgmii(struct mvpp2_port *port)
+static void mvpp22_gop_init_mii(struct mvpp2_port *port)
 {
 	struct mvpp2 *priv = port->priv;
 	u32 val;
 
 	regmap_read(priv->sysctrl_base, GENCONF_PORT_CTRL0, &val);
-	val |= GENCONF_PORT_CTRL0_BUS_WIDTH_SELECT |
-	       GENCONF_PORT_CTRL0_RX_DATA_SAMPLE;
+	val |= GENCONF_PORT_CTRL0_BUS_WIDTH_SELECT;
 	regmap_write(priv->sysctrl_base, GENCONF_PORT_CTRL0, val);
 
-	if (port->gop_id > 1) {
-		regmap_read(priv->sysctrl_base, GENCONF_CTRL0, &val);
-		if (port->gop_id == 2)
-			val &= ~GENCONF_CTRL0_PORT0_RGMII;
-		else if (port->gop_id == 3)
-			val &= ~GENCONF_CTRL0_PORT1_RGMII_MII;
+	regmap_read(priv->sysctrl_base, GENCONF_CTRL0, &val);
+	val |= GENCONF_CTRL0_PORT1_RGMII_MII;
+	val |= GENCONF_CTRL0_PORT1_RGMII;
+	regmap_write(priv->sysctrl_base, GENCONF_CTRL0, val);
+}
+
+static void mvpp22_gop_init_sgmii(struct mvpp2_port *port)
+{
+	struct mvpp2 *priv = port->priv;
+	u32 val;
+
+	regmap_read(priv->sysctrl_base, GENCONF_PORT_CTRL0, &val);
+	val |= GENCONF_PORT_CTRL0_BUS_WIDTH_SELECT |
+	       GENCONF_PORT_CTRL0_RX_DATA_SAMPLE;
+	regmap_write(priv->sysctrl_base, GENCONF_PORT_CTRL0, val);
+
+	if (port->gop_id > 1) {
+		regmap_read(priv->sysctrl_base, GENCONF_CTRL0, &val);
+		if (port->gop_id == 2)
+			val &= ~GENCONF_CTRL0_PORT0_RGMII;
+		else if (port->gop_id == 3)
+			val &= ~GENCONF_CTRL0_PORT1_RGMII_MII;
 		regmap_write(priv->sysctrl_base, GENCONF_CTRL0, val);
 	}
 }
 
-static void mvpp22_gop_init_10gkr(struct mvpp2_port *port)
+static void mvpp22_gop_init_xpcs(struct mvpp2_port *port)
 {
 	struct mvpp2 *priv = port->priv;
-	void __iomem *mpcs = priv->iface_base + MVPP22_MPCS_BASE(port->gop_id);
 	void __iomem *xpcs = priv->iface_base + MVPP22_XPCS_BASE(port->gop_id);
 	u32 val;
 
+	/* Reset the XPCS when reconfiguring the lanes */
+	val = readl(xpcs + MVPP22_XPCS_CFG0);
+	writel(val & ~MVPP22_XPCS_CFG0_RESET_DIS, xpcs + MVPP22_XPCS_CFG0);
+
 	/* XPCS */
 	val = readl(xpcs + MVPP22_XPCS_CFG0);
 	val &= ~(MVPP22_XPCS_CFG0_PCS_MODE(0x3) |
@@ -994,6 +1464,18 @@ static void mvpp22_gop_init_10gkr(struct mvpp2_port *port)
 	val |= MVPP22_XPCS_CFG0_ACTIVE_LANE(2);
 	writel(val, xpcs + MVPP22_XPCS_CFG0);
 
+	/* Release lanes from reset */
+	val = readl(xpcs + MVPP22_XPCS_CFG0);
+	writel(val | MVPP22_XPCS_CFG0_RESET_DIS, xpcs + MVPP22_XPCS_CFG0);
+
+}
+
+static void mvpp22_gop_init_mpcs(struct mvpp2_port *port)
+{
+	struct mvpp2 *priv = port->priv;
+	void __iomem *mpcs = priv->iface_base + MVPP22_MPCS_BASE(port->gop_id);
+	u32 val;
+
 	/* MPCS */
 	val = readl(mpcs + MVPP22_MPCS_CTRL);
 	val &= ~MVPP22_MPCS_CTRL_FWD_ERR_CONN;
@@ -1010,6 +1492,49 @@ static void mvpp22_gop_init_10gkr(struct mvpp2_port *port)
 	writel(val, mpcs + MVPP22_MPCS_CLK_RESET);
 }
 
+static void mvpp22_gop_fca_enable_periodic(struct mvpp2_port *port, bool en)
+{
+	struct mvpp2 *priv = port->priv;
+	void __iomem *fca = priv->iface_base + MVPP22_FCA_BASE(port->gop_id);
+	u32 val;
+
+	val = readl(fca + MVPP22_FCA_CONTROL_REG);
+	val &= ~MVPP22_FCA_ENABLE_PERIODIC;
+	if (en)
+		val |= MVPP22_FCA_ENABLE_PERIODIC;
+	writel(val, fca + MVPP22_FCA_CONTROL_REG);
+}
+
+static void mvpp22_gop_fca_set_timer(struct mvpp2_port *port, u32 timer)
+{
+	struct mvpp2 *priv = port->priv;
+	void __iomem *fca = priv->iface_base + MVPP22_FCA_BASE(port->gop_id);
+	u32 lsb, msb;
+
+	lsb = timer & MVPP22_FCA_REG_MASK;
+	msb = timer >> MVPP22_FCA_REG_SIZE;
+
+	writel(lsb, fca + MVPP22_PERIODIC_COUNTER_LSB_REG);
+	writel(msb, fca + MVPP22_PERIODIC_COUNTER_MSB_REG);
+}
+
+/* Set Flow Control timer x140 faster than pause quanta to ensure that link
+ * partner won't send taffic if port in XOFF mode.
+ */
+static void mvpp22_gop_fca_set_periodic_timer(struct mvpp2_port *port)
+{
+	u32 timer;
+
+	timer = (port->priv->tclk / (USEC_PER_SEC * FC_CLK_DIVIDER))
+		* FC_QUANTA;
+
+	mvpp22_gop_fca_enable_periodic(port, false);
+
+	mvpp22_gop_fca_set_timer(port, timer);
+
+	mvpp22_gop_fca_enable_periodic(port, true);
+}
+
 static int mvpp22_gop_init(struct mvpp2_port *port)
 {
 	struct mvpp2 *priv = port->priv;
@@ -1019,6 +1544,11 @@ static int mvpp22_gop_init(struct mvpp2_port *port)
 		return 0;
 
 	switch (port->phy_interface) {
+	case PHY_INTERFACE_MODE_MII:
+		if (port->gop_id == 0 || port->gop_id == 2)
+			goto invalid_conf;
+		mvpp22_gop_init_mii(port);
+		break;
 	case PHY_INTERFACE_MODE_RGMII:
 	case PHY_INTERFACE_MODE_RGMII_ID:
 	case PHY_INTERFACE_MODE_RGMII_RXID:
@@ -1030,13 +1560,22 @@ static int mvpp22_gop_init(struct mvpp2_port *port)
 	case PHY_INTERFACE_MODE_SGMII:
 	case PHY_INTERFACE_MODE_1000BASEX:
 	case PHY_INTERFACE_MODE_2500BASEX:
+	case PHY_INTERFACE_MODE_2500BASET:
 		mvpp22_gop_init_sgmii(port);
 		break;
-	case PHY_INTERFACE_MODE_10GKR:
+	case PHY_INTERFACE_MODE_RXAUI:
 		if (port->gop_id != 0)
 			goto invalid_conf;
-		mvpp22_gop_init_10gkr(port);
+		mvpp22_gop_init_xpcs(port);
+		break;
+	case PHY_INTERFACE_MODE_10GKR:
+	case PHY_INTERFACE_MODE_5GKR:
+		if (!port->has_xlg_mac)
+			goto invalid_conf;
+		mvpp22_gop_init_mpcs(port);
 		break;
+	case PHY_INTERFACE_MODE_INTERNAL:
+		return 0;
 	default:
 		goto unsupported_conf;
 	}
@@ -1054,6 +1593,8 @@ static int mvpp22_gop_init(struct mvpp2_port *port)
 	val |= GENCONF_SOFT_RESET1_GOP;
 	regmap_write(priv->sysctrl_base, GENCONF_SOFT_RESET1, val);
 
+	mvpp22_gop_fca_set_periodic_timer(port);
+
 unsupported_conf:
 	return 0;
 
@@ -1067,19 +1608,22 @@ static void mvpp22_gop_unmask_irq(struct mvpp2_port *port)
 	u32 val;
 
 	if (phy_interface_mode_is_rgmii(port->phy_interface) ||
+	    phy_interface_mode_is_8023z(port->phy_interface) ||
+	    port->phy_interface == PHY_INTERFACE_MODE_MII ||
 	    port->phy_interface == PHY_INTERFACE_MODE_SGMII ||
-	    port->phy_interface == PHY_INTERFACE_MODE_1000BASEX ||
-	    port->phy_interface == PHY_INTERFACE_MODE_2500BASEX) {
+	    port->phy_interface == PHY_INTERFACE_MODE_2500BASET) {
 		/* Enable the GMAC link status irq for this port */
 		val = readl(port->base + MVPP22_GMAC_INT_SUM_MASK);
 		val |= MVPP22_GMAC_INT_SUM_MASK_LINK_STAT;
 		writel(val, port->base + MVPP22_GMAC_INT_SUM_MASK);
 	}
 
-	if (port->gop_id == 0) {
+	if (port->has_xlg_mac) {
 		/* Enable the XLG/GIG irqs for this port */
 		val = readl(port->base + MVPP22_XLG_EXT_INT_MASK);
-		if (port->phy_interface == PHY_INTERFACE_MODE_10GKR)
+		if (port->phy_interface == PHY_INTERFACE_MODE_10GKR ||
+		    port->phy_interface == PHY_INTERFACE_MODE_5GKR ||
+		    port->phy_interface == PHY_INTERFACE_MODE_INTERNAL)
 			val |= MVPP22_XLG_EXT_INT_MASK_XLG;
 		else
 			val |= MVPP22_XLG_EXT_INT_MASK_GIG;
@@ -1091,7 +1635,7 @@ static void mvpp22_gop_mask_irq(struct mvpp2_port *port)
 {
 	u32 val;
 
-	if (port->gop_id == 0) {
+	if (port->has_xlg_mac) {
 		val = readl(port->base + MVPP22_XLG_EXT_INT_MASK);
 		val &= ~(MVPP22_XLG_EXT_INT_MASK_XLG |
 			 MVPP22_XLG_EXT_INT_MASK_GIG);
@@ -1099,9 +1643,10 @@ static void mvpp22_gop_mask_irq(struct mvpp2_port *port)
 	}
 
 	if (phy_interface_mode_is_rgmii(port->phy_interface) ||
+	    phy_interface_mode_is_8023z(port->phy_interface) ||
+	    port->phy_interface == PHY_INTERFACE_MODE_MII ||
 	    port->phy_interface == PHY_INTERFACE_MODE_SGMII ||
-	    port->phy_interface == PHY_INTERFACE_MODE_1000BASEX ||
-	    port->phy_interface == PHY_INTERFACE_MODE_2500BASEX) {
+	    port->phy_interface == PHY_INTERFACE_MODE_2500BASET) {
 		val = readl(port->base + MVPP22_GMAC_INT_SUM_MASK);
 		val &= ~MVPP22_GMAC_INT_SUM_MASK_LINK_STAT;
 		writel(val, port->base + MVPP22_GMAC_INT_SUM_MASK);
@@ -1112,16 +1657,17 @@ static void mvpp22_gop_setup_irq(struct mvpp2_port *port)
 {
 	u32 val;
 
-	if (phy_interface_mode_is_rgmii(port->phy_interface) ||
-	    port->phy_interface == PHY_INTERFACE_MODE_SGMII ||
-	    port->phy_interface == PHY_INTERFACE_MODE_1000BASEX ||
-	    port->phy_interface == PHY_INTERFACE_MODE_2500BASEX) {
+	if (port->phylink ||
+	    phy_interface_mode_is_rgmii(port->phy_interface) ||
+	    phy_interface_mode_is_8023z(port->phy_interface) ||
+	    port->phy_interface == PHY_INTERFACE_MODE_MII ||
+	    port->phy_interface == PHY_INTERFACE_MODE_SGMII) {
 		val = readl(port->base + MVPP22_GMAC_INT_MASK);
 		val |= MVPP22_GMAC_INT_MASK_LINK_STAT;
 		writel(val, port->base + MVPP22_GMAC_INT_MASK);
 	}
 
-	if (port->gop_id == 0) {
+	if (port->has_xlg_mac) {
 		val = readl(port->base + MVPP22_XLG_INT_MASK);
 		val |= MVPP22_XLG_INT_MASK_LINK;
 		writel(val, port->base + MVPP22_XLG_INT_MASK);
@@ -1142,28 +1688,13 @@ static void mvpp22_gop_setup_irq(struct mvpp2_port *port)
  */
 static int mvpp22_comphy_init(struct mvpp2_port *port)
 {
-	enum phy_mode mode;
 	int ret;
 
 	if (!port->comphy)
 		return 0;
 
-	switch (port->phy_interface) {
-	case PHY_INTERFACE_MODE_SGMII:
-	case PHY_INTERFACE_MODE_1000BASEX:
-		mode = PHY_MODE_SGMII;
-		break;
-	case PHY_INTERFACE_MODE_2500BASEX:
-		mode = PHY_MODE_2500SGMII;
-		break;
-	case PHY_INTERFACE_MODE_10GKR:
-		mode = PHY_MODE_10GKR;
-		break;
-	default:
-		return -EINVAL;
-	}
-
-	ret = phy_set_mode(port->comphy, mode);
+	ret = phy_set_mode_ext(port->comphy, PHY_MODE_ETHERNET,
+			       port->phy_interface);
 	if (ret)
 		return ret;
 
@@ -1174,10 +1705,13 @@ static void mvpp2_port_enable(struct mvpp2_port *port)
 {
 	u32 val;
 
-	/* Only GOP port 0 has an XLG MAC */
-	if (port->gop_id == 0 &&
-	    (port->phy_interface == PHY_INTERFACE_MODE_XAUI ||
-	     port->phy_interface == PHY_INTERFACE_MODE_10GKR)) {
+	if (port->phy_interface == PHY_INTERFACE_MODE_INTERNAL)
+		return;
+
+	if (port->has_xlg_mac &&
+	    (port->phy_interface == PHY_INTERFACE_MODE_RXAUI ||
+	     port->phy_interface == PHY_INTERFACE_MODE_10GKR ||
+	     port->phy_interface == PHY_INTERFACE_MODE_5GKR)) {
 		val = readl(port->base + MVPP22_XLG_CTRL0_REG);
 		val |= MVPP22_XLG_CTRL0_PORT_EN |
 		       MVPP22_XLG_CTRL0_MAC_RESET_DIS;
@@ -1195,17 +1729,16 @@ static void mvpp2_port_disable(struct mvpp2_port *port)
 {
 	u32 val;
 
-	/* Only GOP port 0 has an XLG MAC */
-	if (port->gop_id == 0 &&
-	    (port->phy_interface == PHY_INTERFACE_MODE_XAUI ||
-	     port->phy_interface == PHY_INTERFACE_MODE_10GKR)) {
+	if (port->phy_interface == PHY_INTERFACE_MODE_INTERNAL)
+		return;
+
+	if (port->has_xlg_mac &&
+	    (port->phy_interface == PHY_INTERFACE_MODE_RXAUI ||
+	     port->phy_interface == PHY_INTERFACE_MODE_10GKR ||
+	     port->phy_interface == PHY_INTERFACE_MODE_5GKR)) {
 		val = readl(port->base + MVPP22_XLG_CTRL0_REG);
 		val &= ~MVPP22_XLG_CTRL0_PORT_EN;
 		writel(val, port->base + MVPP22_XLG_CTRL0_REG);
-
-		/* Disable & reset should be done separately */
-		val &= ~MVPP22_XLG_CTRL0_MAC_RESET_DIS;
-		writel(val, port->base + MVPP22_XLG_CTRL0_REG);
 	} else {
 		val = readl(port->base + MVPP2_GMAC_CTRL_0_REG);
 		val &= ~(MVPP2_GMAC_PORT_EN_MASK);
@@ -1236,9 +1769,8 @@ static void mvpp2_port_loopback_set(struct mvpp2_port *port,
 	else
 		val &= ~MVPP2_GMAC_GMII_LB_EN_MASK;
 
-	if (port->phy_interface == PHY_INTERFACE_MODE_SGMII ||
-	    port->phy_interface == PHY_INTERFACE_MODE_1000BASEX ||
-	    port->phy_interface == PHY_INTERFACE_MODE_2500BASEX)
+	if (phy_interface_mode_is_8023z(port->phy_interface) ||
+	    port->phy_interface == PHY_INTERFACE_MODE_SGMII)
 		val |= MVPP2_GMAC_PCS_LB_EN_MASK;
 	else
 		val &= ~MVPP2_GMAC_PCS_LB_EN_MASK;
@@ -1294,24 +1826,148 @@ static const struct mvpp2_ethtool_counter mvpp2_ethtool_regs[] = {
 	{ MVPP2_MIB_FC_RCVD, "fc_received" },
 	{ MVPP2_MIB_RX_FIFO_OVERRUN, "rx_fifo_overrun" },
 	{ MVPP2_MIB_UNDERSIZE_RCVD, "undersize_received" },
-	{ MVPP2_MIB_FRAGMENTS_RCVD, "fragments_received" },
+	{ MVPP2_MIB_FRAGMENTS_ERR_RCVD, "fragments_err_received" },
 	{ MVPP2_MIB_OVERSIZE_RCVD, "oversize_received" },
 	{ MVPP2_MIB_JABBER_RCVD, "jabber_received" },
 	{ MVPP2_MIB_MAC_RCV_ERROR, "mac_receive_error" },
 	{ MVPP2_MIB_BAD_CRC_EVENT, "bad_crc_event" },
 	{ MVPP2_MIB_COLLISION, "collision" },
 	{ MVPP2_MIB_LATE_COLLISION, "late_collision" },
+#define MVPP2_LAST_MIB		MVPP2_MIB_LATE_COLLISION
+
+	/* Extend counters */
+	{ MVPP2_OVERRUN_DROP_REG(0),	"rx_ppv2_overrun" },
+	{ MVPP2_CLS_DROP_REG(0),	"rx_cls_drop" },
+	{ MVPP2_RX_PKT_FULLQ_DROP_REG,	"rx_fullq_drop" },
+	{ MVPP2_RX_PKT_EARLY_DROP_REG,	"rx_early_drop" },
+	{ MVPP2_RX_PKT_BM_DROP_REG,	"rx_bm_drop" },
+
+	/* Extend SW counters (not registers) */
+#define MVPP2_FIRST_CNT_SW		0xf000
+#define MVPP2_TX_GUARD_CNT(cpu)	(MVPP2_FIRST_CNT_SW + cpu)
+	{ MVPP2_TX_GUARD_CNT(0),	"tx-guard-cpu0" },
+	{ MVPP2_TX_GUARD_CNT(1),	"tx-guard-cpu1" },
+	{ MVPP2_TX_GUARD_CNT(2),	"tx-guard-cpu2" },
+	{ MVPP2_TX_GUARD_CNT(3),	"tx-guard-cpu3" },
+};
+
+static const char mvpp22_priv_flags_strings[][ETH_GSTRING_LEN] = {
+	"musdk",
 };
 
+#define MVPP22_F_IF_MUSDK_PRIV	BIT(0)
+
+static int mvpp2_ethtool_get_mib_cntr_size(void)
+{
+	int i = 0;
+
+	while (i < ARRAY_SIZE(mvpp2_ethtool_regs)) {
+		if (mvpp2_ethtool_regs[i++].offset == MVPP2_LAST_MIB)
+			break;
+	}
+	return i; /* mib_size */
+}
+
+static int mvpp2_ethtool_get_cntr_index(u32 offset)
+{
+	int i = 0;
+
+	while (i < ARRAY_SIZE(mvpp2_ethtool_regs)) {
+		if (mvpp2_ethtool_regs[i].offset == offset)
+			break;
+		i++;
+	}
+	return i;
+}
+
+/* hw_get_stats - update the ethtool_stats accumulator from HW-registers
+ * The HW-registers/counters are cleared on read.
+ */
+static void mvpp2_hw_get_stats(struct mvpp2_port *port, u64 *pstats)
+{
+	int i, mib_size, queue, cpu;
+	unsigned int reg_offs;
+	u32 val, cls_drops;
+	u64 *ptmp;
+
+	mib_size = mvpp2_ethtool_get_mib_cntr_size();
+
+	cls_drops = mvpp2_read(port->priv, MVPP2_OVERRUN_DROP_REG(port->id));
+
+	for (i = 0; i < mib_size; i++) {
+		if (mvpp2_ethtool_regs[i].offset == MVPP2_MIB_COLLISION) {
+			val = mvpp2_read_count(port, &mvpp2_ethtool_regs[i]);
+			port->dev->stats.collisions += val;
+			*pstats++ += val;
+			continue;
+		}
+		*pstats++ += mvpp2_read_count(port, &mvpp2_ethtool_regs[i]);
+	}
+
+	/* Extend HW counters */
+	*pstats++ += cls_drops;
+	*pstats++ += mvpp2_read(port->priv, MVPP2_CLS_DROP_REG(port->id));
+	ptmp = pstats;
+	queue = port->first_rxq;
+	while (queue < (port->first_rxq + port->nrxqs)) {
+		mvpp2_write(port->priv, MVPP2_CNT_IDX_REG, queue++);
+		pstats = ptmp;
+		i = mib_size + 2;
+		while (i < ARRAY_SIZE(mvpp2_ethtool_regs)) {
+			reg_offs = mvpp2_ethtool_regs[i++].offset;
+			if (reg_offs == MVPP2_FIRST_CNT_SW)
+				break;
+			*pstats++ += mvpp2_read(port->priv, reg_offs);
+		}
+	}
+
+	/* Extend SW counters (i=MVPP2_FIRST_CNT_SW) */
+	for_each_present_cpu(cpu)
+		*pstats++ = mvpp2_tx_done_guard_get_stats(port, cpu);
+}
+
+static void mvpp2_hw_clear_stats(struct mvpp2_port *port)
+{
+	int i, mib_size, queue;
+	unsigned int reg_offs;
+
+	mib_size = mvpp2_ethtool_get_mib_cntr_size();
+
+	for (i = 0; i < mib_size; i++)
+		mvpp2_read_count(port, &mvpp2_ethtool_regs[i]);
+
+	/* Extend counters */
+	mvpp2_read(port->priv, MVPP2_OVERRUN_DROP_REG(port->id));
+	mvpp2_read(port->priv, MVPP2_CLS_DROP_REG(port->id));
+	queue = port->first_rxq;
+	while (queue < (port->first_rxq + port->nrxqs)) {
+		mvpp2_write(port->priv, MVPP2_CNT_IDX_REG, queue++);
+		i = mib_size + 2;
+		while (i < ARRAY_SIZE(mvpp2_ethtool_regs)) {
+			reg_offs = mvpp2_ethtool_regs[i++].offset;
+			if (reg_offs == MVPP2_FIRST_CNT_SW)
+				break;
+			mvpp2_read(port->priv, reg_offs);
+		}
+	}
+	/* Extend SW counters (i=MVPP2_FIRST_CNT_SW) */
+	/* no clear */
+}
+
 static void mvpp2_ethtool_get_strings(struct net_device *netdev, u32 sset,
 				      u8 *data)
 {
-	if (sset == ETH_SS_STATS) {
-		int i;
+	int i;
 
+	switch (sset) {
+	case ETH_SS_STATS:
 		for (i = 0; i < ARRAY_SIZE(mvpp2_ethtool_regs); i++)
-			strscpy(data + i * ETH_GSTRING_LEN,
-			        mvpp2_ethtool_regs[i].string, ETH_GSTRING_LEN);
+			memcpy(data + i * ETH_GSTRING_LEN,
+			       &mvpp2_ethtool_regs[i].string, ETH_GSTRING_LEN);
+		break;
+	case ETH_SS_PRIV_FLAGS:
+		memcpy(data, mvpp22_priv_flags_strings,
+		       ARRAY_SIZE(mvpp22_priv_flags_strings) * ETH_GSTRING_LEN);
 	}
 }
 
@@ -1320,61 +1976,71 @@ static void mvpp2_gather_hw_statistics(struct work_struct *work)
 	struct delayed_work *del_work = to_delayed_work(work);
 	struct mvpp2_port *port = container_of(del_work, struct mvpp2_port,
 					       stats_work);
-	u64 *pstats;
-	int i;
 
+	/* Update the statistic buffer by q-work only, not by ethtool-S */
 	mutex_lock(&port->gather_stats_lock);
-
-	pstats = port->ethtool_stats;
-	for (i = 0; i < ARRAY_SIZE(mvpp2_ethtool_regs); i++)
-		*pstats++ += mvpp2_read_count(port, &mvpp2_ethtool_regs[i]);
-
-	/* No need to read again the counters right after this function if it
-	 * was called asynchronously by the user (ie. use of ethtool).
-	 */
-	cancel_delayed_work(&port->stats_work);
+	mvpp2_hw_get_stats(port, port->ethtool_stats);
+	mutex_unlock(&port->gather_stats_lock);
 	queue_delayed_work(port->priv->stats_queue, &port->stats_work,
 			   MVPP2_MIB_COUNTERS_STATS_DELAY);
-
-	mutex_unlock(&port->gather_stats_lock);
 }
 
 static void mvpp2_ethtool_get_stats(struct net_device *dev,
 				    struct ethtool_stats *stats, u64 *data)
 {
 	struct mvpp2_port *port = netdev_priv(dev);
+	int cls_drp, fc_rcv;
 
-	/* Update statistics for the given port, then take the lock to avoid
-	 * concurrent accesses on the ethtool_stats structure during its copy.
+	/* Use statistic already accumulated in ethtool_stats by q-work
+	 * and copy under mutex-lock it into given ethtool-data-buffer.
 	 */
-	mvpp2_gather_hw_statistics(&port->stats_work.work);
-
 	mutex_lock(&port->gather_stats_lock);
 	memcpy(data, port->ethtool_stats,
 	       sizeof(u64) * ARRAY_SIZE(mvpp2_ethtool_regs));
 	mutex_unlock(&port->gather_stats_lock);
+
+	/* Do not count flow control receive frames as classifier drops */
+	cls_drp = mvpp2_ethtool_get_cntr_index(MVPP2_CLS_DROP_REG(0));
+	fc_rcv = mvpp2_ethtool_get_cntr_index(MVPP2_MIB_FC_RCVD);
+	data[cls_drp] =
+		data[fc_rcv] > data[cls_drp] ? 0 : data[cls_drp] - data[fc_rcv];
 }
 
 static int mvpp2_ethtool_get_sset_count(struct net_device *dev, int sset)
 {
-	if (sset == ETH_SS_STATS)
-		return ARRAY_SIZE(mvpp2_ethtool_regs);
+	struct mvpp2_port *port = netdev_priv(dev);
 
+	switch (sset) {
+	case ETH_SS_STATS:
+		return ARRAY_SIZE(mvpp2_ethtool_regs);
+	case ETH_SS_PRIV_FLAGS:
+		return (port->priv->hw_version == MVPP21) ?
+			0 : ARRAY_SIZE(mvpp22_priv_flags_strings);
+	}
 	return -EOPNOTSUPP;
 }
 
 static void mvpp2_port_reset(struct mvpp2_port *port)
 {
 	u32 val;
-	unsigned int i;
 
 	/* Read the GOP statistics to reset the hardware counters */
-	for (i = 0; i < ARRAY_SIZE(mvpp2_ethtool_regs); i++)
-		mvpp2_read_count(port, &mvpp2_ethtool_regs[i]);
+	mvpp2_hw_clear_stats(port);
 
 	val = readl(port->base + MVPP2_GMAC_CTRL_2_REG) |
 	      MVPP2_GMAC_PORT_RESET_MASK;
 	writel(val, port->base + MVPP2_GMAC_CTRL_2_REG);
+
+	if (port->has_xlg_mac) {
+		/* Set the XLG MAC in reset */
+		val = readl(port->base + MVPP22_XLG_CTRL0_REG) &
+		      ~MVPP22_XLG_CTRL0_MAC_RESET_DIS;
+		writel(val, port->base + MVPP22_XLG_CTRL0_REG);
+
+		while (readl(port->base + MVPP22_XLG_CTRL0_REG) &
+		       MVPP22_XLG_CTRL0_MAC_RESET_DIS)
+			continue;
+	}
 }
 
 /* Change maximum receive size of the port */
@@ -1382,6 +2048,9 @@ static inline void mvpp2_gmac_max_rx_size_set(struct mvpp2_port *port)
 {
 	u32 val;
 
+	if (port->flags & MVPP22_F_IF_MUSDK)
+		return;
+
 	val = readl(port->base + MVPP2_GMAC_CTRL_0_REG);
 	val &= ~MVPP2_GMAC_MAX_RX_SIZE_MASK;
 	val |= (((port->pkt_size - MVPP2_MH_SIZE) / 2) <<
@@ -1394,6 +2063,9 @@ static inline void mvpp2_xlg_max_rx_size_set(struct mvpp2_port *port)
 {
 	u32 val;
 
+	if (port->flags & MVPP22_F_IF_MUSDK)
+		return;
+
 	val =  readl(port->base + MVPP22_XLG_CTRL1_REG);
 	val &= ~MVPP22_XLG_CTRL1_FRAMESIZELIMIT_MASK;
 	val |= ((port->pkt_size - MVPP2_MH_SIZE) / 2) <<
@@ -1401,19 +2073,42 @@ static inline void mvpp2_xlg_max_rx_size_set(struct mvpp2_port *port)
 	writel(val, port->base + MVPP22_XLG_CTRL1_REG);
 }
 
+static void mvpp2_gmac_tx_fifo_configure(struct mvpp2_port *port)
+{
+	u32 val, tx_fifo_min_th;
+	u8 low_wm, hi_wm;
+
+	tx_fifo_min_th = MVPP2_GMAC_TX_FIFO_MIN_TH;
+	low_wm = MVPP2_GMAC_TX_FIFO_LOW_WM;
+	hi_wm = MVPP2_GMAC_TX_FIFO_HI_WM;
+
+	/* Update TX FIFO MIN Threshold */
+	val = readl(port->base + MVPP2_GMAC_PORT_FIFO_CFG_1_REG);
+	val &= ~MVPP2_GMAC_TX_FIFO_MIN_TH_ALL_MASK;
+	val |= tx_fifo_min_th;
+	writel(val, port->base + MVPP2_GMAC_PORT_FIFO_CFG_1_REG);
+
+	/* Update TX FIFO levels of assertion/deassertion
+	 * of p2mem_ready_signal, which indicates readiness
+	 * for fetching the data from DRAM.
+	 */
+	val = readl(port->base + MVPP2_GMAC_PORT_FIFO_CFG_0_REG);
+	val &= ~MVPP2_GMAC_TX_FIFO_WM_MASK;
+	val |= (low_wm << MVPP2_GMAC_TX_FIFO_WM_LOW_OFFSET) | hi_wm;
+	writel(val, port->base + MVPP2_GMAC_PORT_FIFO_CFG_0_REG);
+}
+
 /* Set defaults to the MVPP2 port */
 static void mvpp2_defaults_set(struct mvpp2_port *port)
 {
 	int tx_port_num, val, queue, lrxq;
 
-	if (port->priv->hw_version == MVPP21) {
-		/* Update TX FIFO MIN Threshold */
-		val = readl(port->base + MVPP2_GMAC_PORT_FIFO_CFG_1_REG);
-		val &= ~MVPP2_GMAC_TX_FIFO_MIN_TH_ALL_MASK;
-		/* Min. TX threshold must be less than minimal packet length */
-		val |= MVPP2_GMAC_TX_FIFO_MIN_TH_MASK(64 - 4 - 2);
-		writel(val, port->base + MVPP2_GMAC_PORT_FIFO_CFG_1_REG);
-	}
+	if (phy_interface_mode_is_rgmii(port->phy_interface) ||
+	    port->phy_interface == PHY_INTERFACE_MODE_MII ||
+	    port->phy_interface == PHY_INTERFACE_MODE_SGMII ||
+	    port->phy_interface == PHY_INTERFACE_MODE_1000BASEX ||
+	    port->phy_interface == PHY_INTERFACE_MODE_2500BASEX)
+		mvpp2_gmac_tx_fifo_configure(port);
 
 	/* Disable Legacy WRR, Disable EJP, Release from reset */
 	tx_port_num = mvpp2_egress_port(port);
@@ -1421,6 +2116,9 @@ static void mvpp2_defaults_set(struct mvpp2_port *port)
 		    tx_port_num);
 	mvpp2_write(port->priv, MVPP2_TXP_SCHED_CMD_1_REG, 0);
 
+	/* Set TXQ scheduling to Round-Robin */
+	mvpp2_write(port->priv, MVPP2_TXP_SCHED_FIXED_PRIO_REG, 0);
+
 	/* Close bandwidth for all queues */
 	for (queue = 0; queue < MVPP2_MAX_TXQ; queue++)
 		mvpp2_write(port->priv,
@@ -1493,6 +2191,9 @@ static void mvpp2_egress_enable(struct mvpp2_port *port)
 	int queue;
 	int tx_port_num = mvpp2_egress_port(port);
 
+	if (port->flags & MVPP22_F_IF_MUSDK)
+		return;
+
 	/* Enable all initialized TXs. */
 	qmap = 0;
 	for (queue = 0; queue < port->ntxqs; queue++) {
@@ -1515,6 +2216,9 @@ static void mvpp2_egress_disable(struct mvpp2_port *port)
 	int delay;
 	int tx_port_num = mvpp2_egress_port(port);
 
+	if (port->flags & MVPP22_F_IF_MUSDK)
+		return;
+
 	/* Issue stop command for active channels only */
 	mvpp2_write(port->priv, MVPP2_TXP_SCHED_PORT_INDEX_REG, tx_port_num);
 	reg_data = (mvpp2_read(port->priv, MVPP2_TXP_SCHED_Q_CMD_REG)) &
@@ -1617,8 +2321,13 @@ mvpp2_txq_next_desc_get(struct mvpp2_tx_queue *txq)
  */
 static void mvpp2_aggr_txq_pend_desc_add(struct mvpp2_port *port, int pending)
 {
+	int cpu = smp_processor_id();
+
+	mvpp2_tx_done_guard_timer_set(port, cpu);
+
 	/* aggregated access - relevant TXQ number is written in TX desc */
-	mvpp2_percpu_write(port->priv, smp_processor_id(),
+	mvpp2_thread_write(port->priv,
+			   mvpp2_cpu_to_thread(port->priv, cpu),
 			   MVPP2_AGGR_TXQ_UPDATE_REG, pending);
 }
 
@@ -1628,14 +2337,15 @@ static void mvpp2_aggr_txq_pend_desc_add(struct mvpp2_port *port, int pending)
  * Called only from mvpp2_tx(), so migration is disabled, using
  * smp_processor_id() is OK.
  */
-static int mvpp2_aggr_desc_num_check(struct mvpp2 *priv,
+static int mvpp2_aggr_desc_num_check(struct mvpp2_port *port,
 				     struct mvpp2_tx_queue *aggr_txq, int num)
 {
 	if ((aggr_txq->count + num) > MVPP2_AGGR_TXQ_SIZE) {
 		/* Update number of occupied aggregated Tx descriptors */
-		int cpu = smp_processor_id();
-		u32 val = mvpp2_read_relaxed(priv,
-					     MVPP2_AGGR_TXQ_STATUS_REG(cpu));
+		unsigned int thread =
+			mvpp2_cpu_to_thread(port->priv, smp_processor_id());
+		u32 val = mvpp2_read_relaxed(port->priv,
+					     MVPP2_AGGR_TXQ_STATUS_REG(thread));
 
 		aggr_txq->count = val & MVPP2_AGGR_TXQ_PENDING_MASK;
 
@@ -1651,16 +2361,17 @@ static int mvpp2_aggr_desc_num_check(struct mvpp2 *priv,
  * only by mvpp2_tx(), so migration is disabled, using
  * smp_processor_id() is OK.
  */
-static int mvpp2_txq_alloc_reserved_desc(struct mvpp2 *priv,
+static int mvpp2_txq_alloc_reserved_desc(struct mvpp2_port *port,
 					 struct mvpp2_tx_queue *txq, int num)
 {
+	unsigned int thread = mvpp2_cpu_to_thread(port->priv, smp_processor_id());
+	struct mvpp2 *priv = port->priv;
 	u32 val;
-	int cpu = smp_processor_id();
 
 	val = (txq->id << MVPP2_TXQ_RSVD_REQ_Q_OFFSET) | num;
-	mvpp2_percpu_write_relaxed(priv, cpu, MVPP2_TXQ_RSVD_REQ_REG, val);
+	mvpp2_thread_write_relaxed(priv, thread, MVPP2_TXQ_RSVD_REQ_REG, val);
 
-	val = mvpp2_percpu_read_relaxed(priv, cpu, MVPP2_TXQ_RSVD_RSLT_REG);
+	val = mvpp2_thread_read_relaxed(priv, thread, MVPP2_TXQ_RSVD_RSLT_REG);
 
 	return val & MVPP2_TXQ_RSVD_RSLT_MASK;
 }
@@ -1668,12 +2379,14 @@ static int mvpp2_txq_alloc_reserved_desc(struct mvpp2 *priv,
 /* Check if there are enough reserved descriptors for transmission.
  * If not, request chunk of reserved descriptors and check again.
  */
-static int mvpp2_txq_reserved_desc_num_proc(struct mvpp2 *priv,
+static int mvpp2_txq_reserved_desc_num_proc(struct mvpp2_port *port,
 					    struct mvpp2_tx_queue *txq,
 					    struct mvpp2_txq_pcpu *txq_pcpu,
 					    int num)
 {
-	int req, cpu, desc_count;
+	unsigned int thread;
+	int req, desc_count;
+	struct mvpp2_txq_pcpu *txq_pcpu_aux;
 
 	if (txq_pcpu->reserved_num >= num)
 		return 0;
@@ -1681,27 +2394,24 @@ static int mvpp2_txq_reserved_desc_num_proc(struct mvpp2 *priv,
 	/* Not enough descriptors reserved! Update the reserved descriptor
 	 * count and check again.
 	 */
-
-	desc_count = 0;
-	/* Compute total of used descriptors */
-	for_each_present_cpu(cpu) {
-		struct mvpp2_txq_pcpu *txq_pcpu_aux;
-
-		txq_pcpu_aux = per_cpu_ptr(txq->pcpu, cpu);
-		desc_count += txq_pcpu_aux->count;
-		desc_count += txq_pcpu_aux->reserved_num;
+	if (num <= MAX_SKB_FRAGS) {
+		req = MVPP2_CPU_DESC_CHUNK;
+	} else {
+		/* Compute total of used descriptors */
+		desc_count = 0;
+		for (thread = 0; thread < port->priv->nthreads; thread++) {
+			txq_pcpu_aux = per_cpu_ptr(txq->pcpu, thread);
+			desc_count += txq_pcpu_aux->reserved_num;
+		}
+		req = max(MVPP2_CPU_DESC_CHUNK, num - txq_pcpu->reserved_num);
+		/* Check the reservation is possible */
+		if ((desc_count + req) > txq->size)
+			return -ENOMEM;
 	}
 
-	req = max(MVPP2_CPU_DESC_CHUNK, num - txq_pcpu->reserved_num);
-	desc_count += req;
-
-	if (desc_count >
-	   (txq->size - (num_present_cpus() * MVPP2_CPU_DESC_CHUNK)))
-		return -ENOMEM;
-
-	txq_pcpu->reserved_num += mvpp2_txq_alloc_reserved_desc(priv, txq, req);
+	txq_pcpu->reserved_num += mvpp2_txq_alloc_reserved_desc(port, txq, req);
 
-	/* OK, the descriptor could have been updated: check again. */
+	/* Check the resulting reservation is enough */
 	if (txq_pcpu->reserved_num < num)
 		return -ENOMEM;
 	return 0;
@@ -1753,7 +2463,7 @@ static u32 mvpp2_txq_desc_csum(int l3_offs, __be16 l3_proto,
 
 /* Get number of sent descriptors and decrement counter.
  * The number of sent descriptors is returned.
- * Per-CPU access
+ * Per-thread access
  *
  * Called only from mvpp2_txq_done(), called from mvpp2_tx()
  * (migration disabled) and from the TX completion tasklet (migration
@@ -1765,7 +2475,8 @@ static inline int mvpp2_txq_sent_desc_proc(struct mvpp2_port *port,
 	u32 val;
 
 	/* Reading status reg resets transmitted descriptor counter */
-	val = mvpp2_percpu_read_relaxed(port->priv, smp_processor_id(),
+	val = mvpp2_thread_read_relaxed(port->priv,
+					mvpp2_cpu_to_thread(port->priv, smp_processor_id()),
 					MVPP2_TXQ_SENT_REG(txq->id));
 
 	return (val & MVPP2_TRANSMITTED_COUNT_MASK) >>
@@ -1780,14 +2491,120 @@ static void mvpp2_txq_sent_counter_clear(void *arg)
 	struct mvpp2_port *port = arg;
 	int queue;
 
+	/* If the thread isn't used, don't do anything */
+	if (smp_processor_id() > port->priv->nthreads)
+		return;
+
 	for (queue = 0; queue < port->ntxqs; queue++) {
 		int id = port->txqs[queue]->id;
 
-		mvpp2_percpu_read(port->priv, smp_processor_id(),
+		mvpp2_thread_read(port->priv,
+				  mvpp2_cpu_to_thread(port->priv, smp_processor_id()),
 				  MVPP2_TXQ_SENT_REG(id));
 	}
 }
 
+/* Avoid wrong tx_done calling for netif_tx_wake at time of
+ * dev-stop or linkDown processing by flag MVPP2_F_IF_TX_ON.
+ * Set/clear it on each cpu.
+ */
+static inline bool mvpp2_tx_stopped(struct mvpp2_port *port)
+{
+	return !(port->flags & MVPP2_F_IF_TX_ON);
+}
+
+static void mvpp2_txqs_on(void *arg)
+{
+	((struct mvpp2_port *)arg)->flags |= MVPP2_F_IF_TX_ON;
+}
+
+static void mvpp2_txqs_off(void *arg)
+{
+	((struct mvpp2_port *)arg)->flags &= ~MVPP2_F_IF_TX_ON;
+}
+
+static void mvpp2_txqs_on_tasklet_cb(unsigned long data)
+{
+	/* Activated/runs on 1 cpu only (with link_status_irq)
+	 * to update/guarantee TX_ON coherency on other cpus
+	 */
+	struct mvpp2_port *port = (struct mvpp2_port *)data;
+
+	if (mvpp2_tx_stopped(port))
+		on_each_cpu(mvpp2_txqs_off, port, 1);
+	else
+		on_each_cpu(mvpp2_txqs_on, port, 1);
+}
+
+static void mvpp2_txqs_on_tasklet_init(struct mvpp2_port *port)
+{
+	/* Init called only for port with link_status_isr */
+	tasklet_init(&port->txqs_on_tasklet,
+		     mvpp2_txqs_on_tasklet_cb,
+		     (unsigned long)port);
+}
+
+static void mvpp2_txqs_on_tasklet_kill(struct mvpp2_port *port)
+{
+	if (port->txqs_on_tasklet.func)
+		tasklet_kill(&port->txqs_on_tasklet);
+}
+
+/* Use mvpp2 APIs instead of netif_TX_ALL:
+ *  netif_tx_start_all_queues -> mvpp2_tx_start_all_queues
+ *  netif_tx_wake_all_queues  -> mvpp2_tx_wake_all_queues
+ *  netif_tx_stop_all_queues  -> mvpp2_tx_stop_all_queues
+ * But keep using per-queue APIs netif_tx_wake_queue,
+ *  netif_tx_stop_queue and netif_tx_queue_stopped.
+ */
+static void mvpp2_tx_start_all_queues(struct net_device *dev)
+{
+	struct mvpp2_port *port = netdev_priv(dev);
+
+	if (port->flags & MVPP22_F_IF_MUSDK)
+		return;
+
+	/* Never called from IRQ. Update all cpus directly */
+	on_each_cpu(mvpp2_txqs_on, port, 1);
+	netif_tx_start_all_queues(dev);
+}
+
+static void mvpp2_tx_wake_all_queues(struct net_device *dev)
+{
+	struct mvpp2_port *port = netdev_priv(dev);
+
+	if (port->flags & MVPP22_F_IF_MUSDK)
+		return;
+
+	if (irqs_disabled()) {
+		/* Link-status IRQ context (also ACPI).
+		 * Set for THIS cpu, update other cpus over tasklet
+		 */
+		mvpp2_txqs_on((void *)port);
+		tasklet_schedule(&port->txqs_on_tasklet);
+	} else {
+		on_each_cpu(mvpp2_txqs_on, port, 1);
+	}
+	netif_tx_wake_all_queues(dev);
+}
+
+static void mvpp2_tx_stop_all_queues(struct net_device *dev)
+{
+	struct mvpp2_port *port = netdev_priv(dev);
+
+	if (port->flags & MVPP22_F_IF_MUSDK)
+		return;
+
+	if (irqs_disabled()) {
+		/* IRQ context. Set for THIS, update other cpus over tasklet */
+		mvpp2_txqs_off((void *)port);
+		tasklet_schedule(&port->txqs_on_tasklet);
+	} else {
+		on_each_cpu(mvpp2_txqs_off, port, 1);
+	}
+	netif_tx_stop_all_queues(dev);
+}
+
 /* Set max sizes for Tx queues */
 static void mvpp2_txp_max_tx_size_set(struct mvpp2_port *port)
 {
@@ -1837,44 +2654,81 @@ static void mvpp2_txp_max_tx_size_set(struct mvpp2_port *port)
 	}
 }
 
+/* Routine set the number of non-occupied descriptors threshold that change
+ * interrupt error cause polled by FW Flow Control
+ */
+void mvpp2_set_rxq_free_tresh(struct mvpp2_port *port,
+			      struct mvpp2_rx_queue *rxq)
+{
+	u32 val;
+
+	mvpp2_write(port->priv, MVPP2_RXQ_NUM_REG, rxq->id);
+
+	val = mvpp2_read(port->priv, MVPP2_RXQ_THRESH_REG);
+	val &= ~MVPP2_RXQ_NON_OCCUPIED_MASK;
+	val |= MSS_THRESHOLD_STOP << MVPP2_RXQ_NON_OCCUPIED_OFFSET;
+	mvpp2_write(port->priv, MVPP2_RXQ_THRESH_REG, val);
+}
+
 /* Set the number of packets that will be received before Rx interrupt
  * will be generated by HW.
  */
 static void mvpp2_rx_pkts_coal_set(struct mvpp2_port *port,
 				   struct mvpp2_rx_queue *rxq)
 {
-	int cpu = get_cpu();
+	unsigned int thread = mvpp2_cpu_to_thread(port->priv, get_cpu());
 
 	if (rxq->pkts_coal > MVPP2_OCCUPIED_THRESH_MASK)
 		rxq->pkts_coal = MVPP2_OCCUPIED_THRESH_MASK;
 
-	mvpp2_percpu_write(port->priv, cpu, MVPP2_RXQ_NUM_REG, rxq->id);
-	mvpp2_percpu_write(port->priv, cpu, MVPP2_RXQ_THRESH_REG,
+	mvpp2_thread_write(port->priv, thread, MVPP2_RXQ_NUM_REG, rxq->id);
+	mvpp2_thread_write(port->priv, thread, MVPP2_RXQ_THRESH_REG,
 			   rxq->pkts_coal);
 
 	put_cpu();
 }
 
-/* For some reason in the LSP this is done on each CPU. Why ? */
-static void mvpp2_tx_pkts_coal_set(struct mvpp2_port *port,
-				   struct mvpp2_tx_queue *txq)
+/* Set pkts-coalescing HW with ZERO or configured VALUE
+ * The same should be set for all TXQs and all for all CPUs.
+ * Setting ZERO causes for immediate flush into tx-done handler.
+ */
+static inline void mvpp2_tx_pkts_coal_set_txqs(struct mvpp2_port *port,
+					       int cpu, u32 val)
 {
-	int cpu = get_cpu();
-	u32 val;
-
-	if (txq->done_pkts_coal > MVPP2_TXQ_THRESH_MASK)
-		txq->done_pkts_coal = MVPP2_TXQ_THRESH_MASK;
+	struct mvpp2_tx_queue *txq;
+	int queue;
 
-	val = (txq->done_pkts_coal << MVPP2_TXQ_THRESH_OFFSET);
-	mvpp2_percpu_write(port->priv, cpu, MVPP2_TXQ_NUM_REG, txq->id);
-	mvpp2_percpu_write(port->priv, cpu, MVPP2_TXQ_THRESH_REG, val);
+	val <<= MVPP2_TXQ_THRESH_OFFSET;
 
-	put_cpu();
+	for (queue = 0; queue < port->ntxqs; queue++) {
+		txq = port->txqs[queue];
+		mvpp2_thread_write(port->priv, cpu, MVPP2_TXQ_NUM_REG,
+				   txq->id);
+		mvpp2_thread_write(port->priv, cpu, MVPP2_TXQ_THRESH_REG, val);
+	}
 }
 
-static u32 mvpp2_usec_to_cycles(u32 usec, unsigned long clk_hz)
+static void mvpp2_tx_pkts_coal_set(struct mvpp2_port *port)
 {
-	u64 tmp = (u64)clk_hz * usec;
+	struct mvpp2_tx_queue *txq = port->txqs[0];
+	u32 cfg_val = txq->done_pkts_coal;
+	int cpu;
+
+	for_each_present_cpu(cpu)
+		mvpp2_tx_pkts_coal_set_txqs(port, cpu, cfg_val);
+}
+
+/* Set ZERO value on on_each_cpu IRQ-context for 1 cpu only */
+static void mvpp2_tx_pkts_coal_set_zero_pcpu(void *arg)
+{
+	struct mvpp2_port *port = arg;
+
+	mvpp2_tx_pkts_coal_set_txqs(port, smp_processor_id(), 0);
+}
+
+static u32 mvpp2_usec_to_cycles(u32 usec, unsigned long clk_hz)
+{
+	u64 tmp = (u64)clk_hz * usec;
 
 	do_div(tmp, USEC_PER_SEC);
 
@@ -1935,12 +2789,22 @@ static void mvpp2_txq_bufs_free(struct mvpp2_port *port,
 		struct mvpp2_txq_pcpu_buf *tx_buf =
 			txq_pcpu->buffs + txq_pcpu->txq_get_index;
 
-		if (!IS_TSO_HEADER(txq_pcpu, tx_buf->dma))
+		if (!tx_buf->skb) {
 			dma_unmap_single(port->dev->dev.parent, tx_buf->dma,
 					 tx_buf->size, DMA_TO_DEVICE);
-		if (tx_buf->skb)
-			dev_kfree_skb_any(tx_buf->skb);
-
+		} else if (tx_buf->skb != TSO_HEADER_MARK) {
+			dma_unmap_single(port->dev->dev.parent, tx_buf->dma,
+					 tx_buf->size, DMA_TO_DEVICE);
+			if (static_branch_unlikely(&mvpp2_recycle_ena)) {
+				mvpp2_recycle_put(port, txq_pcpu, tx_buf);
+				/* sets tx_buf->skb=NULL if put to recycle */
+				if (tx_buf->skb)
+					dev_kfree_skb_any(tx_buf->skb);
+			} else {
+				dev_kfree_skb_any(tx_buf->skb);
+			}
+		}
+		/* else: no action, tx_buf->skb always overwritten in xmit */
 		mvpp2_txq_inc_get(txq_pcpu);
 	}
 }
@@ -1968,7 +2832,7 @@ static void mvpp2_txq_done(struct mvpp2_port *port, struct mvpp2_tx_queue *txq,
 	struct netdev_queue *nq = netdev_get_tx_queue(port->dev, txq->log_id);
 	int tx_done;
 
-	if (txq_pcpu->cpu != smp_processor_id())
+	if (txq_pcpu->thread != mvpp2_cpu_to_thread(port->priv, smp_processor_id()))
 		netdev_err(port->dev, "wrong cpu on the end of Tx processing\n");
 
 	tx_done = mvpp2_txq_sent_desc_proc(port, txq);
@@ -1978,24 +2842,33 @@ static void mvpp2_txq_done(struct mvpp2_port *port, struct mvpp2_tx_queue *txq,
 
 	txq_pcpu->count -= tx_done;
 
-	if (netif_tx_queue_stopped(nq))
-		if (txq_pcpu->count <= txq_pcpu->wake_threshold)
+	if (netif_tx_queue_stopped(nq) && !mvpp2_tx_stopped(port)) {
+		/* Wake if netif_tx_queue_stopped on same txq->log_id */
+		if (txq_pcpu->stopped_on_txq_id == txq->log_id &&
+		    txq_pcpu->count <= txq_pcpu->wake_threshold) {
+			txq_pcpu->stopped_on_txq_id = MVPP2_MAX_TXQ;
+			nq = netdev_get_tx_queue(port->dev, txq->log_id);
 			netif_tx_wake_queue(nq);
+		}
+	}
 }
 
 static unsigned int mvpp2_tx_done(struct mvpp2_port *port, u32 cause,
-				  int cpu)
+				  unsigned int thread)
 {
 	struct mvpp2_tx_queue *txq;
 	struct mvpp2_txq_pcpu *txq_pcpu;
 	unsigned int tx_todo = 0;
 
+	/* Set/Restore "no-force" */
+	mvpp2_tx_done_guard_force_irq(port, thread, 0);
+
 	while (cause) {
 		txq = mvpp2_get_tx_queue(port, cause);
 		if (!txq)
 			break;
 
-		txq_pcpu = per_cpu_ptr(txq->pcpu, cpu);
+		txq_pcpu = per_cpu_ptr(txq->pcpu, thread);
 
 		if (txq_pcpu->count) {
 			mvpp2_txq_done(port, txq, txq_pcpu);
@@ -2011,8 +2884,8 @@ static unsigned int mvpp2_tx_done(struct mvpp2_port *port, u32 cause,
 
 /* Allocate and initialize descriptors for aggr TXQ */
 static int mvpp2_aggr_txq_init(struct platform_device *pdev,
-			       struct mvpp2_tx_queue *aggr_txq, int cpu,
-			       struct mvpp2 *priv)
+			       struct mvpp2_tx_queue *aggr_txq,
+			       unsigned int thread, struct mvpp2 *priv)
 {
 	u32 txq_dma;
 
@@ -2027,7 +2900,7 @@ static int mvpp2_aggr_txq_init(struct platform_device *pdev,
 
 	/* Aggr TXQ no reset WA */
 	aggr_txq->next_desc_to_proc = mvpp2_read(priv,
-						 MVPP2_AGGR_TXQ_INDEX_REG(cpu));
+						 MVPP2_AGGR_TXQ_INDEX_REG(thread));
 
 	/* Set Tx descriptors queue starting address indirect
 	 * access
@@ -2038,8 +2911,8 @@ static int mvpp2_aggr_txq_init(struct platform_device *pdev,
 		txq_dma = aggr_txq->descs_dma >>
 			MVPP22_AGGR_TXQ_DESC_ADDR_OFFS;
 
-	mvpp2_write(priv, MVPP2_AGGR_TXQ_DESC_ADDR_REG(cpu), txq_dma);
-	mvpp2_write(priv, MVPP2_AGGR_TXQ_DESC_SIZE_REG(cpu),
+	mvpp2_write(priv, MVPP2_AGGR_TXQ_DESC_ADDR_REG(thread), txq_dma);
+	mvpp2_write(priv, MVPP2_AGGR_TXQ_DESC_SIZE_REG(thread),
 		    MVPP2_AGGR_TXQ_SIZE);
 
 	return 0;
@@ -2050,8 +2923,8 @@ static int mvpp2_rxq_init(struct mvpp2_port *port,
 			  struct mvpp2_rx_queue *rxq)
 
 {
+	unsigned int thread;
 	u32 rxq_dma;
-	int cpu;
 
 	rxq->size = port->rx_ring_size;
 
@@ -2063,20 +2936,21 @@ static int mvpp2_rxq_init(struct mvpp2_port *port,
 		return -ENOMEM;
 
 	rxq->last_desc = rxq->size - 1;
+	rxq->rx_pending = 0;
 
 	/* Zero occupied and non-occupied counters - direct access */
 	mvpp2_write(port->priv, MVPP2_RXQ_STATUS_REG(rxq->id), 0);
 
 	/* Set Rx descriptors queue starting address - indirect access */
-	cpu = get_cpu();
-	mvpp2_percpu_write(port->priv, cpu, MVPP2_RXQ_NUM_REG, rxq->id);
+	thread = mvpp2_cpu_to_thread(port->priv, get_cpu());
+	mvpp2_thread_write(port->priv, thread, MVPP2_RXQ_NUM_REG, rxq->id);
 	if (port->priv->hw_version == MVPP21)
 		rxq_dma = rxq->descs_dma;
 	else
 		rxq_dma = rxq->descs_dma >> MVPP22_DESC_ADDR_OFFS;
-	mvpp2_percpu_write(port->priv, cpu, MVPP2_RXQ_DESC_ADDR_REG, rxq_dma);
-	mvpp2_percpu_write(port->priv, cpu, MVPP2_RXQ_DESC_SIZE_REG, rxq->size);
-	mvpp2_percpu_write(port->priv, cpu, MVPP2_RXQ_INDEX_REG, 0);
+	mvpp2_thread_write(port->priv, thread, MVPP2_RXQ_DESC_ADDR_REG, rxq_dma);
+	mvpp2_thread_write(port->priv, thread, MVPP2_RXQ_DESC_SIZE_REG, rxq->size);
+	mvpp2_thread_write(port->priv, thread, MVPP2_RXQ_INDEX_REG, 0);
 	put_cpu();
 
 	/* Set Offset */
@@ -2086,6 +2960,9 @@ static int mvpp2_rxq_init(struct mvpp2_port *port,
 	mvpp2_rx_pkts_coal_set(port, rxq);
 	mvpp2_rx_time_coal_set(port, rxq);
 
+	/* Set the number of non occupied descriptors threshold */
+	mvpp2_set_rxq_free_tresh(port, rxq);
+
 	/* Add number of descriptors ready for receiving packets */
 	mvpp2_rxq_status_update(port, rxq->id, 0, rxq->size);
 
@@ -2098,6 +2975,7 @@ static void mvpp2_rxq_drop_pkts(struct mvpp2_port *port,
 {
 	int rx_received, i;
 
+	rxq->rx_pending = 0;
 	rx_received = mvpp2_rxq_received(port, rxq->id);
 	if (!rx_received)
 		return;
@@ -2111,8 +2989,7 @@ static void mvpp2_rxq_drop_pkts(struct mvpp2_port *port,
 			MVPP2_RXD_BM_POOL_ID_OFFS;
 
 		mvpp2_bm_pool_put(port, pool,
-				  mvpp2_rxdesc_dma_addr_get(port, rx_desc),
-				  mvpp2_rxdesc_cookie_get(port, rx_desc));
+				  mvpp2_rxdesc_dma_addr_get(port, rx_desc));
 	}
 	mvpp2_rxq_status_update(port, rxq->id, rx_received, rx_received);
 }
@@ -2121,7 +2998,7 @@ static void mvpp2_rxq_drop_pkts(struct mvpp2_port *port,
 static void mvpp2_rxq_deinit(struct mvpp2_port *port,
 			     struct mvpp2_rx_queue *rxq)
 {
-	int cpu;
+	unsigned int thread;
 
 	mvpp2_rxq_drop_pkts(port, rxq);
 
@@ -2140,19 +3017,33 @@ static void mvpp2_rxq_deinit(struct mvpp2_port *port,
 	 * free descriptor number
 	 */
 	mvpp2_write(port->priv, MVPP2_RXQ_STATUS_REG(rxq->id), 0);
-	cpu = get_cpu();
-	mvpp2_percpu_write(port->priv, cpu, MVPP2_RXQ_NUM_REG, rxq->id);
-	mvpp2_percpu_write(port->priv, cpu, MVPP2_RXQ_DESC_ADDR_REG, 0);
-	mvpp2_percpu_write(port->priv, cpu, MVPP2_RXQ_DESC_SIZE_REG, 0);
+	thread = mvpp2_cpu_to_thread(port->priv, get_cpu());
+	mvpp2_thread_write(port->priv, thread, MVPP2_RXQ_NUM_REG, rxq->id);
+	mvpp2_thread_write(port->priv, thread, MVPP2_RXQ_DESC_ADDR_REG, 0);
+	mvpp2_thread_write(port->priv, thread, MVPP2_RXQ_DESC_SIZE_REG, 0);
 	put_cpu();
 }
 
+/* Disable all rx/ingress queues, called by mvpp2_init */
+static void mvpp2_rxq_disable_all(struct mvpp2 *priv)
+{
+	int i;
+	u32 val;
+
+	for (i = 0; i < MVPP2_RXQ_MAX_NUM; i++) {
+		val = mvpp2_read(priv, MVPP2_RXQ_CONFIG_REG(i));
+		val |= MVPP2_RXQ_DISABLE_MASK;
+		mvpp2_write(priv, MVPP2_RXQ_CONFIG_REG(i), val);
+	}
+}
+
 /* Create and initialize a Tx queue */
 static int mvpp2_txq_init(struct mvpp2_port *port,
 			  struct mvpp2_tx_queue *txq)
 {
 	u32 val;
-	int cpu, desc, desc_per_txq, tx_port_num;
+	unsigned int thread;
+	int desc, desc_per_txq, tx_port_num;
 	struct mvpp2_txq_pcpu *txq_pcpu;
 
 	txq->size = port->tx_ring_size;
@@ -2167,18 +3058,18 @@ static int mvpp2_txq_init(struct mvpp2_port *port,
 	txq->last_desc = txq->size - 1;
 
 	/* Set Tx descriptors queue starting address - indirect access */
-	cpu = get_cpu();
-	mvpp2_percpu_write(port->priv, cpu, MVPP2_TXQ_NUM_REG, txq->id);
-	mvpp2_percpu_write(port->priv, cpu, MVPP2_TXQ_DESC_ADDR_REG,
+	thread = mvpp2_cpu_to_thread(port->priv, get_cpu());
+	mvpp2_thread_write(port->priv, thread, MVPP2_TXQ_NUM_REG, txq->id);
+	mvpp2_thread_write(port->priv, thread, MVPP2_TXQ_DESC_ADDR_REG,
 			   txq->descs_dma);
-	mvpp2_percpu_write(port->priv, cpu, MVPP2_TXQ_DESC_SIZE_REG,
+	mvpp2_thread_write(port->priv, thread, MVPP2_TXQ_DESC_SIZE_REG,
 			   txq->size & MVPP2_TXQ_DESC_SIZE_MASK);
-	mvpp2_percpu_write(port->priv, cpu, MVPP2_TXQ_INDEX_REG, 0);
-	mvpp2_percpu_write(port->priv, cpu, MVPP2_TXQ_RSVD_CLR_REG,
+	mvpp2_thread_write(port->priv, thread, MVPP2_TXQ_INDEX_REG, 0);
+	mvpp2_thread_write(port->priv, thread, MVPP2_TXQ_RSVD_CLR_REG,
 			   txq->id << MVPP2_TXQ_RSVD_CLR_OFFSET);
-	val = mvpp2_percpu_read(port->priv, cpu, MVPP2_TXQ_PENDING_REG);
+	val = mvpp2_thread_read(port->priv, thread, MVPP2_TXQ_PENDING_REG);
 	val &= ~MVPP2_TXQ_PENDING_MASK;
-	mvpp2_percpu_write(port->priv, cpu, MVPP2_TXQ_PENDING_REG, val);
+	mvpp2_thread_write(port->priv, thread, MVPP2_TXQ_PENDING_REG, val);
 
 	/* Calculate base address in prefetch buffer. We reserve 16 descriptors
 	 * for each existing TXQ.
@@ -2189,7 +3080,7 @@ static int mvpp2_txq_init(struct mvpp2_port *port,
 	desc = (port->id * MVPP2_MAX_TXQ * desc_per_txq) +
 	       (txq->log_id * desc_per_txq);
 
-	mvpp2_percpu_write(port->priv, cpu, MVPP2_TXQ_PREF_BUF_REG,
+	mvpp2_thread_write(port->priv, thread, MVPP2_TXQ_PREF_BUF_REG,
 			   MVPP2_PREF_BUF_PTR(desc) | MVPP2_PREF_BUF_SIZE_16 |
 			   MVPP2_PREF_BUF_THRESH(desc_per_txq / 2));
 	put_cpu();
@@ -2208,8 +3099,8 @@ static int mvpp2_txq_init(struct mvpp2_port *port,
 	mvpp2_write(port->priv, MVPP2_TXQ_SCHED_TOKEN_SIZE_REG(txq->log_id),
 		    val);
 
-	for_each_present_cpu(cpu) {
-		txq_pcpu = per_cpu_ptr(txq->pcpu, cpu);
+	for (thread = 0; thread < port->priv->nthreads; thread++) {
+		txq_pcpu = per_cpu_ptr(txq->pcpu, thread);
 		txq_pcpu->size = txq->size;
 		txq_pcpu->buffs = kmalloc_array(txq_pcpu->size,
 						sizeof(*txq_pcpu->buffs),
@@ -2223,8 +3114,11 @@ static int mvpp2_txq_init(struct mvpp2_port *port,
 		txq_pcpu->txq_get_index = 0;
 		txq_pcpu->tso_headers = NULL;
 
-		txq_pcpu->stop_threshold = txq->size - MVPP2_MAX_SKB_DESCS;
-		txq_pcpu->wake_threshold = txq_pcpu->stop_threshold / 2;
+		txq_pcpu->stop_threshold = txq->size -
+				MVPP2_MAX_SKB_DESCS(num_present_cpus());
+		txq_pcpu->wake_threshold = txq_pcpu->stop_threshold -
+						MVPP2_TX_PAUSE_HYSTERESIS;
+		txq_pcpu->stopped_on_txq_id = MVPP2_MAX_TXQ;
 
 		txq_pcpu->tso_headers =
 			dma_alloc_coherent(port->dev->dev.parent,
@@ -2243,10 +3137,10 @@ static void mvpp2_txq_deinit(struct mvpp2_port *port,
 			     struct mvpp2_tx_queue *txq)
 {
 	struct mvpp2_txq_pcpu *txq_pcpu;
-	int cpu;
+	unsigned int thread;
 
-	for_each_present_cpu(cpu) {
-		txq_pcpu = per_cpu_ptr(txq->pcpu, cpu);
+	for (thread = 0; thread < port->priv->nthreads; thread++) {
+		txq_pcpu = per_cpu_ptr(txq->pcpu, thread);
 		kfree(txq_pcpu->buffs);
 
 		if (txq_pcpu->tso_headers)
@@ -2272,10 +3166,10 @@ static void mvpp2_txq_deinit(struct mvpp2_port *port,
 	mvpp2_write(port->priv, MVPP2_TXQ_SCHED_TOKEN_CNTR_REG(txq->log_id), 0);
 
 	/* Set Tx descriptors queue starting address and size */
-	cpu = get_cpu();
-	mvpp2_percpu_write(port->priv, cpu, MVPP2_TXQ_NUM_REG, txq->id);
-	mvpp2_percpu_write(port->priv, cpu, MVPP2_TXQ_DESC_ADDR_REG, 0);
-	mvpp2_percpu_write(port->priv, cpu, MVPP2_TXQ_DESC_SIZE_REG, 0);
+	thread = mvpp2_cpu_to_thread(port->priv, get_cpu());
+	mvpp2_thread_write(port->priv, thread, MVPP2_TXQ_NUM_REG, txq->id);
+	mvpp2_thread_write(port->priv, thread, MVPP2_TXQ_DESC_ADDR_REG, 0);
+	mvpp2_thread_write(port->priv, thread, MVPP2_TXQ_DESC_SIZE_REG, 0);
 	put_cpu();
 }
 
@@ -2283,14 +3177,19 @@ static void mvpp2_txq_deinit(struct mvpp2_port *port,
 static void mvpp2_txq_clean(struct mvpp2_port *port, struct mvpp2_tx_queue *txq)
 {
 	struct mvpp2_txq_pcpu *txq_pcpu;
-	int delay, pending, cpu;
+	int delay, pending;
+	unsigned int thread = mvpp2_cpu_to_thread(port->priv, get_cpu());
 	u32 val;
 
-	cpu = get_cpu();
-	mvpp2_percpu_write(port->priv, cpu, MVPP2_TXQ_NUM_REG, txq->id);
-	val = mvpp2_percpu_read(port->priv, cpu, MVPP2_TXQ_PREF_BUF_REG);
+	mvpp2_thread_write(port->priv, thread, MVPP2_TXQ_NUM_REG, txq->id);
+	val = mvpp2_thread_read(port->priv, thread, MVPP2_TXQ_PREF_BUF_REG);
 	val |= MVPP2_TXQ_DRAIN_EN_MASK;
-	mvpp2_percpu_write(port->priv, cpu, MVPP2_TXQ_PREF_BUF_REG, val);
+	mvpp2_thread_write(port->priv, thread, MVPP2_TXQ_PREF_BUF_REG, val);
+
+	/* Temporarily enable egress for the port.
+	 * It is required for releasing all remaining packets.
+	 */
+	mvpp2_egress_enable(port);
 
 	/* The napi queue has been stopped so wait for all packets
 	 * to be transmitted.
@@ -2306,17 +3205,19 @@ static void mvpp2_txq_clean(struct mvpp2_port *port, struct mvpp2_tx_queue *txq)
 		mdelay(1);
 		delay++;
 
-		pending = mvpp2_percpu_read(port->priv, cpu,
+		pending = mvpp2_thread_read(port->priv, thread,
 					    MVPP2_TXQ_PENDING_REG);
 		pending &= MVPP2_TXQ_PENDING_MASK;
 	} while (pending);
 
+	mvpp2_egress_disable(port);
+
 	val &= ~MVPP2_TXQ_DRAIN_EN_MASK;
-	mvpp2_percpu_write(port->priv, cpu, MVPP2_TXQ_PREF_BUF_REG, val);
+	mvpp2_thread_write(port->priv, thread, MVPP2_TXQ_PREF_BUF_REG, val);
 	put_cpu();
 
-	for_each_present_cpu(cpu) {
-		txq_pcpu = per_cpu_ptr(txq->pcpu, cpu);
+	for (thread = 0; thread < port->priv->nthreads; thread++) {
+		txq_pcpu = per_cpu_ptr(txq->pcpu, thread);
 
 		/* Release all packets */
 		mvpp2_txq_bufs_free(port, txq, txq_pcpu, txq_pcpu->count);
@@ -2360,6 +3261,9 @@ static void mvpp2_cleanup_rxqs(struct mvpp2_port *port)
 
 	for (queue = 0; queue < port->nrxqs; queue++)
 		mvpp2_rxq_deinit(port, port->rxqs[queue]);
+
+	if (port->tx_fc)
+		mvpp2_rxq_disable_fc(port);
 }
 
 /* Init all Rx queues for port */
@@ -2372,6 +3276,10 @@ static int mvpp2_setup_rxqs(struct mvpp2_port *port)
 		if (err)
 			goto err_cleanup;
 	}
+
+	if (port->tx_fc)
+		mvpp2_rxq_enable_fc(port);
+
 	return 0;
 
 err_cleanup:
@@ -2393,11 +3301,8 @@ static int mvpp2_setup_txqs(struct mvpp2_port *port)
 	}
 
 	if (port->has_tx_irqs) {
+		/* Download time-coal. The pkts-coal done in start_dev */
 		mvpp2_tx_time_coal_set(port);
-		for (queue = 0; queue < port->ntxqs; queue++) {
-			txq = port->txqs[queue];
-			mvpp2_tx_pkts_coal_set(port, txq);
-		}
 	}
 
 	on_each_cpu(mvpp2_txq_sent_counter_clear, port, 1);
@@ -2430,8 +3335,11 @@ static irqreturn_t mvpp2_link_status_isr(int irq, void *dev_id)
 
 	mvpp22_gop_mask_irq(port);
 
-	if (port->gop_id == 0 &&
-	    port->phy_interface == PHY_INTERFACE_MODE_10GKR) {
+	if (port->has_xlg_mac &&
+	    (port->phy_interface == PHY_INTERFACE_MODE_RXAUI ||
+	     port->phy_interface == PHY_INTERFACE_MODE_10GKR ||
+	     port->phy_interface == PHY_INTERFACE_MODE_5GKR ||
+	     port->phy_interface == PHY_INTERFACE_MODE_INTERNAL)) {
 		val = readl(port->base + MVPP22_XLG_INT_STAT);
 		if (val & MVPP22_XLG_INT_STAT_LINK) {
 			event = true;
@@ -2440,9 +3348,9 @@ static irqreturn_t mvpp2_link_status_isr(int irq, void *dev_id)
 				link = true;
 		}
 	} else if (phy_interface_mode_is_rgmii(port->phy_interface) ||
-		   port->phy_interface == PHY_INTERFACE_MODE_SGMII ||
-		   port->phy_interface == PHY_INTERFACE_MODE_1000BASEX ||
-		   port->phy_interface == PHY_INTERFACE_MODE_2500BASEX) {
+		   phy_interface_mode_is_8023z(port->phy_interface) ||
+		   port->phy_interface == PHY_INTERFACE_MODE_MII ||
+		   port->phy_interface == PHY_INTERFACE_MODE_SGMII) {
 		val = readl(port->base + MVPP22_GMAC_INT_STAT);
 		if (val & MVPP22_GMAC_INT_STAT_LINK) {
 			event = true;
@@ -2452,23 +3360,23 @@ static irqreturn_t mvpp2_link_status_isr(int irq, void *dev_id)
 		}
 	}
 
+	if (!netif_running(dev) || !event)
+		goto handled;
+
 	if (port->phylink) {
 		phylink_mac_change(port->phylink, link);
 		goto handled;
 	}
 
-	if (!netif_running(dev) || !event)
-		goto handled;
-
 	if (link) {
 		mvpp2_interrupts_enable(port);
 
 		mvpp2_egress_enable(port);
 		mvpp2_ingress_enable(port);
 		netif_carrier_on(dev);
-		netif_tx_wake_all_queues(dev);
+		mvpp2_tx_wake_all_queues(dev);
 	} else {
-		netif_tx_stop_all_queues(dev);
+		mvpp2_tx_stop_all_queues(dev);
 		netif_carrier_off(dev);
 		mvpp2_ingress_disable(port);
 		mvpp2_egress_disable(port);
@@ -2481,39 +3389,43 @@ static irqreturn_t mvpp2_link_status_isr(int irq, void *dev_id)
 	return IRQ_HANDLED;
 }
 
-static void mvpp2_timer_set(struct mvpp2_port_pcpu *port_pcpu)
+static void mvpp2_tx_done_timer_set(struct mvpp2_port_pcpu *port_pcpu)
 {
 	ktime_t interval;
 
-	if (!port_pcpu->timer_scheduled) {
-		port_pcpu->timer_scheduled = true;
+	if (!port_pcpu->tx_done_timer_scheduled) {
+		port_pcpu->tx_done_timer_scheduled = true;
 		interval = MVPP2_TXDONE_HRTIMER_PERIOD_NS;
 		hrtimer_start(&port_pcpu->tx_done_timer, interval,
 			      HRTIMER_MODE_REL_PINNED);
 	}
 }
 
-static void mvpp2_tx_proc_cb(unsigned long data)
+static void mvpp2_tx_done_proc_cb(unsigned long data)
 {
 	struct net_device *dev = (struct net_device *)data;
 	struct mvpp2_port *port = netdev_priv(dev);
-	struct mvpp2_port_pcpu *port_pcpu = this_cpu_ptr(port->pcpu);
+	struct mvpp2_port_pcpu *port_pcpu;
 	unsigned int tx_todo, cause;
 
+	port_pcpu = per_cpu_ptr(port->pcpu,
+				mvpp2_cpu_to_thread(port->priv, smp_processor_id()));
+
 	if (!netif_running(dev))
 		return;
-	port_pcpu->timer_scheduled = false;
+	port_pcpu->tx_done_timer_scheduled = false;
 
 	/* Process all the Tx queues */
 	cause = (1 << port->ntxqs) - 1;
-	tx_todo = mvpp2_tx_done(port, cause, smp_processor_id());
+	tx_todo = mvpp2_tx_done(port, cause,
+				mvpp2_cpu_to_thread(port->priv, smp_processor_id()));
 
 	/* Set the timer in case not all the packets were processed */
 	if (tx_todo)
-		mvpp2_timer_set(port_pcpu);
+		mvpp2_tx_done_timer_set(port_pcpu);
 }
 
-static enum hrtimer_restart mvpp2_hr_timer_cb(struct hrtimer *timer)
+static enum hrtimer_restart mvpp2_tx_done_timer_cb(struct hrtimer *timer)
 {
 	struct mvpp2_port_pcpu *port_pcpu = container_of(timer,
 							 struct mvpp2_port_pcpu,
@@ -2524,6 +3436,303 @@ static enum hrtimer_restart mvpp2_hr_timer_cb(struct hrtimer *timer)
 	return HRTIMER_NORESTART;
 }
 
+/* Bulk-timer could be started/restarted by XMIT, timer-cb or Tasklet.
+ *  XMIT calls bulk-restart() which is CONDITIONAL (restart vs request).
+ *  Timer-cb has own condition-logic, calls hrtimer_forward().
+ *  Tasklet has own condition-logic, calls unconditional bulk-start().
+ *  The flags scheduled::restart_req are used in the state-logic.
+ */
+static inline void mvpp2_bulk_timer_restart(struct mvpp2_port_pcpu *port_pcpu)
+{
+	if (!port_pcpu->bulk_timer_scheduled) {
+		port_pcpu->bulk_timer_scheduled = true;
+		hrtimer_start(&port_pcpu->bulk_timer, MVPP2_TX_BULK_TIME,
+			      HRTIMER_MODE_REL_PINNED);
+	} else {
+		port_pcpu->bulk_timer_restart_req = true;
+	}
+}
+
+static void mvpp2_bulk_timer_start(struct mvpp2_port_pcpu *port_pcpu)
+{
+	port_pcpu->bulk_timer_scheduled = true;
+	port_pcpu->bulk_timer_restart_req = false;
+	hrtimer_start(&port_pcpu->bulk_timer, MVPP2_TX_BULK_TIME,
+		      HRTIMER_MODE_REL_PINNED);
+}
+
+static enum hrtimer_restart mvpp2_bulk_timer_cb(struct hrtimer *timer)
+{
+	/* ISR context */
+	struct mvpp2_port_pcpu *port_pcpu =
+		container_of(timer, struct mvpp2_port_pcpu, bulk_timer);
+
+	if (!port_pcpu->bulk_timer_scheduled) {
+		/* All pending are already flushed by xmit */
+		return HRTIMER_NORESTART;
+	}
+	if (port_pcpu->bulk_timer_restart_req) {
+		/* Not flushed but restart requested by xmit */
+		port_pcpu->bulk_timer_scheduled = true;
+		port_pcpu->bulk_timer_restart_req = false;
+		hrtimer_forward_now(timer, MVPP2_TX_BULK_TIME);
+		return HRTIMER_RESTART;
+	}
+	/* Expired and need the flush for pending */
+	tasklet_schedule(&port_pcpu->bulk_tasklet);
+	return HRTIMER_NORESTART;
+}
+
+static void mvpp2_bulk_tasklet_cb(unsigned long data)
+{
+	struct net_device *dev = (struct net_device *)data;
+	struct mvpp2_port *port = netdev_priv(dev);
+	struct mvpp2_port_pcpu *port_pcpu;
+	struct mvpp2_tx_queue *aggr_txq;
+	int frags;
+	int cpu = smp_processor_id();
+
+	port_pcpu = per_cpu_ptr(port->pcpu, cpu);
+
+	if (!port_pcpu->bulk_timer_scheduled) {
+		/* Flushed by xmit-softirq since timer-irq */
+		return;
+	}
+	port_pcpu->bulk_timer_scheduled = false;
+	if (port_pcpu->bulk_timer_restart_req) {
+		/* Restart requested by xmit-softirq since timer-irq */
+		mvpp2_bulk_timer_start(port_pcpu);
+		return;
+	}
+
+	/* Full time expired. Flush pending packets here */
+	aggr_txq = &port->priv->aggr_txqs[cpu];
+	frags = aggr_txq->pending;
+	if (!frags)
+		return; /* Flushed by xmit */
+	aggr_txq->pending -= frags;
+	mvpp2_aggr_txq_pend_desc_add(port, frags);
+}
+
+/* Guard timer, tasklet, fixer utilities */
+
+/* The Guard fixer, called for 2 opposite actions:
+ *  Activate fix by set frame-coalescing to Zero (according to_zero_map)
+ *     which forces the tx-done IRQ. Called by guard tasklet.
+ *  Deactivate fixer ~ restore the coal-configration (to_zero_map=0)
+ *    when/by tx-done activated.
+ */
+static void mvpp2_tx_done_guard_force_irq(struct mvpp2_port *port,
+					  int sw_thread, u8 to_zero_map)
+{
+	int q;
+	u32 val, coal, qmask, xor;
+	struct mvpp2_port_pcpu *port_pcpu = per_cpu_ptr(port->pcpu, sw_thread);
+
+	if (port_pcpu->txq_coal_is_zero_map == to_zero_map)
+		return; /* all current & requested are already the same */
+
+	xor = port_pcpu->txq_coal_is_zero_map ^ to_zero_map;
+	/* Configuration num-of-frames coalescing is the same for all queues */
+	coal = port->txqs[0]->done_pkts_coal << MVPP2_TXQ_THRESH_OFFSET;
+
+	for (q = 0; q < port->ntxqs; q++) {
+		qmask = 1 << q;
+		if (!(xor & qmask))
+			continue;
+		if (to_zero_map & qmask)
+			val = 0; /* Set ZERO forcing the Interrupt */
+		else
+			val = coal; /* Set/restore configured threshold */
+		mvpp2_thread_write(port->priv, sw_thread,
+				   MVPP2_TXQ_NUM_REG, port->txqs[q]->id);
+		mvpp2_thread_write(port->priv, sw_thread,
+				   MVPP2_TXQ_THRESH_REG, val);
+	}
+	port_pcpu->txq_coal_is_zero_map = to_zero_map;
+}
+
+static inline void mvpp2_tx_done_guard_timer_set(struct mvpp2_port *port,
+						 int sw_thread)
+{
+	struct mvpp2_port_pcpu *port_pcpu = per_cpu_ptr(port->pcpu,
+							sw_thread);
+
+	if (!port_pcpu->guard_timer_scheduled) {
+		port_pcpu->guard_timer_scheduled = true;
+		hrtimer_start(&port_pcpu->tx_done_timer,
+			      MVPP2_GUARD_TXDONE_HRTIMER_NS,
+			      HRTIMER_MODE_REL_PINNED);
+	}
+}
+
+/* Guard timer and tasklet callbacks making check logic upon flags
+ *    guard_timer_scheduled, tx_done_passed,
+ *    txq_coal_is_zero_map, txq_busy_suspect_map
+ */
+static enum hrtimer_restart mvpp2_guard_timer_cb(struct hrtimer *timer)
+{
+	struct mvpp2_port_pcpu *port_pcpu = container_of(timer,
+			 struct mvpp2_port_pcpu, tx_done_timer);
+	struct mvpp2_port *port = port_pcpu->port;
+	struct mvpp2_tx_queue *txq;
+	struct mvpp2_txq_pcpu *txq_pcpu;
+	u8 txq_nonempty_map = 0;
+	int q, cpu;
+	ktime_t time;
+
+	if (port_pcpu->tx_done_passed) {
+		/* ok, tx-done was active since last checking */
+		port_pcpu->tx_done_passed = false;
+		time = MVPP2_GUARD_TXDONE_HRTIMER_NS; /* regular long */
+		goto timer_restart;
+	}
+
+	cpu = smp_processor_id(); /* timer is per-cpu */
+
+	for (q = 0; q < port->ntxqs; q++) {
+		txq = port->txqs[q];
+		txq_pcpu = per_cpu_ptr(txq->pcpu, cpu);
+		if (txq_pcpu->count)
+			txq_nonempty_map |= 1 << q;
+	}
+
+	if (!txq_nonempty_map || mvpp2_tx_stopped(port)) {
+		/* All queues are empty, guard-timer may be stopped now
+		 * It would be started again on new transmit.
+		 */
+		port_pcpu->guard_timer_scheduled = false;
+		return HRTIMER_NORESTART;
+	}
+
+	if (port_pcpu->txq_busy_suspect_map) {
+		/* Second-hit ~~ tx-done is really stalled.
+		 * Activate the tasklet to fix.
+		 * Keep guard_timer_scheduled=TRUE
+		 */
+		tasklet_schedule(&port_pcpu->tx_done_tasklet);
+		return HRTIMER_NORESTART;
+	}
+
+	/* First-hit ~~ tx-done seems stalled. Schedule re-check with SHORT time
+	 * bigger a bit than HW-coal-time-usec (1024=2^10 vs NSEC_PER_USEC)
+	 */
+	time = ktime_set(0, port->tx_time_coal << 10);
+	port_pcpu->txq_busy_suspect_map |= txq_nonempty_map;
+
+timer_restart:
+	/* Keep guard_timer_scheduled=TRUE but set new expiration time */
+	hrtimer_forward_now(timer, time);
+	return HRTIMER_RESTART;
+}
+
+static void mvpp2_tx_done_guard_tasklet_cb(unsigned long data)
+{
+	struct mvpp2_port *port = (void *)data;
+	struct mvpp2_port_pcpu *port_pcpu;
+	int cpu;
+
+	 /* stop_dev() has permanent setting for coal=0 */
+	if (mvpp2_tx_stopped(port))
+		return;
+
+	cpu = get_cpu();
+	port_pcpu = per_cpu_ptr(port->pcpu, cpu); /* tasklet is per-cpu */
+
+	if (port_pcpu->tx_done_passed) {
+		port_pcpu->tx_done_passed = false;
+	} else { /* Force IRQ */
+		mvpp2_tx_done_guard_force_irq(port, cpu,
+					      port_pcpu->txq_busy_suspect_map);
+		port_pcpu->tx_guard_cntr++;
+	}
+	port_pcpu->txq_busy_suspect_map = 0;
+
+	/* guard_timer_scheduled is already TRUE, just start the timer */
+	hrtimer_start(&port_pcpu->tx_done_timer,
+		      MVPP2_GUARD_TXDONE_HRTIMER_NS,
+		      HRTIMER_MODE_REL_PINNED);
+	put_cpu();
+}
+
+static u32 mvpp2_tx_done_guard_get_stats(struct mvpp2_port *port, int cpu)
+{
+	return per_cpu_ptr(port->pcpu, cpu)->tx_guard_cntr;
+}
+
+static void mvpp2_tx_done_init_on_open(struct mvpp2_port *port, bool open)
+{
+	struct mvpp2_port_pcpu *port_pcpu;
+	int cpu;
+
+	if (port->flags & MVPP2_F_LOOPBACK)
+		return;
+
+	if (!open)
+		goto close;
+
+	/* Init tx-done tasklets and variables */
+	for_each_present_cpu(cpu) {
+		port_pcpu = per_cpu_ptr(port->pcpu, cpu);
+
+		/* Timer works in tx-done or Guard mode. To eliminate per-packet
+		 * mode checking each mode has own "_scheduled" flag.
+		 * Set scheduled=FALSE for active mode and TRUE for inactive, so
+		 * timer would never be started in inactive mode.
+		 */
+		if (port->has_tx_irqs) { /* guard-mode */
+			port_pcpu->txq_coal_is_zero_map = 0;
+			port_pcpu->txq_busy_suspect_map = 0;
+			port_pcpu->tx_done_passed = false;
+
+			/* "true" is never started */
+			port_pcpu->tx_done_timer_scheduled = true;
+			port_pcpu->guard_timer_scheduled = false;
+			tasklet_init(&port_pcpu->tx_done_tasklet,
+				     mvpp2_tx_done_guard_tasklet_cb,
+				     (unsigned long)port);
+		} else {
+			port_pcpu->tx_done_timer_scheduled = false;
+			/* "true" is never started */
+			port_pcpu->guard_timer_scheduled = true;
+			tasklet_init(&port_pcpu->tx_done_tasklet,
+				     mvpp2_tx_done_proc_cb,
+				     (unsigned long)port->dev);
+		}
+	}
+	return;
+close:
+	/* Kill tx-done timers and tasklets */
+	for_each_present_cpu(cpu) {
+		port_pcpu = per_cpu_ptr(port->pcpu, cpu);
+		/* Say "scheduled=true" is never started on XMIT */
+		port_pcpu->tx_done_timer_scheduled = true;
+		port_pcpu->guard_timer_scheduled = true;
+		hrtimer_cancel(&port_pcpu->tx_done_timer);
+		tasklet_kill(&port_pcpu->tx_done_tasklet);
+	}
+}
+
+static void mvpp2_tx_done_init_on_probe(struct platform_device *pdev,
+					struct mvpp2_port *port)
+{
+	struct mvpp2_port_pcpu *port_pcpu;
+	int cpu;
+	bool guard_mode = port->has_tx_irqs;
+
+	if (port->flags & MVPP2_F_LOOPBACK)
+		return;
+
+	for_each_present_cpu(cpu) {
+		port_pcpu = per_cpu_ptr(port->pcpu, cpu);
+		port_pcpu->port = port;
+		hrtimer_init(&port_pcpu->tx_done_timer, CLOCK_MONOTONIC,
+			     HRTIMER_MODE_REL_PINNED);
+		port_pcpu->tx_done_timer.function = (guard_mode) ?
+				mvpp2_guard_timer_cb : mvpp2_tx_done_timer_cb;
+	}
+}
+
 /* Main RX/TX processing routines */
 
 /* Display more error info */
@@ -2535,8 +3744,8 @@ static void mvpp2_rx_error(struct mvpp2_port *port,
 	char *err_str = NULL;
 
 	switch (status & MVPP2_RXD_ERR_CODE_MASK) {
-	case MVPP2_RXD_ERR_CRC:
-		err_str = "crc";
+	case MVPP2_RXD_ERR_MAC:
+		err_str = "MAC";
 		break;
 	case MVPP2_RXD_ERR_OVERRUN:
 		err_str = "overrun";
@@ -2546,78 +3755,395 @@ static void mvpp2_rx_error(struct mvpp2_port *port,
 		break;
 	}
 	if (err_str && net_ratelimit())
-		netdev_err(port->dev,
+		netdev_dbg(port->dev,
 			   "bad rx status %08x (%s error), size=%zu\n",
 			   status, err_str, sz);
 }
 
-/* Handle RX checksum offload */
-static void mvpp2_rx_csum(struct mvpp2_port *port, u32 status,
-			  struct sk_buff *skb)
+/* Handle RX checksum offload */
+static void mvpp2_rx_csum(struct mvpp2_port *port, u32 status,
+			  struct sk_buff *skb)
+{
+	if (((status & MVPP2_RXD_L3_IP4) &&
+	     !(status & MVPP2_RXD_IP4_HEADER_ERR)) ||
+	    (status & MVPP2_RXD_L3_IP6))
+		if (((status & MVPP2_RXD_L4_UDP) ||
+		     (status & MVPP2_RXD_L4_TCP)) &&
+		     (status & MVPP2_RXD_L4_CSUM_OK)) {
+			skb->csum = 0;
+			skb->ip_summed = CHECKSUM_UNNECESSARY;
+			return;
+		}
+
+	skb->ip_summed = CHECKSUM_NONE;
+}
+
+/* Allocate a new skb and add it to BM pool */
+static inline int mvpp2_rx_refill(struct mvpp2_port *port,
+				  struct mvpp2_bm_pool *bm_pool, int pool)
+{
+	dma_addr_t dma_addr = mvpp2_buf_alloc(port, bm_pool, GFP_ATOMIC);
+
+	if (!dma_addr)
+		return -ENOMEM;
+
+	mvpp2_bm_pool_put(port, pool, dma_addr);
+
+	return 0;
+}
+
+/* Handle tx checksum */
+static u32 mvpp2_skb_tx_csum(struct mvpp2_port *port, struct sk_buff *skb)
+{
+	if (skb->ip_summed == CHECKSUM_PARTIAL) {
+		int ip_hdr_len = 0;
+		u8 l4_proto;
+		__be16 l3_proto = vlan_get_protocol(skb);
+
+		if (l3_proto == htons(ETH_P_IP)) {
+			struct iphdr *ip4h = ip_hdr(skb);
+
+			/* Calculate IPv4 checksum and L4 checksum */
+			ip_hdr_len = ip4h->ihl;
+			l4_proto = ip4h->protocol;
+		} else if (l3_proto == htons(ETH_P_IPV6)) {
+			struct ipv6hdr *ip6h = ipv6_hdr(skb);
+
+			/* Read l4_protocol from one of IPv6 extra headers */
+			if (skb_network_header_len(skb) > 0)
+				ip_hdr_len = (skb_network_header_len(skb) >> 2);
+			l4_proto = ip6h->nexthdr;
+		} else {
+			return MVPP2_TXD_L4_CSUM_NOT;
+		}
+
+		return mvpp2_txq_desc_csum(skb_network_offset(skb),
+					   l3_proto, ip_hdr_len, l4_proto);
+	}
+
+	return MVPP2_TXD_L4_CSUM_NOT | MVPP2_TXD_IP_CSUM_DISABLE;
+}
+
+void mvpp2_recycle_stats(void)
+{
+	int cpu;
+	int pl_id;
+	struct mvpp2_recycle_pcpu *pcpu;
+
+	pr_info("Recycle-stats: %d open ports (on all CP110s)\n",
+		mvpp2_share.num_open_ports);
+	if (!mvpp2_share.recycle_base)
+		return;
+	pcpu = mvpp2_share.recycle;
+	for_each_online_cpu(cpu) {
+		for (pl_id = 0; pl_id < MVPP2_BM_POOLS_NUM; pl_id++) {
+			pr_info("| cpu[%d].pool_%d: idx=%d\n",
+				cpu, pl_id, pcpu->idx[pl_id]);
+		}
+		pr_info("| ___[%d].skb_____idx=%d__\n",
+			cpu, pcpu->idx[MVPP2_BM_POOLS_NUM]);
+		pcpu++;
+	}
+}
+
+static int mvpp2_recycle_open(void)
+{
+	int cpu, pl_id, size;
+	struct mvpp2_recycle_pcpu *pcpu;
+	phys_addr_t addr;
+
+	mvpp2_share.num_open_ports++;
+	wmb(); /* for num_open_ports */
+
+	if (mvpp2_share.recycle_base)
+		return 0;
+
+	/* Allocate pool-tree */
+	size = sizeof(*pcpu) * num_online_cpus() + L1_CACHE_BYTES;
+	mvpp2_share.recycle_base = kzalloc(size, GFP_KERNEL);
+	if (!mvpp2_share.recycle_base)
+		goto err;
+	/* Use Address aligned to L1_CACHE_BYTES */
+	addr = (phys_addr_t)mvpp2_share.recycle_base + (L1_CACHE_BYTES - 1);
+	addr &= ~(L1_CACHE_BYTES - 1);
+	mvpp2_share.recycle = (void *)addr;
+
+	pcpu = mvpp2_share.recycle;
+	for_each_online_cpu(cpu) {
+		for (pl_id = 0; pl_id <= MVPP2_BM_POOLS_NUM; pl_id++)
+			pcpu->idx[pl_id] = -1;
+		pcpu++;
+	}
+	return 0;
+err:
+	pr_err("mvpp2 error: cannot allocate recycle pool\n");
+	return -ENOMEM;
+}
+
+static void mvpp2_recycle_close(void)
+{
+	int cpu, pl_id, i;
+	struct mvpp2_recycle_pcpu *pcpu;
+	struct mvpp2_recycle_pool *pool;
+
+	mvpp2_share.num_open_ports--;
+	wmb(); /* for num_open_ports */
+
+	/* Do nothing if recycle is not used at all or in use by port/ports */
+	if (mvpp2_share.num_open_ports || !mvpp2_share.recycle_base)
+		return;
+
+	/* Usable (recycle_base!=NULL), but last port gone down
+	 * Let's free all accumulated buffers.
+	 */
+	pcpu = mvpp2_share.recycle;
+	for_each_online_cpu(cpu) {
+		for (pl_id = 0; pl_id <= MVPP2_BM_POOLS_NUM; pl_id++) {
+			pool = &pcpu->pool[pl_id];
+			for (i = 0; i <= pcpu->idx[pl_id]; i++) {
+				if (!pool->pbuf[i])
+					continue;
+				if (pl_id < MVPP2_BM_POOLS_NUM)
+					kfree(pool->pbuf[i]);
+				else
+					kmem_cache_free(skbuff_head_cache,
+							pool->pbuf[i]);
+			}
+		}
+		pcpu++;
+	}
+	kfree(mvpp2_share.recycle_base);
+	mvpp2_share.recycle_base = NULL;
+}
+
+static int mvpp2_recycle_get_bm_id(struct sk_buff *skb)
+{
+	u32 hash;
+
+	/* Keep checking ordering for performance */
+	hash = skb_get_hash_raw(skb);
+	/* Check hash */
+	if (!MVPP2_RXTX_HASH_IS_OK(skb, hash))
+		return -1;
+	/* Check if skb could be free */
+	/* Use skb->cloned but not skb_cloned(), skb_header_cloned() */
+	if (skb_shared(skb) || skb->cloned)
+		return -1;
+	/* ipsec: sp/secpath, _skb_refdst ... */
+	if (!skb_irq_freeable(skb))
+		return -1;
+	if (skb_shinfo(skb)->tx_flags & SKBTX_ZEROCOPY_FRAG)
+		return -1;
+
+	/* Get bm-pool-id */
+	hash &= MVPP2_RXTX_HASH_BMID_MASK;
+	if (hash >= MVPP2_BM_POOLS_NUM)
+		return -1;
+
+	return (int)hash;
+}
+
+static inline void mvpp2_recycle_put(struct mvpp2_port *port,
+				     struct mvpp2_txq_pcpu *txq_pcpu,
+				     struct mvpp2_txq_pcpu_buf *tx_buf)
+{
+	struct mvpp2_recycle_pcpu *pcpu;
+	struct mvpp2_recycle_pool *pool;
+	short int idx, pool_id;
+	struct sk_buff *skb = tx_buf->skb;
+	struct mvpp2_bm_pool *bm_pool;
+
+	/* tx_buf->skb is not NULL */
+	pool_id = mvpp2_recycle_get_bm_id(skb);
+	if (pool_id < 0)
+		return; /* non-recyclable */
+
+	bm_pool = &port->priv->bm_pools[pool_id];
+	if (skb_end_offset(skb) < (bm_pool->frag_size - MVPP2_SKB_SHINFO_SIZE))
+		return; /* shrank -> non-recyclable */
+
+	/* This skb could be destroyed. Put into recycle */
+	pcpu = mvpp2_share.recycle + txq_pcpu->thread;
+	idx = pcpu->idx[pool_id];
+	if (idx < (MVPP2_RECYCLE_FULL - 1)) {
+		pool = &pcpu->pool[pool_id];
+		pool->pbuf[++idx] = skb->head; /* pre-increment */
+		pcpu->idx[pool_id] = idx;
+		skb->head = NULL;
+	}
+	idx = pcpu->idx[MVPP2_BM_POOLS_NUM];
+	if (idx < (MVPP2_RECYCLE_FULL_SKB - 1)) {
+		pool = &pcpu->pool[MVPP2_BM_POOLS_NUM];
+		pool->pbuf[++idx] = skb;
+		pcpu->idx[MVPP2_BM_POOLS_NUM] = idx;
+		if (skb->head) {
+			if (bm_pool->frag_size <= PAGE_SIZE)
+				skb_free_frag(skb->head);
+			else
+				kfree(skb->head);
+		}
+		tx_buf->skb = NULL;
+	}
+}
+
+static struct sk_buff *mvpp2_recycle_get(struct mvpp2_port *port,
+					 struct mvpp2_bm_pool *bm_pool)
 {
-	if (((status & MVPP2_RXD_L3_IP4) &&
-	     !(status & MVPP2_RXD_IP4_HEADER_ERR)) ||
-	    (status & MVPP2_RXD_L3_IP6))
-		if (((status & MVPP2_RXD_L4_UDP) ||
-		     (status & MVPP2_RXD_L4_TCP)) &&
-		     (status & MVPP2_RXD_L4_CSUM_OK)) {
-			skb->csum = 0;
-			skb->ip_summed = CHECKSUM_UNNECESSARY;
-			return;
-		}
+	int cpu;
+	struct mvpp2_recycle_pcpu *pcpu;
+	struct mvpp2_recycle_pool *pool;
+	short int idx;
+	void *frag;
+	struct sk_buff *skb;
+	dma_addr_t dma_addr;
 
-	skb->ip_summed = CHECKSUM_NONE;
+	cpu = smp_processor_id();
+	pcpu = mvpp2_share.recycle + cpu;
+
+	/* GET bm buffer */
+	idx = pcpu->idx[bm_pool->id];
+	pool = &pcpu->pool[bm_pool->id];
+
+	if (idx >= 0) {
+		frag = pool->pbuf[idx];
+		pcpu->idx[bm_pool->id]--; /* post-decrement */
+	} else {
+		/* Allocate 2 buffers, put 1, use another now */
+		pcpu->idx[bm_pool->id] = 0;
+		pool->pbuf[0] = mvpp2_frag_alloc(bm_pool);
+		frag = NULL;
+	}
+	if (!frag)
+		frag = mvpp2_frag_alloc(bm_pool);
+
+	/* refill the buffer into BM */
+	dma_addr = dma_map_single(port->dev->dev.parent, frag,
+				  bm_pool->buf_size, DMA_FROM_DEVICE);
+	if (unlikely(dma_mapping_error(port->dev->dev.parent, dma_addr))) {
+		pcpu->idx[bm_pool->id]++; /* Return back to recycle */
+		netdev_err(port->dev, "failed to refill BM pool-%d (%d:%p)\n",
+			   bm_pool->id, pcpu->idx[bm_pool->id], frag);
+		return NULL;
+	}
+
+	/* GET skb buffer */
+	idx = pcpu->idx[MVPP2_BM_POOLS_NUM];
+	if (idx >= 0) {
+		pool = &pcpu->pool[MVPP2_BM_POOLS_NUM];
+		skb = pool->pbuf[idx];
+		pcpu->idx[MVPP2_BM_POOLS_NUM]--;
+	} else {
+		skb = kmem_cache_alloc(skbuff_head_cache, GFP_ATOMIC);
+	}
+
+	if (unlikely(!skb)) {
+		dma_unmap_single(port->dev->dev.parent, dma_addr,
+				 bm_pool->buf_size, DMA_FROM_DEVICE);
+		mvpp2_frag_free(bm_pool, frag);
+		return NULL;
+	}
+	mvpp2_bm_pool_put(port, bm_pool->id, dma_addr);
+	return skb;
 }
 
-/* Reuse skb if possible, or allocate a new skb and add it to BM pool */
-static int mvpp2_rx_refill(struct mvpp2_port *port,
-			   struct mvpp2_bm_pool *bm_pool, int pool)
+/* SKB and BM-buff alloc/refill like mvpp2_recycle_get but without recycle */
+static inline
+struct sk_buff *mvpp2_bm_refill_skb_get(struct mvpp2_port *port,
+					struct mvpp2_bm_pool *bm_pool)
 {
+	void *frag;
+	struct sk_buff *skb;
 	dma_addr_t dma_addr;
-	phys_addr_t phys_addr;
-	void *buf;
-
-	/* No recycle or too many buffers are in use, so allocate a new skb */
-	buf = mvpp2_buf_alloc(port, bm_pool, &dma_addr, &phys_addr,
-			      GFP_ATOMIC);
-	if (!buf)
-		return -ENOMEM;
 
-	mvpp2_bm_pool_put(port, pool, dma_addr, phys_addr);
+	/* GET bm buffer, refill into BM */
+	frag = mvpp2_frag_alloc(bm_pool);
+	dma_addr = dma_map_single(port->dev->dev.parent, frag,
+				  bm_pool->buf_size, DMA_FROM_DEVICE);
+	if (unlikely(dma_mapping_error(port->dev->dev.parent, dma_addr))) {
+		netdev_err(port->dev, "failed to refill BM pool-%d\n",
+			   bm_pool->id);
+		return NULL;
+	}
 
-	return 0;
+	/* GET skb buffer */
+	skb = kmem_cache_alloc(skbuff_head_cache, GFP_ATOMIC);
+	if (unlikely(!skb)) {
+		dma_unmap_single(port->dev->dev.parent, dma_addr,
+				 bm_pool->buf_size, DMA_FROM_DEVICE);
+		mvpp2_frag_free(bm_pool, frag);
+		return NULL;
+	}
+	mvpp2_bm_pool_put(port, bm_pool->id, dma_addr);
+	return skb;
 }
 
-/* Handle tx checksum */
-static u32 mvpp2_skb_tx_csum(struct mvpp2_port *port, struct sk_buff *skb)
+static inline void mvpp2_skb_set_extra(struct sk_buff *skb,
+				       struct napi_struct *napi,
+				       u32 status,
+				       u8 rxq_id,
+				       struct mvpp2_bm_pool *bm_pool)
 {
-	if (skb->ip_summed == CHECKSUM_PARTIAL) {
-		int ip_hdr_len = 0;
-		u8 l4_proto;
-		__be16 l3_proto = vlan_get_protocol(skb);
+	u32 hash;
+	enum pkt_hash_types hash_type;
 
-		if (l3_proto == htons(ETH_P_IP)) {
-			struct iphdr *ip4h = ip_hdr(skb);
+	/* Improve performance and set identification for RX-TX fast-forward */
+	hash = MVPP2_RXTX_HASH_GENER(skb, bm_pool->id);
+	hash_type = (status & (MVPP2_RXD_L4_UDP | MVPP2_RXD_L4_TCP)) ?
+		PKT_HASH_TYPE_L4 : PKT_HASH_TYPE_L3;
+	skb_set_hash(skb, hash, hash_type);
+	skb_mark_napi_id(skb, napi);
+	skb_record_rx_queue(skb, (u16)rxq_id);
+}
 
-			/* Calculate IPv4 checksum and L4 checksum */
-			ip_hdr_len = ip4h->ihl;
-			l4_proto = ip4h->protocol;
-		} else if (l3_proto == htons(ETH_P_IPV6)) {
-			struct ipv6hdr *ip6h = ipv6_hdr(skb);
+/* This is "fast inline" clone of __build_skb+build_skb,
+ * and also with setting mv-extra information
+ */
+static inline
+struct sk_buff *mvpp2_build_skb(void *data, unsigned int frag_size,
+				struct napi_struct *napi,
+				struct mvpp2_port *port,
+				u32 rx_status,
+				u8 rxq_id,
+				struct mvpp2_bm_pool *bm_pool)
+{
+	struct skb_shared_info *shinfo;
+	struct sk_buff *skb;
+	unsigned int size = frag_size ? : ksize(data);
+
+	if (static_branch_unlikely(&mvpp2_recycle_ena))
+		skb = mvpp2_recycle_get(port, bm_pool);
+	else
+		skb = mvpp2_bm_refill_skb_get(port, bm_pool);
+	if (unlikely(!skb))
+		return NULL;
 
-			/* Read l4_protocol from one of IPv6 extra headers */
-			if (skb_network_header_len(skb) > 0)
-				ip_hdr_len = (skb_network_header_len(skb) >> 2);
-			l4_proto = ip6h->nexthdr;
-		} else {
-			return MVPP2_TXD_L4_CSUM_NOT;
-		}
+	size -= SKB_DATA_ALIGN(sizeof(struct skb_shared_info));
 
-		return mvpp2_txq_desc_csum(skb_network_offset(skb),
-					   l3_proto, ip_hdr_len, l4_proto);
+	memset(skb, 0, offsetof(struct sk_buff, tail));
+	skb->truesize = SKB_TRUESIZE(size);
+	refcount_set(&skb->users, 1);
+	skb->head = data;
+	skb->data = data;
+	skb_reset_tail_pointer(skb);
+	skb->end = skb->tail + size;
+	skb->mac_header = (typeof(skb->mac_header))~0U;
+	skb->transport_header = (typeof(skb->transport_header))~0U;
+
+	/* make sure we initialize shinfo sequentially */
+	shinfo = skb_shinfo(skb);
+	memset(shinfo, 0, offsetof(struct skb_shared_info, dataref));
+	atomic_set(&shinfo->dataref, 1);
+
+	/* From build_skb wrapper */
+	if (frag_size) {
+		skb->head_frag = 1;
+		if (page_is_pfmemalloc(virt_to_head_page(data)))
+			skb->pfmemalloc = 1;
 	}
 
-	return MVPP2_TXD_L4_CSUM_NOT | MVPP2_TXD_IP_CSUM_DISABLE;
+	mvpp2_skb_set_extra(skb, napi, rx_status, rxq_id, bm_pool);
+
+	return skb;
 }
 
 /* Main rx processing */
@@ -2627,13 +4153,23 @@ static int mvpp2_rx(struct mvpp2_port *port, struct napi_struct *napi,
 	struct net_device *dev = port->dev;
 	int rx_received;
 	int rx_done = 0;
-	u32 rcvd_pkts = 0;
+	u32 rcvd_pkts = 0, i = 0;
 	u32 rcvd_bytes = 0;
+	struct sk_buff *skb_all[rx_todo];
 
-	/* Get number of received packets and clamp the to-do */
-	rx_received = mvpp2_rxq_received(port, rxq->id);
-	if (rx_todo > rx_received)
-		rx_todo = rx_received;
+	if (rxq->rx_pending >= rx_todo) {
+		rx_received = rx_todo;
+		rxq->rx_pending -= rx_todo;
+	} else {
+		/* Get number of received packets and clamp the to-do */
+		rx_received = mvpp2_rxq_received(port, rxq->id);
+		if (rx_received < rx_todo) {
+			rx_todo = rx_received;
+			rxq->rx_pending = 0;
+		} else {
+			rxq->rx_pending = rx_received - rx_todo;
+		}
+	}
 
 	while (rx_done < rx_todo) {
 		struct mvpp2_rx_desc *rx_desc = mvpp2_rxq_next_desc_get(rxq);
@@ -2643,7 +4179,7 @@ static int mvpp2_rx(struct mvpp2_port *port, struct napi_struct *napi,
 		dma_addr_t dma_addr;
 		phys_addr_t phys_addr;
 		u32 rx_status;
-		int pool, rx_bytes, err;
+		int pool, rx_bytes;
 		void *data;
 
 		rx_done++;
@@ -2651,7 +4187,7 @@ static int mvpp2_rx(struct mvpp2_port *port, struct napi_struct *napi,
 		rx_bytes = mvpp2_rxdesc_size_get(port, rx_desc);
 		rx_bytes -= MVPP2_MH_SIZE;
 		dma_addr = mvpp2_rxdesc_dma_addr_get(port, rx_desc);
-		phys_addr = mvpp2_rxdesc_cookie_get(port, rx_desc);
+		phys_addr = dma_to_phys(port->dev->dev.parent, dma_addr);
 		data = (void *)phys_to_virt(phys_addr);
 
 		pool = (rx_status & MVPP2_RXD_BM_POOL_ID_MASK) >>
@@ -2668,7 +4204,7 @@ static int mvpp2_rx(struct mvpp2_port *port, struct napi_struct *napi,
 			dev->stats.rx_errors++;
 			mvpp2_rx_error(port, rx_desc);
 			/* Return the buffer to the pool */
-			mvpp2_bm_pool_put(port, pool, dma_addr, phys_addr);
+			mvpp2_bm_pool_put(port, pool, dma_addr);
 			continue;
 		}
 
@@ -2677,32 +4213,38 @@ static int mvpp2_rx(struct mvpp2_port *port, struct napi_struct *napi,
 		else
 			frag_size = bm_pool->frag_size;
 
-		skb = build_skb(data, frag_size);
+		/* _sync_ for coherency (_unmap_ is asynchroneous).
+		 * _sync_ should be done for the SAME size as in map/unmap.
+		 * The prefetch is for CPU and should be after unmap ~ mapToCPU
+		 */
+		if (rx_todo == 1)
+			dma_sync_single_for_cpu(dev->dev.parent, dma_addr,
+						bm_pool->buf_size,
+						DMA_FROM_DEVICE);
+		dma_unmap_single(dev->dev.parent, dma_addr,
+				 bm_pool->buf_size, DMA_FROM_DEVICE);
+
+		prefetch(data + NET_SKB_PAD); /* packet header */
+
+		skb = mvpp2_build_skb(data, frag_size,
+				      napi, port, rx_status, rxq->id, bm_pool);
 		if (!skb) {
 			netdev_warn(port->dev, "skb build failed\n");
 			goto err_drop_frame;
 		}
 
-		err = mvpp2_rx_refill(port, bm_pool, pool);
-		if (err) {
-			netdev_err(port->dev, "failed to refill BM pools\n");
-			goto err_drop_frame;
-		}
-
-		dma_unmap_single(dev->dev.parent, dma_addr,
-				 bm_pool->buf_size, DMA_FROM_DEVICE);
-
-		rcvd_pkts++;
-		rcvd_bytes += rx_bytes;
-
 		skb_reserve(skb, MVPP2_MH_SIZE + NET_SKB_PAD);
 		skb_put(skb, rx_bytes);
 		skb->protocol = eth_type_trans(skb, dev);
 		mvpp2_rx_csum(port, rx_status, skb);
 
-		napi_gro_receive(napi, skb);
+		skb_all[rcvd_pkts++] = skb;
+		rcvd_bytes += rx_bytes;
 	}
 
+	while (i < rcvd_pkts)
+		napi_gro_receive(napi, skb_all[i++]);
+
 	if (rcvd_pkts) {
 		struct mvpp2_pcpu_stats *stats = this_cpu_ptr(port->stats);
 
@@ -2712,8 +4254,7 @@ static int mvpp2_rx(struct mvpp2_port *port, struct napi_struct *napi,
 		u64_stats_update_end(&stats->syncp);
 	}
 
-	/* Update Rx queue management counters */
-	wmb();
+	/* Update HW Rx queue management counters with RX-done */
 	mvpp2_rxq_status_update(port, rxq->id, rx_done, rx_done);
 
 	return rx_todo;
@@ -2723,7 +4264,8 @@ static inline void
 tx_desc_unmap_put(struct mvpp2_port *port, struct mvpp2_tx_queue *txq,
 		  struct mvpp2_tx_desc *desc)
 {
-	struct mvpp2_txq_pcpu *txq_pcpu = this_cpu_ptr(txq->pcpu);
+	unsigned int thread = mvpp2_cpu_to_thread(port->priv, smp_processor_id());
+	struct mvpp2_txq_pcpu *txq_pcpu = per_cpu_ptr(txq->pcpu, thread);
 
 	dma_addr_t buf_dma_addr =
 		mvpp2_txdesc_dma_addr_get(port, desc);
@@ -2740,7 +4282,8 @@ static int mvpp2_tx_frag_process(struct mvpp2_port *port, struct sk_buff *skb,
 				 struct mvpp2_tx_queue *aggr_txq,
 				 struct mvpp2_tx_queue *txq)
 {
-	struct mvpp2_txq_pcpu *txq_pcpu = this_cpu_ptr(txq->pcpu);
+	unsigned int thread = mvpp2_cpu_to_thread(port->priv, smp_processor_id());
+	struct mvpp2_txq_pcpu *txq_pcpu = per_cpu_ptr(txq->pcpu, thread);
 	struct mvpp2_tx_desc *tx_desc;
 	int i;
 	dma_addr_t buf_dma_addr;
@@ -2808,7 +4351,7 @@ static inline void mvpp2_tso_put_hdr(struct sk_buff *skb,
 	mvpp2_txdesc_cmd_set(port, tx_desc, mvpp2_skb_tx_csum(port, skb) |
 					    MVPP2_TXD_F_DESC |
 					    MVPP2_TXD_PADDING_DISABLE);
-	mvpp2_txq_inc_put(port, txq_pcpu, NULL, tx_desc);
+	mvpp2_txq_inc_put(port, txq_pcpu, TSO_HEADER_MARK, tx_desc);
 }
 
 static inline int mvpp2_tso_put_data(struct sk_buff *skb,
@@ -2856,15 +4399,17 @@ static int mvpp2_tx_tso(struct sk_buff *skb, struct net_device *dev,
 	struct mvpp2_port *port = netdev_priv(dev);
 	struct tso_t tso;
 	int hdr_sz = skb_transport_offset(skb) + tcp_hdrlen(skb);
-	int i, len, descs = 0;
+	int i, len, descs = tso_count_descs(skb);
 
-	/* Check number of available descriptors */
-	if (mvpp2_aggr_desc_num_check(port->priv, aggr_txq,
-				      tso_count_descs(skb)) ||
-	    mvpp2_txq_reserved_desc_num_proc(port->priv, txq, txq_pcpu,
-					     tso_count_descs(skb)))
+	/* Check enough free-space in txq and
+	 * number of available aggr/reserved descriptors
+	 */
+	if (((txq_pcpu->size - txq_pcpu->count) < descs) ||
+	    mvpp2_aggr_desc_num_check(port, aggr_txq, descs) ||
+	    mvpp2_txq_reserved_desc_num_proc(port, txq, txq_pcpu, descs))
 		return 0;
 
+	descs = 0; /* real descs <= tso_count_descs() */
 	tso_start(skb, &tso);
 	len = skb->len - hdr_sz;
 	while (len > 0) {
@@ -2908,14 +4453,21 @@ static netdev_tx_t mvpp2_tx(struct sk_buff *skb, struct net_device *dev)
 	struct mvpp2_txq_pcpu *txq_pcpu;
 	struct mvpp2_tx_desc *tx_desc;
 	dma_addr_t buf_dma_addr;
+	unsigned long flags = 0;
+	unsigned int thread;
 	int frags = 0;
 	u16 txq_id;
 	u32 tx_cmd;
 
+	thread = mvpp2_cpu_to_thread(port->priv, smp_processor_id());
+
 	txq_id = skb_get_queue_mapping(skb);
 	txq = port->txqs[txq_id];
-	txq_pcpu = this_cpu_ptr(txq->pcpu);
-	aggr_txq = &port->priv->aggr_txqs[smp_processor_id()];
+	txq_pcpu = per_cpu_ptr(txq->pcpu, thread);
+	aggr_txq = &port->priv->aggr_txqs[thread];
+
+	if (test_bit(thread, &port->priv->lock_map))
+		spin_lock_irqsave(&port->tx_lock[thread], flags);
 
 	if (skb_is_gso(skb)) {
 		frags = mvpp2_tx_tso(skb, dev, txq, aggr_txq, txq_pcpu);
@@ -2923,10 +4475,12 @@ static netdev_tx_t mvpp2_tx(struct sk_buff *skb, struct net_device *dev)
 	}
 	frags = skb_shinfo(skb)->nr_frags + 1;
 
-	/* Check number of available descriptors */
-	if (mvpp2_aggr_desc_num_check(port->priv, aggr_txq, frags) ||
-	    mvpp2_txq_reserved_desc_num_proc(port->priv, txq,
-					     txq_pcpu, frags)) {
+	/* Check enough free-space in txq and
+	 * number of available aggr/reserved descriptors
+	 */
+	if (((txq_pcpu->size - txq_pcpu->count) < frags) ||
+	    mvpp2_aggr_desc_num_check(port, aggr_txq, frags) ||
+	    mvpp2_txq_reserved_desc_num_proc(port, txq, txq_pcpu, frags)) {
 		frags = 0;
 		goto out;
 	}
@@ -2968,20 +4522,42 @@ static netdev_tx_t mvpp2_tx(struct sk_buff *skb, struct net_device *dev)
 
 out:
 	if (frags > 0) {
-		struct mvpp2_pcpu_stats *stats = this_cpu_ptr(port->stats);
-		struct netdev_queue *nq = netdev_get_tx_queue(dev, txq_id);
+		struct mvpp2_pcpu_stats *stats = per_cpu_ptr(port->stats, thread);
+		struct mvpp2_port_pcpu *port_pcpu = this_cpu_ptr(port->pcpu);
+		struct netdev_queue *nq;
+		bool deferred_tx;
 
 		txq_pcpu->reserved_num -= frags;
 		txq_pcpu->count += frags;
 		aggr_txq->count += frags;
 
-		/* Enable transmit */
-		wmb();
-		mvpp2_aggr_txq_pend_desc_add(port, frags);
+		/* Enable transmit; RX-to-TX may be deferred with Bulk-timer */
+		deferred_tx = (frags == 1) &&
+			MVPP2_RXTX_HASH_IS_OK_TX(skb, skb_get_hash_raw(skb)) &&
+			(aggr_txq->pending < min(MVPP2_TX_BULK_MAX_PACKETS,
+					       (int)(txq->done_pkts_coal / 2)));
 
-		if (txq_pcpu->count >= txq_pcpu->stop_threshold)
-			netif_tx_stop_queue(nq);
+		if (deferred_tx) {
+			aggr_txq->pending += frags;
+			mvpp2_bulk_timer_restart(port_pcpu);
+		} else {
+			port_pcpu->bulk_timer_scheduled = false;
+			port_pcpu->bulk_timer_restart_req = false;
+			frags += aggr_txq->pending;
+			aggr_txq->pending = 0;
+			mvpp2_aggr_txq_pend_desc_add(port, frags);
+		}
 
+		if (unlikely(txq_pcpu->count >= txq_pcpu->stop_threshold)) {
+			nq = netdev_get_tx_queue(dev, txq_id);
+			/* txq_id may differ from thread/cpu and come from more
+			 * than one txq_pcpu. Save only the first for wakeup.
+			 */
+			if (unlikely(!netif_tx_queue_stopped(nq))) {
+				txq_pcpu->stopped_on_txq_id = txq_id;
+				netif_tx_stop_queue(nq);
+			}
+		}
 		u64_stats_update_begin(&stats->syncp);
 		stats->tx_packets++;
 		stats->tx_bytes += skb->len;
@@ -2998,31 +4574,23 @@ static netdev_tx_t mvpp2_tx(struct sk_buff *skb, struct net_device *dev)
 	/* Set the timer in case not all frags were processed */
 	if (!port->has_tx_irqs && txq_pcpu->count <= frags &&
 	    txq_pcpu->count > 0) {
-		struct mvpp2_port_pcpu *port_pcpu = this_cpu_ptr(port->pcpu);
+		struct mvpp2_port_pcpu *port_pcpu = per_cpu_ptr(port->pcpu, thread);
 
-		mvpp2_timer_set(port_pcpu);
+		mvpp2_tx_done_timer_set(port_pcpu);
 	}
 
-	return NETDEV_TX_OK;
-}
+	if (test_bit(thread, &port->priv->lock_map))
+		spin_unlock_irqrestore(&port->tx_lock[thread], flags);
 
-static inline void mvpp2_cause_error(struct net_device *dev, int cause)
-{
-	if (cause & MVPP2_CAUSE_FCS_ERR_MASK)
-		netdev_err(dev, "FCS error\n");
-	if (cause & MVPP2_CAUSE_RX_FIFO_OVERRUN_MASK)
-		netdev_err(dev, "rx fifo overrun error\n");
-	if (cause & MVPP2_CAUSE_TX_FIFO_UNDERRUN_MASK)
-		netdev_err(dev, "tx fifo underrun error\n");
+	return NETDEV_TX_OK;
 }
 
 static int mvpp2_poll(struct napi_struct *napi, int budget)
 {
-	u32 cause_rx_tx, cause_rx, cause_tx, cause_misc;
+	u32 cause_rx_tx, cause_rx, cause_tx;
 	int rx_done = 0;
 	struct mvpp2_port *port = netdev_priv(napi->dev);
 	struct mvpp2_queue_vector *qv;
-	int cpu = smp_processor_id();
 
 	qv = container_of(napi, struct mvpp2_queue_vector, napi);
 
@@ -3036,23 +4604,14 @@ static int mvpp2_poll(struct napi_struct *napi, int budget)
 	 *
 	 * Each CPU has its own Rx/Tx cause register
 	 */
-	cause_rx_tx = mvpp2_percpu_read_relaxed(port->priv, qv->sw_thread_id,
+	cause_rx_tx = mvpp2_thread_read_relaxed(port->priv, qv->sw_thread_id,
 						MVPP2_ISR_RX_TX_CAUSE_REG(port->id));
 
-	cause_misc = cause_rx_tx & MVPP2_CAUSE_MISC_SUM_MASK;
-	if (cause_misc) {
-		mvpp2_cause_error(port->dev, cause_misc);
-
-		/* Clear the cause register */
-		mvpp2_write(port->priv, MVPP2_ISR_MISC_CAUSE_REG, 0);
-		mvpp2_percpu_write(port->priv, cpu,
-				   MVPP2_ISR_RX_TX_CAUSE_REG(port->id),
-				   cause_rx_tx & ~MVPP2_CAUSE_MISC_SUM_MASK);
-	}
-
 	if (port->has_tx_irqs) {
 		cause_tx = cause_rx_tx & MVPP2_CAUSE_TXQ_OCCUP_DESC_ALL_MASK;
 		if (cause_tx) {
+			per_cpu_ptr(port->pcpu,
+				    qv->sw_thread_id)->tx_done_passed =	true;
 			cause_tx >>= MVPP2_CAUSE_TXQ_OCCUP_DESC_ALL_OFFSET;
 			mvpp2_tx_done(port, cause_tx, qv->sw_thread_id);
 		}
@@ -3060,7 +4619,7 @@ static int mvpp2_poll(struct napi_struct *napi, int budget)
 
 	/* Process RX packets */
 	cause_rx = cause_rx_tx &
-		   MVPP2_CAUSE_RXQ_OCCUP_DESC_ALL_MASK(port->priv->hw_version);
+		   MVPP2_CAUSE_RXQ_OCCUP_DESC_ALL_MASK(mvpp21_variant);
 	cause_rx <<= qv->first_rxq;
 	cause_rx |= qv->pending_cause_rx;
 	while (cause_rx && budget > 0) {
@@ -3103,13 +4662,16 @@ static void mvpp22_mode_reconfigure(struct mvpp2_port *port)
 	/* gop reconfiguration */
 	mvpp22_gop_init(port);
 
-	/* Only GOP port 0 has an XLG MAC */
-	if (port->gop_id == 0) {
+	if  (port->phy_interface == PHY_INTERFACE_MODE_INTERNAL)
+		return;
+
+	if (port->has_xlg_mac) {
 		ctrl3 = readl(port->base + MVPP22_XLG_CTRL3_REG);
 		ctrl3 &= ~MVPP22_XLG_CTRL3_MACMODESELECT_MASK;
 
-		if (port->phy_interface == PHY_INTERFACE_MODE_XAUI ||
-		    port->phy_interface == PHY_INTERFACE_MODE_10GKR)
+		if (port->phy_interface == PHY_INTERFACE_MODE_RXAUI ||
+		    port->phy_interface == PHY_INTERFACE_MODE_10GKR ||
+		    port->phy_interface == PHY_INTERFACE_MODE_5GKR)
 			ctrl3 |= MVPP22_XLG_CTRL3_MACMODESELECT_10G;
 		else
 			ctrl3 |= MVPP22_XLG_CTRL3_MACMODESELECT_GMAC;
@@ -3117,9 +4679,10 @@ static void mvpp22_mode_reconfigure(struct mvpp2_port *port)
 		writel(ctrl3, port->base + MVPP22_XLG_CTRL3_REG);
 	}
 
-	if (port->gop_id == 0 &&
-	    (port->phy_interface == PHY_INTERFACE_MODE_XAUI ||
-	     port->phy_interface == PHY_INTERFACE_MODE_10GKR))
+	if (port->has_xlg_mac &&
+	    (port->phy_interface == PHY_INTERFACE_MODE_RXAUI ||
+	     port->phy_interface == PHY_INTERFACE_MODE_10GKR ||
+	     port->phy_interface == PHY_INTERFACE_MODE_5GKR))
 		mvpp2_xlg_max_rx_size_set(port);
 	else
 		mvpp2_gmac_max_rx_size_set(port);
@@ -3132,17 +4695,20 @@ static void mvpp2_start_dev(struct mvpp2_port *port)
 
 	mvpp2_txp_max_tx_size_set(port);
 
+	/* stop_dev() sets Coal to ZERO. Care to restore it now */
+	if (port->has_tx_irqs)
+		mvpp2_tx_pkts_coal_set(port);
+
 	for (i = 0; i < port->nqvecs; i++)
 		napi_enable(&port->qvecs[i].napi);
 
-	/* Enable interrupts on all CPUs */
+	/* Enable interrupts on all threads */
 	mvpp2_interrupts_enable(port);
 
-	if (port->priv->hw_version == MVPP22)
+	if (port->priv->hw_version != MVPP21)
 		mvpp22_mode_reconfigure(port);
 
 	if (port->phylink) {
-		netif_carrier_off(port->dev);
 		phylink_start(port->phylink);
 	} else {
 		/* Phylink isn't used as of now for ACPI, so the MAC has to be
@@ -3157,7 +4723,7 @@ static void mvpp2_start_dev(struct mvpp2_port *port)
 				  NULL);
 	}
 
-	netif_tx_start_all_queues(port->dev);
+	mvpp2_tx_start_all_queues(port->dev);
 }
 
 /* Set hw internals when stopping port */
@@ -3165,7 +4731,22 @@ static void mvpp2_stop_dev(struct mvpp2_port *port)
 {
 	int i;
 
-	/* Disable interrupts on all CPUs */
+	/* Stop-dev called by ifconfig but also by ethtool-features.
+	 * Under active traffic the BM/RX and TX PP2-HW could be non-empty.
+	 * Stop asap new packets ariving from both RX and TX directions,
+	 * but do NOT disable egress free/send-out and interrupts tx-done,
+	 * yeild and msleep this context for gracefull finishing.
+	 * Flush all tx-done by forcing pkts-coal to ZERO
+	 */
+	mvpp2_tx_stop_all_queues(port->dev);
+	mvpp2_ingress_disable(port);
+	if (port->has_tx_irqs)
+		on_each_cpu(mvpp2_tx_pkts_coal_set_zero_pcpu, port, 1);
+
+	msleep(40);
+	mvpp2_egress_disable(port);
+
+	/* Disable interrupts on all threads */
 	mvpp2_interrupts_disable(port);
 
 	for (i = 0; i < port->nqvecs; i++)
@@ -3195,11 +4776,8 @@ static int mvpp2_check_ringparam_valid(struct net_device *dev,
 	else if (!IS_ALIGNED(ring->tx_pending, 32))
 		new_tx_pending = ALIGN(ring->tx_pending, 32);
 
-	/* The Tx ring size cannot be smaller than the minimum number of
-	 * descriptors needed for TSO.
-	 */
-	if (new_tx_pending < MVPP2_MAX_SKB_DESCS)
-		new_tx_pending = ALIGN(MVPP2_MAX_SKB_DESCS, 32);
+	if (new_tx_pending < MVPP2_MIN_TXD(num_present_cpus()))
+		new_tx_pending = MVPP2_MIN_TXD(num_present_cpus());
 
 	if (ring->rx_pending != new_rx_pending) {
 		netdev_info(dev, "illegal Rx ring size value %d, round to %d\n",
@@ -3238,16 +4816,31 @@ static int mvpp2_irqs_init(struct mvpp2_port *port)
 	for (i = 0; i < port->nqvecs; i++) {
 		struct mvpp2_queue_vector *qv = port->qvecs + i;
 
-		if (qv->type == MVPP2_QUEUE_VECTOR_PRIVATE)
+		if (qv->type == MVPP2_QUEUE_VECTOR_PRIVATE) {
+			qv->mask = kzalloc(cpumask_size(), GFP_KERNEL);
+			if (!qv->mask) {
+				err = -ENOMEM;
+				goto err;
+			}
+
 			irq_set_status_flags(qv->irq, IRQ_NO_BALANCING);
+		}
 
 		err = request_irq(qv->irq, mvpp2_isr, 0, port->dev->name, qv);
 		if (err)
 			goto err;
 
-		if (qv->type == MVPP2_QUEUE_VECTOR_PRIVATE)
-			irq_set_affinity_hint(qv->irq,
-					      cpumask_of(qv->sw_thread_id));
+		if (qv->type == MVPP2_QUEUE_VECTOR_PRIVATE) {
+			unsigned int cpu;
+
+			for_each_present_cpu(cpu) {
+				if (mvpp2_cpu_to_thread(port->priv, cpu) ==
+				    qv->sw_thread_id)
+					cpumask_set_cpu(cpu, qv->mask);
+			}
+
+			irq_set_affinity_hint(qv->irq, qv->mask);
+		}
 	}
 
 	return 0;
@@ -3256,6 +4849,8 @@ static int mvpp2_irqs_init(struct mvpp2_port *port)
 		struct mvpp2_queue_vector *qv = port->qvecs + i;
 
 		irq_set_affinity_hint(qv->irq, NULL);
+		kfree(qv->mask);
+		qv->mask = NULL;
 		free_irq(qv->irq, qv);
 	}
 
@@ -3270,35 +4865,45 @@ static void mvpp2_irqs_deinit(struct mvpp2_port *port)
 		struct mvpp2_queue_vector *qv = port->qvecs + i;
 
 		irq_set_affinity_hint(qv->irq, NULL);
+		kfree(qv->mask);
+		qv->mask = NULL;
 		irq_clear_status_flags(qv->irq, IRQ_NO_BALANCING);
 		free_irq(qv->irq, qv);
 	}
 }
 
-static bool mvpp22_rss_is_supported(void)
+static bool mvpp22_rss_is_supported(struct mvpp2_port *port)
 {
-	return queue_mode == MVPP2_QDIST_MULTI_MODE;
+	return (queue_mode == MVPP2_QDIST_MULTI_MODE) &&
+		!(port->flags & MVPP2_F_LOOPBACK) &&
+		!(port->flags & MVPP22_F_IF_MUSDK);
 }
 
 static int mvpp2_open(struct net_device *dev)
 {
 	struct mvpp2_port *port = netdev_priv(dev);
 	struct mvpp2 *priv = port->priv;
+	struct mvpp2_port_pcpu *port_pcpu;
 	unsigned char mac_bcast[ETH_ALEN] = {
 			0xff, 0xff, 0xff, 0xff, 0xff, 0xff };
 	bool valid = false;
-	int err;
+	int err, cpu;
 
 	err = mvpp2_prs_mac_da_accept(port, mac_bcast, true);
 	if (err) {
 		netdev_err(dev, "mvpp2_prs_mac_da_accept BC failed\n");
 		return err;
 	}
+
 	err = mvpp2_prs_mac_da_accept(port, dev->dev_addr, true);
 	if (err) {
 		netdev_err(dev, "mvpp2_prs_mac_da_accept own addr failed\n");
 		return err;
 	}
+
+	if (port->flags & MVPP22_F_IF_MUSDK)
+		goto skip_musdk_parser;
+
 	err = mvpp2_prs_tag_mode_set(port->priv, port->id, MVPP2_TAG_TYPE_MH);
 	if (err) {
 		netdev_err(dev, "mvpp2_prs_tag_mode_set failed\n");
@@ -3310,6 +4915,7 @@ static int mvpp2_open(struct net_device *dev)
 		return err;
 	}
 
+skip_musdk_parser:
 	/* Allocate the Rx/Tx queues */
 	err = mvpp2_setup_rxqs(port);
 	if (err) {
@@ -3323,6 +4929,9 @@ static int mvpp2_open(struct net_device *dev)
 		goto err_cleanup_rxqs;
 	}
 
+	/* Recycle buffer pool for performance optimization */
+	mvpp2_recycle_open();
+
 	err = mvpp2_irqs_init(port);
 	if (err) {
 		netdev_err(port->dev, "cannot init IRQs\n");
@@ -3341,7 +4950,9 @@ static int mvpp2_open(struct net_device *dev)
 		valid = true;
 	}
 
-	if (priv->hw_version == MVPP22 && port->link_irq) {
+	if (priv->hw_version != MVPP21 && port->link_irq &&
+	    (!port->phylink || !port->has_phy)) {
+		mvpp2_txqs_on_tasklet_init(port);
 		err = request_irq(port->link_irq, mvpp2_link_status_isr, 0,
 				  dev->name, port);
 		if (err) {
@@ -3366,10 +4977,19 @@ static int mvpp2_open(struct net_device *dev)
 		goto err_free_irq;
 	}
 
+	/* Init bulk-transmit timer */
+	for_each_present_cpu(cpu) {
+		port_pcpu = per_cpu_ptr(port->pcpu, cpu);
+		port_pcpu->bulk_timer_scheduled = false;
+		port_pcpu->bulk_timer_restart_req = false;
+	}
+
 	/* Unmask interrupts on all CPUs */
 	on_each_cpu(mvpp2_interrupts_unmask, port, 1);
 	mvpp2_shared_interrupt_mask_unmask(port, false);
 
+	mvpp2_tx_done_init_on_open(port, true);
+
 	mvpp2_start_dev(port);
 
 	/* Start hardware statistics gathering */
@@ -3391,11 +5011,12 @@ static int mvpp2_stop(struct net_device *dev)
 {
 	struct mvpp2_port *port = netdev_priv(dev);
 	struct mvpp2_port_pcpu *port_pcpu;
+	unsigned int thread;
 	int cpu;
 
 	mvpp2_stop_dev(port);
 
-	/* Mask interrupts on all CPUs */
+	/* Mask interrupts on all threads */
 	on_each_cpu(mvpp2_interrupts_mask, port, 1);
 	mvpp2_shared_interrupt_mask_unmask(port, true);
 
@@ -3406,19 +5027,29 @@ static int mvpp2_stop(struct net_device *dev)
 
 	mvpp2_irqs_deinit(port);
 	if (!port->has_tx_irqs) {
-		for_each_present_cpu(cpu) {
-			port_pcpu = per_cpu_ptr(port->pcpu, cpu);
+		for (thread = 0; thread < port->priv->nthreads; thread++) {
+			port_pcpu = per_cpu_ptr(port->pcpu, thread);
 
 			hrtimer_cancel(&port_pcpu->tx_done_timer);
-			port_pcpu->timer_scheduled = false;
+			port_pcpu->tx_done_timer_scheduled = false;
 			tasklet_kill(&port_pcpu->tx_done_tasklet);
 		}
 	}
+	/* Cancel bulk tasklet and timer */
+	for_each_present_cpu(cpu) {
+		port_pcpu = per_cpu_ptr(port->pcpu, cpu);
+		hrtimer_cancel(&port_pcpu->bulk_timer);
+		tasklet_kill(&port_pcpu->bulk_tasklet);
+	}
+	mvpp2_tx_done_init_on_open(port, false);
+	mvpp2_txqs_on_tasklet_kill(port);
 	mvpp2_cleanup_rxqs(port);
 	mvpp2_cleanup_txqs(port);
 
 	cancel_delayed_work_sync(&port->stats_work);
 
+	mvpp2_recycle_close();
+
 	return 0;
 }
 
@@ -3505,10 +5136,9 @@ static int mvpp2_change_mtu(struct net_device *dev, int mtu)
 	bool running = netif_running(dev);
 	int err;
 
-	if (!IS_ALIGNED(MVPP2_RX_PKT_SIZE(mtu), 8)) {
-		netdev_info(dev, "illegal MTU value %d, round to %d\n", mtu,
-			    ALIGN(MVPP2_RX_PKT_SIZE(mtu), 8));
-		mtu = ALIGN(MVPP2_RX_PKT_SIZE(mtu), 8);
+	if (port->flags & MVPP22_F_IF_MUSDK) {
+		netdev_err(dev, "MTU cannot be modified in MUSDK mode\n");
+		return -EPERM;
 	}
 
 	if (running)
@@ -3537,7 +5167,7 @@ mvpp2_get_stats64(struct net_device *dev, struct rtnl_link_stats64 *stats)
 {
 	struct mvpp2_port *port = netdev_priv(dev);
 	unsigned int start;
-	int cpu;
+	unsigned int cpu;
 
 	for_each_possible_cpu(cpu) {
 		struct mvpp2_pcpu_stats *cpu_stats;
@@ -3564,6 +5194,7 @@ mvpp2_get_stats64(struct net_device *dev, struct rtnl_link_stats64 *stats)
 	stats->rx_errors	= dev->stats.rx_errors;
 	stats->rx_dropped	= dev->stats.rx_dropped;
 	stats->tx_dropped	= dev->stats.tx_dropped;
+	stats->collisions	= dev->stats.collisions;
 }
 
 static int mvpp2_ioctl(struct net_device *dev, struct ifreq *ifr, int cmd)
@@ -3642,6 +5273,7 @@ static int mvpp2_ethtool_set_coalesce(struct net_device *dev,
 				      struct ethtool_coalesce *c)
 {
 	struct mvpp2_port *port = netdev_priv(dev);
+	struct mvpp2_tx_queue *txq;
 	int queue;
 
 	for (queue = 0; queue < port->nrxqs; queue++) {
@@ -3653,18 +5285,22 @@ static int mvpp2_ethtool_set_coalesce(struct net_device *dev,
 		mvpp2_rx_time_coal_set(port, rxq);
 	}
 
-	if (port->has_tx_irqs) {
+	/* Set TX time and pkts coalescing configuration */
+	if (port->has_tx_irqs)
 		port->tx_time_coal = c->tx_coalesce_usecs;
-		mvpp2_tx_time_coal_set(port);
-	}
 
 	for (queue = 0; queue < port->ntxqs; queue++) {
-		struct mvpp2_tx_queue *txq = port->txqs[queue];
-
+		txq = port->txqs[queue];
 		txq->done_pkts_coal = c->tx_max_coalesced_frames;
+		if (port->has_tx_irqs &&
+		    txq->done_pkts_coal > MVPP2_TXQ_THRESH_MASK)
+			txq->done_pkts_coal = MVPP2_TXQ_THRESH_MASK;
+	}
 
-		if (port->has_tx_irqs)
-			mvpp2_tx_pkts_coal_set(port, txq);
+	if (port->has_tx_irqs) {
+		/* Download configured values into MVPP2 HW */
+		mvpp2_tx_time_coal_set(port);
+		mvpp2_tx_pkts_coal_set(port);
 	}
 
 	return 0;
@@ -3686,12 +5322,16 @@ static int mvpp2_ethtool_get_coalesce(struct net_device *dev,
 static void mvpp2_ethtool_get_drvinfo(struct net_device *dev,
 				      struct ethtool_drvinfo *drvinfo)
 {
+	struct mvpp2_port *port = netdev_priv(dev);
+
 	strlcpy(drvinfo->driver, MVPP2_DRIVER_NAME,
 		sizeof(drvinfo->driver));
 	strlcpy(drvinfo->version, MVPP2_DRIVER_VERSION,
 		sizeof(drvinfo->version));
 	strlcpy(drvinfo->bus_info, dev_name(&dev->dev),
 		sizeof(drvinfo->bus_info));
+	drvinfo->n_priv_flags = (port->priv->hw_version == MVPP21) ?
+			0 : ARRAY_SIZE(mvpp22_priv_flags_strings);
 }
 
 static void mvpp2_ethtool_get_ringparam(struct net_device *dev,
@@ -3717,6 +5357,15 @@ static int mvpp2_ethtool_set_ringparam(struct net_device *dev,
 	if (err)
 		return err;
 
+	if (ring->rx_pending < MSS_THRESHOLD_START && port->tx_fc) {
+		netdev_warn(dev, "TX FC disabled. Ring size is less than %d\n",
+			    MSS_THRESHOLD_START);
+		port->tx_fc = false;
+		mvpp2_rxq_disable_fc(port);
+		if (port->priv->hw_version == MVPP23)
+			mvpp23_rx_fifo_fc_en(port->priv, port->id, false);
+	}
+
 	if (!netif_running(dev)) {
 		port->rx_ring_size = ring->rx_pending;
 		port->tx_ring_size = ring->tx_pending;
@@ -3776,11 +5425,52 @@ static void mvpp2_ethtool_get_pause_param(struct net_device *dev,
 	phylink_ethtool_get_pauseparam(port->phylink, pause);
 }
 
+static void mvpp2_reconfigure_fc(struct mvpp2_port *port)
+{
+	struct mvpp2_bm_pool **pools_pcpu = port->priv->pools_pcpu;
+	int cpu;
+
+	if (recycle) {
+		for_each_present_cpu(cpu)
+			mvpp2_bm_pool_update_fc(port, pools_pcpu[cpu],
+						port->tx_fc);
+		if (port->pool_long->type == MVPP2_BM_JUMBO)
+			mvpp2_bm_pool_update_fc(port,
+						port->pool_long, port->tx_fc);
+		else
+			mvpp2_bm_pool_update_fc(port,
+						port->pool_short, port->tx_fc);
+	} else {
+		mvpp2_bm_pool_update_fc(port, port->pool_long, port->tx_fc);
+		mvpp2_bm_pool_update_fc(port, port->pool_short, port->tx_fc);
+	}
+	if (port->priv->hw_version == MVPP23)
+		mvpp23_rx_fifo_fc_en(port->priv, port->id, port->tx_fc);
+}
+
 static int mvpp2_ethtool_set_pause_param(struct net_device *dev,
 					 struct ethtool_pauseparam *pause)
 {
 	struct mvpp2_port *port = netdev_priv(dev);
 
+	if (pause->tx_pause && port->priv->global_tx_fc &&
+	    bm_underrun_protect) {
+		if (port->rx_ring_size < MSS_THRESHOLD_START) {
+			netdev_err(dev, "TX FC cannot be supported.");
+			netdev_err(dev, "Ring size is less than %d\n",
+				   MSS_THRESHOLD_START);
+			return -EINVAL;
+		}
+
+		port->tx_fc = true;
+		mvpp2_rxq_enable_fc(port);
+		mvpp2_reconfigure_fc(port);
+	} else if (port->priv->global_tx_fc) {
+		port->tx_fc = false;
+		mvpp2_rxq_disable_fc(port);
+		mvpp2_reconfigure_fc(port);
+	}
+
 	if (!port->phylink)
 		return -ENOTSUPP;
 
@@ -3815,7 +5505,7 @@ static int mvpp2_ethtool_get_rxnfc(struct net_device *dev,
 	struct mvpp2_port *port = netdev_priv(dev);
 	int ret = 0;
 
-	if (!mvpp22_rss_is_supported())
+	if (!mvpp22_rss_is_supported(port))
 		return -EOPNOTSUPP;
 
 	switch (info->cmd) {
@@ -3838,7 +5528,7 @@ static int mvpp2_ethtool_set_rxnfc(struct net_device *dev,
 	struct mvpp2_port *port = netdev_priv(dev);
 	int ret = 0;
 
-	if (!mvpp22_rss_is_supported())
+	if (!mvpp22_rss_is_supported(port))
 		return -EOPNOTSUPP;
 
 	switch (info->cmd) {
@@ -3853,7 +5543,9 @@ static int mvpp2_ethtool_set_rxnfc(struct net_device *dev,
 
 static u32 mvpp2_ethtool_get_rxfh_indir_size(struct net_device *dev)
 {
-	return mvpp22_rss_is_supported() ? MVPP22_RSS_TABLE_ENTRIES : 0;
+	struct mvpp2_port *port = netdev_priv(dev);
+
+	return mvpp22_rss_is_supported(port) ? MVPP22_RSS_TABLE_ENTRIES : 0;
 }
 
 static int mvpp2_ethtool_get_rxfh(struct net_device *dev, u32 *indir, u8 *key,
@@ -3861,7 +5553,7 @@ static int mvpp2_ethtool_get_rxfh(struct net_device *dev, u32 *indir, u8 *key,
 {
 	struct mvpp2_port *port = netdev_priv(dev);
 
-	if (!mvpp22_rss_is_supported())
+	if (!mvpp22_rss_is_supported(port))
 		return -EOPNOTSUPP;
 
 	if (indir)
@@ -3879,7 +5571,7 @@ static int mvpp2_ethtool_set_rxfh(struct net_device *dev, const u32 *indir,
 {
 	struct mvpp2_port *port = netdev_priv(dev);
 
-	if (!mvpp22_rss_is_supported())
+	if (!mvpp22_rss_is_supported(port))
 		return -EOPNOTSUPP;
 
 	if (hfunc != ETH_RSS_HASH_NO_CHANGE && hfunc != ETH_RSS_HASH_CRC32)
@@ -3897,6 +5589,130 @@ static int mvpp2_ethtool_set_rxfh(struct net_device *dev, const u32 *indir,
 	return 0;
 }
 
+static u32 mvpp22_get_priv_flags(struct net_device *dev)
+{
+	struct mvpp2_port *port = netdev_priv(dev);
+	u32 priv_flags = 0;
+
+	if (port->flags & MVPP22_F_IF_MUSDK)
+		priv_flags |= MVPP22_F_IF_MUSDK_PRIV;
+	return priv_flags;
+}
+
+static int mvpp2_port_musdk_cfg(struct net_device *dev, bool ena)
+{
+	struct mvpp2_port_us_cfg {
+		unsigned int nqvecs;
+		unsigned int nrxqs;
+		unsigned int ntxqs;
+		int mtu;
+		bool rxhash_en;
+		u8 rss_en;
+	} *us;
+
+	struct mvpp2_port *port = netdev_priv(dev);
+	int rxq;
+
+	if (ena) {
+		/* Disable Queues and IntVec allocations for MUSDK,
+		 * but save original values.
+		 */
+		us = kzalloc(sizeof(*us), GFP_KERNEL);
+		if (!us)
+			return -ENOMEM;
+		port->us_cfg = (void *)us;
+		us->nqvecs = port->nqvecs;
+		us->nrxqs  = port->nrxqs;
+		us->ntxqs = port->ntxqs;
+		us->mtu = dev->mtu;
+		us->rxhash_en = !!(dev->hw_features & NETIF_F_RXHASH);
+
+		port->nqvecs = 0;
+		port->nrxqs  = 0;
+		port->ntxqs  = 0;
+		if (us->rxhash_en) {
+			dev->hw_features &= ~NETIF_F_RXHASH;
+			netdev_update_features(dev);
+		}
+	} else {
+		/* Back to Kernel mode */
+		us = port->us_cfg;
+		port->nqvecs = us->nqvecs;
+		port->nrxqs  = us->nrxqs;
+		port->ntxqs  = us->ntxqs;
+		if (us->rxhash_en) {
+			dev->hw_features |= NETIF_F_RXHASH;
+			netdev_update_features(dev);
+		}
+		kfree(us);
+		port->us_cfg = NULL;
+
+		/* Restore RxQ/pool association */
+		for (rxq = 0; rxq < port->nrxqs; rxq++) {
+			mvpp2_rxq_long_pool_set(port, rxq, port->pool_long->id);
+			mvpp2_rxq_short_pool_set(port, rxq,
+						 port->pool_short->id);
+		}
+	}
+	return 0;
+}
+
+static int mvpp2_port_musdk_set(struct net_device *dev, bool ena)
+{
+	struct mvpp2_port *port = netdev_priv(dev);
+	bool running = netif_running(dev);
+	int err;
+
+	/* This procedure is called by ethtool change or by Module-remove.
+	 * For "remove" do anything only if we are in musdk-mode
+	 * and toggling back to Kernel-mode is really required.
+	 */
+	if (!ena && !port->us_cfg)
+		return 0;
+
+	if (running)
+		mvpp2_stop(dev);
+
+	if (ena) {
+		err = mvpp2_port_musdk_cfg(dev, ena);
+		port->flags |= MVPP22_F_IF_MUSDK;
+	} else {
+		err = mvpp2_port_musdk_cfg(dev, ena);
+		port->flags &= ~MVPP22_F_IF_MUSDK;
+	}
+
+	if (err) {
+		netdev_err(dev, "musdk set=%d: error=%d\n", ena, err);
+		if (err)
+			return err;
+		/* print Error message but continue */
+	}
+
+	if (running)
+		mvpp2_open(dev);
+
+	return 0;
+}
+
+static int mvpp22_set_priv_flags(struct net_device *dev, u32 priv_flags)
+{
+	struct mvpp2_port *port = netdev_priv(dev);
+	bool f_old, f_new;
+	int err = 0;
+
+	if (recycle && (priv_flags & MVPP22_F_IF_MUSDK_PRIV)) {
+		WARN(1, "Fail to enable MUSDK. KS recycling feature enabled.");
+		return -EOPNOTSUPP;
+	}
+
+	f_old = port->flags & MVPP22_F_IF_MUSDK;
+	f_new = priv_flags & MVPP22_F_IF_MUSDK_PRIV;
+	if (f_old != f_new)
+		err = mvpp2_port_musdk_set(dev, f_new);
+
+	return err;
+}
+
 /* Device ops */
 
 static const struct net_device_ops mvpp2_netdev_ops = {
@@ -3933,7 +5749,8 @@ static const struct ethtool_ops mvpp2_eth_tool_ops = {
 	.get_rxfh_indir_size	= mvpp2_ethtool_get_rxfh_indir_size,
 	.get_rxfh		= mvpp2_ethtool_get_rxfh,
 	.set_rxfh		= mvpp2_ethtool_set_rxfh,
-
+	.get_priv_flags		= mvpp22_get_priv_flags,
+	.set_priv_flags		= mvpp22_set_priv_flags,
 };
 
 /* Used for PPv2.1, or PPv2.2 with the old Device Tree binding that
@@ -3964,12 +5781,18 @@ static int mvpp2_simple_queue_vectors_init(struct mvpp2_port *port,
 static int mvpp2_multi_queue_vectors_init(struct mvpp2_port *port,
 					  struct device_node *port_node)
 {
+	struct mvpp2 *priv = port->priv;
 	struct mvpp2_queue_vector *v;
 	int i, ret;
 
-	port->nqvecs = num_possible_cpus();
-	if (queue_mode == MVPP2_QDIST_SINGLE_MODE)
-		port->nqvecs += 1;
+	switch (queue_mode) {
+	case MVPP2_QDIST_SINGLE_MODE:
+		port->nqvecs = priv->nthreads + 1;
+		break;
+	case MVPP2_QDIST_MULTI_MODE:
+		port->nqvecs = priv->nthreads;
+		break;
+	}
 
 	for (i = 0; i < port->nqvecs; i++) {
 		char irqname[16];
@@ -3981,17 +5804,22 @@ static int mvpp2_multi_queue_vectors_init(struct mvpp2_port *port,
 		v->sw_thread_id = i;
 		v->sw_thread_mask = BIT(i);
 
-		snprintf(irqname, sizeof(irqname), "tx-cpu%d", i);
+		if (port->flags & MVPP2_F_DT_COMPAT)
+			snprintf(irqname, sizeof(irqname), "tx-cpu%d", i);
+		else
+			snprintf(irqname, sizeof(irqname), "hif%d", i);
 
 		if (queue_mode == MVPP2_QDIST_MULTI_MODE) {
-			v->first_rxq = i * MVPP2_DEFAULT_RXQ;
-			v->nrxqs = MVPP2_DEFAULT_RXQ;
+			v->first_rxq = i;
+			v->nrxqs = 1;
 		} else if (queue_mode == MVPP2_QDIST_SINGLE_MODE &&
 			   i == (port->nqvecs - 1)) {
 			v->first_rxq = 0;
 			v->nrxqs = port->nrxqs;
 			v->type = MVPP2_QUEUE_VECTOR_SHARED;
-			strncpy(irqname, "rx-shared", sizeof(irqname));
+
+			if (port->flags & MVPP2_F_DT_COMPAT)
+				strncpy(irqname, "rx-shared", sizeof(irqname));
 		}
 
 		if (port_node)
@@ -4045,7 +5873,7 @@ static void mvpp2_rx_irqs_setup(struct mvpp2_port *port)
 		return;
 	}
 
-	/* Handle the more complicated PPv2.2 case */
+	/* Handle the more complicated PPv2.2 and PPv2.3 case */
 	for (i = 0; i < port->nqvecs; i++) {
 		struct mvpp2_queue_vector *qv = port->qvecs + i;
 
@@ -4068,15 +5896,15 @@ static int mvpp2_port_init(struct mvpp2_port *port)
 	struct device *dev = port->dev->dev.parent;
 	struct mvpp2 *priv = port->priv;
 	struct mvpp2_txq_pcpu *txq_pcpu;
-	int queue, cpu, err;
+	unsigned int thread;
+	int queue, err;
 
 	/* Checks for hardware constraints */
 	if (port->first_rxq + port->nrxqs >
 	    MVPP2_MAX_PORTS * priv->max_port_rxqs)
 		return -EINVAL;
 
-	if (port->nrxqs % MVPP2_DEFAULT_RXQ ||
-	    port->nrxqs > priv->max_port_rxqs || port->ntxqs > MVPP2_MAX_TXQ)
+	if (port->nrxqs > priv->max_port_rxqs || port->ntxqs > MVPP2_MAX_TXQ)
 		return -EINVAL;
 
 	/* Disable port */
@@ -4112,9 +5940,9 @@ static int mvpp2_port_init(struct mvpp2_port *port)
 		txq->id = queue_phy_id;
 		txq->log_id = queue;
 		txq->done_pkts_coal = MVPP2_TXDONE_COAL_PKTS_THRESH;
-		for_each_present_cpu(cpu) {
-			txq_pcpu = per_cpu_ptr(txq->pcpu, cpu);
-			txq_pcpu->cpu = cpu;
+		for (thread = 0; thread < priv->nthreads; thread++) {
+			txq_pcpu = per_cpu_ptr(txq->pcpu, thread);
+			txq_pcpu->thread = thread;
 		}
 
 		port->txqs[queue] = txq;
@@ -4140,7 +5968,7 @@ static int mvpp2_port_init(struct mvpp2_port *port)
 		/* Map this Rx queue to a physical queue */
 		rxq->id = port->first_rxq + queue;
 		rxq->port = port->id;
-		rxq->logic_rxq = queue;
+		rxq->logic_rxq = (u8)queue;
 
 		port->rxqs[queue] = rxq;
 	}
@@ -4165,14 +5993,17 @@ static int mvpp2_port_init(struct mvpp2_port *port)
 	mvpp2_cls_oversize_rxq_set(port);
 	mvpp2_cls_port_config(port);
 
-	if (mvpp22_rss_is_supported())
+	if (mvpp22_rss_is_supported(port))
 		mvpp22_rss_port_init(port);
 
 	/* Provide an initial Rx packet size */
 	port->pkt_size = MVPP2_RX_PKT_SIZE(port->dev->mtu);
 
 	/* Initialize pools for swf */
-	err = mvpp2_swf_bm_pool_init(port);
+	if (recycle)
+		err = mvpp2_swf_bm_pool_pcpu_init(port);
+	else
+		err = mvpp2_swf_bm_pool_init(port);
 	if (err)
 		goto err_free_percpu;
 
@@ -4187,24 +6018,51 @@ static int mvpp2_port_init(struct mvpp2_port *port)
 	return err;
 }
 
-/* Checks if the port DT description has the TX interrupts
- * described. On PPv2.1, there are no such interrupts. On PPv2.2,
- * there are available, but we need to keep support for old DTs.
+static bool mvpp22_port_has_legacy_tx_irqs(struct device_node *port_node,
+					   unsigned long *flags)
+{
+	char *irqs[5] = { "rx-shared", "tx-cpu0", "tx-cpu1", "tx-cpu2",
+			  "tx-cpu3" };
+	int i;
+
+	for (i = 0; i < 5; i++)
+		if (of_property_match_string(port_node, "interrupt-names",
+					     irqs[i]) < 0)
+			return false;
+
+	*flags |= MVPP2_F_DT_COMPAT;
+	return true;
+}
+
+/* Checks if the port dt description has the required Tx interrupts:
+ * - PPv2.1: there are no such interrupts.
+ * - PPv2.2 and PPv2.3:
+ *   - The old DTs have: "rx-shared", "tx-cpuX" with X in [0...3]
+ *   - The new ones have: "hifX" with X in [0..8]
+ *
+ * All those variants are supported to keep the backward compatibility.
  */
-static bool mvpp2_port_has_tx_irqs(struct mvpp2 *priv,
-				   struct device_node *port_node)
+static bool mvpp2_port_has_irqs(struct mvpp2 *priv,
+				struct device_node *port_node,
+				unsigned long *flags)
 {
-	char *irqs[5] = { "rx-shared", "tx-cpu0", "tx-cpu1",
-			  "tx-cpu2", "tx-cpu3" };
-	int ret, i;
+	char name[5];
+	int i;
+
+	/* ACPI */
+	if (!port_node)
+		return true;
 
 	if (priv->hw_version == MVPP21)
 		return false;
 
-	for (i = 0; i < 5; i++) {
-		ret = of_property_match_string(port_node, "interrupt-names",
-					       irqs[i]);
-		if (ret < 0)
+	if (mvpp22_port_has_legacy_tx_irqs(port_node, flags))
+		return true;
+
+	for (i = 0; i < MVPP2_MAX_THREADS; i++) {
+		snprintf(name, 5, "hif%d", i);
+		if (of_property_match_string(port_node, "interrupt-names",
+					     name) < 0)
 			return false;
 	}
 
@@ -4248,15 +6106,25 @@ static void mvpp2_phylink_validate(struct net_device *dev,
 	/* Invalid combinations */
 	switch (state->interface) {
 	case PHY_INTERFACE_MODE_10GKR:
-	case PHY_INTERFACE_MODE_XAUI:
+	case PHY_INTERFACE_MODE_5GKR:
+	case PHY_INTERFACE_MODE_INTERNAL:
+		if (!port->has_xlg_mac)
+			goto empty_set;
+		break;
+	case PHY_INTERFACE_MODE_RXAUI:
 		if (port->gop_id != 0)
 			goto empty_set;
 		break;
+	case PHY_INTERFACE_MODE_MII:
+		if (port->gop_id == 2)
+			goto empty_set;
+		/* Fall-through */
+	case PHY_INTERFACE_MODE_GMII:
 	case PHY_INTERFACE_MODE_RGMII:
 	case PHY_INTERFACE_MODE_RGMII_ID:
 	case PHY_INTERFACE_MODE_RGMII_RXID:
 	case PHY_INTERFACE_MODE_RGMII_TXID:
-		if (port->priv->hw_version == MVPP22 && port->gop_id == 0)
+		if (port->priv->hw_version != MVPP21 && port->gop_id == 0)
 			goto empty_set;
 		break;
 	default:
@@ -4270,9 +6138,10 @@ static void mvpp2_phylink_validate(struct net_device *dev,
 
 	switch (state->interface) {
 	case PHY_INTERFACE_MODE_10GKR:
-	case PHY_INTERFACE_MODE_XAUI:
+	case PHY_INTERFACE_MODE_RXAUI:
 	case PHY_INTERFACE_MODE_NA:
-		if (port->gop_id == 0) {
+	case PHY_INTERFACE_MODE_INTERNAL:
+		if (port->has_xlg_mac) {
 			phylink_set(mask, 10000baseT_Full);
 			phylink_set(mask, 10000baseCR_Full);
 			phylink_set(mask, 10000baseSR_Full);
@@ -4282,19 +6151,29 @@ static void mvpp2_phylink_validate(struct net_device *dev,
 			phylink_set(mask, 10000baseKR_Full);
 		}
 		/* Fall-through */
+	case PHY_INTERFACE_MODE_5GKR:
+		if (port->has_xlg_mac)
+			phylink_set(mask, 5000baseT_Full);
+		/* Fall-through */
+	case PHY_INTERFACE_MODE_2500BASET:
+		phylink_set(mask, 2500baseT_Full);
+		/* Fall-through */
+	case PHY_INTERFACE_MODE_GMII:
 	case PHY_INTERFACE_MODE_RGMII:
 	case PHY_INTERFACE_MODE_RGMII_ID:
 	case PHY_INTERFACE_MODE_RGMII_RXID:
 	case PHY_INTERFACE_MODE_RGMII_TXID:
 	case PHY_INTERFACE_MODE_SGMII:
+		phylink_set(mask, 1000baseT_Full);
+		/* Fall-through */
+	case PHY_INTERFACE_MODE_MII:
 		phylink_set(mask, 10baseT_Half);
 		phylink_set(mask, 10baseT_Full);
 		phylink_set(mask, 100baseT_Half);
 		phylink_set(mask, 100baseT_Full);
-		/* Fall-through */
+		break;
 	case PHY_INTERFACE_MODE_1000BASEX:
 	case PHY_INTERFACE_MODE_2500BASEX:
-		phylink_set(mask, 1000baseT_Full);
 		phylink_set(mask, 1000baseX_Full);
 		phylink_set(mask, 2500baseX_Full);
 		break;
@@ -4316,7 +6195,11 @@ static void mvpp22_xlg_link_state(struct mvpp2_port *port,
 {
 	u32 val;
 
-	state->speed = SPEED_10000;
+	if (state->interface == PHY_INTERFACE_MODE_5GKR)
+		state->speed = SPEED_5000;
+	else
+		state->speed = SPEED_10000;
+
 	state->duplex = 1;
 	state->an_complete = 1;
 
@@ -4347,6 +6230,7 @@ static void mvpp2_gmac_link_state(struct mvpp2_port *port,
 		state->speed = SPEED_1000;
 		break;
 	case PHY_INTERFACE_MODE_2500BASEX:
+	case PHY_INTERFACE_MODE_2500BASET:
 		state->speed = SPEED_2500;
 		break;
 	default:
@@ -4370,7 +6254,7 @@ static int mvpp2_phylink_mac_link_state(struct net_device *dev,
 {
 	struct mvpp2_port *port = netdev_priv(dev);
 
-	if (port->priv->hw_version == MVPP22 && port->gop_id == 0) {
+	if (port->has_xlg_mac) {
 		u32 mode = readl(port->base + MVPP22_XLG_CTRL3_REG);
 		mode &= MVPP22_XLG_CTRL3_MACMODESELECT_MASK;
 
@@ -4387,17 +6271,12 @@ static int mvpp2_phylink_mac_link_state(struct net_device *dev,
 static void mvpp2_mac_an_restart(struct net_device *dev)
 {
 	struct mvpp2_port *port = netdev_priv(dev);
-	u32 val;
-
-	if (port->phy_interface != PHY_INTERFACE_MODE_SGMII)
-		return;
+	u32 val = readl(port->base + MVPP2_GMAC_AUTONEG_CONFIG);
 
-	val = readl(port->base + MVPP2_GMAC_AUTONEG_CONFIG);
-	/* The RESTART_AN bit is cleared by the h/w after restarting the AN
-	 * process.
-	 */
-	val |= MVPP2_GMAC_IN_BAND_RESTART_AN | MVPP2_GMAC_IN_BAND_AUTONEG;
-	writel(val, port->base + MVPP2_GMAC_AUTONEG_CONFIG);
+	writel(val | MVPP2_GMAC_IN_BAND_RESTART_AN,
+	       port->base + MVPP2_GMAC_AUTONEG_CONFIG);
+	writel(val & ~MVPP2_GMAC_IN_BAND_RESTART_AN,
+	       port->base + MVPP2_GMAC_AUTONEG_CONFIG);
 }
 
 static void mvpp2_xlg_config(struct mvpp2_port *port, unsigned int mode,
@@ -4408,14 +6287,22 @@ static void mvpp2_xlg_config(struct mvpp2_port *port, unsigned int mode,
 	ctrl0 = readl(port->base + MVPP22_XLG_CTRL0_REG);
 	ctrl4 = readl(port->base + MVPP22_XLG_CTRL4_REG);
 
+	ctrl0 |= MVPP22_XLG_CTRL0_MAC_RESET_DIS;
+
 	if (state->pause & MLO_PAUSE_TX)
 		ctrl0 |= MVPP22_XLG_CTRL0_TX_FLOW_CTRL_EN;
+	else
+		ctrl0 &= ~MVPP22_XLG_CTRL0_TX_FLOW_CTRL_EN;
+
 	if (state->pause & MLO_PAUSE_RX)
 		ctrl0 |= MVPP22_XLG_CTRL0_RX_FLOW_CTRL_EN;
+	else
+		ctrl0 &= ~MVPP22_XLG_CTRL0_RX_FLOW_CTRL_EN;
 
-	ctrl4 &= ~(MVPP22_XLG_CTRL4_MACMODSELECT_GMAC |
-		   MVPP22_XLG_CTRL4_EN_IDLE_CHECK);
-	ctrl4 |= MVPP22_XLG_CTRL4_FWD_FC | MVPP22_XLG_CTRL4_FWD_PFC;
+	ctrl4 &= ~MVPP22_XLG_CTRL4_MACMODSELECT_GMAC;
+
+	if (state->interface == PHY_INTERFACE_MODE_RXAUI)
+		ctrl4 |= MVPP22_XLG_CTRL4_USE_XPCS;
 
 	writel(ctrl0, port->base + MVPP22_XLG_CTRL0_REG);
 	writel(ctrl4, port->base + MVPP22_XLG_CTRL4_REG);
@@ -4424,88 +6311,134 @@ static void mvpp2_xlg_config(struct mvpp2_port *port, unsigned int mode,
 static void mvpp2_gmac_config(struct mvpp2_port *port, unsigned int mode,
 			      const struct phylink_link_state *state)
 {
-	u32 an, ctrl0, ctrl2, ctrl4;
-	u32 old_ctrl2;
-
-	an = readl(port->base + MVPP2_GMAC_AUTONEG_CONFIG);
-	ctrl0 = readl(port->base + MVPP2_GMAC_CTRL_0_REG);
-	ctrl2 = readl(port->base + MVPP2_GMAC_CTRL_2_REG);
-	ctrl4 = readl(port->base + MVPP22_GMAC_CTRL_4_REG);
+	u32 old_an, an;
+	u32 old_ctrl0, ctrl0;
+	u32 old_ctrl2, ctrl2;
+	u32 old_ctrl4, ctrl4;
 
-	old_ctrl2 = ctrl2;
-
-	/* Force link down */
-	an &= ~MVPP2_GMAC_FORCE_LINK_PASS;
-	an |= MVPP2_GMAC_FORCE_LINK_DOWN;
-	writel(an, port->base + MVPP2_GMAC_AUTONEG_CONFIG);
-
-	/* Set the GMAC in a reset state */
-	ctrl2 |= MVPP2_GMAC_PORT_RESET_MASK;
-	writel(ctrl2, port->base + MVPP2_GMAC_CTRL_2_REG);
+	old_an = an = readl(port->base + MVPP2_GMAC_AUTONEG_CONFIG);
+	old_ctrl0 = ctrl0 = readl(port->base + MVPP2_GMAC_CTRL_0_REG);
+	old_ctrl2 = ctrl2 = readl(port->base + MVPP2_GMAC_CTRL_2_REG);
+	old_ctrl4 = ctrl4 = readl(port->base + MVPP22_GMAC_CTRL_4_REG);
 
 	an &= ~(MVPP2_GMAC_CONFIG_MII_SPEED | MVPP2_GMAC_CONFIG_GMII_SPEED |
 		MVPP2_GMAC_AN_SPEED_EN | MVPP2_GMAC_FC_ADV_EN |
 		MVPP2_GMAC_FC_ADV_ASM_EN | MVPP2_GMAC_FLOW_CTRL_AUTONEG |
 		MVPP2_GMAC_CONFIG_FULL_DUPLEX | MVPP2_GMAC_AN_DUPLEX_EN |
-		MVPP2_GMAC_FORCE_LINK_DOWN);
+		MVPP2_GMAC_IN_BAND_AUTONEG | MVPP2_GMAC_IN_BAND_AUTONEG_BYPASS);
 	ctrl0 &= ~MVPP2_GMAC_PORT_TYPE_MASK;
-	ctrl2 &= ~(MVPP2_GMAC_PORT_RESET_MASK | MVPP2_GMAC_PCS_ENABLE_MASK);
-
-	if (state->interface == PHY_INTERFACE_MODE_1000BASEX ||
-	    state->interface == PHY_INTERFACE_MODE_2500BASEX) {
-		/* 1000BaseX and 2500BaseX ports cannot negotiate speed nor can
-		 * they negotiate duplex: they are always operating with a fixed
-		 * speed of 1000/2500Mbps in full duplex, so force 1000/2500
-		 * speed and full duplex here.
-		 */
-		ctrl0 |= MVPP2_GMAC_PORT_TYPE_MASK;
-		an |= MVPP2_GMAC_CONFIG_GMII_SPEED |
-		      MVPP2_GMAC_CONFIG_FULL_DUPLEX;
-	} else if (!phy_interface_mode_is_rgmii(state->interface)) {
-		an |= MVPP2_GMAC_AN_SPEED_EN | MVPP2_GMAC_FLOW_CTRL_AUTONEG;
+	ctrl2 &= ~(MVPP2_GMAC_INBAND_AN_MASK | MVPP2_GMAC_PORT_RESET_MASK |
+		   MVPP2_GMAC_PCS_ENABLE_MASK);
+	ctrl4 &= ~(MVPP22_CTRL4_RX_FC_EN | MVPP22_CTRL4_TX_FC_EN);
+
+	/* Configure port type */
+	if (phy_interface_mode_is_8023z(state->interface)) {
+		ctrl2 |= MVPP2_GMAC_PCS_ENABLE_MASK;
+		ctrl4 &= ~MVPP22_CTRL4_EXT_PIN_GMII_SEL;
+		ctrl4 |= MVPP22_CTRL4_SYNC_BYPASS_DIS |
+			 MVPP22_CTRL4_DP_CLK_SEL |
+			 MVPP22_CTRL4_QSGMII_BYPASS_ACTIVE;
+	} else if (state->interface == PHY_INTERFACE_MODE_SGMII ||
+		   state->interface == PHY_INTERFACE_MODE_2500BASET) {
+		ctrl2 |= MVPP2_GMAC_PCS_ENABLE_MASK | MVPP2_GMAC_INBAND_AN_MASK;
+		ctrl4 &= ~MVPP22_CTRL4_EXT_PIN_GMII_SEL;
+		ctrl4 |= MVPP22_CTRL4_SYNC_BYPASS_DIS |
+			 MVPP22_CTRL4_DP_CLK_SEL |
+			 MVPP22_CTRL4_QSGMII_BYPASS_ACTIVE;
+	} else if ((phy_interface_mode_is_rgmii(state->interface)) ||
+		   (state->interface == PHY_INTERFACE_MODE_MII)) {
+		ctrl4 &= ~MVPP22_CTRL4_DP_CLK_SEL;
+		ctrl4 |= MVPP22_CTRL4_EXT_PIN_GMII_SEL |
+			 MVPP22_CTRL4_SYNC_BYPASS_DIS |
+			 MVPP22_CTRL4_QSGMII_BYPASS_ACTIVE;
 	}
 
-	if (state->duplex)
-		an |= MVPP2_GMAC_CONFIG_FULL_DUPLEX;
+	/* Configure advertisement bits */
 	if (phylink_test(state->advertising, Pause))
 		an |= MVPP2_GMAC_FC_ADV_EN;
 	if (phylink_test(state->advertising, Asym_Pause))
 		an |= MVPP2_GMAC_FC_ADV_ASM_EN;
 
-	if (state->interface == PHY_INTERFACE_MODE_SGMII ||
-	    state->interface == PHY_INTERFACE_MODE_1000BASEX ||
-	    state->interface == PHY_INTERFACE_MODE_2500BASEX) {
-		an |= MVPP2_GMAC_IN_BAND_AUTONEG;
-		ctrl2 |= MVPP2_GMAC_INBAND_AN_MASK | MVPP2_GMAC_PCS_ENABLE_MASK;
-
-		ctrl4 &= ~(MVPP22_CTRL4_EXT_PIN_GMII_SEL |
-			   MVPP22_CTRL4_RX_FC_EN | MVPP22_CTRL4_TX_FC_EN);
-		ctrl4 |= MVPP22_CTRL4_SYNC_BYPASS_DIS |
-			 MVPP22_CTRL4_DP_CLK_SEL |
-			 MVPP22_CTRL4_QSGMII_BYPASS_ACTIVE;
+	ctrl4 &= ~(MVPP22_CTRL4_RX_FC_EN | MVPP22_CTRL4_TX_FC_EN);
 
-		if (state->pause & MLO_PAUSE_TX)
-			ctrl4 |= MVPP22_CTRL4_TX_FC_EN;
-		if (state->pause & MLO_PAUSE_RX)
-			ctrl4 |= MVPP22_CTRL4_RX_FC_EN;
-	} else if (phy_interface_mode_is_rgmii(state->interface)) {
-		an |= MVPP2_GMAC_IN_BAND_AUTONEG_BYPASS;
+	/* Configure negotiation style */
+	if (!phylink_autoneg_inband(mode)) {
+		/* Phy or fixed speed - no in-band AN */
+		if (state->duplex)
+			an |= MVPP2_GMAC_CONFIG_FULL_DUPLEX;
 
-		if (state->speed == SPEED_1000)
+		if (state->speed == SPEED_1000 || state->speed == SPEED_2500)
 			an |= MVPP2_GMAC_CONFIG_GMII_SPEED;
 		else if (state->speed == SPEED_100)
 			an |= MVPP2_GMAC_CONFIG_MII_SPEED;
 
-		ctrl4 &= ~MVPP22_CTRL4_DP_CLK_SEL;
-		ctrl4 |= MVPP22_CTRL4_EXT_PIN_GMII_SEL |
-			 MVPP22_CTRL4_SYNC_BYPASS_DIS |
-			 MVPP22_CTRL4_QSGMII_BYPASS_ACTIVE;
+	} else if (state->interface == PHY_INTERFACE_MODE_SGMII) {
+		/* SGMII in-band mode receives the speed and duplex from
+		 * the PHY. Flow control information is not received.
+		 */
+		an &= ~(MVPP2_GMAC_FORCE_LINK_DOWN |
+			MVPP2_GMAC_FORCE_LINK_PASS);
+		an |= MVPP2_GMAC_IN_BAND_AUTONEG |
+		      MVPP2_GMAC_AN_SPEED_EN |
+		      MVPP2_GMAC_AN_DUPLEX_EN;
+
+	} else if (phy_interface_mode_is_8023z(state->interface) ||
+		   state->interface == PHY_INTERFACE_MODE_2500BASET) {
+		/* 1000BaseX and 2500BaseX ports cannot negotiate speed nor can
+		 * they negotiate duplex: they are always operating with a fixed
+		 * speed of 1000/2500Mbps in full duplex, so force 1000/2500
+		 * speed and full duplex here.
+		 */
+		ctrl0 |= MVPP2_GMAC_PORT_TYPE_MASK;
+		an &= ~(MVPP2_GMAC_FORCE_LINK_DOWN |
+			MVPP2_GMAC_FORCE_LINK_PASS);
+		an |= MVPP2_GMAC_IN_BAND_AUTONEG |
+		      MVPP2_GMAC_IN_BAND_AUTONEG_BYPASS |
+		      MVPP2_GMAC_CONFIG_GMII_SPEED |
+		      MVPP2_GMAC_CONFIG_FULL_DUPLEX;
+
+		if (state->pause & MLO_PAUSE_AN && state->an_enabled)
+			an |= MVPP2_GMAC_FLOW_CTRL_AUTONEG;
+	}
+
+	if (state->pause & MLO_PAUSE_TX)
+		ctrl4 |= MVPP22_CTRL4_TX_FC_EN;
+	if (state->pause & MLO_PAUSE_RX)
+		ctrl4 |= MVPP22_CTRL4_RX_FC_EN;
+
+/* Some fields of the auto-negotiation register require the port to be down when
+ * their value is updated.
+ */
+#define MVPP2_GMAC_AN_PORT_DOWN_MASK	\
+		(MVPP2_GMAC_IN_BAND_AUTONEG | \
+		 MVPP2_GMAC_IN_BAND_AUTONEG_BYPASS | \
+		 MVPP2_GMAC_CONFIG_MII_SPEED | MVPP2_GMAC_CONFIG_GMII_SPEED | \
+		 MVPP2_GMAC_AN_SPEED_EN | MVPP2_GMAC_CONFIG_FULL_DUPLEX | \
+		 MVPP2_GMAC_AN_DUPLEX_EN)
+
+	if ((old_ctrl0 ^ ctrl0) & MVPP2_GMAC_PORT_TYPE_MASK ||
+	    (old_ctrl2 ^ ctrl2) & MVPP2_GMAC_INBAND_AN_MASK ||
+	    (old_an ^ an) & MVPP2_GMAC_AN_PORT_DOWN_MASK) {
+		/* Force link down */
+		old_an &= ~MVPP2_GMAC_FORCE_LINK_PASS;
+		old_an |= MVPP2_GMAC_FORCE_LINK_DOWN;
+		writel(old_an, port->base + MVPP2_GMAC_AUTONEG_CONFIG);
+
+		/* Set the GMAC in a reset state - do this in a way that
+		 * ensures we clear it below.
+		 */
+		old_ctrl2 |= MVPP2_GMAC_PORT_RESET_MASK;
+		writel(old_ctrl2, port->base + MVPP2_GMAC_CTRL_2_REG);
 	}
 
-	writel(ctrl0, port->base + MVPP2_GMAC_CTRL_0_REG);
-	writel(ctrl2, port->base + MVPP2_GMAC_CTRL_2_REG);
-	writel(ctrl4, port->base + MVPP22_GMAC_CTRL_4_REG);
-	writel(an, port->base + MVPP2_GMAC_AUTONEG_CONFIG);
+	if (old_ctrl0 != ctrl0)
+		writel(ctrl0, port->base + MVPP2_GMAC_CTRL_0_REG);
+	if (old_ctrl2 != ctrl2)
+		writel(ctrl2, port->base + MVPP2_GMAC_CTRL_2_REG);
+	if (old_ctrl4 != ctrl4)
+		writel(ctrl4, port->base + MVPP22_GMAC_CTRL_4_REG);
+	if (old_an != an)
+		writel(an, port->base + MVPP2_GMAC_AUTONEG_CONFIG);
 
 	if (old_ctrl2 & MVPP2_GMAC_PORT_RESET_MASK) {
 		while (readl(port->base + MVPP2_GMAC_CTRL_2_REG) &
@@ -4518,38 +6451,60 @@ static void mvpp2_mac_config(struct net_device *dev, unsigned int mode,
 			     const struct phylink_link_state *state)
 {
 	struct mvpp2_port *port = netdev_priv(dev);
+	bool change_interface = port->phy_interface != state->interface;
 
 	/* Check for invalid configuration */
-	if (state->interface == PHY_INTERFACE_MODE_10GKR && port->gop_id != 0) {
-		netdev_err(dev, "Invalid mode on %s\n", dev->name);
-		return;
-	}
+	switch (state->interface) {
+	case PHY_INTERFACE_MODE_10GKR:
+	case PHY_INTERFACE_MODE_5GKR:
+		if (!port->has_xlg_mac) {
+			netdev_err(dev, "Invalid mode %s on %s\n",
+				   phy_modes(port->phy_interface), dev->name);
+			return;
+		}
+		break;
+	case PHY_INTERFACE_MODE_RXAUI:
+		if (port->id != 0) {
+			netdev_err(dev, "Invalid mode %s on %s\n",
+				   phy_modes(port->phy_interface), dev->name);
+			return;
+		}
+	default:
+		break;
+	};
 
-	/* Make sure the port is disabled when reconfiguring the mode */
-	mvpp2_port_disable(port);
+	if (port->priv->hw_version != MVPP21 && change_interface) {
+		/* Make sure the port is disabled when reconfiguring the mode */
+		mvpp2_tx_stop_all_queues(port->dev);
+		mvpp2_port_disable(port);
+
+		mvpp22_gop_mask_irq(port);
 
-	if (port->priv->hw_version == MVPP22 &&
-	    port->phy_interface != state->interface) {
 		port->phy_interface = state->interface;
 
 		/* Reconfigure the serdes lanes */
 		phy_power_off(port->comphy);
 		mvpp22_mode_reconfigure(port);
+
+		mvpp2_tx_wake_all_queues(dev);
+		mvpp2_port_enable(port);
 	}
 
 	/* mac (re)configuration */
-	if (state->interface == PHY_INTERFACE_MODE_10GKR)
+	if (state->interface == PHY_INTERFACE_MODE_RXAUI ||
+	    state->interface == PHY_INTERFACE_MODE_10GKR ||
+	    state->interface == PHY_INTERFACE_MODE_5GKR) {
 		mvpp2_xlg_config(port, mode, state);
-	else if (phy_interface_mode_is_rgmii(state->interface) ||
-		 state->interface == PHY_INTERFACE_MODE_SGMII ||
-		 state->interface == PHY_INTERFACE_MODE_1000BASEX ||
-		 state->interface == PHY_INTERFACE_MODE_2500BASEX)
+	} else {
 		mvpp2_gmac_config(port, mode, state);
+		mvpp2_gmac_tx_fifo_configure(port);
+	}
 
 	if (port->priv->hw_version == MVPP21 && port->flags & MVPP2_F_LOOPBACK)
 		mvpp2_port_loopback_set(port, state);
 
-	mvpp2_port_enable(port);
+	if (port->priv->hw_version != MVPP21 && change_interface)
+		mvpp22_gop_unmask_irq(port);
 }
 
 static void mvpp2_mac_link_up(struct net_device *dev, unsigned int mode,
@@ -4559,11 +6514,12 @@ static void mvpp2_mac_link_up(struct net_device *dev, unsigned int mode,
 	u32 val;
 
 	if (!phylink_autoneg_inband(mode) &&
-	    interface != PHY_INTERFACE_MODE_10GKR) {
+	    interface != PHY_INTERFACE_MODE_RXAUI &&
+	    interface != PHY_INTERFACE_MODE_10GKR &&
+	    interface != PHY_INTERFACE_MODE_5GKR) {
 		val = readl(port->base + MVPP2_GMAC_AUTONEG_CONFIG);
 		val &= ~MVPP2_GMAC_FORCE_LINK_DOWN;
-		if (phy_interface_mode_is_rgmii(interface))
-			val |= MVPP2_GMAC_FORCE_LINK_PASS;
+		val |= MVPP2_GMAC_FORCE_LINK_PASS;
 		writel(val, port->base + MVPP2_GMAC_AUTONEG_CONFIG);
 	}
 
@@ -4571,7 +6527,7 @@ static void mvpp2_mac_link_up(struct net_device *dev, unsigned int mode,
 
 	mvpp2_egress_enable(port);
 	mvpp2_ingress_enable(port);
-	netif_tx_wake_all_queues(dev);
+	mvpp2_tx_wake_all_queues(dev);
 }
 
 static void mvpp2_mac_link_down(struct net_device *dev, unsigned int mode,
@@ -4581,24 +6537,19 @@ static void mvpp2_mac_link_down(struct net_device *dev, unsigned int mode,
 	u32 val;
 
 	if (!phylink_autoneg_inband(mode) &&
-	    interface != PHY_INTERFACE_MODE_10GKR) {
+	    interface != PHY_INTERFACE_MODE_RXAUI &&
+	    interface != PHY_INTERFACE_MODE_10GKR &&
+	    interface != PHY_INTERFACE_MODE_5GKR) {
 		val = readl(port->base + MVPP2_GMAC_AUTONEG_CONFIG);
 		val &= ~MVPP2_GMAC_FORCE_LINK_PASS;
 		val |= MVPP2_GMAC_FORCE_LINK_DOWN;
 		writel(val, port->base + MVPP2_GMAC_AUTONEG_CONFIG);
 	}
 
-	netif_tx_stop_all_queues(dev);
+	mvpp2_tx_stop_all_queues(dev);
 	mvpp2_egress_disable(port);
 	mvpp2_ingress_disable(port);
 
-	/* When using link interrupts to notify phylink of a MAC state change,
-	 * we do not want the port to be disabled (we want to receive further
-	 * interrupts, to be notified when the port will have a link later).
-	 */
-	if (!port->has_phy)
-		return;
-
 	mvpp2_port_disable(port);
 }
 
@@ -4611,6 +6562,34 @@ static const struct phylink_mac_ops mvpp2_phylink_ops = {
 	.mac_link_down = mvpp2_mac_link_down,
 };
 
+/* DSA notifier */
+static void mvpp2_dsa_port_register(struct net_device *dev)
+{
+	struct mvpp2_port *port = netdev_priv(dev);
+	struct mvpp2 *priv = port->priv;
+	u32 reg;
+
+	/* For switch port enable non-extended DSA tags and make sure
+	 * the extended DSA tag usage is disabled as those
+	 * two options cannot coexist.
+	 */
+	reg = mvpp2_read(priv, MVPP2_MH_REG(port->id));
+	reg &= ~MVPP2_DSA_EXTENDED;
+	reg |= MVPP2_DSA_NON_EXTENDED;
+	mvpp2_write(priv, MVPP2_MH_REG(port->id), reg);
+}
+
+static int mvpp2_dsa_notifier(struct notifier_block *unused,
+			      unsigned long event, void *ptr)
+{
+	struct dsa_notifier_register_info *info = ptr;
+
+	if (event == DSA_PORT_REGISTER)
+		mvpp2_dsa_port_register(info->master);
+
+	return NOTIFY_DONE;
+}
+
 /* Ports initialization */
 static int mvpp2_port_probe(struct platform_device *pdev,
 			    struct fwnode_handle *port_fwnode,
@@ -4625,32 +6604,45 @@ static int mvpp2_port_probe(struct platform_device *pdev,
 	struct phylink *phylink;
 	char *mac_from = "";
 	unsigned int ntxqs, nrxqs;
+	unsigned long flags = 0;
 	bool has_tx_irqs;
+	dma_addr_t p;
 	u32 id;
 	int features;
 	int phy_mode;
-	int err, i, cpu;
+	int err, i;
+	int cpu;
 
-	if (port_node) {
-		has_tx_irqs = mvpp2_port_has_tx_irqs(priv, port_node);
-	} else {
-		has_tx_irqs = true;
-		queue_mode = MVPP2_QDIST_MULTI_MODE;
+	has_tx_irqs = mvpp2_port_has_irqs(priv, port_node, &flags);
+	if (!has_tx_irqs && queue_mode == MVPP2_QDIST_MULTI_MODE) {
+		dev_err(&pdev->dev,
+			"not enough IRQs to support multi queue mode\n");
+		return -EINVAL;
 	}
 
-	if (!has_tx_irqs)
-		queue_mode = MVPP2_QDIST_SINGLE_MODE;
-
 	ntxqs = MVPP2_MAX_TXQ;
-	if (priv->hw_version == MVPP22 && queue_mode == MVPP2_QDIST_MULTI_MODE)
-		nrxqs = MVPP2_DEFAULT_RXQ * num_possible_cpus();
-	else
-		nrxqs = MVPP2_DEFAULT_RXQ;
+	if (priv->hw_version != MVPP21 && queue_mode ==
+	    MVPP2_QDIST_SINGLE_MODE) {
+		nrxqs = 1;
+	} else {
+		/* According to the PPv2.2 datasheet and our experiments on
+		 * PPv2.1, RX queues have an allocation granularity of 4 (when
+		 * more than a single one on PPv2.2).
+		 * Round up to nearest multiple of 4.
+		 */
+		nrxqs = (num_possible_cpus() + 3) & ~0x3;
+		if (nrxqs > MVPP2_PORT_MAX_RXQ)
+			nrxqs = MVPP2_PORT_MAX_RXQ;
+	}
 
 	dev = alloc_etherdev_mqs(sizeof(*port), ntxqs, nrxqs);
 	if (!dev)
 		return -ENOMEM;
 
+	/* XPS mapping queues to 0..N cpus (may be less than ntxqs) */
+	for_each_online_cpu(cpu)
+		netif_set_xps_queue(dev, cpumask_of(cpu), cpu);
+
 	phy_mode = fwnode_get_phy_mode(port_fwnode);
 	if (phy_mode < 0) {
 		dev_err(&pdev->dev, "incorrect phy mode\n");
@@ -4684,10 +6676,17 @@ static int mvpp2_port_probe(struct platform_device *pdev,
 	port->dev = dev;
 	port->fwnode = port_fwnode;
 	port->has_phy = !!of_find_property(port_node, "phy", NULL);
+	if (port->has_phy && phy_mode == PHY_INTERFACE_MODE_INTERNAL) {
+		err = -EINVAL;
+		dev_err(&pdev->dev, "internal mode doesn't work with phy\n");
+		goto err_free_netdev;
+	}
+
 	port->ntxqs = ntxqs;
 	port->nrxqs = nrxqs;
 	port->priv = priv;
 	port->has_tx_irqs = has_tx_irqs;
+	port->flags = flags;
 
 	err = mvpp2_queue_vectors_init(port, port_node);
 	if (err)
@@ -4718,6 +6717,10 @@ static int mvpp2_port_probe(struct platform_device *pdev,
 	port->phy_interface = phy_mode;
 	port->comphy = comphy;
 
+	if ((port->id == 0 && port->priv->hw_version != MVPP21) ||
+	    (port->id == 1 && port->priv->hw_version == MVPP23))
+		port->has_xlg_mac = true;
+
 	if (priv->hw_version == MVPP21) {
 		res = platform_get_resource(pdev, IORESOURCE_MEM, 2 + id);
 		port->base = devm_ioremap_resource(&pdev->dev, res);
@@ -4750,13 +6753,16 @@ static int mvpp2_port_probe(struct platform_device *pdev,
 		goto err_free_irq;
 	}
 
-	port->ethtool_stats = devm_kcalloc(&pdev->dev,
-					   ARRAY_SIZE(mvpp2_ethtool_regs),
-					   sizeof(u64), GFP_KERNEL);
-	if (!port->ethtool_stats) {
+	p = (dma_addr_t)devm_kcalloc(&pdev->dev,
+				     ARRAY_SIZE(mvpp2_ethtool_regs) +
+				     L1_CACHE_BYTES,
+				     sizeof(u64), GFP_KERNEL);
+	if (!p) {
 		err = -ENOMEM;
 		goto err_free_stats;
 	}
+	p = (p + ~CACHE_LINE_MASK) & CACHE_LINE_MASK;
+	port->ethtool_stats = (void *)p;
 
 	mutex_init(&port->gather_stats_lock);
 	INIT_DELAYED_WORK(&port->stats_work, mvpp2_gather_hw_statistics);
@@ -4783,28 +6789,25 @@ static int mvpp2_port_probe(struct platform_device *pdev,
 		goto err_free_txq_pcpu;
 	}
 
-	if (!port->has_tx_irqs) {
-		for_each_present_cpu(cpu) {
-			port_pcpu = per_cpu_ptr(port->pcpu, cpu);
-
-			hrtimer_init(&port_pcpu->tx_done_timer, CLOCK_MONOTONIC,
-				     HRTIMER_MODE_REL_PINNED);
-			port_pcpu->tx_done_timer.function = mvpp2_hr_timer_cb;
-			port_pcpu->timer_scheduled = false;
+	/* Init tx-done/guard timer and tasklet */
+	 mvpp2_tx_done_init_on_probe(pdev, port);
 
-			tasklet_init(&port_pcpu->tx_done_tasklet,
-				     mvpp2_tx_proc_cb,
-				     (unsigned long)dev);
-		}
+	/* Init bulk timer and tasklet */
+	for_each_present_cpu(cpu) {
+		port_pcpu = per_cpu_ptr(port->pcpu, cpu);
+		hrtimer_init(&port_pcpu->bulk_timer,
+			     CLOCK_MONOTONIC, HRTIMER_MODE_REL_PINNED);
+		port_pcpu->bulk_timer.function = mvpp2_bulk_timer_cb;
+		tasklet_init(&port_pcpu->bulk_tasklet,
+			     mvpp2_bulk_tasklet_cb, (unsigned long)dev);
 	}
 
 	features = NETIF_F_SG | NETIF_F_IP_CSUM | NETIF_F_IPV6_CSUM |
-		   NETIF_F_TSO;
+		   NETIF_F_TSO | NETIF_F_HW_VLAN_CTAG_FILTER;
 	dev->features = features | NETIF_F_RXCSUM;
-	dev->hw_features |= features | NETIF_F_RXCSUM | NETIF_F_GRO |
-			    NETIF_F_HW_VLAN_CTAG_FILTER;
+	dev->hw_features |= features | NETIF_F_RXCSUM | NETIF_F_GRO;
 
-	if (mvpp22_rss_is_supported())
+	if (mvpp22_rss_is_supported(port))
 		dev->hw_features |= NETIF_F_RXHASH;
 
 	if (port->pool_long->id == MVPP2_BM_JUMBO && port->id != 0) {
@@ -4818,8 +6821,8 @@ static int mvpp2_port_probe(struct platform_device *pdev,
 
 	/* MTU range: 68 - 9704 */
 	dev->min_mtu = ETH_MIN_MTU;
-	/* 9704 == 9728 - 20 and rounding to 8 */
-	dev->max_mtu = MVPP2_BM_JUMBO_PKT_SIZE;
+	/* 9704 == 9728 - 24 (no rounding for MTU but for frag_size) */
+	dev->max_mtu = MVPP2_BM_JUMBO_PKT_SIZE - MVPP2_MTU_OVERHEAD_SIZE;
 	dev->dev.of_node = port_node;
 
 	/* Phylink isn't used w/ ACPI as of now */
@@ -4844,6 +6847,37 @@ static int mvpp2_port_probe(struct platform_device *pdev,
 
 	priv->port_list[priv->port_count++] = port;
 
+	/* Port may be configured by Uboot to transmit IDLE, so a remote side
+	 * feels the link as UP. Stop TX in same way as in mvpp2_open/stop.
+	 */
+	if (port->of_node && port->phylink) {
+		if (rtnl_is_locked()) {
+			if (!phylink_of_phy_connect(port->phylink,
+						    port->of_node, 0))
+				phylink_disconnect_phy(port->phylink);
+		} else {
+			rtnl_lock();
+			if (!phylink_of_phy_connect(port->phylink,
+						    port->of_node, 0))
+				phylink_disconnect_phy(port->phylink);
+			rtnl_unlock();
+		}
+	}
+
+	/* Init TX locks and bm locks */
+	for (i = 0; i < MVPP2_MAX_THREADS; i++) {
+		spin_lock_init(&port->bm_lock[i]);
+		spin_lock_init(&port->tx_lock[i]);
+	}
+
+	/* Register DSA notifier */
+	port->dsa_notifier.notifier_call = mvpp2_dsa_notifier;
+	err = register_dsa_notifier(&port->dsa_notifier);
+	if (err) {
+		dev_err(&pdev->dev, "failed to register DSA notifier\n");
+		goto err_phylink;
+	}
+
 	return 0;
 
 err_phylink:
@@ -4871,7 +6905,10 @@ static void mvpp2_port_remove(struct mvpp2_port *port)
 {
 	int i;
 
+	mvpp2_port_musdk_set(port->dev, false);
+	kfree(port->dbgfs_port_flow_entry);
 	unregister_netdev(port->dev);
+	unregister_dsa_notifier(&port->dsa_notifier);
 	if (port->phylink)
 		phylink_destroy(port->phylink);
 	free_percpu(port->pcpu);
@@ -4934,32 +6971,56 @@ static void mvpp2_rx_fifo_init(struct mvpp2 *priv)
 	mvpp2_write(priv, MVPP2_RX_FIFO_INIT_REG, 0x1);
 }
 
-static void mvpp22_rx_fifo_init(struct mvpp2 *priv)
+static void mvpp22_rx_fifo_set_hw(struct mvpp2 *priv, int port, int data_size)
 {
-	int port;
+	int attr_size = MVPP2_RX_FIFO_PORT_ATTR_SIZE(data_size);
 
-	/* The FIFO size parameters are set depending on the maximum speed a
-	 * given port can handle:
-	 * - Port 0: 10Gbps
-	 * - Port 1: 2.5Gbps
-	 * - Ports 2 and 3: 1Gbps
-	 */
+	mvpp2_write(priv, MVPP2_RX_DATA_FIFO_SIZE_REG(port), data_size);
+	mvpp2_write(priv, MVPP2_RX_ATTR_FIFO_SIZE_REG(port), attr_size);
+}
 
-	mvpp2_write(priv, MVPP2_RX_DATA_FIFO_SIZE_REG(0),
-		    MVPP2_RX_FIFO_PORT_DATA_SIZE_32KB);
-	mvpp2_write(priv, MVPP2_RX_ATTR_FIFO_SIZE_REG(0),
-		    MVPP2_RX_FIFO_PORT_ATTR_SIZE_32KB);
+/* Initialize TX FIFO's: the total FIFO size is 48kB on PPv2.2 and PPv2.3.
+ * 4kB fixed space must be assigned for the loopback port.
+ * Redistribute remaining avialable 44kB space among all active ports.
+ * Guarantee minimum 32kB for 10G port and 8kB for port 1, capable of 2.5G
+ * SGMII link.
+ */
+static void mvpp22_rx_fifo_init(struct mvpp2 *priv)
+{
+	int port, size;
+	unsigned long port_map;
+	int remaining_ports_count;
+	int size_remainder;
+
+	/* The loopback requires fixed 4kB of the FIFO space assignment. */
+	mvpp22_rx_fifo_set_hw(priv, MVPP2_LOOPBACK_PORT_INDEX,
+			      MVPP2_RX_FIFO_PORT_DATA_SIZE_4KB);
+	port_map = priv->port_map & ~BIT(MVPP2_LOOPBACK_PORT_INDEX);
+
+	/* Set RX FIFO size to 0 for inactive ports. */
+	for_each_clear_bit(port, &port_map, MVPP2_LOOPBACK_PORT_INDEX)
+		mvpp22_rx_fifo_set_hw(priv, port, 0);
+
+	/* Assign remaining RX FIFO space among all active ports. */
+	size_remainder = MVPP2_RX_FIFO_PORT_DATA_SIZE_44KB;
+	remaining_ports_count = hweight_long(port_map);
+
+	for_each_set_bit(port, &port_map, MVPP2_LOOPBACK_PORT_INDEX) {
+		if (remaining_ports_count == 1)
+			size = size_remainder;
+		else if (port == 0)
+			size = max(size_remainder / remaining_ports_count,
+				   MVPP2_RX_FIFO_PORT_DATA_SIZE_32KB);
+		else if (port == 1)
+			size = max(size_remainder / remaining_ports_count,
+				   MVPP2_RX_FIFO_PORT_DATA_SIZE_8KB);
+		else
+			size = size_remainder / remaining_ports_count;
 
-	mvpp2_write(priv, MVPP2_RX_DATA_FIFO_SIZE_REG(1),
-		    MVPP2_RX_FIFO_PORT_DATA_SIZE_8KB);
-	mvpp2_write(priv, MVPP2_RX_ATTR_FIFO_SIZE_REG(1),
-		    MVPP2_RX_FIFO_PORT_ATTR_SIZE_8KB);
+		size_remainder -= size;
+		remaining_ports_count--;
 
-	for (port = 2; port < MVPP2_MAX_PORTS; port++) {
-		mvpp2_write(priv, MVPP2_RX_DATA_FIFO_SIZE_REG(port),
-			    MVPP2_RX_FIFO_PORT_DATA_SIZE_4KB);
-		mvpp2_write(priv, MVPP2_RX_ATTR_FIFO_SIZE_REG(port),
-			    MVPP2_RX_FIFO_PORT_ATTR_SIZE_4KB);
+		mvpp22_rx_fifo_set_hw(priv, port, size);
 	}
 
 	mvpp2_write(priv, MVPP2_RX_MIN_PKT_SIZE_REG,
@@ -4967,27 +7028,155 @@ static void mvpp22_rx_fifo_init(struct mvpp2 *priv)
 	mvpp2_write(priv, MVPP2_RX_FIFO_INIT_REG, 0x1);
 }
 
-/* Initialize Tx FIFO's: the total FIFO size is 19kB on PPv2.2 and 10G
- * interfaces must have a Tx FIFO size of 10kB. As only port 0 can do 10G,
- * configure its Tx FIFO size to 10kB and the others ports Tx FIFO size to 3kB.
- */
-static void mvpp22_tx_fifo_init(struct mvpp2 *priv)
+/* Configure Rx FIFO Flow control thresholds */
+static void mvpp23_rx_fifo_fc_set_tresh(struct mvpp2 *priv)
 {
-	int port, size, thrs;
+	int port, val;
 
-	for (port = 0; port < MVPP2_MAX_PORTS; port++) {
+	/* Port 0: maximum speed -10Gb/s port
+	 *	   required by spec RX FIFO threshold 9KB
+	 * Port 1: maximum speed -5Gb/s port
+	 *	   required by spec RX FIFO threshold 4KB
+	 * Port 2: maximum speed -1Gb/s port
+	 *	   required by spec RX FIFO threshold 2KB
+	 */
+
+	/* Without loopback port */
+	for (port = 0; port < (MVPP2_MAX_PORTS - 1); port++) {
 		if (port == 0) {
-			size = MVPP22_TX_FIFO_DATA_SIZE_10KB;
-			thrs = MVPP2_TX_FIFO_THRESHOLD_10KB;
+			val = (MVPP23_PORT0_FIFO_TRSH / MVPP2_RX_FC_TRSH_UNIT)
+				<< MVPP2_RX_FC_TRSH_OFFS;
+			val &= MVPP2_RX_FC_TRSH_MASK;
+			mvpp2_write(priv, MVPP2_RX_FC_REG(port), val);
+		} else if (port == 1) {
+			val = (MVPP23_PORT1_FIFO_TRSH / MVPP2_RX_FC_TRSH_UNIT)
+				<< MVPP2_RX_FC_TRSH_OFFS;
+			val &= MVPP2_RX_FC_TRSH_MASK;
+			mvpp2_write(priv, MVPP2_RX_FC_REG(port), val);
 		} else {
-			size = MVPP22_TX_FIFO_DATA_SIZE_3KB;
-			thrs = MVPP2_TX_FIFO_THRESHOLD_3KB;
+			val = (MVPP23_PORT2_FIFO_TRSH / MVPP2_RX_FC_TRSH_UNIT)
+				<< MVPP2_RX_FC_TRSH_OFFS;
+			val &= MVPP2_RX_FC_TRSH_MASK;
+			mvpp2_write(priv, MVPP2_RX_FC_REG(port), val);
 		}
-		mvpp2_write(priv, MVPP22_TX_FIFO_SIZE_REG(port), size);
-		mvpp2_write(priv, MVPP22_TX_FIFO_THRESH_REG(port), thrs);
 	}
 }
 
+/* Configure Rx FIFO Flow control thresholds */
+void mvpp23_rx_fifo_fc_en(struct mvpp2 *priv, int port, bool en)
+{
+	int val;
+
+	val = mvpp2_read(priv, MVPP2_RX_FC_REG(port));
+
+	if (en)
+		val |= MVPP2_RX_FC_EN;
+	else
+		val &= ~MVPP2_RX_FC_EN;
+
+	mvpp2_write(priv, MVPP2_RX_FC_REG(port), val);
+}
+
+static void mvpp22_tx_fifo_set_hw(struct mvpp2 *priv, int port, int size)
+{
+	int threshold = MVPP2_TX_FIFO_THRESHOLD(size);
+
+	mvpp2_write(priv, MVPP22_TX_FIFO_SIZE_REG(port), size);
+	mvpp2_write(priv, MVPP22_TX_FIFO_THRESH_REG(port), threshold);
+}
+
+/* Initialize TX FIFO's: the total FIFO size is 19kB on PPv2.2 and PPv2.3.
+ * 1kB fixed space must be assigned for the loopback port.
+ * Redistribute remaining avialable 18kB space among all active ports.
+ * The 10G interface should use 10kB (which is maximum possible size
+ * per single port).
+ */
+static void mvpp22_tx_fifo_init_default(struct mvpp2 *priv)
+{
+	int port, size;
+	unsigned long port_map;
+	int remaining_ports_count;
+	int size_remainder;
+
+	/* The loopback requires fixed 1kB of the FIFO space assignment. */
+	mvpp22_tx_fifo_set_hw(priv, MVPP2_LOOPBACK_PORT_INDEX,
+			      MVPP22_TX_FIFO_DATA_SIZE_1KB);
+	port_map = priv->port_map & ~BIT(MVPP2_LOOPBACK_PORT_INDEX);
+
+	/* Set TX FIFO size to 0 for inactive ports. */
+	for_each_clear_bit(port, &port_map, MVPP2_LOOPBACK_PORT_INDEX)
+		mvpp22_tx_fifo_set_hw(priv, port, 0);
+
+	/* Assign remaining TX FIFO space among all active ports. */
+	size_remainder = MVPP22_TX_FIFO_DATA_SIZE_18KB;
+	remaining_ports_count = hweight_long(port_map);
+
+	for_each_set_bit(port, &port_map, MVPP2_LOOPBACK_PORT_INDEX) {
+		if (remaining_ports_count == 1)
+			size = min(size_remainder,
+				   MVPP22_TX_FIFO_DATA_SIZE_10KB);
+		else if (port == 0)
+			size = MVPP22_TX_FIFO_DATA_SIZE_10KB;
+		else
+			size = size_remainder / remaining_ports_count;
+
+		size_remainder -= size;
+		remaining_ports_count--;
+
+		mvpp22_tx_fifo_set_hw(priv, port, size);
+	}
+}
+
+static void mvpp22_tx_fifo_init_param(struct platform_device *pdev,
+				      struct mvpp2 *priv)
+{
+	unsigned long port_map;
+	int size_remainder;
+	int port, size;
+
+	/* The loopback requires fixed 1kB of the FIFO space assignment. */
+	mvpp22_tx_fifo_set_hw(priv, MVPP2_LOOPBACK_PORT_INDEX,
+			      MVPP22_TX_FIFO_DATA_SIZE_1KB);
+	port_map = priv->port_map & ~BIT(MVPP2_LOOPBACK_PORT_INDEX);
+
+	/* Set TX FIFO size to 0 for inactive ports. */
+	for_each_clear_bit(port, &port_map, MVPP2_LOOPBACK_PORT_INDEX) {
+		mvpp22_tx_fifo_set_hw(priv, port, 0);
+		if (MVPP22_TX_FIFO_EXTRA_PARAM_SIZE(port + priv->cp_id * MVPP2_MAX_PORTS,
+						    tx_fifo_map))
+			goto error;
+	}
+
+	/* The physical port requires minimum 3kB */
+	for_each_set_bit(port, &port_map, MVPP2_LOOPBACK_PORT_INDEX) {
+		size = MVPP22_TX_FIFO_EXTRA_PARAM_SIZE(port + priv->cp_id * MVPP2_MAX_PORTS,
+						       tx_fifo_map);
+		if (size < MVPP22_TX_FIFO_DATA_SIZE_MIN ||
+		    size > MVPP22_TX_FIFO_DATA_SIZE_MAX)
+			goto error;
+	}
+
+	/* Assign remaining TX FIFO space among all active ports. */
+	size_remainder = MVPP22_TX_FIFO_DATA_SIZE_18KB;
+	for (port = 0; port < MVPP2_LOOPBACK_PORT_INDEX; port++) {
+		size = MVPP22_TX_FIFO_EXTRA_PARAM_SIZE(port + priv->cp_id * MVPP2_MAX_PORTS,
+						       tx_fifo_map);
+		if (!size)
+			continue;
+		size_remainder -= size;
+		mvpp22_tx_fifo_set_hw(priv, port, size);
+	}
+
+	if (size_remainder)
+		goto error;
+
+	return;
+
+error:
+	dev_warn(&pdev->dev, "Fail to set TX FIFO from module_param, fallback to default\n");
+	mvpp22_tx_fifo_init_default(priv);
+}
+
 static void mvpp2_axi_init(struct mvpp2 *priv)
 {
 	u32 val, rdval, wrval;
@@ -5017,6 +7206,10 @@ static void mvpp2_axi_init(struct mvpp2 *priv)
 	mvpp2_write(priv, MVPP22_AXI_RXQ_DESCR_WR_ATTR_REG, wrval);
 
 	/* Buffer Data */
+	/* Force TX FIFO transactions priority on the AXI QOS bus */
+	if (tx_fifo_protection)
+		rdval |= MVPP22_AXI_TX_DATA_RD_QOS_ATTRIBUTE;
+
 	mvpp2_write(priv, MVPP22_AXI_TX_DATA_RD_ATTR_REG, rdval);
 	mvpp2_write(priv, MVPP22_AXI_RX_DATA_WR_ATTR_REG, wrval);
 
@@ -5048,13 +7241,14 @@ static int mvpp2_init(struct platform_device *pdev, struct mvpp2 *priv)
 	const struct mbus_dram_target_info *dram_target_info;
 	int err, i;
 	u32 val;
+	dma_addr_t p;
 
 	/* MBUS windows configuration */
 	dram_target_info = mv_mbus_dram_info();
 	if (dram_target_info)
 		mvpp2_conf_mbus_windows(dram_target_info, priv);
 
-	if (priv->hw_version == MVPP22)
+	if (priv->hw_version != MVPP21)
 		mvpp2_axi_init(priv);
 
 	/* Disable HW PHY polling */
@@ -5068,14 +7262,18 @@ static int mvpp2_init(struct platform_device *pdev, struct mvpp2 *priv)
 		writel(val, priv->iface_base + MVPP22_SMI_MISC_CFG_REG);
 	}
 
-	/* Allocate and initialize aggregated TXQs */
-	priv->aggr_txqs = devm_kcalloc(&pdev->dev, num_present_cpus(),
-				       sizeof(*priv->aggr_txqs),
-				       GFP_KERNEL);
-	if (!priv->aggr_txqs)
+	/* Allocate and initialize aggregated TXQs
+	 * The aggr_txqs[per-cpu] entry should be aligned onto cache.
+	 * So allocate more than needed and round-up the pointer.
+	 */
+	val = sizeof(*priv->aggr_txqs) * MVPP2_MAX_THREADS + L1_CACHE_BYTES;
+	p = (dma_addr_t)devm_kzalloc(&pdev->dev, val, GFP_KERNEL);
+	if (!p)
 		return -ENOMEM;
+	p = (p + ~CACHE_LINE_MASK) & CACHE_LINE_MASK;
+	priv->aggr_txqs = (struct mvpp2_tx_queue *)p;
 
-	for_each_present_cpu(i) {
+	for (i = 0; i < MVPP2_MAX_THREADS; i++) {
 		priv->aggr_txqs[i].id = i;
 		priv->aggr_txqs[i].size = MVPP2_AGGR_TXQ_SIZE;
 		err = mvpp2_aggr_txq_init(pdev, &priv->aggr_txqs[i], i, priv);
@@ -5088,7 +7286,12 @@ static int mvpp2_init(struct platform_device *pdev, struct mvpp2 *priv)
 		mvpp2_rx_fifo_init(priv);
 	} else {
 		mvpp22_rx_fifo_init(priv);
-		mvpp22_tx_fifo_init(priv);
+		if (tx_fifo_map)
+			mvpp22_tx_fifo_init_param(pdev, priv);
+		else
+			mvpp22_tx_fifo_init_default(priv);
+		if (priv->hw_version == MVPP23)
+			mvpp23_rx_fifo_fc_set_tresh(priv);
 	}
 
 	if (priv->hw_version == MVPP21)
@@ -5111,18 +7314,51 @@ static int mvpp2_init(struct platform_device *pdev, struct mvpp2 *priv)
 	/* Classifier default initialization */
 	mvpp2_cls_init(priv);
 
+	/* Disable all ingress queues */
+	mvpp2_rxq_disable_all(priv);
+
+	return 0;
+}
+
+static int mvpp2_get_sram(struct platform_device *pdev,
+			  struct mvpp2 *priv)
+{
+	struct device_node *dn = pdev->dev.of_node;
+	struct resource *res;
+
+	if (has_acpi_companion(&pdev->dev)) {
+		res = platform_get_resource(pdev, IORESOURCE_MEM, 2);
+		if (!res) {
+			dev_warn(&pdev->dev, "ACPI is too old, TX FC disabled\n");
+			return 0;
+		}
+		priv->cm3_base = devm_ioremap_resource(&pdev->dev, res);
+		if (IS_ERR(priv->cm3_base))
+			return PTR_ERR(priv->cm3_base);
+	} else {
+		priv->sram_pool = of_gen_pool_get(dn, "cm3-mem", 0);
+		if (!priv->sram_pool) {
+			dev_warn(&pdev->dev, "DT is too old, TX FC disabled\n");
+			return 0;
+		}
+		priv->cm3_base = (void __iomem *)gen_pool_alloc(priv->sram_pool,
+								MSS_SRAM_SIZE);
+		if (!priv->cm3_base)
+			return -ENOMEM;
+	}
 	return 0;
 }
 
 static int mvpp2_probe(struct platform_device *pdev)
 {
+	static int cp_id;
 	const struct acpi_device_id *acpi_id;
 	struct fwnode_handle *fwnode = pdev->dev.fwnode;
 	struct fwnode_handle *port_fwnode;
 	struct mvpp2 *priv;
 	struct resource *res;
 	void __iomem *base;
-	int i;
+	int i, shared;
 	int err;
 
 	priv = devm_kzalloc(&pdev->dev, sizeof(*priv), GFP_KERNEL);
@@ -5132,8 +7368,6 @@ static int mvpp2_probe(struct platform_device *pdev)
 	if (has_acpi_companion(&pdev->dev)) {
 		acpi_id = acpi_match_device(pdev->dev.driver->acpi_match_table,
 					    &pdev->dev);
-		if (!acpi_id)
-			return -EINVAL;
 		priv->hw_version = (unsigned long)acpi_id->driver_data;
 	} else {
 		priv->hw_version =
@@ -5172,9 +7406,18 @@ static int mvpp2_probe(struct platform_device *pdev)
 		priv->iface_base = devm_ioremap_resource(&pdev->dev, res);
 		if (IS_ERR(priv->iface_base))
 			return PTR_ERR(priv->iface_base);
+
+		/* Map CM3 SRAM */
+		err = mvpp2_get_sram(pdev, priv);
+		if (err)
+			dev_warn(&pdev->dev, "Fail to alloc CM3 SRAM\n");
+
+		/* Enable global Flow Control only if hanler to SRAM not NULL */
+		if (priv->cm3_base)
+			priv->global_tx_fc = true;
 	}
 
-	if (priv->hw_version == MVPP22 && dev_of_node(&pdev->dev)) {
+	if (priv->hw_version != MVPP21 && dev_of_node(&pdev->dev)) {
 		priv->sysctrl_base =
 			syscon_regmap_lookup_by_phandle(pdev->dev.of_node,
 							"marvell,system-controller");
@@ -5187,7 +7430,13 @@ static int mvpp2_probe(struct platform_device *pdev)
 			priv->sysctrl_base = NULL;
 	}
 
-	mvpp2_setup_bm_pool();
+	priv->nthreads = min_t(unsigned int, num_present_cpus(),
+			       MVPP2_MAX_THREADS);
+
+	shared = num_present_cpus() - priv->nthreads;
+	if (shared > 0)
+		bitmap_fill(&priv->lock_map,
+			    min_t(int, shared, MVPP2_MAX_THREADS));
 
 	for (i = 0; i < MVPP2_MAX_THREADS; i++) {
 		u32 addr_space_sz;
@@ -5197,18 +7446,15 @@ static int mvpp2_probe(struct platform_device *pdev)
 		priv->swth_base[i] = base + i * addr_space_sz;
 	}
 
-	if (priv->hw_version == MVPP21)
-		priv->max_port_rxqs = 8;
-	else
-		priv->max_port_rxqs = 32;
-
 	if (dev_of_node(&pdev->dev)) {
 		priv->pp_clk = devm_clk_get(&pdev->dev, "pp_clk");
-		if (IS_ERR(priv->pp_clk))
-			return PTR_ERR(priv->pp_clk);
+		if (IS_ERR(priv->pp_clk)) {
+			err = PTR_ERR(priv->pp_clk);
+			goto err_cm3;
+		}
 		err = clk_prepare_enable(priv->pp_clk);
 		if (err < 0)
-			return err;
+			goto err_cm3;
 
 		priv->gop_clk = devm_clk_get(&pdev->dev, "gop_clk");
 		if (IS_ERR(priv->gop_clk)) {
@@ -5219,7 +7465,7 @@ static int mvpp2_probe(struct platform_device *pdev)
 		if (err < 0)
 			goto err_pp_clk;
 
-		if (priv->hw_version == MVPP22) {
+		if (priv->hw_version != MVPP21) {
 			priv->mg_clk = devm_clk_get(&pdev->dev, "mg_clk");
 			if (IS_ERR(priv->mg_clk)) {
 				err = PTR_ERR(priv->mg_clk);
@@ -5260,10 +7506,39 @@ static int mvpp2_probe(struct platform_device *pdev)
 		return -EINVAL;
 	}
 
-	if (priv->hw_version == MVPP22) {
+	if (priv->hw_version != MVPP21) {
+		if (mvpp2_read(priv, MVPP2_VER_ID_REG) == MVPP2_VER_PP23)
+			priv->hw_version = MVPP23;
+	}
+
+	if (priv->hw_version == MVPP21)
+		priv->max_port_rxqs = 8;
+	else
+		priv->max_port_rxqs = 32;
+
+	priv->custom_dma_mask = false;
+	if (priv->hw_version != MVPP21) {
+		/* If dma_mask points to coherent_dma_mask, setting both will
+		 * override the value of the other. This is problematic as the
+		 * PPv2 driver uses a 32-bit-mask for coherent accesses (txq,
+		 * rxq, bm) and a 40-bit mask for all other accesses.
+		 */
+		if (pdev->dev.dma_mask == &pdev->dev.coherent_dma_mask) {
+			pdev->dev.dma_mask =
+				kzalloc(sizeof(*pdev->dev.dma_mask),
+					GFP_KERNEL);
+			if (!pdev->dev.dma_mask) {
+				err = -ENOMEM;
+				goto err_mg_clk;
+			}
+
+			priv->custom_dma_mask = true;
+		}
+
 		err = dma_set_mask(&pdev->dev, MVPP2_DESC_DMA_MASK);
 		if (err)
-			goto err_axi_clk;
+			goto err_dma_mask;
+
 		/* Sadly, the BM pools all share the same register to
 		 * store the high 32 bits of their address. So they
 		 * must all have the same high 32 bits, which forces
@@ -5271,9 +7546,38 @@ static int mvpp2_probe(struct platform_device *pdev)
 		 */
 		err = dma_set_coherent_mask(&pdev->dev, DMA_BIT_MASK(32));
 		if (err)
-			goto err_axi_clk;
+			goto err_dma_mask;
+	}
+
+	/* Assign the reserved memory region to the device for DMA allocations,
+	 * if a memory-region phandle is found.
+	 */
+	if (dev_of_node(&pdev->dev))
+		of_reserved_mem_device_init_by_idx(&pdev->dev,
+						   pdev->dev.of_node, 0);
+
+	/* Configure branch prediction switch */
+	if (priv->hw_version == MVPP21)
+		static_branch_enable(&mvpp21_variant);
+	if (recycle) {
+		dev_info(&pdev->dev,
+			 "kernel space packet recycling feature enabled\n");
+		static_branch_enable(&mvpp2_recycle_ena);
+	}
+	/* else - keep the DEFINE_STATIC_KEY_FALSE */
+
+	/* Map DTS-active ports. Should be done before FIFO mvpp2_init */
+	fwnode_for_each_available_child_node(fwnode, port_fwnode) {
+		if (!fwnode_property_read_u32(port_fwnode, "port-id", &i))
+			priv->port_map |= BIT(i);
 	}
 
+	/* Init mss lock */
+	spin_lock_init(&priv->mss_spinlock);
+
+	priv->cp_id = cp_id;
+	cp_id++;
+
 	/* Initialize network controller */
 	err = mvpp2_init(pdev, priv);
 	if (err < 0) {
@@ -5309,6 +7613,12 @@ static int mvpp2_probe(struct platform_device *pdev)
 		goto err_port_probe;
 	}
 
+	if (priv->global_tx_fc && priv->hw_version != MVPP21) {
+		err = mvpp2_enable_global_fc(priv);
+		if (err)
+			dev_warn(&pdev->dev, "CM3 firmware not running, TX FC disabled\n");
+	}
+
 	mvpp2_dbgfs_init(priv, pdev->name);
 
 	platform_set_drvdata(pdev, priv);
@@ -5321,19 +7631,29 @@ static int mvpp2_probe(struct platform_device *pdev)
 			mvpp2_port_remove(priv->port_list[i]);
 		i++;
 	}
+err_dma_mask:
+	if (priv->custom_dma_mask) {
+		kfree(pdev->dev.dma_mask);
+		pdev->dev.dma_mask = &pdev->dev.coherent_dma_mask;
+	}
 err_axi_clk:
 	clk_disable_unprepare(priv->axi_clk);
 
 err_mg_core_clk:
-	if (priv->hw_version == MVPP22)
+	if (priv->hw_version != MVPP21)
 		clk_disable_unprepare(priv->mg_core_clk);
 err_mg_clk:
-	if (priv->hw_version == MVPP22)
+	if (priv->hw_version != MVPP21)
 		clk_disable_unprepare(priv->mg_clk);
 err_gop_clk:
 	clk_disable_unprepare(priv->gop_clk);
 err_pp_clk:
 	clk_disable_unprepare(priv->pp_clk);
+err_cm3:
+	if (!has_acpi_companion(&pdev->dev))
+		gen_pool_free(priv->sram_pool, (unsigned long)priv->cm3_base,
+			      MSS_SRAM_SIZE);
+
 	return err;
 }
 
@@ -5346,6 +7666,9 @@ static int mvpp2_remove(struct platform_device *pdev)
 
 	mvpp2_dbgfs_cleanup(priv);
 
+	flush_workqueue(priv->stats_queue);
+	destroy_workqueue(priv->stats_queue);
+
 	fwnode_for_each_available_child_node(fwnode, port_fwnode) {
 		if (priv->port_list[i]) {
 			mutex_destroy(&priv->port_list[i]->gather_stats_lock);
@@ -5354,15 +7677,13 @@ static int mvpp2_remove(struct platform_device *pdev)
 		i++;
 	}
 
-	destroy_workqueue(priv->stats_queue);
-
 	for (i = 0; i < MVPP2_BM_POOLS_NUM; i++) {
 		struct mvpp2_bm_pool *bm_pool = &priv->bm_pools[i];
 
 		mvpp2_bm_pool_destroy(pdev, priv, bm_pool);
 	}
 
-	for_each_present_cpu(i) {
+	for (i = 0; i < MVPP2_MAX_THREADS; i++) {
 		struct mvpp2_tx_queue *aggr_txq = &priv->aggr_txqs[i];
 
 		dma_free_coherent(&pdev->dev,
@@ -5371,6 +7692,17 @@ static int mvpp2_remove(struct platform_device *pdev)
 				  aggr_txq->descs_dma);
 	}
 
+	if (priv->custom_dma_mask) {
+		kfree(pdev->dev.dma_mask);
+		pdev->dev.dma_mask = &pdev->dev.coherent_dma_mask;
+	}
+
+	if (!has_acpi_companion(&pdev->dev)) {
+		gen_pool_free(priv->sram_pool, (unsigned long)priv->cm3_base,
+			      MSS_SRAM_SIZE);
+		gen_pool_destroy(priv->sram_pool);
+	}
+
 	if (is_acpi_node(port_fwnode))
 		return 0;
 
diff --git a/drivers/net/ethernet/marvell/mvpp2/mvpp2_prs.c b/drivers/net/ethernet/marvell/mvpp2/mvpp2_prs.c
old mode 100644
new mode 100755
index 5692c6087bbb..29b8df64cbd2
--- a/drivers/net/ethernet/marvell/mvpp2/mvpp2_prs.c
+++ b/drivers/net/ethernet/marvell/mvpp2/mvpp2_prs.c
@@ -29,16 +29,16 @@ static int mvpp2_prs_hw_write(struct mvpp2 *priv, struct mvpp2_prs_entry *pe)
 	/* Clear entry invalidation bit */
 	pe->tcam[MVPP2_PRS_TCAM_INV_WORD] &= ~MVPP2_PRS_TCAM_INV_MASK;
 
-	/* Write tcam index - indirect access */
-	mvpp2_write(priv, MVPP2_PRS_TCAM_IDX_REG, pe->index);
-	for (i = 0; i < MVPP2_PRS_TCAM_WORDS; i++)
-		mvpp2_write(priv, MVPP2_PRS_TCAM_DATA_REG(i), pe->tcam[i]);
-
 	/* Write sram index - indirect access */
 	mvpp2_write(priv, MVPP2_PRS_SRAM_IDX_REG, pe->index);
 	for (i = 0; i < MVPP2_PRS_SRAM_WORDS; i++)
 		mvpp2_write(priv, MVPP2_PRS_SRAM_DATA_REG(i), pe->sram[i]);
 
+	/* Write tcam index - indirect access */
+	mvpp2_write(priv, MVPP2_PRS_TCAM_IDX_REG, pe->index);
+	for (i = 0; i < MVPP2_PRS_TCAM_WORDS; i++)
+		mvpp2_write(priv, MVPP2_PRS_TCAM_DATA_REG(i), pe->tcam[i]);
+
 	return 0;
 }
 
@@ -405,6 +405,39 @@ static int mvpp2_prs_tcam_first_free(struct mvpp2 *priv, unsigned char start,
 	return -EINVAL;
 }
 
+/* Drop flow control pause frames */
+static void mv_pp2x_prs_drop_fc(struct mvpp2 *priv)
+{
+	struct mvpp2_prs_entry pe;
+	unsigned int len;
+	unsigned char da[ETH_ALEN] = {
+			0x01, 0x80, 0xC2, 0x00, 0x00, 0x01 };
+
+	memset(&pe, 0, sizeof(pe));
+
+	/* For all ports - drop flow control frames */
+	pe.index = MVPP2_PE_FC_DROP;
+	mvpp2_prs_tcam_lu_set(&pe, MVPP2_PRS_LU_MAC);
+
+	/* Set match on DA */
+	len = ETH_ALEN;
+	while (len--)
+		mvpp2_prs_tcam_data_byte_set(&pe, len, da[len], 0xff);
+
+	mvpp2_prs_sram_ri_update(&pe, MVPP2_PRS_RI_DROP_MASK,
+				 MVPP2_PRS_RI_DROP_MASK);
+
+	mvpp2_prs_sram_bits_set(&pe, MVPP2_PRS_SRAM_LU_GEN_BIT, 1);
+	mvpp2_prs_sram_next_lu_set(&pe, MVPP2_PRS_LU_FLOWS);
+
+	/* Mask all ports */
+	mvpp2_prs_tcam_port_map_set(&pe, MVPP2_PRS_PORT_MASK);
+
+	/* Update shadow table and hw entry */
+	mvpp2_prs_shadow_set(priv, pe.index, MVPP2_PRS_LU_MAC);
+	mvpp2_prs_hw_write(priv, &pe);
+}
+
 /* Enable/disable dropping all mac da's */
 static void mvpp2_prs_mac_drop_all_set(struct mvpp2 *priv, int port, bool add)
 {
@@ -527,12 +560,8 @@ static void mvpp2_prs_dsa_tag_set(struct mvpp2 *priv, int port, bool add,
 					     MVPP2_PRS_TCAM_DSA_TAGGED_BIT);
 
 			/* Set ai bits for next iteration */
-			if (extend)
-				mvpp2_prs_sram_ai_update(&pe, 1,
-							MVPP2_PRS_SRAM_AI_MASK);
-			else
-				mvpp2_prs_sram_ai_update(&pe, 0,
-							MVPP2_PRS_SRAM_AI_MASK);
+			mvpp2_prs_sram_ai_update(&pe, extend,
+						 MVPP2_PRS_SRAM_AI_MASK);
 
 			/* Set result info bits to 'single vlan' */
 			mvpp2_prs_sram_ri_update(&pe, MVPP2_PRS_RI_VLAN_SINGLE,
@@ -882,15 +911,14 @@ static int mvpp2_prs_ip4_proto(struct mvpp2 *priv, unsigned short proto,
 	mvpp2_prs_tcam_lu_set(&pe, MVPP2_PRS_LU_IP4);
 	pe.index = tid;
 
-	/* Set next lu to IPv4 */
-	mvpp2_prs_sram_next_lu_set(&pe, MVPP2_PRS_LU_IP4);
-	mvpp2_prs_sram_shift_set(&pe, 12, MVPP2_PRS_SRAM_OP_SEL_SHIFT_ADD);
-	/* Set L4 offset */
-	mvpp2_prs_sram_offset_set(&pe, MVPP2_PRS_SRAM_UDF_TYPE_L4,
-				  sizeof(struct iphdr) - 4,
+	/* Finished: go to flowid generation */
+	mvpp2_prs_sram_next_lu_set(&pe, MVPP2_PRS_LU_FLOWS);
+	mvpp2_prs_sram_bits_set(&pe, MVPP2_PRS_SRAM_LU_GEN_BIT, 1);
+
+	/* Set L3 offset */
+	mvpp2_prs_sram_offset_set(&pe, MVPP2_PRS_SRAM_UDF_TYPE_L3, -4,
 				  MVPP2_PRS_SRAM_OP_SEL_UDF_ADD);
-	mvpp2_prs_sram_ai_update(&pe, MVPP2_PRS_IPV4_DIP_AI_BIT,
-				 MVPP2_PRS_IPV4_DIP_AI_BIT);
+	mvpp2_prs_sram_ai_update(&pe, 0, MVPP2_PRS_IPV4_DIP_AI_BIT);
 	mvpp2_prs_sram_ri_update(&pe, ri, ri_mask | MVPP2_PRS_RI_IP_FRAG_MASK);
 
 	mvpp2_prs_tcam_data_byte_set(&pe, 2, 0x00,
@@ -899,7 +927,8 @@ static int mvpp2_prs_ip4_proto(struct mvpp2 *priv, unsigned short proto,
 				     MVPP2_PRS_TCAM_PROTO_MASK);
 
 	mvpp2_prs_tcam_data_byte_set(&pe, 5, proto, MVPP2_PRS_TCAM_PROTO_MASK);
-	mvpp2_prs_tcam_ai_update(&pe, 0, MVPP2_PRS_IPV4_DIP_AI_BIT);
+	mvpp2_prs_tcam_ai_update(&pe, MVPP2_PRS_IPV4_DIP_AI_BIT,
+				 MVPP2_PRS_IPV4_DIP_AI_BIT);
 	/* Unmask all ports */
 	mvpp2_prs_tcam_port_map_set(&pe, MVPP2_PRS_PORT_MASK);
 
@@ -967,12 +996,17 @@ static int mvpp2_prs_ip4_cast(struct mvpp2 *priv, unsigned short l3_cast)
 		return -EINVAL;
 	}
 
-	/* Finished: go to flowid generation */
-	mvpp2_prs_sram_next_lu_set(&pe, MVPP2_PRS_LU_FLOWS);
-	mvpp2_prs_sram_bits_set(&pe, MVPP2_PRS_SRAM_LU_GEN_BIT, 1);
+	/* Go again to ipv4 */
+	mvpp2_prs_sram_next_lu_set(&pe, MVPP2_PRS_LU_IP4);
 
-	mvpp2_prs_tcam_ai_update(&pe, MVPP2_PRS_IPV4_DIP_AI_BIT,
+	mvpp2_prs_sram_ai_update(&pe, MVPP2_PRS_IPV4_DIP_AI_BIT,
 				 MVPP2_PRS_IPV4_DIP_AI_BIT);
+
+	/* Shift back to IPv4 proto */
+	mvpp2_prs_sram_shift_set(&pe, -12, MVPP2_PRS_SRAM_OP_SEL_SHIFT_ADD);
+
+	mvpp2_prs_tcam_ai_update(&pe, 0, MVPP2_PRS_IPV4_DIP_AI_BIT);
+
 	/* Unmask all ports */
 	mvpp2_prs_tcam_port_map_set(&pe, MVPP2_PRS_PORT_MASK);
 
@@ -1134,6 +1168,21 @@ static void mvpp2_prs_mh_init(struct mvpp2 *priv)
 	/* Update shadow table and hw entry */
 	mvpp2_prs_shadow_set(priv, pe.index, MVPP2_PRS_LU_MH);
 	mvpp2_prs_hw_write(priv, &pe);
+
+	/* Set MH entry that skip parser */
+	pe.index = MVPP2_PE_MH_SKIP_PRS;
+	mvpp2_prs_tcam_lu_set(&pe, MVPP2_PRS_LU_MH);
+	mvpp2_prs_sram_shift_set(&pe, MVPP2_MH_SIZE,
+				 MVPP2_PRS_SRAM_OP_SEL_SHIFT_ADD);
+	mvpp2_prs_sram_bits_set(&pe, MVPP2_PRS_SRAM_LU_GEN_BIT, 1);
+	mvpp2_prs_sram_next_lu_set(&pe, MVPP2_PRS_LU_FLOWS);
+
+	/* Mask all ports */
+	mvpp2_prs_tcam_port_map_set(&pe, 0);
+
+	/* Update shadow table and hw entry */
+	mvpp2_prs_shadow_set(priv, pe.index, MVPP2_PRS_LU_MH);
+	mvpp2_prs_hw_write(priv, &pe);
 }
 
 /* Set default entires (place holder) for promiscuous, non-promiscuous and
@@ -1162,6 +1211,7 @@ static void mvpp2_prs_mac_init(struct mvpp2 *priv)
 	mvpp2_prs_hw_write(priv, &pe);
 
 	/* Create dummy entries for drop all and promiscuous modes */
+	mv_pp2x_prs_drop_fc(priv);
 	mvpp2_prs_mac_drop_all_set(priv, 0, false);
 	mvpp2_prs_mac_promisc_set(priv, 0, MVPP2_PRS_L2_UNI_CAST, false);
 	mvpp2_prs_mac_promisc_set(priv, 0, MVPP2_PRS_L2_MULTI_CAST, false);
@@ -1281,7 +1331,7 @@ static void mvpp2_prs_vid_init(struct mvpp2 *priv)
 static int mvpp2_prs_etype_init(struct mvpp2 *priv)
 {
 	struct mvpp2_prs_entry pe;
-	int tid;
+	int tid, ihl;
 
 	/* Ethertype: PPPoE */
 	tid = mvpp2_prs_tcam_first_free(priv, MVPP2_PE_FIRST_FREE_TID,
@@ -1373,66 +1423,43 @@ static int mvpp2_prs_etype_init(struct mvpp2 *priv)
 				MVPP2_PRS_RI_UDF3_MASK);
 	mvpp2_prs_hw_write(priv, &pe);
 
-	/* Ethertype: IPv4 without options */
-	tid = mvpp2_prs_tcam_first_free(priv, MVPP2_PE_FIRST_FREE_TID,
-					MVPP2_PE_LAST_FREE_TID);
-	if (tid < 0)
-		return tid;
-
-	memset(&pe, 0, sizeof(pe));
-	mvpp2_prs_tcam_lu_set(&pe, MVPP2_PRS_LU_L2);
-	pe.index = tid;
-
-	mvpp2_prs_match_etype(&pe, 0, ETH_P_IP);
-	mvpp2_prs_tcam_data_byte_set(&pe, MVPP2_ETH_TYPE_LEN,
-				     MVPP2_PRS_IPV4_HEAD | MVPP2_PRS_IPV4_IHL,
-				     MVPP2_PRS_IPV4_HEAD_MASK |
-				     MVPP2_PRS_IPV4_IHL_MASK);
-
-	mvpp2_prs_sram_next_lu_set(&pe, MVPP2_PRS_LU_IP4);
-	mvpp2_prs_sram_ri_update(&pe, MVPP2_PRS_RI_L3_IP4,
-				 MVPP2_PRS_RI_L3_PROTO_MASK);
-	/* Skip eth_type + 4 bytes of IP header */
-	mvpp2_prs_sram_shift_set(&pe, MVPP2_ETH_TYPE_LEN + 4,
-				 MVPP2_PRS_SRAM_OP_SEL_SHIFT_ADD);
-	/* Set L3 offset */
-	mvpp2_prs_sram_offset_set(&pe, MVPP2_PRS_SRAM_UDF_TYPE_L3,
-				  MVPP2_ETH_TYPE_LEN,
-				  MVPP2_PRS_SRAM_OP_SEL_UDF_ADD);
-
-	/* Update shadow table and hw entry */
-	mvpp2_prs_shadow_set(priv, pe.index, MVPP2_PRS_LU_L2);
-	priv->prs_shadow[pe.index].udf = MVPP2_PRS_UDF_L2_DEF;
-	priv->prs_shadow[pe.index].finish = false;
-	mvpp2_prs_shadow_ri_set(priv, pe.index, MVPP2_PRS_RI_L3_IP4,
-				MVPP2_PRS_RI_L3_PROTO_MASK);
-	mvpp2_prs_hw_write(priv, &pe);
-
-	/* Ethertype: IPv4 with options */
-	tid = mvpp2_prs_tcam_first_free(priv, MVPP2_PE_FIRST_FREE_TID,
-					MVPP2_PE_LAST_FREE_TID);
-	if (tid < 0)
-		return tid;
-
-	pe.index = tid;
+	/* Ethertype: IPv4 with header length >= 5 */
+	for (ihl = MVPP2_PRS_IPV4_IHL_MIN; ihl <= MVPP2_PRS_IPV4_IHL_MAX; ihl++) {
+		tid = mvpp2_prs_tcam_first_free(priv, MVPP2_PE_FIRST_FREE_TID,
+						MVPP2_PE_LAST_FREE_TID);
+		if (tid < 0)
+			return tid;
 
-	mvpp2_prs_tcam_data_byte_set(&pe, MVPP2_ETH_TYPE_LEN,
-				     MVPP2_PRS_IPV4_HEAD,
-				     MVPP2_PRS_IPV4_HEAD_MASK);
+		memset(&pe, 0, sizeof(pe));
+		mvpp2_prs_tcam_lu_set(&pe, MVPP2_PRS_LU_L2);
+		pe.index = tid;
 
-	/* Clear ri before updating */
-	pe.sram[MVPP2_PRS_SRAM_RI_WORD] = 0x0;
-	pe.sram[MVPP2_PRS_SRAM_RI_CTRL_WORD] = 0x0;
-	mvpp2_prs_sram_ri_update(&pe, MVPP2_PRS_RI_L3_IP4_OPT,
-				 MVPP2_PRS_RI_L3_PROTO_MASK);
+		mvpp2_prs_match_etype(&pe, 0, ETH_P_IP);
+		mvpp2_prs_tcam_data_byte_set(&pe, MVPP2_ETH_TYPE_LEN,
+					     MVPP2_PRS_IPV4_HEAD | ihl,
+					     MVPP2_PRS_IPV4_HEAD_MASK |
+					     MVPP2_PRS_IPV4_IHL_MASK);
+
+		mvpp2_prs_sram_next_lu_set(&pe, MVPP2_PRS_LU_IP4);
+		mvpp2_prs_sram_ri_update(&pe, MVPP2_PRS_RI_L3_IP4,
+					 MVPP2_PRS_RI_L3_PROTO_MASK);
+		/* goto ipv4 dst-address (skip eth_type + IP-header-size - 4) */
+		mvpp2_prs_sram_shift_set(&pe, MVPP2_ETH_TYPE_LEN +
+					 sizeof(struct iphdr) - 4,
+					 MVPP2_PRS_SRAM_OP_SEL_SHIFT_ADD);
+		/* Set L4 offset */
+		mvpp2_prs_sram_offset_set(&pe, MVPP2_PRS_SRAM_UDF_TYPE_L4,
+					  MVPP2_ETH_TYPE_LEN + (ihl * 4),
+					  MVPP2_PRS_SRAM_OP_SEL_UDF_ADD);
 
-	/* Update shadow table and hw entry */
-	mvpp2_prs_shadow_set(priv, pe.index, MVPP2_PRS_LU_L2);
-	priv->prs_shadow[pe.index].udf = MVPP2_PRS_UDF_L2_DEF;
-	priv->prs_shadow[pe.index].finish = false;
-	mvpp2_prs_shadow_ri_set(priv, pe.index, MVPP2_PRS_RI_L3_IP4_OPT,
-				MVPP2_PRS_RI_L3_PROTO_MASK);
-	mvpp2_prs_hw_write(priv, &pe);
+		/* Update shadow table and hw entry */
+		mvpp2_prs_shadow_set(priv, pe.index, MVPP2_PRS_LU_L2);
+		priv->prs_shadow[pe.index].udf = MVPP2_PRS_UDF_L2_DEF;
+		priv->prs_shadow[pe.index].finish = false;
+		mvpp2_prs_shadow_ri_set(priv, pe.index, MVPP2_PRS_RI_L3_IP4,
+					MVPP2_PRS_RI_L3_PROTO_MASK);
+		mvpp2_prs_hw_write(priv, &pe);
+	}
 
 	/* Ethertype: IPv6 without options */
 	tid = mvpp2_prs_tcam_first_free(priv, MVPP2_PE_FIRST_FREE_TID,
@@ -1597,8 +1624,9 @@ static int mvpp2_prs_pppoe_init(struct mvpp2 *priv)
 	mvpp2_prs_sram_next_lu_set(&pe, MVPP2_PRS_LU_IP4);
 	mvpp2_prs_sram_ri_update(&pe, MVPP2_PRS_RI_L3_IP4_OPT,
 				 MVPP2_PRS_RI_L3_PROTO_MASK);
-	/* Skip eth_type + 4 bytes of IP header */
-	mvpp2_prs_sram_shift_set(&pe, MVPP2_ETH_TYPE_LEN + 4,
+	/* goto ipv4 dest-address (skip eth_type + IP-header-size - 4) */
+	mvpp2_prs_sram_shift_set(&pe, MVPP2_ETH_TYPE_LEN +
+				 sizeof(struct iphdr) - 4,
 				 MVPP2_PRS_SRAM_OP_SEL_SHIFT_ADD);
 	/* Set L3 offset */
 	mvpp2_prs_sram_offset_set(&pe, MVPP2_PRS_SRAM_UDF_TYPE_L3,
@@ -1618,7 +1646,8 @@ static int mvpp2_prs_pppoe_init(struct mvpp2 *priv)
 	pe.index = tid;
 
 	mvpp2_prs_tcam_data_byte_set(&pe, MVPP2_ETH_TYPE_LEN,
-				     MVPP2_PRS_IPV4_HEAD | MVPP2_PRS_IPV4_IHL,
+				     MVPP2_PRS_IPV4_HEAD |
+				     MVPP2_PRS_IPV4_IHL_MIN,
 				     MVPP2_PRS_IPV4_HEAD_MASK |
 				     MVPP2_PRS_IPV4_IHL_MASK);
 
@@ -1647,8 +1676,9 @@ static int mvpp2_prs_pppoe_init(struct mvpp2 *priv)
 	mvpp2_prs_sram_next_lu_set(&pe, MVPP2_PRS_LU_IP6);
 	mvpp2_prs_sram_ri_update(&pe, MVPP2_PRS_RI_L3_IP6,
 				 MVPP2_PRS_RI_L3_PROTO_MASK);
-	/* Skip eth_type + 4 bytes of IPv6 header */
-	mvpp2_prs_sram_shift_set(&pe, MVPP2_ETH_TYPE_LEN + 4,
+	/* Jump to DIP of IPV6 header */
+	mvpp2_prs_sram_shift_set(&pe, MVPP2_ETH_TYPE_LEN + 8 +
+				 MVPP2_MAX_L3_ADDR_SIZE,
 				 MVPP2_PRS_SRAM_OP_SEL_SHIFT_ADD);
 	/* Set L3 offset */
 	mvpp2_prs_sram_offset_set(&pe, MVPP2_PRS_SRAM_UDF_TYPE_L3,
@@ -1727,19 +1757,19 @@ static int mvpp2_prs_ip4_init(struct mvpp2 *priv)
 	mvpp2_prs_tcam_lu_set(&pe, MVPP2_PRS_LU_IP4);
 	pe.index = MVPP2_PE_IP4_PROTO_UN;
 
-	/* Set next lu to IPv4 */
-	mvpp2_prs_sram_next_lu_set(&pe, MVPP2_PRS_LU_IP4);
-	mvpp2_prs_sram_shift_set(&pe, 12, MVPP2_PRS_SRAM_OP_SEL_SHIFT_ADD);
-	/* Set L4 offset */
-	mvpp2_prs_sram_offset_set(&pe, MVPP2_PRS_SRAM_UDF_TYPE_L4,
-				  sizeof(struct iphdr) - 4,
+	/* Finished: go to flowid generation */
+	mvpp2_prs_sram_next_lu_set(&pe, MVPP2_PRS_LU_FLOWS);
+	mvpp2_prs_sram_bits_set(&pe, MVPP2_PRS_SRAM_LU_GEN_BIT, 1);
+
+	/* Set L3 offset */
+	mvpp2_prs_sram_offset_set(&pe, MVPP2_PRS_SRAM_UDF_TYPE_L3, -4,
 				  MVPP2_PRS_SRAM_OP_SEL_UDF_ADD);
-	mvpp2_prs_sram_ai_update(&pe, MVPP2_PRS_IPV4_DIP_AI_BIT,
-				 MVPP2_PRS_IPV4_DIP_AI_BIT);
+	mvpp2_prs_sram_ai_update(&pe, 0, MVPP2_PRS_IPV4_DIP_AI_BIT);
 	mvpp2_prs_sram_ri_update(&pe, MVPP2_PRS_RI_L4_OTHER,
 				 MVPP2_PRS_RI_L4_PROTO_MASK);
 
-	mvpp2_prs_tcam_ai_update(&pe, 0, MVPP2_PRS_IPV4_DIP_AI_BIT);
+	mvpp2_prs_tcam_ai_update(&pe, MVPP2_PRS_IPV4_DIP_AI_BIT,
+				 MVPP2_PRS_IPV4_DIP_AI_BIT);
 	/* Unmask all ports */
 	mvpp2_prs_tcam_port_map_set(&pe, MVPP2_PRS_PORT_MASK);
 
@@ -1752,14 +1782,19 @@ static int mvpp2_prs_ip4_init(struct mvpp2 *priv)
 	mvpp2_prs_tcam_lu_set(&pe, MVPP2_PRS_LU_IP4);
 	pe.index = MVPP2_PE_IP4_ADDR_UN;
 
-	/* Finished: go to flowid generation */
-	mvpp2_prs_sram_next_lu_set(&pe, MVPP2_PRS_LU_FLOWS);
-	mvpp2_prs_sram_bits_set(&pe, MVPP2_PRS_SRAM_LU_GEN_BIT, 1);
+	/* Go again to ipv4 */
+	mvpp2_prs_sram_next_lu_set(&pe, MVPP2_PRS_LU_IP4);
+
+	mvpp2_prs_sram_ai_update(&pe, MVPP2_PRS_IPV4_DIP_AI_BIT,
+				 MVPP2_PRS_IPV4_DIP_AI_BIT);
+
+	/* Shift back to IPv4 proto */
+	mvpp2_prs_sram_shift_set(&pe, -12, MVPP2_PRS_SRAM_OP_SEL_SHIFT_ADD);
+
 	mvpp2_prs_sram_ri_update(&pe, MVPP2_PRS_RI_L3_UCAST,
 				 MVPP2_PRS_RI_L3_ADDR_MASK);
+	mvpp2_prs_tcam_ai_update(&pe, 0, MVPP2_PRS_IPV4_DIP_AI_BIT);
 
-	mvpp2_prs_tcam_ai_update(&pe, MVPP2_PRS_IPV4_DIP_AI_BIT,
-				 MVPP2_PRS_IPV4_DIP_AI_BIT);
 	/* Unmask all ports */
 	mvpp2_prs_tcam_port_map_set(&pe, MVPP2_PRS_PORT_MASK);
 
@@ -1906,7 +1941,8 @@ static int mvpp2_prs_ip6_init(struct mvpp2 *priv)
 }
 
 /* Find tcam entry with matched pair <vid,port> */
-static int mvpp2_prs_vid_range_find(struct mvpp2_port *port, u16 vid, u16 mask)
+static int mvpp2_prs_vid_range_find(struct mvpp2 *priv, int port_id, u16 vid,
+				    u16 mask)
 {
 	unsigned char byte[2], enable[2];
 	struct mvpp2_prs_entry pe;
@@ -1914,13 +1950,13 @@ static int mvpp2_prs_vid_range_find(struct mvpp2_port *port, u16 vid, u16 mask)
 	int tid;
 
 	/* Go through the all entries with MVPP2_PRS_LU_VID */
-	for (tid = MVPP2_PRS_VID_PORT_FIRST(port->id);
-	     tid <= MVPP2_PRS_VID_PORT_LAST(port->id); tid++) {
-		if (!port->priv->prs_shadow[tid].valid ||
-		    port->priv->prs_shadow[tid].lu != MVPP2_PRS_LU_VID)
+	for (tid = MVPP2_PRS_VID_PORT_FIRST(port_id);
+	     tid <= MVPP2_PRS_VID_PORT_LAST(port_id); tid++) {
+		if (!priv->prs_shadow[tid].valid ||
+		    priv->prs_shadow[tid].lu != MVPP2_PRS_LU_VID)
 			continue;
 
-		mvpp2_prs_init_from_hw(port->priv, &pe, tid);
+		mvpp2_prs_init_from_hw(priv, &pe, tid);
 
 		mvpp2_prs_tcam_data_byte_get(&pe, 2, &byte[0], &enable[0]);
 		mvpp2_prs_tcam_data_byte_get(&pe, 3, &byte[1], &enable[1]);
@@ -1950,7 +1986,7 @@ int mvpp2_prs_vid_entry_add(struct mvpp2_port *port, u16 vid)
 	memset(&pe, 0, sizeof(pe));
 
 	/* Scan TCAM and see if entry with this <vid,port> already exist */
-	tid = mvpp2_prs_vid_range_find(port, vid, mask);
+	tid = mvpp2_prs_vid_range_find(priv, port->id, vid, mask);
 
 	reg_val = mvpp2_read(priv, MVPP2_MH_REG(port->id));
 	if (reg_val & MVPP2_DSA_EXTENDED)
@@ -2008,7 +2044,7 @@ void mvpp2_prs_vid_entry_remove(struct mvpp2_port *port, u16 vid)
 	int tid;
 
 	/* Scan TCAM and see if entry with this <vid,port> already exist */
-	tid = mvpp2_prs_vid_range_find(port, vid, 0xfff);
+	tid = mvpp2_prs_vid_range_find(priv, port->id, vid, 0xfff);
 
 	/* No such entry */
 	if (tid < 0)
@@ -2026,7 +2062,8 @@ void mvpp2_prs_vid_remove_all(struct mvpp2_port *port)
 
 	for (tid = MVPP2_PRS_VID_PORT_FIRST(port->id);
 	     tid <= MVPP2_PRS_VID_PORT_LAST(port->id); tid++) {
-		if (priv->prs_shadow[tid].valid) {
+		if (priv->prs_shadow[tid].valid &&
+		    priv->prs_shadow[tid].lu == MVPP2_PRS_LU_VID) {
 			mvpp2_prs_hw_inv(priv, tid);
 			priv->prs_shadow[tid].valid = false;
 		}
diff --git a/drivers/net/ethernet/marvell/mvpp2/mvpp2_prs.h b/drivers/net/ethernet/marvell/mvpp2/mvpp2_prs.h
old mode 100644
new mode 100755
index e22f6c85d380..b3d76cdc28e0
--- a/drivers/net/ethernet/marvell/mvpp2/mvpp2_prs.h
+++ b/drivers/net/ethernet/marvell/mvpp2/mvpp2_prs.h
@@ -28,7 +28,8 @@
 #define MVPP2_PRS_IPV4_MC		0xe0
 #define MVPP2_PRS_IPV4_MC_MASK		0xf0
 #define MVPP2_PRS_IPV4_BC_MASK		0xff
-#define MVPP2_PRS_IPV4_IHL		0x5
+#define MVPP2_PRS_IPV4_IHL_MIN		0x5
+#define MVPP2_PRS_IPV4_IHL_MAX		0xf
 #define MVPP2_PRS_IPV4_IHL_MASK		0xf
 #define MVPP2_PRS_IPV6_MC		0xff
 #define MVPP2_PRS_IPV6_MC_MASK		0xff
@@ -51,6 +52,7 @@
 #define MVPP2_PRS_AI_MASK			0xff
 #define MVPP2_PRS_PORT_MASK			0xff
 #define MVPP2_PRS_LU_MASK			0xf
+#define MVPP2_PRS_WORD_MASK			0xffff
 
 /* TCAM entries in registers are accessed using 16 data bits + 16 enable bits */
 #define MVPP2_PRS_BYTE_TO_WORD(byte)	((byte) / 2)
@@ -103,10 +105,11 @@
 #define MVPP2_PE_MAC_RANGE_START	(MVPP2_PE_MAC_RANGE_END - \
 						MVPP2_PRS_MAC_RANGE_SIZE + 1)
 /* VLAN filtering range */
-#define MVPP2_PE_VID_FILT_RANGE_END     (MVPP2_PRS_TCAM_SRAM_SIZE - 31)
+#define MVPP2_PE_VID_FILT_RANGE_END     (MVPP2_PRS_TCAM_SRAM_SIZE - 32)
 #define MVPP2_PE_VID_FILT_RANGE_START   (MVPP2_PE_VID_FILT_RANGE_END - \
 					 MVPP2_PRS_VLAN_FILT_RANGE_SIZE + 1)
-#define MVPP2_PE_LAST_FREE_TID          (MVPP2_PE_MAC_RANGE_START - 1)
+#define MVPP2_PE_LAST_FREE_TID		(MVPP2_PE_MAC_RANGE_START - 1)
+#define MVPP2_PE_MH_SKIP_PRS		(MVPP2_PRS_TCAM_SRAM_SIZE - 31)
 #define MVPP2_PE_IP6_EXT_PROTO_UN	(MVPP2_PRS_TCAM_SRAM_SIZE - 30)
 #define MVPP2_PE_IP6_ADDR_UN		(MVPP2_PRS_TCAM_SRAM_SIZE - 29)
 #define MVPP2_PE_IP4_ADDR_UN		(MVPP2_PRS_TCAM_SRAM_SIZE - 28)
@@ -129,7 +132,7 @@
 #define MVPP2_PE_VID_EDSA_FLTR_DEFAULT	(MVPP2_PRS_TCAM_SRAM_SIZE - 7)
 #define MVPP2_PE_VLAN_DBL		(MVPP2_PRS_TCAM_SRAM_SIZE - 6)
 #define MVPP2_PE_VLAN_NONE		(MVPP2_PRS_TCAM_SRAM_SIZE - 5)
-/* reserved */
+#define MVPP2_PE_FC_DROP		(MVPP2_PRS_TCAM_SRAM_SIZE - 4)
 #define MVPP2_PE_MAC_MC_PROMISCUOUS	(MVPP2_PRS_TCAM_SRAM_SIZE - 3)
 #define MVPP2_PE_MAC_UC_PROMISCUOUS	(MVPP2_PRS_TCAM_SRAM_SIZE - 2)
 #define MVPP2_PE_MAC_NON_PROMISCUOUS	(MVPP2_PRS_TCAM_SRAM_SIZE - 1)
diff --git a/drivers/net/ethernet/marvell/pxa168_eth.c b/drivers/net/ethernet/marvell/pxa168_eth.c
index ff2fea0f8b75..19c53ac12a28 100644
--- a/drivers/net/ethernet/marvell/pxa168_eth.c
+++ b/drivers/net/ethernet/marvell/pxa168_eth.c
@@ -362,9 +362,9 @@ static void rxq_refill(struct net_device *dev)
 	}
 }
 
-static inline void rxq_refill_timer_wrapper(struct timer_list *t)
+static inline void rxq_refill_timer_wrapper(unsigned long data)
 {
-	struct pxa168_eth_private *pep = from_timer(pep, t, timeout);
+	struct pxa168_eth_private *pep = (void *)data;
 	napi_schedule(&pep->napi);
 }
 
@@ -1509,7 +1509,8 @@ static int pxa168_eth_probe(struct platform_device *pdev)
 	netif_napi_add(dev, &pep->napi, pxa168_rx_poll, pep->rx_ring_size);
 
 	memset(&pep->timeout, 0, sizeof(struct timer_list));
-	timer_setup(&pep->timeout, rxq_refill_timer_wrapper, 0);
+	setup_timer(&pep->timeout, rxq_refill_timer_wrapper,
+		    (unsigned long)pep);
 
 	pep->smi_bus = mdiobus_alloc();
 	if (!pep->smi_bus) {
diff --git a/drivers/net/phy/phylink.c b/drivers/net/phy/phylink.c
index 723611ac9102..3c44b15ef1ce 100644
--- a/drivers/net/phy/phylink.c
+++ b/drivers/net/phy/phylink.c
@@ -72,32 +72,6 @@ struct phylink {
 	struct sfp_bus *sfp_bus;
 };
 
-static inline void linkmode_zero(unsigned long *dst)
-{
-	bitmap_zero(dst, __ETHTOOL_LINK_MODE_MASK_NBITS);
-}
-
-static inline void linkmode_copy(unsigned long *dst, const unsigned long *src)
-{
-	bitmap_copy(dst, src, __ETHTOOL_LINK_MODE_MASK_NBITS);
-}
-
-static inline void linkmode_and(unsigned long *dst, const unsigned long *a,
-				const unsigned long *b)
-{
-	bitmap_and(dst, a, b, __ETHTOOL_LINK_MODE_MASK_NBITS);
-}
-
-static inline void linkmode_or(unsigned long *dst, const unsigned long *a,
-				const unsigned long *b)
-{
-	bitmap_or(dst, a, b, __ETHTOOL_LINK_MODE_MASK_NBITS);
-}
-
-static inline bool linkmode_empty(const unsigned long *src)
-{
-	return bitmap_empty(src, __ETHTOOL_LINK_MODE_MASK_NBITS);
-}
 
 /**
  * phylink_set_port_modes() - set the port type modes in the ethtool mask
@@ -289,7 +263,30 @@ static int phylink_parse_mode(struct phylink *pl, struct fwnode_handle *fwnode)
 			phylink_set(pl->supported, 2500baseX_Full);
 			break;
 
+		case PHY_INTERFACE_MODE_2500BASET:
+			phylink_set(pl->supported, 10baseT_Half);
+			phylink_set(pl->supported, 10baseT_Full);
+			phylink_set(pl->supported, 100baseT_Half);
+			phylink_set(pl->supported, 100baseT_Full);
+			phylink_set(pl->supported, 1000baseT_Half);
+			phylink_set(pl->supported, 1000baseT_Full);
+			phylink_set(pl->supported, 2500baseT_Full);
+			break;
+
+		case PHY_INTERFACE_MODE_5GKR:
+			phylink_set(pl->supported, 10baseT_Half);
+			phylink_set(pl->supported, 10baseT_Full);
+			phylink_set(pl->supported, 100baseT_Half);
+			phylink_set(pl->supported, 100baseT_Full);
+			phylink_set(pl->supported, 1000baseT_Half);
+			phylink_set(pl->supported, 1000baseT_Full);
+			phylink_set(pl->supported, 1000baseX_Full);
+			phylink_set(pl->supported, 2500baseT_Full);
+			phylink_set(pl->supported, 5000baseT_Full);
+			break;
+
 		case PHY_INTERFACE_MODE_10GKR:
+		case PHY_INTERFACE_MODE_INTERNAL:
 			phylink_set(pl->supported, 10baseT_Half);
 			phylink_set(pl->supported, 10baseT_Full);
 			phylink_set(pl->supported, 100baseT_Half);
@@ -483,12 +480,12 @@ static void phylink_resolve(struct work_struct *w)
 		if (!link_state.link) {
 			netif_carrier_off(ndev);
 			pl->ops->mac_link_down(ndev, pl->link_an_mode,
-					       pl->cur_interface);
+					       pl->phy_state.interface);
 			netdev_info(ndev, "Link is Down\n");
 		} else {
-			pl->cur_interface = link_state.interface;
 			pl->ops->mac_link_up(ndev, pl->link_an_mode,
-					     pl->cur_interface, pl->phydev);
+					     pl->phy_state.interface,
+					     pl->phydev);
 
 			netif_carrier_on(ndev);
 
@@ -907,6 +904,20 @@ void phylink_mac_change(struct phylink *pl, bool up)
 {
 	if (!up)
 		pl->mac_link_dropped = true;
+
+#if IS_ENABLED(CONFIG_SFP)
+	/* Make sure the event is propagated to the SFP layer. */
+	if (pl->sfp_bus && up) {
+		if (rtnl_is_locked()) {
+			sfp_link_up(pl->sfp_bus);
+		} else {
+			rtnl_lock();
+			sfp_link_up(pl->sfp_bus);
+			rtnl_unlock();
+		}
+	}
+#endif
+
 	phylink_run_resolve(pl);
 	netdev_dbg(pl->netdev, "mac link %s\n", up ? "up" : "down");
 }
@@ -1251,6 +1262,7 @@ int phylink_ethtool_set_pauseparam(struct phylink *pl,
 				   struct ethtool_pauseparam *pause)
 {
 	struct phylink_link_state *config = &pl->link_config;
+	u32 advertising = 0;
 
 	ASSERT_RTNL();
 
@@ -1262,7 +1274,7 @@ int phylink_ethtool_set_pauseparam(struct phylink *pl,
 	    !pause->autoneg && pause->rx_pause != pause->tx_pause)
 		return -EINVAL;
 
-	config->pause &= ~(MLO_PAUSE_AN | MLO_PAUSE_TXRX_MASK);
+	config->pause &= ~(MLO_PAUSE_AN | MLO_PAUSE_TXRX_MASK | MLO_PAUSE_SYM | MLO_PAUSE_ASYM);
 
 	if (pause->autoneg)
 		config->pause |= MLO_PAUSE_AN;
@@ -1271,12 +1283,38 @@ int phylink_ethtool_set_pauseparam(struct phylink *pl,
 	if (pause->tx_pause)
 		config->pause |= MLO_PAUSE_TX;
 
+	if (pause->autoneg) {
+		phylink_clear(config->advertising, Pause);
+		phylink_clear(config->advertising, Asym_Pause);
+		if (pause->rx_pause && pause->tx_pause) {
+			phylink_set(config->advertising, Pause);
+			config->pause |= MLO_PAUSE_SYM;
+		} else if (pause->tx_pause) {
+			phylink_set(config->advertising, Asym_Pause);
+			config->pause |= MLO_PAUSE_ASYM;
+		} else if (pause->rx_pause) {
+			config->pause |= (MLO_PAUSE_SYM | MLO_PAUSE_ASYM);
+			phylink_set(config->advertising, Pause);
+			phylink_set(config->advertising, Asym_Pause);
+		}
+		ethtool_convert_link_mode_to_legacy_u32(&advertising,
+							config->advertising);
+		if (pl->phydev)
+			pl->phydev->advertising = advertising;
+	}
+
 	if (!test_bit(PHYLINK_DISABLE_STOPPED, &pl->phylink_disable_state)) {
 		switch (pl->link_an_mode) {
 		case MLO_AN_PHY:
-			/* Silently mark the carrier down, and then trigger a resolve */
-			netif_carrier_off(pl->netdev);
-			phylink_run_resolve(pl);
+			if (pause->autoneg) {
+				phy_start_aneg(pl->phydev);
+			} else {
+				/* Silently mark the carrier down, and then
+				 * trigger a resolve.
+				 */
+				netif_carrier_off(pl->netdev);
+				phylink_run_resolve(pl);
+			}
 			break;
 
 		case MLO_AN_FIXED:
diff --git a/drivers/net/phy/sfp.c b/drivers/net/phy/sfp.c
index 998d08ae7431..4ad294b7c51b 100644
--- a/drivers/net/phy/sfp.c
+++ b/drivers/net/phy/sfp.c
@@ -50,6 +50,7 @@ enum {
 
 	SFP_DEV_DOWN = 0,
 	SFP_DEV_UP,
+	SFP_DEV_UNKNOWN,
 
 	SFP_S_DOWN = 0,
 	SFP_S_INIT,
@@ -163,6 +164,8 @@ static const enum gpiod_flags gpio_flags[] = {
 /* Give this long for the PHY to reset. */
 #define T_PHY_RESET_MS	50
 
+static DEFINE_MUTEX(sfp_mutex);
+
 struct sff_data {
 	unsigned int gpios;
 	bool (*module_supported)(const struct sfp_eeprom_id *id);
@@ -280,8 +283,8 @@ static int sfp_i2c_read(struct sfp *sfp, bool a2, u8 dev_addr, void *buf,
 			size_t len)
 {
 	struct i2c_msg msgs[2];
-	u8 bus_addr = a2 ? 0x51 : 0x50;
 	size_t this_len;
+	u8 bus_addr = a2 ? 0x51 : 0x50;
 	int ret;
 
 	msgs[0].addr = bus_addr;
@@ -300,7 +303,7 @@ static int sfp_i2c_read(struct sfp *sfp, bool a2, u8 dev_addr, void *buf,
 
 		msgs[1].len = this_len;
 
-		ret = i2c_transfer(sfp->i2c, msgs, ARRAY_SIZE(msgs));
+		ret = i2c_transfer(i2c, msgs, ARRAY_SIZE(msgs));
 		if (ret < 0)
 			return ret;
 
@@ -414,6 +417,7 @@ static umode_t sfp_hwmon_is_visible(const void *data,
 	switch (type) {
 	case hwmon_temp:
 		switch (attr) {
+		case hwmon_temp_input:
 		case hwmon_temp_min_alarm:
 		case hwmon_temp_max_alarm:
 		case hwmon_temp_lcrit_alarm:
@@ -422,16 +426,13 @@ static umode_t sfp_hwmon_is_visible(const void *data,
 		case hwmon_temp_max:
 		case hwmon_temp_lcrit:
 		case hwmon_temp_crit:
-			if (!(sfp->id.ext.enhopts & SFP_ENHOPTS_ALARMWARN))
-				return 0;
-			/* fall through */
-		case hwmon_temp_input:
 			return 0444;
 		default:
 			return 0;
 		}
 	case hwmon_in:
 		switch (attr) {
+		case hwmon_in_input:
 		case hwmon_in_min_alarm:
 		case hwmon_in_max_alarm:
 		case hwmon_in_lcrit_alarm:
@@ -440,16 +441,13 @@ static umode_t sfp_hwmon_is_visible(const void *data,
 		case hwmon_in_max:
 		case hwmon_in_lcrit:
 		case hwmon_in_crit:
-			if (!(sfp->id.ext.enhopts & SFP_ENHOPTS_ALARMWARN))
-				return 0;
-			/* fall through */
-		case hwmon_in_input:
 			return 0444;
 		default:
 			return 0;
 		}
 	case hwmon_curr:
 		switch (attr) {
+		case hwmon_curr_input:
 		case hwmon_curr_min_alarm:
 		case hwmon_curr_max_alarm:
 		case hwmon_curr_lcrit_alarm:
@@ -458,10 +456,6 @@ static umode_t sfp_hwmon_is_visible(const void *data,
 		case hwmon_curr_max:
 		case hwmon_curr_lcrit:
 		case hwmon_curr_crit:
-			if (!(sfp->id.ext.enhopts & SFP_ENHOPTS_ALARMWARN))
-				return 0;
-			/* fall through */
-		case hwmon_curr_input:
 			return 0444;
 		default:
 			return 0;
@@ -477,6 +471,7 @@ static umode_t sfp_hwmon_is_visible(const void *data,
 		    channel == 1)
 			return 0;
 		switch (attr) {
+		case hwmon_power_input:
 		case hwmon_power_min_alarm:
 		case hwmon_power_max_alarm:
 		case hwmon_power_lcrit_alarm:
@@ -485,10 +480,6 @@ static umode_t sfp_hwmon_is_visible(const void *data,
 		case hwmon_power_max:
 		case hwmon_power_lcrit:
 		case hwmon_power_crit:
-			if (!(sfp->id.ext.enhopts & SFP_ENHOPTS_ALARMWARN))
-				return 0;
-			/* fall through */
-		case hwmon_power_input:
 			return 0444;
 		default:
 			return 0;
@@ -514,7 +505,7 @@ static int sfp_hwmon_read_sensor(struct sfp *sfp, int reg, long *value)
 
 static void sfp_hwmon_to_rx_power(long *value)
 {
-	*value = DIV_ROUND_CLOSEST(*value, 10);
+	*value = DIV_ROUND_CLOSEST(*value, 100);
 }
 
 static void sfp_hwmon_calibrate(struct sfp *sfp, unsigned int slope, int offset,
@@ -1549,6 +1540,15 @@ static void sfp_sm_event(struct sfp *sfp, unsigned int event)
 			sfp->sm_dev_state = SFP_DEV_DOWN;
 		}
 		break;
+
+	case SFP_DEV_UNKNOWN:
+		/* We can't know the state of the SFP link. Report the
+		 * link as being up as its status has to be guessed by
+		 * other layers.
+		 */
+		if (event != SFP_E_DEV_UP)
+			sfp_link_up(sfp->sfp_bus);
+		break;
 	}
 
 	/* Some events are global */
@@ -1886,7 +1886,8 @@ static int sfp_probe(struct platform_device *pdev)
 			continue;
 
 		irq = gpiod_to_irq(sfp->gpio[i]);
-		if (!irq) {
+		if (irq < 0) {
+			irq = 0;
 			poll = true;
 			continue;
 		}
@@ -1903,6 +1904,10 @@ static int sfp_probe(struct platform_device *pdev)
 	if (poll)
 		mod_delayed_work(system_wq, &sfp->poll, poll_jiffies);
 
+	sfp->sfp_bus = sfp_register_socket(sfp->dev, sfp, &sfp_module_ops);
+	if (!sfp->sfp_bus)
+		return -ENOMEM;
+
 	/* We could have an issue in cases no Tx disable pin is available or
 	 * wired as modules using a laser as their light source will continue to
 	 * be active when the fiber is removed. This could be a safety issue and
@@ -1912,9 +1917,11 @@ static int sfp_probe(struct platform_device *pdev)
 		dev_warn(sfp->dev,
 			 "No tx_disable pin: SFP modules will always be emitting.\n");
 
-	sfp->sfp_bus = sfp_register_socket(sfp->dev, sfp, &sfp_module_ops);
-	if (!sfp->sfp_bus)
-		return -ENOMEM;
+	/* We won't be able to know the state of the SFP link, report it as
+	 * unknown.
+	 */
+	if (!sfp->gpio[GPIO_MODDEF0] && !sfp->gpio[GPIO_LOS])
+		sfp->sm_dev_state = SFP_DEV_UNKNOWN;
 
 	return 0;
 }
diff --git a/drivers/net/phy/swphy.c b/drivers/net/phy/swphy.c
index 34f58f2349e9..b430803bdb9a 100644
--- a/drivers/net/phy/swphy.c
+++ b/drivers/net/phy/swphy.c
@@ -33,6 +33,8 @@ enum {
 	SWMII_SPEED_10 = 0,
 	SWMII_SPEED_100,
 	SWMII_SPEED_1000,
+	SWMII_SPEED_2500,
+	SWMII_SPEED_10000,
 	SWMII_DUPLEX_HALF = 0,
 	SWMII_DUPLEX_FULL,
 };
@@ -77,6 +79,10 @@ static const struct swmii_regs duplex[] = {
 static int swphy_decode_speed(int speed)
 {
 	switch (speed) {
+	case 10000:
+		return SWMII_SPEED_10000;
+	case 2500:
+		return SWMII_SPEED_2500;
 	case 1000:
 		return SWMII_SPEED_1000;
 	case 100:
diff --git a/drivers/net/usb/ax88179_178a.c b/drivers/net/usb/ax88179_178a.c
index 8455f72007b9..0bffc78a4fb4 100644
--- a/drivers/net/usb/ax88179_178a.c
+++ b/drivers/net/usb/ax88179_178a.c
@@ -1404,7 +1404,6 @@ static int ax88179_rx_fixup(struct usbnet *dev, struct sk_buff *skb)
 			/* Skip IP alignment pseudo header */
 			skb_pull(skb, 2);
 			skb_set_tail_pointer(skb, skb->len);
-			skb->truesize = pkt_len + sizeof(struct sk_buff);
 			ax88179_rx_checksum(skb, pkt_hdr);
 			return 1;
 		}
@@ -1415,7 +1414,6 @@ static int ax88179_rx_fixup(struct usbnet *dev, struct sk_buff *skb)
 			/* Skip IP alignment pseudo header */
 			skb_pull(ax_skb, 2);
 			skb_set_tail_pointer(ax_skb, ax_skb->len);
-			ax_skb->truesize = pkt_len + sizeof(struct sk_buff);
 			ax88179_rx_checksum(ax_skb, pkt_hdr);
 			usbnet_skb_return(dev, ax_skb);
 		} else {
diff --git a/drivers/pci/controller/dwc/pcie-armada8k.c b/drivers/pci/controller/dwc/pcie-armada8k.c
index 0c389a30ef5d..9f56644868b5 100644
--- a/drivers/pci/controller/dwc/pcie-armada8k.c
+++ b/drivers/pci/controller/dwc/pcie-armada8k.c
@@ -22,13 +22,23 @@
 #include <linux/resource.h>
 #include <linux/of_pci.h>
 #include <linux/of_irq.h>
+#include <linux/mfd/syscon.h>
+#include <linux/regmap.h>
 
 #include "pcie-designware.h"
+#include <linux/of_gpio.h>
 
 struct armada8k_pcie {
+#define MV_A8K_PCIE_MAX_WIDTH		4
 	struct dw_pcie *pci;
 	struct clk *clk;
-	struct clk *clk_reg;
+	struct gpio_desc	*reset_gpio;
+	struct regmap *sysctrl_base;
+	u32 mac_rest_bitmask;
+	struct work_struct recover_link_work;
+	enum of_gpio_flags	flags;
+	int phy_count;
+	struct phy *comphy[MV_A8K_PCIE_MAX_WIDTH];
 };
 
 #define PCIE_VENDOR_REGS_OFFSET		0x8000
@@ -50,6 +60,10 @@ struct armada8k_pcie {
 #define PCIE_INT_C_ASSERT_MASK		BIT(11)
 #define PCIE_INT_D_ASSERT_MASK		BIT(12)
 
+#define PCIE_GLOBAL_INT_CAUSE2_REG	(PCIE_VENDOR_REGS_OFFSET + 0x24)
+#define PCIE_GLOBAL_INT_MASK2_REG	(PCIE_VENDOR_REGS_OFFSET + 0x28)
+#define PCIE_INT2_PHY_RST_LINK_DOWN	BIT(1)
+
 #define PCIE_ARCACHE_TRC_REG		(PCIE_VENDOR_REGS_OFFSET + 0x50)
 #define PCIE_AWCACHE_TRC_REG		(PCIE_VENDOR_REGS_OFFSET + 0x54)
 #define PCIE_ARUSER_REG			(PCIE_VENDOR_REGS_OFFSET + 0x5C)
@@ -65,6 +79,18 @@ struct armada8k_pcie {
 #define AX_USER_DOMAIN_MASK		0x3
 #define AX_USER_DOMAIN_SHIFT		4
 
+#define PCIE_STREAM_ID			(PCIE_VENDOR_REGS_OFFSET + 0x64)
+#define STREAM_ID_BUS_BITS		2
+#define STREAM_ID_DEV_BITS		2
+#define STREAM_ID_FUNC_BITS		3
+#define STREAM_ID_PREFIX		0x80
+#define PCIE_STREAM_ID_CFG		(STREAM_ID_PREFIX << 12 | \
+					STREAM_ID_BUS_BITS << 8 | \
+					STREAM_ID_DEV_BITS << 4 | \
+					STREAM_ID_FUNC_BITS)
+
+#define UNIT_SOFT_RESET_CONFIG_REG	0x268
+
 #define to_armada8k_pcie(x)	dev_get_drvdata((x)->dev)
 
 static int armada8k_pcie_link_up(struct dw_pcie *pci)
@@ -86,6 +112,9 @@ static void armada8k_pcie_establish_link(struct armada8k_pcie *pcie)
 	struct dw_pcie *pci = pcie->pci;
 	u32 reg;
 
+	/* Setup Requester-ID to Stream-ID mapping */
+	dw_pcie_writel_dbi(pci, PCIE_STREAM_ID, PCIE_STREAM_ID_CFG);
+
 	if (!dw_pcie_link_up(pci)) {
 		/* Disable LTSSM state machine to enable configuration */
 		reg = dw_pcie_readl_dbi(pci, PCIE_GLOBAL_CONTROL_REG);
@@ -120,6 +149,11 @@ static void armada8k_pcie_establish_link(struct armada8k_pcie *pcie)
 	       PCIE_INT_C_ASSERT_MASK | PCIE_INT_D_ASSERT_MASK;
 	dw_pcie_writel_dbi(pci, PCIE_GLOBAL_INT_MASK1_REG, reg);
 
+	/* Also enable link down interrupts */
+	reg = dw_pcie_readl_dbi(pci, PCIE_GLOBAL_INT_MASK2_REG);
+	reg |= PCIE_INT2_PHY_RST_LINK_DOWN;
+	dw_pcie_writel_dbi(pci, PCIE_GLOBAL_INT_MASK2_REG, reg);
+
 	if (!dw_pcie_link_up(pci)) {
 		/* Configuration done. Start LTSSM */
 		reg = dw_pcie_readl_dbi(pci, PCIE_GLOBAL_CONTROL_REG);
@@ -143,6 +177,71 @@ static int armada8k_pcie_host_init(struct pcie_port *pp)
 	return 0;
 }
 
+/* armada8k_pcie_reset
+ * The function implements the PCIe reset via GPIO.
+ * First, pull down the GPIO used for PCIe reset, and wait 200ms;
+ * Second, set the GPIO output value with setting from DTS, and wait
+ * 200ms for taking effect.
+ * Return: void, always success.
+ */
+static void armada8k_pcie_reset(struct armada8k_pcie *pcie)
+{
+	/* Set the reset gpio to low first */
+	gpiod_direction_output(pcie->reset_gpio, 0);
+	/* After 200ms to reset pcie */
+	mdelay(200);
+	gpiod_direction_output(pcie->reset_gpio,
+			       (pcie->flags & OF_GPIO_ACTIVE_LOW) ? 0 : 1);
+	mdelay(200);
+}
+
+static void armada8k_pcie_recover_link(struct work_struct *ws)
+{
+	struct armada8k_pcie *pcie = container_of(ws, struct armada8k_pcie,
+						  recover_link_work);
+	struct pci_bus *bus = pcie->pci->pp.root_bus;
+	struct pcie_port *pp = &pcie->pci->pp;
+	struct regmap *sysctrl_base = pcie->sysctrl_base;
+	struct pci_dev *root_port;
+	u32 reg;
+
+	root_port = pci_get_slot(bus, 0);
+	if (!root_port) {
+		dev_err(pcie->pci->dev, "failed to get root port\n");
+		return;
+	}
+	pci_lock_rescan_remove();
+	/* remove bus */
+	pci_stop_and_remove_bus_device(root_port);
+
+	/* reset endpoint */
+	if (pcie->reset_gpio)
+		armada8k_pcie_reset(pcie);
+	else
+	/*
+	 * delay is included in reset ep.
+	 * without reset ep delay needed before resetting mac.
+	 */
+		mdelay(100);
+
+	/* reset mac */
+	regmap_read(sysctrl_base,
+		    UNIT_SOFT_RESET_CONFIG_REG, &reg);
+	reg &= ~pcie->mac_rest_bitmask;
+	regmap_write(sysctrl_base,
+		     UNIT_SOFT_RESET_CONFIG_REG, reg);
+	udelay(1);
+	reg |= pcie->mac_rest_bitmask;
+	regmap_write(sysctrl_base,
+		     UNIT_SOFT_RESET_CONFIG_REG, reg);
+	udelay(1);
+	armada8k_pcie_host_init(pp);
+
+	/* rescan bus */
+	pci_rescan_bus(bus);
+	pci_unlock_rescan_remove();
+}
+
 static irqreturn_t armada8k_pcie_irq_handler(int irq, void *arg)
 {
 	struct armada8k_pcie *pcie = arg;
@@ -157,6 +256,40 @@ static irqreturn_t armada8k_pcie_irq_handler(int irq, void *arg)
 	val = dw_pcie_readl_dbi(pci, PCIE_GLOBAL_INT_CAUSE1_REG);
 	dw_pcie_writel_dbi(pci, PCIE_GLOBAL_INT_CAUSE1_REG, val);
 
+	val = dw_pcie_readl_dbi(pci, PCIE_GLOBAL_INT_CAUSE2_REG);
+
+	if (PCIE_INT2_PHY_RST_LINK_DOWN & val) {
+		u32 reg = dw_pcie_readl_dbi(pci, PCIE_GLOBAL_CONTROL_REG);
+		/*
+		 * The link went down. Disable LTSSM immediately. This
+		 * unlocks the root complex config registers. Downstream
+		 * device accesses will return all-Fs without freezing the
+		 * CPU.
+		 */
+		reg &= ~(PCIE_APP_LTSSM_EN);
+		dw_pcie_writel_dbi(pci, PCIE_GLOBAL_CONTROL_REG, reg);
+		/*
+		 * Mask link down interrupts. They can be re-enabled once
+		 * the link is retrained.
+		 */
+
+		reg = dw_pcie_readl_dbi(pci, PCIE_GLOBAL_INT_MASK2_REG);
+		reg &= ~PCIE_INT2_PHY_RST_LINK_DOWN;
+		dw_pcie_writel_dbi(pci, PCIE_GLOBAL_INT_MASK2_REG, reg);
+		/*
+		 * At this point a worker thread can be triggered to
+		 * initiate a link retrain. If link retrains were
+		 * possible, that is.
+		 */
+
+		if (pcie->sysctrl_base && pcie->mac_rest_bitmask)
+			schedule_work(&pcie->recover_link_work);
+		dev_dbg(pci->dev, "%s: link went down\n", __func__);
+	}
+
+	/* Now clear the second interrupt cause. */
+	dw_pcie_writel_dbi(pci, PCIE_GLOBAL_INT_CAUSE2_REG, val);
+
 	return IRQ_HANDLED;
 }
 
@@ -172,6 +305,7 @@ static int armada8k_add_pcie_port(struct armada8k_pcie *pcie,
 	struct device *dev = &pdev->dev;
 	int ret;
 
+	pp->root_bus_nr = -1;
 	pp->ops = &armada8k_pcie_host_ops;
 
 	pp->irq = platform_get_irq(pdev, 0);
@@ -200,12 +334,82 @@ static const struct dw_pcie_ops dw_pcie_ops = {
 	.link_up = armada8k_pcie_link_up,
 };
 
+static int armada8k_phy_config(struct platform_device *pdev,
+			       struct armada8k_pcie *pcie)
+{
+	struct phy *comphy;
+	int err;
+	int i;
+
+	pcie->phy_count = of_count_phandle_with_args(pdev->dev.of_node, "phys",
+					       "#phy-cells");
+	if (pcie->phy_count <= 0)
+		return 0;
+
+	for (i = 0; i < pcie->phy_count; i++) {
+		comphy = devm_of_phy_get_by_index(&pdev->dev,
+						  pdev->dev.of_node, i);
+		if (IS_ERR(comphy)) {
+			dev_err(&pdev->dev, "Failed to get phy %d\n", i);
+			return PTR_ERR(comphy);
+		}
+
+		pcie->comphy[i] = comphy;
+
+		switch (pcie->phy_count) {
+		case PCIE_LNK_X1:
+		case PCIE_LNK_X2:
+		case PCIE_LNK_X4:
+			phy_set_bus_width(comphy, pcie->phy_count);
+			break;
+		default:
+			dev_err(&pdev->dev, "wrong pcie width %d",
+				pcie->phy_count);
+			return -EINVAL;
+		}
+
+		err = phy_set_mode(comphy, PHY_MODE_PCIE);
+		if (err) {
+			dev_err(&pdev->dev, "failed to set comphy\n");
+			return err;
+		}
+
+		err = phy_init(comphy);
+		if (err < 0) {
+			dev_err(&pdev->dev, "phy init failed %d",
+				pcie->phy_count);
+			return err;
+		}
+
+		err = phy_power_on(comphy);
+		if (err < 0) {
+			dev_err(&pdev->dev, "phy init failed %d",
+				pcie->phy_count);
+			phy_exit(comphy);
+			return err;
+		}
+	}
+
+	return err;
+}
+
+static void armada8k_phy_deconfig(struct armada8k_pcie *pcie)
+{
+	int i;
+
+	for (i = 0; i < pcie->phy_count; i++) {
+		phy_power_off(pcie->comphy[i]);
+		phy_exit(pcie->comphy[i]);
+	}
+}
+
 static int armada8k_pcie_probe(struct platform_device *pdev)
 {
 	struct dw_pcie *pci;
 	struct armada8k_pcie *pcie;
 	struct device *dev = &pdev->dev;
 	struct resource *base;
+	int reset_gpio;
 	int ret;
 
 	pcie = devm_kzalloc(dev, sizeof(*pcie), GFP_KERNEL);
@@ -218,9 +422,10 @@ static int armada8k_pcie_probe(struct platform_device *pdev)
 
 	pci->dev = dev;
 	pci->ops = &dw_pcie_ops;
-
 	pcie->pci = pci;
 
+	INIT_WORK(&pcie->recover_link_work, armada8k_pcie_recover_link);
+
 	pcie->clk = devm_clk_get(dev, NULL);
 	if (IS_ERR(pcie->clk))
 		return PTR_ERR(pcie->clk);
@@ -229,42 +434,79 @@ static int armada8k_pcie_probe(struct platform_device *pdev)
 	if (ret)
 		return ret;
 
-	pcie->clk_reg = devm_clk_get(dev, "reg");
-	if (pcie->clk_reg == ERR_PTR(-EPROBE_DEFER)) {
-		ret = -EPROBE_DEFER;
-		goto fail;
-	}
-	if (!IS_ERR(pcie->clk_reg)) {
-		ret = clk_prepare_enable(pcie->clk_reg);
-		if (ret)
-			goto fail_clkreg;
-	}
-
 	/* Get the dw-pcie unit configuration/control registers base. */
 	base = platform_get_resource_byname(pdev, IORESOURCE_MEM, "ctrl");
 	pci->dbi_base = devm_pci_remap_cfg_resource(dev, base);
 	if (IS_ERR(pci->dbi_base)) {
 		dev_err(dev, "couldn't remap regs base %p\n", base);
 		ret = PTR_ERR(pci->dbi_base);
-		goto fail_clkreg;
+		goto fail;
+	}
+
+	/* Config reset gpio for pcie if the reset connected to gpio */
+	reset_gpio = of_get_named_gpio_flags(pdev->dev.of_node,
+					     "reset-gpio", 0,
+					     &pcie->flags);
+	if (gpio_is_valid(reset_gpio)) {
+		pcie->reset_gpio = gpio_to_desc(reset_gpio);
+		armada8k_pcie_reset(pcie);
+	}
+
+	pcie->sysctrl_base =
+		syscon_regmap_lookup_by_phandle(pdev->dev.of_node,
+						"marvell,system-controller");
+
+	ret = of_property_read_u32(pdev->dev.of_node,
+				   "mac-reset-bit-mask",
+				   &pcie->mac_rest_bitmask);
+	if (ret < 0) {
+		dev_err(dev, "couldn't find mac reset bit mask: %d\n", ret);
+		pcie->mac_rest_bitmask = 0x0;
+	}
+
+	ret = armada8k_phy_config(pdev, pcie);
+	if (ret < 0) {
+		dev_err(dev, "PHYs config failed: %d\n", ret);
+		goto fail;
 	}
 
 	platform_set_drvdata(pdev, pcie);
 
 	ret = armada8k_add_pcie_port(pcie, pdev);
 	if (ret)
-		goto fail_clkreg;
+		goto fail_phy;
 
 	return 0;
 
-fail_clkreg:
-	clk_disable_unprepare(pcie->clk_reg);
+fail_phy:
+	armada8k_phy_deconfig(pcie);
 fail:
-	clk_disable_unprepare(pcie->clk);
+	if (!IS_ERR(pcie->clk))
+		clk_disable_unprepare(pcie->clk);
 
 	return ret;
 }
 
+static int armada8k_pcie_remove(struct platform_device *pdev)
+{
+	struct armada8k_pcie *pcie = platform_get_drvdata(pdev);
+	struct dw_pcie *pci = pcie->pci;
+	struct device *dev = &pdev->dev;
+
+	cancel_work_sync(&pcie->recover_link_work);
+
+	dw_pcie_host_deinit(&pci->pp);
+
+	armada8k_phy_deconfig(pcie);
+
+	if (!IS_ERR(pcie->clk))
+		clk_disable_unprepare(pcie->clk);
+
+	dev_dbg(dev, "%s\n", __func__);
+
+	return 0;
+}
+
 static const struct of_device_id armada8k_pcie_of_match[] = {
 	{ .compatible = "marvell,armada8k-pcie", },
 	{},
@@ -272,10 +514,10 @@ static const struct of_device_id armada8k_pcie_of_match[] = {
 
 static struct platform_driver armada8k_pcie_driver = {
 	.probe		= armada8k_pcie_probe,
+	.remove		= armada8k_pcie_remove,
 	.driver = {
 		.name	= "armada8k-pcie",
 		.of_match_table = of_match_ptr(armada8k_pcie_of_match),
-		.suppress_bind_attrs = true,
 	},
 };
 builtin_platform_driver(armada8k_pcie_driver);
diff --git a/drivers/pci/controller/dwc/pcie-designware-host.c b/drivers/pci/controller/dwc/pcie-designware-host.c
index be62f654c8eb..51d299ab1c96 100644
--- a/drivers/pci/controller/dwc/pcie-designware-host.c
+++ b/drivers/pci/controller/dwc/pcie-designware-host.c
@@ -517,6 +517,28 @@ int dw_pcie_host_init(struct pcie_port *pp)
 	return ret;
 }
 
+void dw_pcie_host_deinit(struct pcie_port *pp)
+{
+	int i;
+
+	/* Everything at the dw_pcie layer is created through devres,
+	 * except for the root bus and the MSI interrupt domain.
+	 */
+	pci_stop_root_bus(pp->root_bus);
+	pci_remove_root_bus(pp->root_bus);
+
+	if (IS_ENABLED(CONFIG_PCI_MSI) && !pp->ops->msi_host_init) {
+		unsigned int virq;
+
+		for (i = 0; i < MAX_MSI_IRQS; i++) {
+			virq = irq_find_mapping(pp->irq_domain, i);
+			if (virq)
+				irq_dispose_mapping(virq);
+		}
+		irq_domain_remove(pp->irq_domain);
+	}
+}
+
 static int dw_pcie_rd_other_conf(struct pcie_port *pp, struct pci_bus *bus,
 				 u32 devfn, int where, int size, u32 *val)
 {
diff --git a/drivers/pci/controller/dwc/pcie-designware.h b/drivers/pci/controller/dwc/pcie-designware.h
index 14dcf6646699..5af5ff385f6b 100644
--- a/drivers/pci/controller/dwc/pcie-designware.h
+++ b/drivers/pci/controller/dwc/pcie-designware.h
@@ -142,6 +142,7 @@ struct dw_pcie_host_ops {
 
 struct pcie_port {
 	u8			root_bus_nr;
+	struct pci_bus		*root_bus;
 	u64			cfg0_base;
 	void __iomem		*va_cfg0_base;
 	u32			cfg0_size;
@@ -315,6 +316,7 @@ void dw_pcie_free_msi(struct pcie_port *pp);
 void dw_pcie_setup_rc(struct pcie_port *pp);
 int dw_pcie_host_init(struct pcie_port *pp);
 int dw_pcie_allocate_domains(struct pcie_port *pp);
+void dw_pcie_host_deinit(struct pcie_port *pp);
 #else
 static inline irqreturn_t dw_handle_msi_irq(struct pcie_port *pp)
 {
@@ -342,6 +344,9 @@ static inline int dw_pcie_allocate_domains(struct pcie_port *pp)
 {
 	return 0;
 }
+static inline void dw_pcie_host_deinit(struct pcie_port *pp)
+{
+}
 #endif
 
 #ifdef CONFIG_PCIE_DW_EP
diff --git a/drivers/pci/iov.c b/drivers/pci/iov.c
index c3b0b10f95cb..af96e7d2f880 100644
--- a/drivers/pci/iov.c
+++ b/drivers/pci/iov.c
@@ -25,6 +25,7 @@ int pci_iov_virtfn_bus(struct pci_dev *dev, int vf_id)
 	return dev->bus->number + ((dev->devfn + dev->sriov->offset +
 				    dev->sriov->stride * vf_id) >> 8);
 }
+EXPORT_SYMBOL_GPL(pci_iov_virtfn_bus);
 
 int pci_iov_virtfn_devfn(struct pci_dev *dev, int vf_id)
 {
@@ -33,6 +34,7 @@ int pci_iov_virtfn_devfn(struct pci_dev *dev, int vf_id)
 	return (dev->devfn + dev->sriov->offset +
 		dev->sriov->stride * vf_id) & 0xff;
 }
+EXPORT_SYMBOL_GPL(pci_iov_virtfn_devfn);
 
 /*
  * Per SR-IOV spec sec 3.3.10 and 3.3.11, First VF Offset and VF Stride may
diff --git a/drivers/pci/probe.c b/drivers/pci/probe.c
index 9a5b6a8e2502..fe25c40c11e1 100644
--- a/drivers/pci/probe.c
+++ b/drivers/pci/probe.c
@@ -1087,6 +1087,41 @@ static void pci_enable_crs(struct pci_dev *pdev)
 static unsigned int pci_scan_child_bus_extend(struct pci_bus *bus,
 					      unsigned int available_buses);
 
+/*
+ * pci_ea_fixed_busnrs() - Read fixed Secondary and Subordinate bus
+ *				numbers from EA capability
+ * @dev: Bridge with EA
+ * @secondary: updated with secondary bus number in EA
+ * @subordinate: updated with subordinate bus number in EA
+ *
+ * If it is a bridge with EA capability then fixed bus numbers are
+ * read from EA capability list and secondary and subordinate reference
+ * variables will be updated. Otherwise secondary and subordinate reference
+ * variables will be zeroed.
+ */
+static void pci_ea_fixed_busnrs(struct pci_dev *dev, u8 *secondary,
+				u8 *subordinate)
+{
+	int ea;
+	int offset;
+	u32 dw;
+
+	*secondary = *subordinate = 0;
+
+	if (dev->hdr_type != PCI_HEADER_TYPE_BRIDGE)
+		return;
+
+	/* find PCI EA capability in list */
+	ea = pci_find_capability(dev, PCI_CAP_ID_EA);
+	if (!ea)
+		return;
+
+	offset = ea + PCI_EA_FIRST_ENT;
+	pci_read_config_dword(dev, offset, &dw);
+	*secondary = dw & PCI_EA_SEC_BUS_MASK;
+	*subordinate = (dw & PCI_EA_SUB_BUS_MASK) >> PCI_EA_SUB_BUS_SHIFT;
+}
+
 /*
  * pci_scan_bridge_extend() - Scan buses behind a bridge
  * @bus: Parent bus the bridge is on
@@ -1120,6 +1155,8 @@ static int pci_scan_bridge_extend(struct pci_bus *bus, struct pci_dev *dev,
 	u16 bctl;
 	u8 primary, secondary, subordinate;
 	int broken = 0;
+	u8 fixed_sec, fixed_sub;
+	int next_busnr;
 
 	/*
 	 * Make sure the bridge is powered on to be able to access config
@@ -1219,6 +1256,18 @@ static int pci_scan_bridge_extend(struct pci_bus *bus, struct pci_dev *dev,
 		/* Clear errors */
 		pci_write_config_word(dev, PCI_STATUS, 0xffff);
 
+		/* read bus numbers from EA */
+		pci_ea_fixed_busnrs(dev, &fixed_sec, &fixed_sub);
+
+		next_busnr = max + 1;
+		/* Use secondary bus number in EA */
+		if (fixed_sec)
+			next_busnr = fixed_sec;
+
+		/* Prevent assigning a bus number that already exists.
+		 * This can happen when a bridge is hot-plugged, so in
+		 * this case we only re-scan this bus. */
+		child = pci_find_bus(pci_domain_nr(bus), next_busnr);
 		/*
 		 * Prevent assigning a bus number that already exists.
 		 * This can happen when a bridge is hot-plugged, so in this
@@ -1226,10 +1275,10 @@ static int pci_scan_bridge_extend(struct pci_bus *bus, struct pci_dev *dev,
 		 */
 		child = pci_find_bus(pci_domain_nr(bus), max+1);
 		if (!child) {
-			child = pci_add_new_bus(bus, dev, max+1);
+			child = pci_add_new_bus(bus, dev, next_busnr);
 			if (!child)
 				goto out;
-			pci_bus_insert_busn_res(child, max+1,
+			pci_bus_insert_busn_res(child, next_busnr,
 						bus->busn_res.end);
 		}
 		max++;
@@ -1290,6 +1339,14 @@ static int pci_scan_bridge_extend(struct pci_bus *bus, struct pci_dev *dev,
 			max += i;
 		}
 
+		/*
+		 * Set the subordinate bus number to its real value.
+		 * If fixed subordinate bus number exists from EA
+		 * capability then use it.
+		 */
+		if (fixed_sub)
+			max = fixed_sub;
+
 		/* Set subordinate bus number to its real value */
 		pci_bus_update_busn_res_end(child, max);
 		pci_write_config_byte(dev, PCI_SUBORDINATE_BUS, max);
diff --git a/drivers/pci/quirks.c b/drivers/pci/quirks.c
index af2149632102..8559cee5d48a 100644
--- a/drivers/pci/quirks.c
+++ b/drivers/pci/quirks.c
@@ -1020,6 +1020,88 @@ static void quirk_cavium_sriov_rnm_link(struct pci_dev *dev)
 DECLARE_PCI_FIXUP_FINAL(PCI_VENDOR_ID_CAVIUM, 0xa018, quirk_cavium_sriov_rnm_link);
 #endif
 
+#ifdef CONFIG_PCI_IOV
+/*
+ * Cavium OcteonTx needs Multibyte atomic I/O (LDST) for some devices.
+ * LDST needs LMTLINE and LMTCANCEL to be mapped along with devices,
+ * to be usable by software.
+ * Unfortunately devices like PKO and SSO don't adevertize it in their BAR's
+ * This quirks adds LMT region in to PKO and SSOW at VBAR 2.
+ */
+#define LMTLINE_SIZE	0x10000
+static void quirk_octeontx_lmtline(struct pci_dev *dev)
+{
+	struct resource *res = dev->resource + PCI_IOV_RESOURCES + 2;
+	struct pci_bus_region bus_region;
+	u16 devid;
+
+	pci_read_config_word(dev, PCI_DEVICE_ID, &devid);
+	res->name = pci_name(dev);
+	res->flags = IORESOURCE_MEM | IORESOURCE_PCI_FIXED |
+		IORESOURCE_PCI_EA_BEI;
+
+	/*
+	 * Because 83XX doesn't have a Multi node config not
+	 * included node into address.
+	 * If this changes add NODE id of the device into address.
+	 */
+	if (devid == 0xA048)
+		bus_region.start = 0x87F191000000;
+	else
+		bus_region.start = 0x87F101000000;
+
+	bus_region.end = bus_region.start + LMTLINE_SIZE - 1;
+	pcibios_bus_to_resource(dev->bus, res, &bus_region);
+
+	dev_info(&dev->dev, "quirk(LMTLINE): added at VBAR 2\n");
+}
+DECLARE_PCI_FIXUP_HEADER(PCI_VENDOR_ID_CAVIUM, 0XA048, quirk_octeontx_lmtline);
+DECLARE_PCI_FIXUP_HEADER(PCI_VENDOR_ID_CAVIUM, 0XA04C, quirk_octeontx_lmtline);
+
+/*
+ * OcteonTx 83XX has SRIOV for PKO, SSO, FPA etc etc
+ * most of them dont have a Mailbox to communicate.
+ * The proposed Resource manager desgin depends on SSO mailbox
+ * for this.
+ *
+ * Problem with these devices is PF is fully loaded,
+ * VF needs to do lot of communication with PF for things like
+ * setup, getting stats, getting link state etc.
+ * The mailbox provided by SSO is 64 bits in each direction, which  is not
+ * sufficient for this. the latencies to do a trivial task is very high.
+ * Solution is to hava a RAM based mailbox, this quirk adds a VF BAR
+ * to SSOW with 64K RAM so that VF and PF can use this to send messages.
+ * the desgin still uses SSO Mailbox for identity and sending
+ * interrupts/notifications when message is pending.
+ *
+ * Ideally the BAR should go to SSO Vf,
+ * because its already full creaing a BAR in SSOW.
+ *
+ * This patch Assumes the Firmware did appropriate changes to
+ * create a hole in RAM at address 0x1400000 with sufficient space.
+ */
+#define SSO_MBOX_BASE	0x1400000
+#define SSO_MBOX_SIZE	0x10000
+static void quirk_octeontx_ssombox(struct pci_dev *dev)
+{
+	struct resource *res = dev->resource + PCI_IOV_RESOURCES + 4;
+	struct pci_bus_region bus_region;
+	u16 devid;
+
+	pci_read_config_word(dev, PCI_DEVICE_ID, &devid);
+	res->name = pci_name(dev);
+	res->flags = IORESOURCE_MEM | IORESOURCE_PCI_FIXED |
+		IORESOURCE_PCI_EA_BEI;
+
+	bus_region.start = SSO_MBOX_BASE;
+	bus_region.end = bus_region.start + SSO_MBOX_SIZE - 1;
+	pcibios_bus_to_resource(dev->bus, res, &bus_region);
+
+	dev_info(&dev->dev, "quirk(SSO MBOX): added at BAR 4\n");
+}
+DECLARE_PCI_FIXUP_HEADER(PCI_VENDOR_ID_CAVIUM, 0XA04C, quirk_octeontx_ssombox);
+#endif
+
 /*
  * Some settings of MMRBC can lead to data corruption so block changes.
  * See AMD 8131 HyperTransport PCI-X Tunnel Revision Guide
@@ -3475,6 +3557,20 @@ DECLARE_PCI_FIXUP_HEADER(PCI_VENDOR_ID_ATHEROS, 0x0032, quirk_no_bus_reset);
 DECLARE_PCI_FIXUP_HEADER(PCI_VENDOR_ID_ATHEROS, 0x003c, quirk_no_bus_reset);
 DECLARE_PCI_FIXUP_HEADER(PCI_VENDOR_ID_ATHEROS, 0x0033, quirk_no_bus_reset);
 DECLARE_PCI_FIXUP_HEADER(PCI_VENDOR_ID_ATHEROS, 0x0034, quirk_no_bus_reset);
+/*octeontx-83xx has no FLR support.
+ * and Reset of blocks are highly dependent of each other.
+ * so lets disable bus reset and do device reset though octeontx
+ */
+DECLARE_PCI_FIXUP_HEADER(PCI_VENDOR_ID_CAVIUM, 0xa047, quirk_no_bus_reset);
+DECLARE_PCI_FIXUP_HEADER(PCI_VENDOR_ID_CAVIUM, 0xa0dd, quirk_no_bus_reset);
+DECLARE_PCI_FIXUP_HEADER(PCI_VENDOR_ID_CAVIUM, 0xa048, quirk_no_bus_reset);
+DECLARE_PCI_FIXUP_HEADER(PCI_VENDOR_ID_CAVIUM, 0xa049, quirk_no_bus_reset);
+DECLARE_PCI_FIXUP_HEADER(PCI_VENDOR_ID_CAVIUM, 0xa04a, quirk_no_bus_reset);
+DECLARE_PCI_FIXUP_HEADER(PCI_VENDOR_ID_CAVIUM, 0xa04b, quirk_no_bus_reset);
+DECLARE_PCI_FIXUP_HEADER(PCI_VENDOR_ID_CAVIUM, 0xa04c, quirk_no_bus_reset);
+DECLARE_PCI_FIXUP_HEADER(PCI_VENDOR_ID_CAVIUM, 0xa04d, quirk_no_bus_reset);
+DECLARE_PCI_FIXUP_HEADER(PCI_VENDOR_ID_CAVIUM, 0xa052, quirk_no_bus_reset);
+DECLARE_PCI_FIXUP_HEADER(PCI_VENDOR_ID_CAVIUM, 0xa053, quirk_no_bus_reset);
 
 /*
  * Root port on some Cavium CN8xxx chips do not successfully complete a bus
@@ -3773,6 +3869,102 @@ static int reset_chelsio_generic_dev(struct pci_dev *dev, int probe)
 #define PCI_DEVICE_ID_INTEL_IVB_M_VGA      0x0156
 #define PCI_DEVICE_ID_INTEL_IVB_M2_VGA     0x0166
 
+#define PCI_DEVICE_ID_OCTEONTX_SSO_VF	0xA04B
+#define PCI_DEVICE_ID_OCTEONTX_SSOW_VF	0xA04D
+#define PCI_DEVICE_ID_OCTEONTX_FPA_VF	0xA053
+#define PCI_DEVICE_ID_OCTEONTX_PKI_VF	0xA0DD
+#define PCI_DEVICE_ID_OCTEONTX_PKO_VF	0xA049
+#define PCI_DEVICE_ID_OCTEONTX_TIM_VF	0xA051
+#define PCI_DEVICE_ID_OCTEONTX_CPT_VF	0xA041
+#define PCI_DEVICE_ID_OCTEONTX_DPI_VF	0xA058
+#define PCI_DEVICE_ID_OCTEONTX_ZIP_VF	0xA037
+#define SSO_VF_VHGRPX_PF_MBOXX(x, y)	(0x200ULL | ((x) << 20) | ((y) << 3))
+#define MBOX_TRIGGER_OOB_RESET	0x01 /* OOB reset request */
+#define MBOX_TRIGGER_OOB_RES	0x80 /* OOB response mask */
+#define MBOX_OPERATION_TIMEOUT	1000 /* set timeout 1 second */
+
+enum octtx_coprocessor {
+	OCTTX_SSO,
+	OCTTX_SSOW,
+	OCTTX_FPA,
+	OCTTX_PKI,
+	OCTTX_PKO,
+	OCTTX_TIM,
+	OCTTX_CPT,
+	OCTTX_DPI,
+	OCTTX_ZIP,
+	OCTTX_COPROCESSOR_CNT
+};
+
+atomic64_t octtx_vf_reset[OCTTX_COPROCESSOR_CNT] = ATOMIC64_INIT(0);
+EXPORT_SYMBOL(octtx_vf_reset);
+
+/*
+ * Device-specific reset method for Cavium OcteonTx VF devices.
+ * It will trigger a reset of the OcteonTX domain.
+ */
+static int reset_cavium_octeon_vf(struct pci_dev *pdev, int probe)
+{
+	u64 val;
+	int vf_id;
+	int count = 2000;
+	enum octtx_coprocessor cop;
+
+	switch (pdev->device) {
+	case PCI_DEVICE_ID_OCTEONTX_SSO_VF:
+		cop = OCTTX_SSO;
+		break;
+	case PCI_DEVICE_ID_OCTEONTX_SSOW_VF:
+		cop = OCTTX_SSOW;
+		break;
+	case PCI_DEVICE_ID_OCTEONTX_FPA_VF:
+		cop = OCTTX_FPA;
+		break;
+	case PCI_DEVICE_ID_OCTEONTX_PKI_VF:
+		cop = OCTTX_PKI;
+		break;
+	case PCI_DEVICE_ID_OCTEONTX_PKO_VF:
+		cop = OCTTX_PKO;
+		break;
+	case PCI_DEVICE_ID_OCTEONTX_TIM_VF:
+		cop = OCTTX_TIM;
+		break;
+	case PCI_DEVICE_ID_OCTEONTX_CPT_VF:
+		cop = OCTTX_CPT;
+		break;
+	case PCI_DEVICE_ID_OCTEONTX_DPI_VF:
+		cop = OCTTX_DPI;
+		break;
+	case PCI_DEVICE_ID_OCTEONTX_ZIP_VF:
+		cop = OCTTX_ZIP;
+		break;
+	default:
+		return -ENOTTY;
+	}
+
+	if (probe)
+		return 0;
+
+	vf_id = pdev->devfn - 1;
+	dev_dbg(&pdev->dev, "setting 0x%p bit %d\n",
+		&octtx_vf_reset[cop], vf_id);
+	atomic64_fetch_or(1ULL << vf_id, &octtx_vf_reset[cop]);
+	/* make sure other party reads it*/
+	mb();
+
+	while (count) {
+		usleep_range(1000, 2000);
+		val = atomic_read(&octtx_vf_reset[cop]);
+		if ((val & (1ULL << vf_id)) == 0)
+			goto exit;
+		count--;
+	}
+	dev_err(&pdev->dev, "%s() reset timeout, vf_id %d, cop %u\n", __func__,
+		vf_id, cop);
+exit:
+	return 0;
+}
+
 /*
  * The Samsung SM961/PM961 controller can sometimes enter a fatal state after
  * FLR where config space reads from the device return -1.  We seem to be
@@ -3886,6 +4078,24 @@ static const struct pci_dev_reset_methods pci_dev_reset_methods[] = {
 	{ PCI_VENDOR_ID_INTEL, 0x0953, delay_250ms_after_flr },
 	{ PCI_VENDOR_ID_CHELSIO, PCI_ANY_ID,
 		reset_chelsio_generic_dev },
+	{ PCI_VENDOR_ID_CAVIUM,	PCI_DEVICE_ID_OCTEONTX_SSO_VF,
+		reset_cavium_octeon_vf },
+	{ PCI_VENDOR_ID_CAVIUM,	PCI_DEVICE_ID_OCTEONTX_SSOW_VF,
+		reset_cavium_octeon_vf },
+	{ PCI_VENDOR_ID_CAVIUM,	PCI_DEVICE_ID_OCTEONTX_FPA_VF,
+		reset_cavium_octeon_vf },
+	{ PCI_VENDOR_ID_CAVIUM,	PCI_DEVICE_ID_OCTEONTX_PKI_VF,
+		reset_cavium_octeon_vf },
+	{ PCI_VENDOR_ID_CAVIUM,	PCI_DEVICE_ID_OCTEONTX_PKO_VF,
+		reset_cavium_octeon_vf },
+	{ PCI_VENDOR_ID_CAVIUM,	PCI_DEVICE_ID_OCTEONTX_TIM_VF,
+		reset_cavium_octeon_vf },
+	{ PCI_VENDOR_ID_CAVIUM,	PCI_DEVICE_ID_OCTEONTX_CPT_VF,
+		reset_cavium_octeon_vf },
+	{ PCI_VENDOR_ID_CAVIUM,	PCI_DEVICE_ID_OCTEONTX_DPI_VF,
+		reset_cavium_octeon_vf },
+	{ PCI_VENDOR_ID_CAVIUM,	PCI_DEVICE_ID_OCTEONTX_ZIP_VF,
+		reset_cavium_octeon_vf },
 	{ 0 }
 };
 
@@ -4347,7 +4557,7 @@ static int pci_quirk_amd_sb_acs(struct pci_dev *dev, u16 acs_flags)
 
 static bool pci_quirk_cavium_acs_match(struct pci_dev *dev)
 {
-	if (!pci_is_pcie(dev) || pci_pcie_type(dev) != PCI_EXP_TYPE_ROOT_PORT)
+	if (!pci_is_pcie(dev))
 		return false;
 
 	switch (dev->device) {
@@ -4426,6 +4636,16 @@ static const u16 pci_quirk_intel_pch_acs_ids[] = {
 	0x8c90, 0x8c92, 0x8c94, 0x8c96, 0x8c98, 0x8c9a, 0x8c9c, 0x8c9e,
 };
 
+/*
+ * Some of Marvell's PCIe ports do not support ACS capability
+ * but also do not enable peer-to-peer transactions so allow them
+ * to safely use the ACS quirk
+ */
+static const u16 pci_quirk_marvell_acs_ids[] = {
+	/* Marvell CP-110 south bridge */
+	0x0110,
+};
+
 static bool pci_quirk_intel_pch_acs_match(struct pci_dev *dev)
 {
 	int i;
@@ -4552,6 +4772,21 @@ static int pci_quirk_intel_spt_pch_acs(struct pci_dev *dev, u16 acs_flags)
 	return pci_acs_ctrl_enabled(acs_flags, ctrl);
 }
 
+static int pci_quirk_marvell_acs(struct pci_dev *dev, u16 acs_flags)
+{
+	int i;
+
+	/* Filter out a few obvious non-matches first */
+	if (!pci_is_pcie(dev) || pci_pcie_type(dev) != PCI_EXP_TYPE_ROOT_PORT)
+		return false;
+
+	for (i = 0; i < ARRAY_SIZE(pci_quirk_marvell_acs_ids); i++)
+		if (pci_quirk_marvell_acs_ids[i] == dev->device)
+			return true;
+
+	return false;
+}
+
 static int pci_quirk_mf_endpoint_acs(struct pci_dev *dev, u16 acs_flags)
 {
 	/*
@@ -4673,6 +4908,8 @@ static const struct pci_dev_acs_enabled {
 	{ PCI_VENDOR_ID_INTEL, PCI_ANY_ID, pci_quirk_intel_spt_pch_acs },
 	{ 0x19a2, 0x710, pci_quirk_mf_endpoint_acs }, /* Emulex BE3-R */
 	{ 0x10df, 0x720, pci_quirk_mf_endpoint_acs }, /* Emulex Skyhawk-R */
+	/* Marvell PCIe root port */
+	{ PCI_VENDOR_ID_MARVELL, PCI_ANY_ID, pci_quirk_marvell_acs },
 	/* Cavium ThunderX */
 	{ PCI_VENDOR_ID_CAVIUM, PCI_ANY_ID, pci_quirk_cavium_acs },
 	/* APM X-Gene */
diff --git a/drivers/phy/Kconfig b/drivers/phy/Kconfig
index 5c8d452e35e2..c9d7c8dda084 100644
--- a/drivers/phy/Kconfig
+++ b/drivers/phy/Kconfig
@@ -40,6 +40,17 @@ config PHY_XGENE
 	help
 	  This option enables support for APM X-Gene SoC multi-purpose PHY.
 
+config PHY_MVEBU_UTMI
+	def_bool y
+	depends on ARCH_MVEBU
+	depends on OF
+	select GENERIC_PHY
+	help
+	  Enable this to support Marvell utmi phy driver. The utmi driver
+	  supports Armada-3700 and CP110. This driver is responsible for
+	  configuring PHY accordingly.
+
+
 source "drivers/phy/allwinner/Kconfig"
 source "drivers/phy/amlogic/Kconfig"
 source "drivers/phy/broadcom/Kconfig"
diff --git a/drivers/phy/Makefile b/drivers/phy/Makefile
index 84e3bd9c5665..02eb32205439 100644
--- a/drivers/phy/Makefile
+++ b/drivers/phy/Makefile
@@ -4,6 +4,7 @@
 #
 
 obj-$(CONFIG_GENERIC_PHY)		+= phy-core.o
+obj-$(CONFIG_PHY_MVEBU_UTMI)		+= phy-utmi-mvebu.o
 obj-$(CONFIG_PHY_LPC18XX_USB_OTG)	+= phy-lpc18xx-usb-otg.o
 obj-$(CONFIG_PHY_XGENE)			+= phy-xgene.o
 obj-$(CONFIG_PHY_PISTACHIO_USB)		+= phy-pistachio-usb.o
diff --git a/drivers/phy/allwinner/phy-sun4i-usb.c b/drivers/phy/allwinner/phy-sun4i-usb.c
index 920f61eff9cd..700b9dc823af 100644
--- a/drivers/phy/allwinner/phy-sun4i-usb.c
+++ b/drivers/phy/allwinner/phy-sun4i-usb.c
@@ -475,7 +475,8 @@ static int sun4i_usb_phy_power_off(struct phy *_phy)
 	return 0;
 }
 
-static int sun4i_usb_phy_set_mode(struct phy *_phy, enum phy_mode mode)
+static int sun4i_usb_phy_set_mode(struct phy *_phy,
+				  enum phy_mode mode, int submode)
 {
 	struct sun4i_usb_phy *phy = phy_get_drvdata(_phy);
 	struct sun4i_usb_phy_data *data = to_sun4i_usb_phy_data(phy);
diff --git a/drivers/phy/amlogic/phy-meson-gxl-usb2.c b/drivers/phy/amlogic/phy-meson-gxl-usb2.c
index 9f9b5414b97a..148ef0bdb9c1 100644
--- a/drivers/phy/amlogic/phy-meson-gxl-usb2.c
+++ b/drivers/phy/amlogic/phy-meson-gxl-usb2.c
@@ -152,7 +152,8 @@ static int phy_meson_gxl_usb2_reset(struct phy *phy)
 	return 0;
 }
 
-static int phy_meson_gxl_usb2_set_mode(struct phy *phy, enum phy_mode mode)
+static int phy_meson_gxl_usb2_set_mode(struct phy *phy,
+				       enum phy_mode mode, int submode)
 {
 	struct phy_meson_gxl_usb2_priv *priv = phy_get_drvdata(phy);
 
@@ -209,7 +210,7 @@ static int phy_meson_gxl_usb2_power_on(struct phy *phy)
 	/* power on the PHY by taking it out of reset mode */
 	regmap_update_bits(priv->regmap, U2P_R0, U2P_R0_POWER_ON_RESET, 0);
 
-	ret = phy_meson_gxl_usb2_set_mode(phy, priv->mode);
+	ret = phy_meson_gxl_usb2_set_mode(phy, priv->mode, 0);
 	if (ret) {
 		phy_meson_gxl_usb2_power_off(phy);
 
diff --git a/drivers/phy/marvell/phy-mvebu-cp110-comphy.c b/drivers/phy/marvell/phy-mvebu-cp110-comphy.c
index 86a5f7b9448b..c1c860769602 100644
--- a/drivers/phy/marvell/phy-mvebu-cp110-comphy.c
+++ b/drivers/phy/marvell/phy-mvebu-cp110-comphy.c
@@ -5,521 +5,375 @@
  * Antoine Tenart <antoine.tenart@free-electrons.com>
  */
 
+#include <linux/arm-smccc.h>
 #include <linux/io.h>
 #include <linux/iopoll.h>
 #include <linux/mfd/syscon.h>
 #include <linux/module.h>
+#include <linux/of_device.h>
+#include <linux/phy.h>
 #include <linux/phy/phy.h>
 #include <linux/platform_device.h>
-#include <linux/regmap.h>
-
-/* Relative to priv->base */
-#define MVEBU_COMPHY_SERDES_CFG0(n)		(0x0 + (n) * 0x1000)
-#define     MVEBU_COMPHY_SERDES_CFG0_PU_PLL	BIT(1)
-#define     MVEBU_COMPHY_SERDES_CFG0_GEN_RX(n)	((n) << 3)
-#define     MVEBU_COMPHY_SERDES_CFG0_GEN_TX(n)	((n) << 7)
-#define     MVEBU_COMPHY_SERDES_CFG0_PU_RX	BIT(11)
-#define     MVEBU_COMPHY_SERDES_CFG0_PU_TX	BIT(12)
-#define     MVEBU_COMPHY_SERDES_CFG0_HALF_BUS	BIT(14)
-#define MVEBU_COMPHY_SERDES_CFG1(n)		(0x4 + (n) * 0x1000)
-#define     MVEBU_COMPHY_SERDES_CFG1_RESET	BIT(3)
-#define     MVEBU_COMPHY_SERDES_CFG1_RX_INIT	BIT(4)
-#define     MVEBU_COMPHY_SERDES_CFG1_CORE_RESET	BIT(5)
-#define     MVEBU_COMPHY_SERDES_CFG1_RF_RESET	BIT(6)
-#define MVEBU_COMPHY_SERDES_CFG2(n)		(0x8 + (n) * 0x1000)
-#define     MVEBU_COMPHY_SERDES_CFG2_DFE_EN	BIT(4)
-#define MVEBU_COMPHY_SERDES_STATUS0(n)		(0x18 + (n) * 0x1000)
-#define     MVEBU_COMPHY_SERDES_STATUS0_TX_PLL_RDY	BIT(2)
-#define     MVEBU_COMPHY_SERDES_STATUS0_RX_PLL_RDY	BIT(3)
-#define     MVEBU_COMPHY_SERDES_STATUS0_RX_INIT		BIT(4)
-#define MVEBU_COMPHY_PWRPLL_CTRL(n)		(0x804 + (n) * 0x1000)
-#define     MVEBU_COMPHY_PWRPLL_CTRL_RFREQ(n)	((n) << 0)
-#define     MVEBU_COMPHY_PWRPLL_PHY_MODE(n)	((n) << 5)
-#define MVEBU_COMPHY_IMP_CAL(n)			(0x80c + (n) * 0x1000)
-#define     MVEBU_COMPHY_IMP_CAL_TX_EXT(n)	((n) << 10)
-#define     MVEBU_COMPHY_IMP_CAL_TX_EXT_EN	BIT(15)
-#define MVEBU_COMPHY_DFE_RES(n)			(0x81c + (n) * 0x1000)
-#define     MVEBU_COMPHY_DFE_RES_FORCE_GEN_TBL	BIT(15)
-#define MVEBU_COMPHY_COEF(n)			(0x828 + (n) * 0x1000)
-#define     MVEBU_COMPHY_COEF_DFE_EN		BIT(14)
-#define     MVEBU_COMPHY_COEF_DFE_CTRL		BIT(15)
-#define MVEBU_COMPHY_GEN1_S0(n)			(0x834 + (n) * 0x1000)
-#define     MVEBU_COMPHY_GEN1_S0_TX_AMP(n)	((n) << 1)
-#define     MVEBU_COMPHY_GEN1_S0_TX_EMPH(n)	((n) << 7)
-#define MVEBU_COMPHY_GEN1_S1(n)			(0x838 + (n) * 0x1000)
-#define     MVEBU_COMPHY_GEN1_S1_RX_MUL_PI(n)	((n) << 0)
-#define     MVEBU_COMPHY_GEN1_S1_RX_MUL_PF(n)	((n) << 3)
-#define     MVEBU_COMPHY_GEN1_S1_RX_MUL_FI(n)	((n) << 6)
-#define     MVEBU_COMPHY_GEN1_S1_RX_MUL_FF(n)	((n) << 8)
-#define     MVEBU_COMPHY_GEN1_S1_RX_DFE_EN	BIT(10)
-#define     MVEBU_COMPHY_GEN1_S1_RX_DIV(n)	((n) << 11)
-#define MVEBU_COMPHY_GEN1_S2(n)			(0x8f4 + (n) * 0x1000)
-#define     MVEBU_COMPHY_GEN1_S2_TX_EMPH(n)	((n) << 0)
-#define     MVEBU_COMPHY_GEN1_S2_TX_EMPH_EN	BIT(4)
-#define MVEBU_COMPHY_LOOPBACK(n)		(0x88c + (n) * 0x1000)
-#define     MVEBU_COMPHY_LOOPBACK_DBUS_WIDTH(n)	((n) << 1)
-#define MVEBU_COMPHY_VDD_CAL0(n)		(0x908 + (n) * 0x1000)
-#define     MVEBU_COMPHY_VDD_CAL0_CONT_MODE	BIT(15)
-#define MVEBU_COMPHY_EXT_SELV(n)		(0x914 + (n) * 0x1000)
-#define     MVEBU_COMPHY_EXT_SELV_RX_SAMPL(n)	((n) << 5)
-#define MVEBU_COMPHY_MISC_CTRL0(n)		(0x93c + (n) * 0x1000)
-#define     MVEBU_COMPHY_MISC_CTRL0_ICP_FORCE	BIT(5)
-#define     MVEBU_COMPHY_MISC_CTRL0_REFCLK_SEL	BIT(10)
-#define MVEBU_COMPHY_RX_CTRL1(n)		(0x940 + (n) * 0x1000)
-#define     MVEBU_COMPHY_RX_CTRL1_RXCLK2X_SEL	BIT(11)
-#define     MVEBU_COMPHY_RX_CTRL1_CLK8T_EN	BIT(12)
-#define MVEBU_COMPHY_SPEED_DIV(n)		(0x954 + (n) * 0x1000)
-#define     MVEBU_COMPHY_SPEED_DIV_TX_FORCE	BIT(7)
-#define MVEBU_SP_CALIB(n)			(0x96c + (n) * 0x1000)
-#define     MVEBU_SP_CALIB_SAMPLER(n)		((n) << 8)
-#define     MVEBU_SP_CALIB_SAMPLER_EN		BIT(12)
-#define MVEBU_COMPHY_TX_SLEW_RATE(n)		(0x974 + (n) * 0x1000)
-#define     MVEBU_COMPHY_TX_SLEW_RATE_EMPH(n)	((n) << 5)
-#define     MVEBU_COMPHY_TX_SLEW_RATE_SLC(n)	((n) << 10)
-#define MVEBU_COMPHY_DLT_CTRL(n)		(0x984 + (n) * 0x1000)
-#define     MVEBU_COMPHY_DLT_CTRL_DTL_FLOOP_EN	BIT(2)
-#define MVEBU_COMPHY_FRAME_DETECT0(n)		(0xa14 + (n) * 0x1000)
-#define     MVEBU_COMPHY_FRAME_DETECT0_PATN(n)	((n) << 7)
-#define MVEBU_COMPHY_FRAME_DETECT3(n)		(0xa20 + (n) * 0x1000)
-#define     MVEBU_COMPHY_FRAME_DETECT3_LOST_TIMEOUT_EN	BIT(12)
-#define MVEBU_COMPHY_DME(n)			(0xa28 + (n) * 0x1000)
-#define     MVEBU_COMPHY_DME_ETH_MODE		BIT(7)
-#define MVEBU_COMPHY_TRAINING0(n)		(0xa68 + (n) * 0x1000)
-#define     MVEBU_COMPHY_TRAINING0_P2P_HOLD	BIT(15)
-#define MVEBU_COMPHY_TRAINING5(n)		(0xaa4 + (n) * 0x1000)
-#define	    MVEBU_COMPHY_TRAINING5_RX_TIMER(n)	((n) << 0)
-#define MVEBU_COMPHY_TX_TRAIN_PRESET(n)		(0xb1c + (n) * 0x1000)
-#define     MVEBU_COMPHY_TX_TRAIN_PRESET_16B_AUTO_EN	BIT(8)
-#define     MVEBU_COMPHY_TX_TRAIN_PRESET_PRBS11		BIT(9)
-#define MVEBU_COMPHY_GEN1_S3(n)			(0xc40 + (n) * 0x1000)
-#define     MVEBU_COMPHY_GEN1_S3_FBCK_SEL	BIT(9)
-#define MVEBU_COMPHY_GEN1_S4(n)			(0xc44 + (n) * 0x1000)
-#define	    MVEBU_COMPHY_GEN1_S4_DFE_RES(n)	((n) << 8)
-#define MVEBU_COMPHY_TX_PRESET(n)		(0xc68 + (n) * 0x1000)
-#define     MVEBU_COMPHY_TX_PRESET_INDEX(n)	((n) << 0)
-#define MVEBU_COMPHY_GEN1_S5(n)			(0xd38 + (n) * 0x1000)
-#define     MVEBU_COMPHY_GEN1_S5_ICP(n)		((n) << 0)
-
-/* Relative to priv->regmap */
-#define MVEBU_COMPHY_CONF1(n)			(0x1000 + (n) * 0x28)
-#define     MVEBU_COMPHY_CONF1_PWRUP		BIT(1)
-#define     MVEBU_COMPHY_CONF1_USB_PCIE		BIT(2)	/* 0: Ethernet/SATA */
-#define MVEBU_COMPHY_CONF6(n)			(0x1014 + (n) * 0x28)
-#define     MVEBU_COMPHY_CONF6_40B		BIT(18)
-#define MVEBU_COMPHY_SELECTOR			0x1140
-#define     MVEBU_COMPHY_SELECTOR_PHY(n)	((n) * 0x4)
-#define MVEBU_COMPHY_PIPE_SELECTOR		0x1144
-#define     MVEBU_COMPHY_PIPE_SELECTOR_PIPE(n)	((n) * 0x4)
-
-#define MVEBU_COMPHY_LANES	6
-#define MVEBU_COMPHY_PORTS	3
+
+#include <dt-bindings/phy/phy-comphy-mvebu.h>
 
 struct mvebu_comhy_conf {
 	enum phy_mode mode;
+	int submode;
 	unsigned lane;
 	unsigned port;
-	u32 mux;
 };
 
-#define MVEBU_COMPHY_CONF(_lane, _port, _mode, _mux)	\
+#define COMPHY_FORCE_PCIE_CONFIG	BIT(21)
+
+#define MVEBU_COMPHY_CONF(_lane, _port, _mode)	\
+	{					\
+		.lane = _lane,			\
+		.port = _port,			\
+		.mode = _mode,			\
+		.submode = PHY_INTERFACE_MODE_NA,			\
+	}
+#define MVEBU_COMPHY_CONF_ETH(_lane, _port, _submode)	\
 	{						\
 		.lane = _lane,				\
 		.port = _port,				\
-		.mode = _mode,				\
-		.mux = _mux,				\
+		.mode = PHY_MODE_ETHERNET,		\
+		.submode = _submode,			\
 	}
 
+/* FW related definitions */
+
+#define MV_SIP_COMPHY_POWER_ON	0x82000001
+#define MV_SIP_COMPHY_POWER_OFF	0x82000002
+#define MV_SIP_COMPHY_PLL_LOCK	0x82000003
+#define MV_SIP_COMPHY_DIG_RESET	0x82000005
+
+#define COMPHY_FW_MODE_FORMAT(mode)		((mode) << 12)
+#define COMPHY_FW_NET_FORMAT(mode, idx, speeds)	\
+		(COMPHY_FW_MODE_FORMAT(mode) | ((idx) << 8) | ((speeds) << 2))
+
+#define COMPHY_FW_PCIE_FORMAT(pcie_width, mode, idx, speeds)	\
+		(((pcie_width) << 18) | COMPHY_FW_NET_FORMAT(mode, idx, speeds)\
+		| COMPHY_FORCE_PCIE_CONFIG)
+
+#define COMPHY_SATA_MODE	0x1
+#define COMPHY_SGMII_MODE	0x2	/* SGMII 1G */
+#define COMPHY_HS_SGMII_MODE	0x3	/* SGMII 2.5G */
+#define COMPHY_USB3H_MODE	0x4
+#define COMPHY_USB3D_MODE	0x5
+#define COMPHY_PCIE_MODE	0x6
+#define COMPHY_RXAUI_MODE	0x7
+#define COMPHY_XFI_MODE		0x8
+#define COMPHY_SFI_MODE		0x9
+#define COMPHY_USB3_MODE	0xa
+#define COMPHY_AP_MODE		0xb
+
+/* COMPHY speed macro */
+#define COMPHY_SPEED_1_25G		0 /* SGMII 1G */
+#define COMPHY_SPEED_2_5G		1
+#define COMPHY_SPEED_3_125G		2 /* SGMII 2.5G */
+#define COMPHY_SPEED_5G			3
+#define COMPHY_SPEED_5_15625G		4 /* XFI 5G */
+#define COMPHY_SPEED_6G			5
+#define COMPHY_SPEED_10_3125G		6 /* XFI 10G */
+#define COMPHY_SPEED_MAX		0x3F
+
+#define COMPHY_FW_NOT_SUPPORTED		(-1)
+
+typedef unsigned long (comphy_fn)(unsigned long, phys_addr_t,
+				  unsigned long, unsigned long);
+
+static unsigned long cp110_comphy_smc(unsigned long function_id,
+				      phys_addr_t comphy_phys_addr,
+				      unsigned long lane, unsigned long mode)
+{
+	struct arm_smccc_res res;
+
+	arm_smccc_smc(function_id, comphy_phys_addr,
+		      lane, mode, 0, 0, 0, 0, &res);
+	return res.a0;
+}
+
+static unsigned long a3700_comphy_smc(unsigned long function_id,
+				      phys_addr_t comphy_phys_addr,
+				      unsigned long lane, unsigned long mode)
+{
+	struct arm_smccc_res res;
+
+	arm_smccc_smc(function_id, lane, mode, 0, 0, 0, 0, 0, &res);
+	return res.a0;
+}
+
+static const struct mvebu_comhy_conf mvebu_comphy_a3700_modes[] = {
+	/* lane 0 */
+	MVEBU_COMPHY_CONF_ETH(0, 1, PHY_INTERFACE_MODE_SGMII),
+	MVEBU_COMPHY_CONF_ETH(0, 1, PHY_INTERFACE_MODE_2500BASEX),
+	MVEBU_COMPHY_CONF_ETH(0, 1, PHY_INTERFACE_MODE_2500BASET),
+	MVEBU_COMPHY_CONF(0, 0, PHY_MODE_USB_HOST),
+	MVEBU_COMPHY_CONF(0, 0, PHY_MODE_USB_DEVICE),
+	/* lane 1 */
+	MVEBU_COMPHY_CONF(1, 0, PHY_MODE_PCIE),
+	MVEBU_COMPHY_CONF_ETH(1, 0, PHY_INTERFACE_MODE_SGMII),
+	/* lane 2 */
+	MVEBU_COMPHY_CONF(2, 0, PHY_MODE_SATA),
+	MVEBU_COMPHY_CONF(2, 0, PHY_MODE_USB_HOST),
+	MVEBU_COMPHY_CONF(2, 0, PHY_MODE_USB_DEVICE),
+};
+
 static const struct mvebu_comhy_conf mvebu_comphy_cp110_modes[] = {
 	/* lane 0 */
-	MVEBU_COMPHY_CONF(0, 1, PHY_MODE_SGMII, 0x1),
-	MVEBU_COMPHY_CONF(0, 1, PHY_MODE_2500SGMII, 0x1),
+	MVEBU_COMPHY_CONF_ETH(0, 1, PHY_INTERFACE_MODE_SGMII),
+	MVEBU_COMPHY_CONF_ETH(0, 1, PHY_INTERFACE_MODE_2500BASEX),
+	MVEBU_COMPHY_CONF_ETH(0, 1, PHY_INTERFACE_MODE_2500BASET),
+	MVEBU_COMPHY_CONF(0, 0, PHY_MODE_PCIE),
+	MVEBU_COMPHY_CONF(0, 1, PHY_MODE_SATA),
 	/* lane 1 */
-	MVEBU_COMPHY_CONF(1, 2, PHY_MODE_SGMII, 0x1),
-	MVEBU_COMPHY_CONF(1, 2, PHY_MODE_2500SGMII, 0x1),
+	MVEBU_COMPHY_CONF_ETH(1, 2, PHY_INTERFACE_MODE_SGMII),
+	MVEBU_COMPHY_CONF_ETH(1, 2, PHY_INTERFACE_MODE_2500BASEX),
+	MVEBU_COMPHY_CONF_ETH(1, 2, PHY_INTERFACE_MODE_2500BASET),
+	MVEBU_COMPHY_CONF(1, 0, PHY_MODE_PCIE),
+	MVEBU_COMPHY_CONF(1, 0, PHY_MODE_SATA),
+	MVEBU_COMPHY_CONF(1, 0, PHY_MODE_USB_HOST),
 	/* lane 2 */
-	MVEBU_COMPHY_CONF(2, 0, PHY_MODE_SGMII, 0x1),
-	MVEBU_COMPHY_CONF(2, 0, PHY_MODE_2500SGMII, 0x1),
-	MVEBU_COMPHY_CONF(2, 0, PHY_MODE_10GKR, 0x1),
+	MVEBU_COMPHY_CONF_ETH(2, 0, PHY_INTERFACE_MODE_SGMII),
+	MVEBU_COMPHY_CONF_ETH(2, 0, PHY_INTERFACE_MODE_2500BASEX),
+	MVEBU_COMPHY_CONF_ETH(2, 0, PHY_INTERFACE_MODE_2500BASET),
+	MVEBU_COMPHY_CONF_ETH(2, 0, PHY_INTERFACE_MODE_10GKR),
+	MVEBU_COMPHY_CONF_ETH(2, 0, PHY_INTERFACE_MODE_5GKR),
+	MVEBU_COMPHY_CONF_ETH(2, 0, PHY_INTERFACE_MODE_INTERNAL),
+	MVEBU_COMPHY_CONF(2, 0, PHY_MODE_PCIE),
+	MVEBU_COMPHY_CONF(2, 0, PHY_MODE_USB_HOST),
+	MVEBU_COMPHY_CONF(2, 0, PHY_MODE_SATA),
+	MVEBU_COMPHY_CONF_ETH(2, 0, PHY_INTERFACE_MODE_RXAUI),
 	/* lane 3 */
-	MVEBU_COMPHY_CONF(3, 1, PHY_MODE_SGMII, 0x2),
-	MVEBU_COMPHY_CONF(3, 1, PHY_MODE_2500SGMII, 0x2),
+	MVEBU_COMPHY_CONF_ETH(3, 1, PHY_INTERFACE_MODE_SGMII),
+	MVEBU_COMPHY_CONF_ETH(3, 1, PHY_INTERFACE_MODE_2500BASEX),
+	MVEBU_COMPHY_CONF_ETH(3, 1, PHY_INTERFACE_MODE_2500BASET),
+	MVEBU_COMPHY_CONF(3, 0, PHY_MODE_PCIE),
+	MVEBU_COMPHY_CONF(3, 1, PHY_MODE_SATA),
+	MVEBU_COMPHY_CONF(3, 1, PHY_MODE_USB_HOST),
+	MVEBU_COMPHY_CONF_ETH(3, 0, PHY_INTERFACE_MODE_RXAUI),
 	/* lane 4 */
-	MVEBU_COMPHY_CONF(4, 0, PHY_MODE_SGMII, 0x2),
-	MVEBU_COMPHY_CONF(4, 0, PHY_MODE_2500SGMII, 0x2),
-	MVEBU_COMPHY_CONF(4, 0, PHY_MODE_10GKR, 0x2),
-	MVEBU_COMPHY_CONF(4, 1, PHY_MODE_SGMII, 0x1),
+	MVEBU_COMPHY_CONF_ETH(4, 0, PHY_INTERFACE_MODE_SGMII),
+	MVEBU_COMPHY_CONF_ETH(4, 0, PHY_INTERFACE_MODE_2500BASEX),
+	MVEBU_COMPHY_CONF_ETH(4, 1, PHY_INTERFACE_MODE_2500BASEX),
+	MVEBU_COMPHY_CONF_ETH(4, 0, PHY_INTERFACE_MODE_2500BASET),
+	MVEBU_COMPHY_CONF_ETH(4, 1, PHY_INTERFACE_MODE_2500BASET),
+	MVEBU_COMPHY_CONF_ETH(4, 0, PHY_INTERFACE_MODE_10GKR),
+	MVEBU_COMPHY_CONF_ETH(4, 1, PHY_INTERFACE_MODE_10GKR),
+	MVEBU_COMPHY_CONF_ETH(4, 0, PHY_INTERFACE_MODE_5GKR),
+	MVEBU_COMPHY_CONF_ETH(4, 0, PHY_INTERFACE_MODE_INTERNAL),
+	MVEBU_COMPHY_CONF_ETH(4, 1, PHY_INTERFACE_MODE_5GKR),
+	MVEBU_COMPHY_CONF_ETH(4, 1, PHY_INTERFACE_MODE_SGMII),
+	MVEBU_COMPHY_CONF(4, 1, PHY_MODE_PCIE),
+	MVEBU_COMPHY_CONF(4, 1, PHY_MODE_USB_HOST),
+	MVEBU_COMPHY_CONF_ETH(4, 0, PHY_INTERFACE_MODE_RXAUI),
 	/* lane 5 */
-	MVEBU_COMPHY_CONF(5, 2, PHY_MODE_SGMII, 0x1),
-	MVEBU_COMPHY_CONF(5, 2, PHY_MODE_2500SGMII, 0x1),
+	MVEBU_COMPHY_CONF_ETH(5, 2, PHY_INTERFACE_MODE_SGMII),
+	MVEBU_COMPHY_CONF_ETH(5, 2, PHY_INTERFACE_MODE_2500BASEX),
+	MVEBU_COMPHY_CONF_ETH(5, 2, PHY_INTERFACE_MODE_2500BASET),
+	MVEBU_COMPHY_CONF(5, 2, PHY_MODE_PCIE),
+	MVEBU_COMPHY_CONF(5, 1, PHY_MODE_SATA),
+	MVEBU_COMPHY_CONF_ETH(5, 0, PHY_INTERFACE_MODE_RXAUI),
+};
+
+struct mvebu_comphy_data {
+	comphy_fn *comphy_smc;
+	const struct mvebu_comhy_conf *modes;
+	size_t modes_size;
+	u8 lanes;
+	u8 ports;
 };
 
 struct mvebu_comphy_priv {
-	void __iomem *base;
-	struct regmap *regmap;
+	phys_addr_t phys;
 	struct device *dev;
+	const struct mvebu_comphy_data *data;
 };
 
 struct mvebu_comphy_lane {
 	struct mvebu_comphy_priv *priv;
 	unsigned id;
 	enum phy_mode mode;
+	int submode;
 	int port;
 };
 
-static int mvebu_comphy_get_mux(int lane, int port, enum phy_mode mode)
-{
-	int i, n = ARRAY_SIZE(mvebu_comphy_cp110_modes);
+static const struct mvebu_comphy_data a3700_data = {
+	.comphy_smc = a3700_comphy_smc,
+	.modes = mvebu_comphy_a3700_modes,
+	.modes_size = ARRAY_SIZE(mvebu_comphy_a3700_modes),
+	.lanes = 3,
+	.ports = 2,
+};
 
-	/* Unused PHY mux value is 0x0 */
-	if (mode == PHY_MODE_INVALID)
-		return 0;
+static const struct mvebu_comphy_data cp110_data = {
+	.comphy_smc = cp110_comphy_smc,
+	.modes = mvebu_comphy_cp110_modes,
+	.modes_size = ARRAY_SIZE(mvebu_comphy_cp110_modes),
+	.lanes = 6,
+	.ports = 3,
+};
 
-	for (i = 0; i < n; i++) {
-		if (mvebu_comphy_cp110_modes[i].lane == lane &&
-		    mvebu_comphy_cp110_modes[i].port == port &&
-		    mvebu_comphy_cp110_modes[i].mode == mode)
+static int mvebu_is_comphy_mode_valid(struct mvebu_comphy_lane *lane,
+				      enum phy_mode mode, int submode)
+{
+	const struct mvebu_comphy_data *data = lane->priv->data;
+	const struct mvebu_comhy_conf *modes = data->modes;
+	int i;
+
+	for (i = 0; i < data->modes_size; i++) {
+		if (modes[i].lane == lane->id &&
+		    modes[i].port == lane->port &&
+		    modes[i].mode == mode &&
+		    modes[i].submode == submode)
 			break;
 	}
 
-	if (i == n)
+	if (i == data->modes_size)
 		return -EINVAL;
 
-	return mvebu_comphy_cp110_modes[i].mux;
+	return 0;
 }
 
-static void mvebu_comphy_ethernet_init_reset(struct mvebu_comphy_lane *lane,
-					     enum phy_mode mode)
+static int mvebu_comphy_eth_get_mode(struct mvebu_comphy_lane *lane,
+				     unsigned long *comphy_mode)
 {
 	struct mvebu_comphy_priv *priv = lane->priv;
-	u32 val;
-
-	regmap_read(priv->regmap, MVEBU_COMPHY_CONF1(lane->id), &val);
-	val &= ~MVEBU_COMPHY_CONF1_USB_PCIE;
-	val |= MVEBU_COMPHY_CONF1_PWRUP;
-	regmap_write(priv->regmap, MVEBU_COMPHY_CONF1(lane->id), val);
-
-	/* Select baud rates and PLLs */
-	val = readl(priv->base + MVEBU_COMPHY_SERDES_CFG0(lane->id));
-	val &= ~(MVEBU_COMPHY_SERDES_CFG0_PU_PLL |
-		 MVEBU_COMPHY_SERDES_CFG0_PU_RX |
-		 MVEBU_COMPHY_SERDES_CFG0_PU_TX |
-		 MVEBU_COMPHY_SERDES_CFG0_HALF_BUS |
-		 MVEBU_COMPHY_SERDES_CFG0_GEN_RX(0xf) |
-		 MVEBU_COMPHY_SERDES_CFG0_GEN_TX(0xf));
-	if (mode == PHY_MODE_10GKR)
-		val |= MVEBU_COMPHY_SERDES_CFG0_GEN_RX(0xe) |
-		       MVEBU_COMPHY_SERDES_CFG0_GEN_TX(0xe);
-	else if (mode == PHY_MODE_2500SGMII)
-		val |= MVEBU_COMPHY_SERDES_CFG0_GEN_RX(0x8) |
-		       MVEBU_COMPHY_SERDES_CFG0_GEN_TX(0x8) |
-		       MVEBU_COMPHY_SERDES_CFG0_HALF_BUS;
-	else if (mode == PHY_MODE_SGMII)
-		val |= MVEBU_COMPHY_SERDES_CFG0_GEN_RX(0x6) |
-		       MVEBU_COMPHY_SERDES_CFG0_GEN_TX(0x6) |
-		       MVEBU_COMPHY_SERDES_CFG0_HALF_BUS;
-	writel(val, priv->base + MVEBU_COMPHY_SERDES_CFG0(lane->id));
-
-	/* reset */
-	val = readl(priv->base + MVEBU_COMPHY_SERDES_CFG1(lane->id));
-	val &= ~(MVEBU_COMPHY_SERDES_CFG1_RESET |
-		 MVEBU_COMPHY_SERDES_CFG1_CORE_RESET |
-		 MVEBU_COMPHY_SERDES_CFG1_RF_RESET);
-	writel(val, priv->base + MVEBU_COMPHY_SERDES_CFG1(lane->id));
-
-	/* de-assert reset */
-	val = readl(priv->base + MVEBU_COMPHY_SERDES_CFG1(lane->id));
-	val |= MVEBU_COMPHY_SERDES_CFG1_RESET |
-	       MVEBU_COMPHY_SERDES_CFG1_CORE_RESET;
-	writel(val, priv->base + MVEBU_COMPHY_SERDES_CFG1(lane->id));
-
-	/* wait until clocks are ready */
-	mdelay(1);
-
-	/* exlicitly disable 40B, the bits isn't clear on reset */
-	regmap_read(priv->regmap, MVEBU_COMPHY_CONF6(lane->id), &val);
-	val &= ~MVEBU_COMPHY_CONF6_40B;
-	regmap_write(priv->regmap, MVEBU_COMPHY_CONF6(lane->id), val);
-
-	/* refclk selection */
-	val = readl(priv->base + MVEBU_COMPHY_MISC_CTRL0(lane->id));
-	val &= ~MVEBU_COMPHY_MISC_CTRL0_REFCLK_SEL;
-	if (mode == PHY_MODE_10GKR)
-		val |= MVEBU_COMPHY_MISC_CTRL0_ICP_FORCE;
-	writel(val, priv->base + MVEBU_COMPHY_MISC_CTRL0(lane->id));
-
-	/* power and pll selection */
-	val = readl(priv->base + MVEBU_COMPHY_PWRPLL_CTRL(lane->id));
-	val &= ~(MVEBU_COMPHY_PWRPLL_CTRL_RFREQ(0x1f) |
-		 MVEBU_COMPHY_PWRPLL_PHY_MODE(0x7));
-	val |= MVEBU_COMPHY_PWRPLL_CTRL_RFREQ(0x1) |
-	       MVEBU_COMPHY_PWRPLL_PHY_MODE(0x4);
-	writel(val, priv->base + MVEBU_COMPHY_PWRPLL_CTRL(lane->id));
-
-	val = readl(priv->base + MVEBU_COMPHY_LOOPBACK(lane->id));
-	val &= ~MVEBU_COMPHY_LOOPBACK_DBUS_WIDTH(0x7);
-	val |= MVEBU_COMPHY_LOOPBACK_DBUS_WIDTH(0x1);
-	writel(val, priv->base + MVEBU_COMPHY_LOOPBACK(lane->id));
-}
 
-static int mvebu_comphy_init_plls(struct mvebu_comphy_lane *lane,
-				  enum phy_mode mode)
-{
-	struct mvebu_comphy_priv *priv = lane->priv;
-	u32 val;
-
-	/* SERDES external config */
-	val = readl(priv->base + MVEBU_COMPHY_SERDES_CFG0(lane->id));
-	val |= MVEBU_COMPHY_SERDES_CFG0_PU_PLL |
-	       MVEBU_COMPHY_SERDES_CFG0_PU_RX |
-	       MVEBU_COMPHY_SERDES_CFG0_PU_TX;
-	writel(val, priv->base + MVEBU_COMPHY_SERDES_CFG0(lane->id));
-
-	/* check rx/tx pll */
-	readl_poll_timeout(priv->base + MVEBU_COMPHY_SERDES_STATUS0(lane->id),
-			   val,
-			   val & (MVEBU_COMPHY_SERDES_STATUS0_RX_PLL_RDY |
-				  MVEBU_COMPHY_SERDES_STATUS0_TX_PLL_RDY),
-			   1000, 150000);
-	if (!(val & (MVEBU_COMPHY_SERDES_STATUS0_RX_PLL_RDY |
-		     MVEBU_COMPHY_SERDES_STATUS0_TX_PLL_RDY)))
-		return -ETIMEDOUT;
-
-	/* rx init */
-	val = readl(priv->base + MVEBU_COMPHY_SERDES_CFG1(lane->id));
-	val |= MVEBU_COMPHY_SERDES_CFG1_RX_INIT;
-	writel(val, priv->base + MVEBU_COMPHY_SERDES_CFG1(lane->id));
-
-	/* check rx */
-	readl_poll_timeout(priv->base + MVEBU_COMPHY_SERDES_STATUS0(lane->id),
-			   val, val & MVEBU_COMPHY_SERDES_STATUS0_RX_INIT,
-			   1000, 10000);
-	if (!(val & MVEBU_COMPHY_SERDES_STATUS0_RX_INIT))
-		return -ETIMEDOUT;
-
-	val = readl(priv->base + MVEBU_COMPHY_SERDES_CFG1(lane->id));
-	val &= ~MVEBU_COMPHY_SERDES_CFG1_RX_INIT;
-	writel(val, priv->base + MVEBU_COMPHY_SERDES_CFG1(lane->id));
+
+	switch (lane->submode) {
+	case PHY_INTERFACE_MODE_SGMII:
+		*comphy_mode = COMPHY_FW_NET_FORMAT(COMPHY_SGMII_MODE,
+						    lane->port,
+						    COMPHY_SPEED_1_25G);
+		break;
+	case PHY_INTERFACE_MODE_2500BASEX:
+	case PHY_INTERFACE_MODE_2500BASET:
+		*comphy_mode = COMPHY_FW_NET_FORMAT(COMPHY_HS_SGMII_MODE,
+						    lane->port,
+						    COMPHY_SPEED_3_125G);
+		break;
+	case PHY_INTERFACE_MODE_5GKR:
+		*comphy_mode = COMPHY_FW_NET_FORMAT(COMPHY_XFI_MODE,
+						    lane->port,
+						    COMPHY_SPEED_5_15625G);
+		break;
+	case PHY_INTERFACE_MODE_10GKR:
+		*comphy_mode = COMPHY_FW_NET_FORMAT(COMPHY_XFI_MODE,
+						    lane->port,
+						    COMPHY_SPEED_10_3125G);
+		break;
+	case PHY_INTERFACE_MODE_INTERNAL:
+		*comphy_mode = COMPHY_FW_NET_FORMAT(COMPHY_AP_MODE,
+						    lane->port,
+						    COMPHY_SPEED_10_3125G);
+		break;
+	case PHY_INTERFACE_MODE_RXAUI:
+		*comphy_mode = COMPHY_FW_MODE_FORMAT(COMPHY_RXAUI_MODE);
+		break;
+	default:
+		dev_err(priv->dev, "unsupported PHY submode (%d)\n",
+			lane->submode);
+		return -ENOTSUPP;
+	}
 
 	return 0;
 }
 
-static int mvebu_comphy_set_mode_sgmii(struct phy *phy, enum phy_mode mode)
+static int mvebu_comphy_eth_power_on(struct phy *phy)
 {
 	struct mvebu_comphy_lane *lane = phy_get_drvdata(phy);
 	struct mvebu_comphy_priv *priv = lane->priv;
-	u32 val;
-
-	mvebu_comphy_ethernet_init_reset(lane, mode);
-
-	val = readl(priv->base + MVEBU_COMPHY_RX_CTRL1(lane->id));
-	val &= ~MVEBU_COMPHY_RX_CTRL1_CLK8T_EN;
-	val |= MVEBU_COMPHY_RX_CTRL1_RXCLK2X_SEL;
-	writel(val, priv->base + MVEBU_COMPHY_RX_CTRL1(lane->id));
+	const struct mvebu_comphy_data *data = priv->data;
+	unsigned long comphy_mode;
+	int ret;
 
-	val = readl(priv->base + MVEBU_COMPHY_DLT_CTRL(lane->id));
-	val &= ~MVEBU_COMPHY_DLT_CTRL_DTL_FLOOP_EN;
-	writel(val, priv->base + MVEBU_COMPHY_DLT_CTRL(lane->id));
+	/* Map interface type to the ComPhy mode */
+	ret = mvebu_comphy_eth_get_mode(lane, &comphy_mode);
+	if (ret < 0)
+		return ret;
 
-	regmap_read(priv->regmap, MVEBU_COMPHY_CONF1(lane->id), &val);
-	val &= ~MVEBU_COMPHY_CONF1_USB_PCIE;
-	val |= MVEBU_COMPHY_CONF1_PWRUP;
-	regmap_write(priv->regmap, MVEBU_COMPHY_CONF1(lane->id), val);
+	/* Power on the SerDes lane */
+	ret = data->comphy_smc(MV_SIP_COMPHY_POWER_ON, priv->phys,
+			       lane->id, comphy_mode);
 
-	val = readl(priv->base + MVEBU_COMPHY_GEN1_S0(lane->id));
-	val &= ~MVEBU_COMPHY_GEN1_S0_TX_EMPH(0xf);
-	val |= MVEBU_COMPHY_GEN1_S0_TX_EMPH(0x1);
-	writel(val, priv->base + MVEBU_COMPHY_GEN1_S0(lane->id));
+	/* In case of RXAUI enable also the second lane */
+	if (lane->submode == PHY_INTERFACE_MODE_RXAUI)
+		ret |= data->comphy_smc(MV_SIP_COMPHY_POWER_ON, priv->phys,
+					lane->id + 1, comphy_mode);
 
-	return mvebu_comphy_init_plls(lane, PHY_MODE_SGMII);
+	return ret;
 }
 
-static int mvebu_comphy_set_mode_10gkr(struct phy *phy)
+static int mvebu_comphy_exit(struct phy *phy)
 {
 	struct mvebu_comphy_lane *lane = phy_get_drvdata(phy);
 	struct mvebu_comphy_priv *priv = lane->priv;
-	u32 val;
-
-	mvebu_comphy_ethernet_init_reset(lane, PHY_MODE_10GKR);
-
-	val = readl(priv->base + MVEBU_COMPHY_RX_CTRL1(lane->id));
-	val |= MVEBU_COMPHY_RX_CTRL1_RXCLK2X_SEL |
-	       MVEBU_COMPHY_RX_CTRL1_CLK8T_EN;
-	writel(val, priv->base + MVEBU_COMPHY_RX_CTRL1(lane->id));
-
-	val = readl(priv->base + MVEBU_COMPHY_DLT_CTRL(lane->id));
-	val |= MVEBU_COMPHY_DLT_CTRL_DTL_FLOOP_EN;
-	writel(val, priv->base + MVEBU_COMPHY_DLT_CTRL(lane->id));
-
-	/* Speed divider */
-	val = readl(priv->base + MVEBU_COMPHY_SPEED_DIV(lane->id));
-	val |= MVEBU_COMPHY_SPEED_DIV_TX_FORCE;
-	writel(val, priv->base + MVEBU_COMPHY_SPEED_DIV(lane->id));
-
-	val = readl(priv->base + MVEBU_COMPHY_SERDES_CFG2(lane->id));
-	val |= MVEBU_COMPHY_SERDES_CFG2_DFE_EN;
-	writel(val, priv->base + MVEBU_COMPHY_SERDES_CFG2(lane->id));
-
-	/* DFE resolution */
-	val = readl(priv->base + MVEBU_COMPHY_DFE_RES(lane->id));
-	val |= MVEBU_COMPHY_DFE_RES_FORCE_GEN_TBL;
-	writel(val, priv->base + MVEBU_COMPHY_DFE_RES(lane->id));
-
-	val = readl(priv->base + MVEBU_COMPHY_GEN1_S0(lane->id));
-	val &= ~(MVEBU_COMPHY_GEN1_S0_TX_AMP(0x1f) |
-		 MVEBU_COMPHY_GEN1_S0_TX_EMPH(0xf));
-	val |= MVEBU_COMPHY_GEN1_S0_TX_AMP(0x1c) |
-	       MVEBU_COMPHY_GEN1_S0_TX_EMPH(0xe);
-	writel(val, priv->base + MVEBU_COMPHY_GEN1_S0(lane->id));
-
-	val = readl(priv->base + MVEBU_COMPHY_GEN1_S2(lane->id));
-	val &= ~MVEBU_COMPHY_GEN1_S2_TX_EMPH(0xf);
-	val |= MVEBU_COMPHY_GEN1_S2_TX_EMPH_EN;
-	writel(val, priv->base + MVEBU_COMPHY_GEN1_S2(lane->id));
-
-	val = readl(priv->base + MVEBU_COMPHY_TX_SLEW_RATE(lane->id));
-	val |= MVEBU_COMPHY_TX_SLEW_RATE_EMPH(0x3) |
-	       MVEBU_COMPHY_TX_SLEW_RATE_SLC(0x3f);
-	writel(val, priv->base + MVEBU_COMPHY_TX_SLEW_RATE(lane->id));
-
-	/* Impedance calibration */
-	val = readl(priv->base + MVEBU_COMPHY_IMP_CAL(lane->id));
-	val &= ~MVEBU_COMPHY_IMP_CAL_TX_EXT(0x1f);
-	val |= MVEBU_COMPHY_IMP_CAL_TX_EXT(0xe) |
-	       MVEBU_COMPHY_IMP_CAL_TX_EXT_EN;
-	writel(val, priv->base + MVEBU_COMPHY_IMP_CAL(lane->id));
-
-	val = readl(priv->base + MVEBU_COMPHY_GEN1_S5(lane->id));
-	val &= ~MVEBU_COMPHY_GEN1_S5_ICP(0xf);
-	writel(val, priv->base + MVEBU_COMPHY_GEN1_S5(lane->id));
-
-	val = readl(priv->base + MVEBU_COMPHY_GEN1_S1(lane->id));
-	val &= ~(MVEBU_COMPHY_GEN1_S1_RX_MUL_PI(0x7) |
-		 MVEBU_COMPHY_GEN1_S1_RX_MUL_PF(0x7) |
-		 MVEBU_COMPHY_GEN1_S1_RX_MUL_FI(0x3) |
-		 MVEBU_COMPHY_GEN1_S1_RX_MUL_FF(0x3));
-	val |= MVEBU_COMPHY_GEN1_S1_RX_DFE_EN |
-	       MVEBU_COMPHY_GEN1_S1_RX_MUL_PI(0x2) |
-	       MVEBU_COMPHY_GEN1_S1_RX_MUL_PF(0x2) |
-	       MVEBU_COMPHY_GEN1_S1_RX_MUL_FF(0x1) |
-	       MVEBU_COMPHY_GEN1_S1_RX_DIV(0x3);
-	writel(val, priv->base + MVEBU_COMPHY_GEN1_S1(lane->id));
-
-	val = readl(priv->base + MVEBU_COMPHY_COEF(lane->id));
-	val &= ~(MVEBU_COMPHY_COEF_DFE_EN | MVEBU_COMPHY_COEF_DFE_CTRL);
-	writel(val, priv->base + MVEBU_COMPHY_COEF(lane->id));
-
-	val = readl(priv->base + MVEBU_COMPHY_GEN1_S4(lane->id));
-	val &= ~MVEBU_COMPHY_GEN1_S4_DFE_RES(0x3);
-	val |= MVEBU_COMPHY_GEN1_S4_DFE_RES(0x1);
-	writel(val, priv->base + MVEBU_COMPHY_GEN1_S4(lane->id));
-
-	val = readl(priv->base + MVEBU_COMPHY_GEN1_S3(lane->id));
-	val |= MVEBU_COMPHY_GEN1_S3_FBCK_SEL;
-	writel(val, priv->base + MVEBU_COMPHY_GEN1_S3(lane->id));
-
-	/* rx training timer */
-	val = readl(priv->base + MVEBU_COMPHY_TRAINING5(lane->id));
-	val &= ~MVEBU_COMPHY_TRAINING5_RX_TIMER(0x3ff);
-	val |= MVEBU_COMPHY_TRAINING5_RX_TIMER(0x13);
-	writel(val, priv->base + MVEBU_COMPHY_TRAINING5(lane->id));
-
-	/* tx train peak to peak hold */
-	val = readl(priv->base + MVEBU_COMPHY_TRAINING0(lane->id));
-	val |= MVEBU_COMPHY_TRAINING0_P2P_HOLD;
-	writel(val, priv->base + MVEBU_COMPHY_TRAINING0(lane->id));
-
-	val = readl(priv->base + MVEBU_COMPHY_TX_PRESET(lane->id));
-	val &= ~MVEBU_COMPHY_TX_PRESET_INDEX(0xf);
-	val |= MVEBU_COMPHY_TX_PRESET_INDEX(0x2);	/* preset coeff */
-	writel(val, priv->base + MVEBU_COMPHY_TX_PRESET(lane->id));
-
-	val = readl(priv->base + MVEBU_COMPHY_FRAME_DETECT3(lane->id));
-	val &= ~MVEBU_COMPHY_FRAME_DETECT3_LOST_TIMEOUT_EN;
-	writel(val, priv->base + MVEBU_COMPHY_FRAME_DETECT3(lane->id));
-
-	val = readl(priv->base + MVEBU_COMPHY_TX_TRAIN_PRESET(lane->id));
-	val |= MVEBU_COMPHY_TX_TRAIN_PRESET_16B_AUTO_EN |
-	       MVEBU_COMPHY_TX_TRAIN_PRESET_PRBS11;
-	writel(val, priv->base + MVEBU_COMPHY_TX_TRAIN_PRESET(lane->id));
-
-	val = readl(priv->base + MVEBU_COMPHY_FRAME_DETECT0(lane->id));
-	val &= ~MVEBU_COMPHY_FRAME_DETECT0_PATN(0x1ff);
-	val |= MVEBU_COMPHY_FRAME_DETECT0_PATN(0x88);
-	writel(val, priv->base + MVEBU_COMPHY_FRAME_DETECT0(lane->id));
-
-	val = readl(priv->base + MVEBU_COMPHY_DME(lane->id));
-	val |= MVEBU_COMPHY_DME_ETH_MODE;
-	writel(val, priv->base + MVEBU_COMPHY_DME(lane->id));
-
-	val = readl(priv->base + MVEBU_COMPHY_VDD_CAL0(lane->id));
-	val |= MVEBU_COMPHY_VDD_CAL0_CONT_MODE;
-	writel(val, priv->base + MVEBU_COMPHY_VDD_CAL0(lane->id));
-
-	val = readl(priv->base + MVEBU_SP_CALIB(lane->id));
-	val &= ~MVEBU_SP_CALIB_SAMPLER(0x3);
-	val |= MVEBU_SP_CALIB_SAMPLER(0x3) |
-	       MVEBU_SP_CALIB_SAMPLER_EN;
-	writel(val, priv->base + MVEBU_SP_CALIB(lane->id));
-	val &= ~MVEBU_SP_CALIB_SAMPLER_EN;
-	writel(val, priv->base + MVEBU_SP_CALIB(lane->id));
-
-	/* External rx regulator */
-	val = readl(priv->base + MVEBU_COMPHY_EXT_SELV(lane->id));
-	val &= ~MVEBU_COMPHY_EXT_SELV_RX_SAMPL(0x1f);
-	val |= MVEBU_COMPHY_EXT_SELV_RX_SAMPL(0x1a);
-	writel(val, priv->base + MVEBU_COMPHY_EXT_SELV(lane->id));
-
-	return mvebu_comphy_init_plls(lane, PHY_MODE_10GKR);
+
+	dev_dbg(priv->dev, "phy exited (lane %u port %u)\n",
+		lane->id, lane->port);
+
+	/* Let the port go. */
+	lane->port = -1;
+
+	return 0;
 }
 
 static int mvebu_comphy_power_on(struct phy *phy)
 {
 	struct mvebu_comphy_lane *lane = phy_get_drvdata(phy);
 	struct mvebu_comphy_priv *priv = lane->priv;
-	int ret, mux;
-	u32 val;
-
-	mux = mvebu_comphy_get_mux(lane->id, lane->port, lane->mode);
-	if (mux < 0)
-		return -ENOTSUPP;
-
-	regmap_read(priv->regmap, MVEBU_COMPHY_PIPE_SELECTOR, &val);
-	val &= ~(0xf << MVEBU_COMPHY_PIPE_SELECTOR_PIPE(lane->id));
-	regmap_write(priv->regmap, MVEBU_COMPHY_PIPE_SELECTOR, val);
-
-	regmap_read(priv->regmap, MVEBU_COMPHY_SELECTOR, &val);
-	val &= ~(0xf << MVEBU_COMPHY_SELECTOR_PHY(lane->id));
-	val |= mux << MVEBU_COMPHY_SELECTOR_PHY(lane->id);
-	regmap_write(priv->regmap, MVEBU_COMPHY_SELECTOR, val);
+	const struct mvebu_comphy_data *data = priv->data;
+	int ret;
 
 	switch (lane->mode) {
-	case PHY_MODE_SGMII:
-	case PHY_MODE_2500SGMII:
-		ret = mvebu_comphy_set_mode_sgmii(phy, lane->mode);
+	case PHY_MODE_PCIE:
+		ret = data->comphy_smc(MV_SIP_COMPHY_POWER_ON, priv->phys,
+				 lane->id,
+				 COMPHY_FW_PCIE_FORMAT(phy->attrs.bus_width,
+						       COMPHY_PCIE_MODE,
+						       lane->port,
+						       COMPHY_SPEED_5G));
+		break;
+	case PHY_MODE_SATA:
+		ret = data->comphy_smc(MV_SIP_COMPHY_POWER_ON, priv->phys,
+				 lane->id,
+				 COMPHY_FW_MODE_FORMAT(COMPHY_SATA_MODE));
 		break;
-	case PHY_MODE_10GKR:
-		ret = mvebu_comphy_set_mode_10gkr(phy);
+	case PHY_MODE_USB_HOST:
+		ret = data->comphy_smc(MV_SIP_COMPHY_POWER_ON, priv->phys,
+				 lane->id,
+				 COMPHY_FW_MODE_FORMAT(COMPHY_USB3H_MODE));
+		break;
+	case PHY_MODE_ETHERNET:
+		ret = mvebu_comphy_eth_power_on(phy);
 		break;
 	default:
 		return -ENOTSUPP;
 	}
 
-	/* digital reset */
-	val = readl(priv->base + MVEBU_COMPHY_SERDES_CFG1(lane->id));
-	val |= MVEBU_COMPHY_SERDES_CFG1_RF_RESET;
-	writel(val, priv->base + MVEBU_COMPHY_SERDES_CFG1(lane->id));
+	dev_dbg(priv->dev, "%s: smc returned %d\n", __func__, ret);
 
 	return ret;
 }
 
-static int mvebu_comphy_set_mode(struct phy *phy, enum phy_mode mode)
+static int mvebu_comphy_set_mode(struct phy *phy,
+				 enum phy_mode mode, int submode)
 {
 	struct mvebu_comphy_lane *lane = phy_get_drvdata(phy);
 
-	if (mvebu_comphy_get_mux(lane->id, lane->port, mode) < 0)
+	if (submode == PHY_INTERFACE_MODE_1000BASEX)
+		submode = PHY_INTERFACE_MODE_SGMII;
+
+	if (mvebu_is_comphy_mode_valid(lane, mode, submode) < 0) {
+		dev_dbg(&phy->dev, "invalid mode %d or submode %d for lane %d\n",
+		       mode, submode, lane->id);
 		return -EINVAL;
+	}
 
 	lane->mode = mode;
+	lane->submode = submode;
 	return 0;
 }
 
@@ -527,29 +381,54 @@ static int mvebu_comphy_power_off(struct phy *phy)
 {
 	struct mvebu_comphy_lane *lane = phy_get_drvdata(phy);
 	struct mvebu_comphy_priv *priv = lane->priv;
-	u32 val;
+	const struct mvebu_comphy_data *data = priv->data;
 
-	val = readl(priv->base + MVEBU_COMPHY_SERDES_CFG1(lane->id));
-	val &= ~(MVEBU_COMPHY_SERDES_CFG1_RESET |
-		 MVEBU_COMPHY_SERDES_CFG1_CORE_RESET |
-		 MVEBU_COMPHY_SERDES_CFG1_RF_RESET);
-	writel(val, priv->base + MVEBU_COMPHY_SERDES_CFG1(lane->id));
-
-	regmap_read(priv->regmap, MVEBU_COMPHY_SELECTOR, &val);
-	val &= ~(0xf << MVEBU_COMPHY_SELECTOR_PHY(lane->id));
-	regmap_write(priv->regmap, MVEBU_COMPHY_SELECTOR, val);
+	return data->comphy_smc(MV_SIP_COMPHY_POWER_OFF, priv->phys,
+				lane->id, COMPHY_FORCE_PCIE_CONFIG);
+}
 
-	regmap_read(priv->regmap, MVEBU_COMPHY_PIPE_SELECTOR, &val);
-	val &= ~(0xf << MVEBU_COMPHY_PIPE_SELECTOR_PIPE(lane->id));
-	regmap_write(priv->regmap, MVEBU_COMPHY_PIPE_SELECTOR, val);
+static int mvebu_comphy_send_command(struct phy *phy, u32 command)
+{
+	struct mvebu_comphy_lane *lane = phy_get_drvdata(phy);
+	struct mvebu_comphy_priv *priv = lane->priv;
+	const struct mvebu_comphy_data *data = priv->data;
+	unsigned long comphy_mode;
+	int ret = 0;
+
+	switch (command) {
+	case (COMPHY_COMMAND_DIGITAL_PWR_OFF):
+	case (COMPHY_COMMAND_DIGITAL_PWR_ON):
+		/* Map interface type to the ComPhy mode */
+		ret = mvebu_comphy_eth_get_mode(lane, &comphy_mode);
+		if (ret < 0)
+			return ret;
+
+		/* Perform digital reset of the SerDes lane */
+		ret = data->comphy_smc(MV_SIP_COMPHY_DIG_RESET, priv->phys,
+				       lane->id, comphy_mode);
+		if (ret < 0)
+			dev_err(priv->dev, "%s: smc returned %d\n",
+				__func__, ret);
+		break;
+	default:
+		dev_err(priv->dev, "%s: unsupported command (0x%x)\n",
+			__func__, command);
+		ret = -EINVAL;
+	}
 
-	return 0;
+	return ret;
 }
 
 static const struct phy_ops mvebu_comphy_ops = {
+	.exit           = mvebu_comphy_exit,
 	.power_on	= mvebu_comphy_power_on,
 	.power_off	= mvebu_comphy_power_off,
 	.set_mode	= mvebu_comphy_set_mode,
+	.send_command	= mvebu_comphy_send_command,
+	.owner		= THIS_MODULE,
+};
+
+static const struct phy_ops mvebu_comphy_ops_deprecated = {
 	.owner		= THIS_MODULE,
 };
 
@@ -557,9 +436,12 @@ static struct phy *mvebu_comphy_xlate(struct device *dev,
 				      struct of_phandle_args *args)
 {
 	struct mvebu_comphy_lane *lane;
+	struct mvebu_comphy_priv *priv;
 	struct phy *phy;
 
-	if (WARN_ON(args->args[0] >= MVEBU_COMPHY_PORTS))
+	priv = dev_get_drvdata(dev);
+
+	if (WARN_ON(args->args[0] >= priv->data->ports))
 		return ERR_PTR(-EINVAL);
 
 	phy = of_phy_simple_xlate(dev, args);
@@ -567,8 +449,6 @@ static struct phy *mvebu_comphy_xlate(struct device *dev,
 		return phy;
 
 	lane = phy_get_drvdata(phy);
-	if (lane->port >= 0)
-		return ERR_PTR(-EBUSY);
 	lane->port = args->args[0];
 
 	return phy;
@@ -577,24 +457,40 @@ static struct phy *mvebu_comphy_xlate(struct device *dev,
 static int mvebu_comphy_probe(struct platform_device *pdev)
 {
 	struct mvebu_comphy_priv *priv;
+	const struct mvebu_comphy_data *data;
 	struct phy_provider *provider;
 	struct device_node *child;
 	struct resource *res;
+	int i;
 
 	priv = devm_kzalloc(&pdev->dev, sizeof(*priv), GFP_KERNEL);
 	if (!priv)
 		return -ENOMEM;
 
+	data = of_device_get_match_data(&pdev->dev);
+	priv->data = data;
+
 	priv->dev = &pdev->dev;
-	priv->regmap =
-		syscon_regmap_lookup_by_phandle(pdev->dev.of_node,
-						"marvell,system-controller");
-	if (IS_ERR(priv->regmap))
-		return PTR_ERR(priv->regmap);
-	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
-	priv->base = devm_ioremap_resource(&pdev->dev, res);
-	if (IS_ERR(priv->base))
-		return PTR_ERR(priv->base);
+
+	/*
+	 * Request all resources declared in dts for this driver, even if they
+	 * are not used explicit by this driver. This will prevent other Linux
+	 * drivers from accessing comphy register range, and therefore prevent
+	 * concurrent access with FW, which handles comphy initialization via RT
+	 * services.
+	 */
+	for (i = 0; i < pdev->num_resources; i++) {
+		res = platform_get_resource(pdev, IORESOURCE_MEM, i);
+
+		if (i == 0)
+			priv->phys = res->start;
+
+		if (!devm_request_mem_region(&pdev->dev, res->start,
+					     resource_size(res), res->name)) {
+			dev_err(&pdev->dev, "resource %s busy\n", res->name);
+			return -EBUSY;
+		}
+	}
 
 	for_each_available_child_of_node(pdev->dev.of_node, child) {
 		struct mvebu_comphy_lane *lane;
@@ -609,7 +505,7 @@ static int mvebu_comphy_probe(struct platform_device *pdev)
 			continue;
 		}
 
-		if (val >= MVEBU_COMPHY_LANES) {
+		if (val >= data->lanes) {
 			dev_err(&pdev->dev, "invalid 'reg' property\n");
 			continue;
 		}
@@ -628,11 +524,29 @@ static int mvebu_comphy_probe(struct platform_device *pdev)
 		lane->port = -1;
 		phy_set_drvdata(phy, lane);
 
+		if (of_get_property(phy->dev.of_node, "phy-skip-config", NULL))
+			continue;
+
 		/*
-		 * Once all modes are supported in this driver we should call
-		 * mvebu_comphy_power_off(phy) here to avoid relying on the
-		 * bootloader/firmware configuration.
+		 * To avoid relying on the bootloader/firmware configuration,
+		 * power off all comphys.
 		 */
+		ret = mvebu_comphy_power_off(phy);
+		if (ret == COMPHY_FW_NOT_SUPPORTED) {
+			dev_warn(&pdev->dev, "RELYING ON BOTLOADER SETTINGS\n");
+			dev_WARN(&pdev->dev, "firmware updated needed\n");
+
+			/*
+			 * If comphy power off fails it means that the
+			 * deprecated firmware is used and we should rely on
+			 * bootloader settings, therefore we are switching to
+			 * empty ops.
+			 */
+			phy_destroy(phy);
+			phy = devm_phy_create(&pdev->dev, child,
+					      &mvebu_comphy_ops_deprecated);
+			phy_set_drvdata(phy, lane);
+		}
 	}
 
 	dev_set_drvdata(&pdev->dev, priv);
@@ -642,7 +556,14 @@ static int mvebu_comphy_probe(struct platform_device *pdev)
 }
 
 static const struct of_device_id mvebu_comphy_of_match_table[] = {
-	{ .compatible = "marvell,comphy-cp110" },
+	{
+		.compatible = "marvell,comphy-cp110",
+		.data = &cp110_data,
+	},
+	{
+		.compatible = "marvell,comphy-a3700",
+		.data = &a3700_data,
+	},
 	{ },
 };
 MODULE_DEVICE_TABLE(of, mvebu_comphy_of_match_table);
@@ -656,6 +577,6 @@ static struct platform_driver mvebu_comphy_driver = {
 };
 module_platform_driver(mvebu_comphy_driver);
 
-MODULE_AUTHOR("Antoine Tenart <antoine.tenart@free-electrons.com>");
+MODULE_AUTHOR("Antoine Tenart <antoine.tenart@free-electrons.com>, Grzegorz Jaszczyk <jaz@semihalf.com>");
 MODULE_DESCRIPTION("Common PHY driver for mvebu SoCs");
 MODULE_LICENSE("GPL v2");
diff --git a/drivers/phy/phy-core.c b/drivers/phy/phy-core.c
index 35fd38c5a4a1..6f6806ff3e57 100644
--- a/drivers/phy/phy-core.c
+++ b/drivers/phy/phy-core.c
@@ -360,7 +360,7 @@ int phy_power_off(struct phy *phy)
 }
 EXPORT_SYMBOL_GPL(phy_power_off);
 
-int phy_set_mode(struct phy *phy, enum phy_mode mode)
+int phy_set_mode_ext(struct phy *phy, enum phy_mode mode, int submode)
 {
 	int ret;
 
@@ -368,14 +368,14 @@ int phy_set_mode(struct phy *phy, enum phy_mode mode)
 		return 0;
 
 	mutex_lock(&phy->mutex);
-	ret = phy->ops->set_mode(phy, mode);
+	ret = phy->ops->set_mode(phy, mode, submode);
 	if (!ret)
 		phy->attrs.mode = mode;
 	mutex_unlock(&phy->mutex);
 
 	return ret;
 }
-EXPORT_SYMBOL_GPL(phy_set_mode);
+EXPORT_SYMBOL_GPL(phy_set_mode_ext);
 
 int phy_reset(struct phy *phy)
 {
@@ -407,6 +407,21 @@ int phy_calibrate(struct phy *phy)
 }
 EXPORT_SYMBOL_GPL(phy_calibrate);
 
+int phy_send_command(struct phy *phy, u32 command)
+{
+	int ret;
+
+	if (!phy || !phy->ops->send_command)
+		return 0;
+
+	mutex_lock(&phy->mutex);
+	ret = phy->ops->send_command(phy, command);
+	mutex_unlock(&phy->mutex);
+
+	return ret;
+}
+EXPORT_SYMBOL_GPL(phy_send_command);
+
 /**
  * _of_phy_get() - lookup and obtain a reference to a phy by phandle
  * @np: device_node for which to get the phy
diff --git a/drivers/phy/phy-utmi-mvebu.c b/drivers/phy/phy-utmi-mvebu.c
new file mode 100644
index 000000000000..9bc8ba67b679
--- /dev/null
+++ b/drivers/phy/phy-utmi-mvebu.c
@@ -0,0 +1,664 @@
+/*
+ * Marvell UTMI PHY driver
+ *
+ * Copyright (C) 2018 Marvell
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ */
+
+#include <linux/delay.h>
+#include <linux/io.h>
+#include <linux/module.h>
+#include <linux/of_device.h>
+#include <linux/phy/phy.h>
+#include <linux/platform_device.h>
+#include <linux/of_address.h>
+#include <dt-bindings/phy/phy-utmi-mvebu.h>
+
+/* SoC Armada 37xx UTMI register macro definetions */
+#define USB2_PHY_PLL_CTRL_REG0		(0x0)
+#define PLL_REF_DIV_OFF			(0)
+#define PLL_REF_DIV_MASK		(0x7F << PLL_REF_DIV_OFF)
+#define PLL_REF_DIV_5			(0x5)
+#define PLL_FB_DIV_OFF			(16)
+#define PLL_FB_DIV_MASK			(0x1FF << PLL_FB_DIV_OFF)
+#define PLL_FB_DIV_96			(96)
+#define PLL_SEL_LPFR_OFF		(28)
+#define PLL_SEL_LPFR_MASK		(0x3 << PLL_SEL_LPFR_OFF)
+#define PLL_READY			BIT(31)
+/* Both UTMI PHY and UTMI OTG PHY */
+#define USB2_PHY_CAL_CTRL_ADDR		(0x8)
+#define PHY_PLLCAL_DONE			BIT(31)
+#define PHY_IMPCAL_DONE			BIT(23)
+#define USB2_RX_CHAN_CTRL1_ADDR		(0x18)
+#define USB2PHY_SQCAL_DONE		BIT(31)
+#define USB2_PHY_OTG_CTRL_ADDR		(0x34)
+#define PHY_PU_OTG			BIT(4)
+#define USB2_PHY_CHRGR_DET_ADDR		(0x38)
+#define PHY_CDP_EN			BIT(2)
+#define PHY_DCP_EN			BIT(3)
+#define PHY_PD_EN			BIT(4)
+#define PHY_PU_CHRG_DTC			BIT(5)
+#define PHY_CDP_DM_AUTO			BIT(7)
+#define PHY_ENSWITCH_DP			BIT(12)
+#define PHY_ENSWITCH_DM			BIT(13)
+#define USB2_PHY2_CTRL_ADDR		(0x804)
+#define USB2_PHY2_SUSPM			BIT(7)
+#define USB2_PHY2_PU			BIT(0)
+#define USB2_OTG_PHY_CTRL_ADDR		(0x820)
+#define USB2_OTGPHY2_SUSPM		BIT(14)
+#define USB2_OTGPHY2_PU			BIT(0)
+#define USB2_DP_PULLDN_DEV_MODE		BIT(5)
+#define USB2_DM_PULLDN_DEV_MODE		BIT(6)
+
+#define USB2_PHY_CTRL_ADDR(usb32) (usb32 == 0 ? USB2_PHY2_CTRL_ADDR :\
+						USB2_OTG_PHY_CTRL_ADDR)
+#define RB_USB2PHY_SUSPM(usb32) (usb32 == 0 ? USB2_PHY2_SUSPM :\
+						USB2_OTGPHY2_SUSPM)
+#define RB_USB2PHY_PU(usb32) (usb32 == 0 ? USB2_PHY2_PU : USB2_OTGPHY2_PU)
+
+/* CP110 UTMI register macro definetions */
+#define UTMI_USB_CFG_DEVICE_EN_OFFSET		0
+#define UTMI_USB_CFG_DEVICE_EN_MASK		\
+	(0x1 << UTMI_USB_CFG_DEVICE_EN_OFFSET)
+#define UTMI_USB_CFG_DEVICE_MUX_OFFSET		1
+#define UTMI_USB_CFG_DEVICE_MUX_MASK		\
+	(0x1 << UTMI_USB_CFG_DEVICE_MUX_OFFSET)
+#define UTMI_USB_CFG_PLL_OFFSET			25
+#define UTMI_USB_CFG_PLL_MASK			\
+	(0x1 << UTMI_USB_CFG_PLL_OFFSET)
+#define UTMI_PHY_CFG_PU_OFFSET			5
+#define UTMI_PHY_CFG_PU_MASK			\
+	(0x1 << UTMI_PHY_CFG_PU_OFFSET)
+#define UTMI_PLL_CTRL_REG			0x0
+#define UTMI_PLL_CTRL_REFDIV_OFFSET		0
+#define UTMI_PLL_CTRL_REFDIV_MASK		\
+	(0x7f << UTMI_PLL_CTRL_REFDIV_OFFSET)
+#define UTMI_PLL_CTRL_FBDIV_OFFSET		16
+#define UTMI_PLL_CTRL_FBDIV_MASK		\
+	(0x1FF << UTMI_PLL_CTRL_FBDIV_OFFSET)
+#define UTMI_PLL_CTRL_SEL_LPFR_OFFSET		28
+#define UTMI_PLL_CTRL_SEL_LPFR_MASK		\
+	(0x3 << UTMI_PLL_CTRL_SEL_LPFR_OFFSET)
+#define UTMI_PLL_CTRL_PLL_RDY_OFFSET		31
+#define UTMI_PLL_CTRL_PLL_RDY_MASK		\
+	(0x1 << UTMI_PLL_CTRL_PLL_RDY_OFFSET)
+#define UTMI_CALIB_CTRL_REG			0x8
+#define UTMI_CALIB_CTRL_IMPCAL_VTH_OFFSET	8
+#define UTMI_CALIB_CTRL_IMPCAL_VTH_MASK		\
+	(0x7 << UTMI_CALIB_CTRL_IMPCAL_VTH_OFFSET)
+#define UTMI_CALIB_CTRL_IMPCAL_DONE_OFFSET	23
+#define UTMI_CALIB_CTRL_IMPCAL_DONE_MASK	\
+	(0x1 << UTMI_CALIB_CTRL_IMPCAL_DONE_OFFSET)
+#define UTMI_CALIB_CTRL_PLLCAL_DONE_OFFSET	31
+#define UTMI_CALIB_CTRL_PLLCAL_DONE_MASK	\
+	(0x1 << UTMI_CALIB_CTRL_PLLCAL_DONE_OFFSET)
+#define UTMI_TX_CH_CTRL_REG			0xC
+#define UTMI_TX_CH_CTRL_DRV_EN_LS_OFFSET	12
+#define UTMI_TX_CH_CTRL_DRV_EN_LS_MASK		\
+	(0xf << UTMI_TX_CH_CTRL_DRV_EN_LS_OFFSET)
+#define UTMI_TX_CH_CTRL_IMP_SEL_LS_OFFSET	16
+#define UTMI_TX_CH_CTRL_IMP_SEL_LS_MASK		\
+	(0xf << UTMI_TX_CH_CTRL_IMP_SEL_LS_OFFSET)
+#define UTMI_TX_CH_CTRL_AMP_OFFSET		20
+#define UTMI_TX_CH_CTRL_AMP_MASK		\
+	(0x7 << UTMI_TX_CH_CTRL_AMP_OFFSET)
+#define UTMI_RX_CH_CTRL0_REG			0x14
+#define UTMI_RX_CH_CTRL0_SQ_DET_OFFSET		15
+#define UTMI_RX_CH_CTRL0_SQ_DET_MASK		\
+	(0x1 << UTMI_RX_CH_CTRL0_SQ_DET_OFFSET)
+#define UTMI_RX_CH_CTRL0_SQ_ANA_DTC_OFFSET	28
+#define UTMI_RX_CH_CTRL0_SQ_ANA_DTC_MASK	\
+	(0x1 << UTMI_RX_CH_CTRL0_SQ_ANA_DTC_OFFSET)
+#define UTMI_RX_CH_CTRL1_REG			0x18
+#define UTMI_RX_CH_CTRL1_SQ_AMP_CAL_OFFSET	0
+#define UTMI_RX_CH_CTRL1_SQ_AMP_CAL_MASK	\
+	(0x7 << UTMI_RX_CH_CTRL1_SQ_AMP_CAL_OFFSET)
+#define UTMI_RX_CH_CTRL1_SQ_AMP_CAL_EN_OFFSET	3
+#define UTMI_RX_CH_CTRL1_SQ_AMP_CAL_EN_MASK	\
+	(0x1 << UTMI_RX_CH_CTRL1_SQ_AMP_CAL_EN_OFFSET)
+#define UTMI_CTRL_STATUS0_REG			0x24
+#define UTMI_CTRL_STATUS0_SUSPENDM_OFFSET	22
+#define UTMI_CTRL_STATUS0_SUSPENDM_MASK		\
+	(0x1 << UTMI_CTRL_STATUS0_SUSPENDM_OFFSET)
+#define UTMI_CTRL_STATUS0_TEST_SEL_OFFSET	25
+#define UTMI_CTRL_STATUS0_TEST_SEL_MASK		\
+	(0x1 << UTMI_CTRL_STATUS0_TEST_SEL_OFFSET)
+#define UTMI_CHGDTC_CTRL_REG			0x38
+#define UTMI_CHGDTC_CTRL_VDAT_OFFSET		8
+#define UTMI_CHGDTC_CTRL_VDAT_MASK		\
+	(0x3 << UTMI_CHGDTC_CTRL_VDAT_OFFSET)
+#define UTMI_CHGDTC_CTRL_VSRC_OFFSET		10
+#define UTMI_CHGDTC_CTRL_VSRC_MASK		\
+	(0x3 << UTMI_CHGDTC_CTRL_VSRC_OFFSET)
+
+#define ARMADA37XX_PLL_LOCK_TIMEOUT	1000
+#define CP110_PLL_LOCK_TIMEOUT		100
+
+struct mvebu_utmi_phy {
+	struct phy *phy;
+	void __iomem *regs;
+	void __iomem *utmi_cfg_reg;
+	void __iomem *usb_cfg_reg;
+	spinlock_t *usb_cfg_lock; /* USB config reg access lock */
+	u32 connect_to;
+	u32 index;
+};
+
+/* The same USB config register are accessed in both UTMI0 and
+ * UTMI1 initialization, so a spin lock is defined in case it
+ * may 2 CPUs power on/off the UTMI and need to access the
+ * register in the same time. The spin lock is shared by
+ * all CP110 units.
+ */
+static DEFINE_SPINLOCK(cp110_usb_cfg_lock);
+
+/* poll_reg
+ *
+ * return: 0 on success, or timeout
+ */
+static inline u32 poll_reg(void __iomem *addr, u32 val, u32 mask, u32 timeout)
+{
+	u32 rval = 0xdead;
+
+	for (; timeout > 0; timeout--) {
+		rval = readl(addr);
+		if ((rval & mask) == val)
+			return 0;
+
+		mdelay(10);
+	}
+
+	return -ETIME;
+}
+
+static inline void reg_set(void __iomem *addr, u32 data, u32 mask)
+{
+	u32 reg_data;
+
+	reg_data = readl(addr);
+	reg_data &= ~mask;
+	reg_data |= data;
+	writel(reg_data, addr);
+}
+
+static int mvebu_a3700_utmi_phy_power_on(struct phy *phy)
+{
+	int ret = 0;
+	u32 data, mask;
+	bool usb32;
+	struct mvebu_utmi_phy *utmi_phy = phy_get_drvdata(phy);
+	struct device *dev = &phy->dev;
+
+	dev_dbg(dev, "%s: Enter\n", __func__);
+
+	if (!utmi_phy)
+		return -ENODEV;
+
+	/* On Armada 37xx there are 2 kinds of USB controller, one is USB2
+	 * controller, which only supports USB2 protocol, and another is USB32
+	 * controller, which supports both USB2 and USB3. To support USB2, both
+	 * USB controllers need connect to corresponding UTMI PHY. So a flag of
+	 * usb32 is needed to differentiate the USB controller that the UTMI
+	 * connect to, and run corresponding initialization.
+	 */
+	if (utmi_phy->connect_to == UTMI_PHY_TO_USB3_HOST0)
+		usb32 = true;
+	else
+		usb32 = false;
+
+	/* 0. Setup PLL. 40MHz clock uses defaults.It is 25MHz now.
+	 *    See "PLL Settings for Typical REFCLK" table
+	 */
+	data = (PLL_REF_DIV_5 << PLL_REF_DIV_OFF);
+	data |= (PLL_FB_DIV_96 << PLL_FB_DIV_OFF);
+	mask = PLL_REF_DIV_MASK | PLL_FB_DIV_MASK | PLL_SEL_LPFR_MASK;
+	reg_set(USB2_PHY_PLL_CTRL_REG0 + utmi_phy->regs, data, mask);
+
+	/* 1. PHY pull up and disable USB2 suspend */
+	reg_set(USB2_PHY_CTRL_ADDR(usb32) + utmi_phy->regs,
+		RB_USB2PHY_SUSPM(usb32) | RB_USB2PHY_PU(usb32), 0);
+
+	if (usb32) {
+		/* 2. Power up OTG module */
+		reg_set(USB2_PHY_OTG_CTRL_ADDR + utmi_phy->regs, PHY_PU_OTG, 0);
+
+		/* 3. Configure PHY charger detection */
+		reg_set(USB2_PHY_CHRGR_DET_ADDR + utmi_phy->regs, 0,
+			PHY_CDP_EN | PHY_DCP_EN | PHY_PD_EN | PHY_CDP_DM_AUTO |
+			PHY_ENSWITCH_DP | PHY_ENSWITCH_DM | PHY_PU_CHRG_DTC);
+
+		/* 4. Clear USB2 Host and Device OTG phy DP/DM pull-down,
+		 *    needed in evice mode
+		 */
+		reg_set(USB2_OTG_PHY_CTRL_ADDR + utmi_phy->regs, 0,
+			USB2_DP_PULLDN_DEV_MODE | USB2_DM_PULLDN_DEV_MODE);
+	}
+
+	/* Assert PLL calibration done */
+	ret = poll_reg(USB2_PHY_CAL_CTRL_ADDR + utmi_phy->regs,
+		       PHY_PLLCAL_DONE,
+		       PHY_PLLCAL_DONE,
+		       ARMADA37XX_PLL_LOCK_TIMEOUT);
+	if (ret) {
+		dev_err(dev, "Failed to end USB2 PLL calibration\n");
+		return ret;
+	}
+
+	/* Assert impedance calibration done */
+	ret = poll_reg(USB2_PHY_CAL_CTRL_ADDR + utmi_phy->regs,
+		       PHY_IMPCAL_DONE,
+		       PHY_IMPCAL_DONE,
+		       ARMADA37XX_PLL_LOCK_TIMEOUT);
+	if (ret) {
+		dev_err(dev, "Failed to end USB2 impedance calibration\n");
+		return ret;
+	}
+
+	/* Assert squetch calibration done */
+	ret = poll_reg(USB2_RX_CHAN_CTRL1_ADDR + utmi_phy->regs,
+		       USB2PHY_SQCAL_DONE,
+		       USB2PHY_SQCAL_DONE,
+		       ARMADA37XX_PLL_LOCK_TIMEOUT);
+	if (ret) {
+		dev_err(dev, "Failed to end USB2 unknown calibration\n");
+		return ret;
+	}
+
+	/* Assert PLL is ready */
+	ret = poll_reg(USB2_PHY_PLL_CTRL_REG0 + utmi_phy->regs,
+		       PLL_READY,
+		       PLL_READY,
+		       ARMADA37XX_PLL_LOCK_TIMEOUT);
+
+	if (ret) {
+		dev_err(dev, "Failed to lock USB2 PLL\n");
+		return ret;
+	}
+
+	dev_dbg(dev, "%s: Exit\n", __func__);
+
+	return ret;
+}
+
+static int mvebu_a3700_utmi_phy_power_off(struct phy *phy)
+{
+	bool usb32;
+	struct mvebu_utmi_phy *utmi_phy = phy_get_drvdata(phy);
+
+	dev_dbg(&phy->dev, "%s: Enter\n", __func__);
+
+	if (!utmi_phy)
+		return -ENODEV;
+
+	if (utmi_phy->connect_to == UTMI_PHY_TO_USB3_HOST0)
+		usb32 = true;
+	else
+		usb32 = false;
+
+	/* 1. PHY pull down and enable USB2 suspend */
+	reg_set(USB2_PHY_CTRL_ADDR(usb32) + utmi_phy->regs,
+		0, RB_USB2PHY_SUSPM(usb32) | RB_USB2PHY_PU(usb32));
+
+	/* 2. Power down OTG module */
+	if (usb32)
+		reg_set(USB2_PHY_OTG_CTRL_ADDR + utmi_phy->regs, 0, PHY_PU_OTG);
+
+	dev_dbg(&phy->dev, "%s: Exit\n", __func__);
+
+	return 0;
+}
+
+/* mvebu_cp110_usb_cfg_set
+ * The function sets the USB config register.
+ * The USB config register are accessed in both UTMI0 and UTMI1 initialization,
+ * so a spin lock is involved in case it may 2 CPUs power on/off the UTMI
+ * and need to access the register in the same time.
+ * Return: void.
+ */
+static inline void mvebu_cp110_usb_cfg_set(struct mvebu_utmi_phy *utmi_phy,
+					   u32 data, u32 mask)
+{
+	spin_lock(utmi_phy->usb_cfg_lock);
+
+	reg_set(utmi_phy->usb_cfg_reg, data, mask);
+
+	spin_unlock(utmi_phy->usb_cfg_lock);
+}
+
+/* mvebu_cp110_utmi_phy_power_off
+ * The function implements the UTMI power off.
+ * 1) Power down UTMI PHY
+ * 2) Power down PLL
+ * return: 0 for success; non-zero for failed.
+ */
+static int mvebu_cp110_utmi_phy_power_off(struct phy *phy)
+{
+	struct mvebu_utmi_phy *utmi_phy = phy_get_drvdata(phy);
+
+	dev_dbg(&phy->dev, "%s: Enter\n", __func__);
+
+	if (!utmi_phy)
+		return -ENODEV;
+
+	/* Power down UTMI PHY */
+	reg_set(utmi_phy->utmi_cfg_reg, 0x0, UTMI_PHY_CFG_PU_MASK);
+
+	/* PLL Power down */
+	mvebu_cp110_usb_cfg_set(utmi_phy,
+				0x0 << UTMI_USB_CFG_PLL_OFFSET,
+				UTMI_USB_CFG_PLL_MASK);
+
+	dev_dbg(&phy->dev, "%s: Exit\n", __func__);
+
+	return 0;
+}
+
+/* mvebu_cp110_utmi_phy_config
+ * The function implements the UTMI configurations.
+ * 1) Set clock
+ * 2) Set Calibration and LS TX driver
+ * 3) Enable SQ, analog squelch detect and External squelch calibration
+ * 4) Set VDAT/VSRC Reference Voltage
+ * return: void.
+ */
+static void mvebu_cp110_utmi_phy_config(struct phy *phy)
+{
+	u32 mask, data;
+	struct mvebu_utmi_phy *utmi_phy = phy_get_drvdata(phy);
+
+	/* Reference Clock Divider Select */
+	mask = UTMI_PLL_CTRL_REFDIV_MASK;
+	data = 0x5 << UTMI_PLL_CTRL_REFDIV_OFFSET;
+	/* Feedback Clock Divider Select - 90 for 25Mhz*/
+	mask |= UTMI_PLL_CTRL_FBDIV_MASK;
+	data |= 0x60 << UTMI_PLL_CTRL_FBDIV_OFFSET;
+	/* Select LPFR - 0x0 for 25Mhz/5=5Mhz*/
+	mask |= UTMI_PLL_CTRL_SEL_LPFR_MASK;
+	data |= 0x0 << UTMI_PLL_CTRL_SEL_LPFR_OFFSET;
+	reg_set(utmi_phy->regs + UTMI_PLL_CTRL_REG, data, mask);
+
+	/* Impedance Calibration Threshold Setting */
+	reg_set(utmi_phy->regs + UTMI_CALIB_CTRL_REG,
+		0x7 << UTMI_CALIB_CTRL_IMPCAL_VTH_OFFSET,
+		UTMI_CALIB_CTRL_IMPCAL_VTH_MASK);
+
+	/* Set LS TX driver strength coarse control */
+	mask = UTMI_TX_CH_CTRL_AMP_MASK;
+	data = 0x4 << UTMI_TX_CH_CTRL_AMP_OFFSET;
+	reg_set(utmi_phy->regs + UTMI_TX_CH_CTRL_REG, data, mask);
+
+	/* Enable SQ */
+	mask = UTMI_RX_CH_CTRL0_SQ_DET_MASK;
+	data = 0x0 << UTMI_RX_CH_CTRL0_SQ_DET_OFFSET;
+	/* Enable analog squelch detect */
+	mask |= UTMI_RX_CH_CTRL0_SQ_ANA_DTC_MASK;
+	data |= 0x1 << UTMI_RX_CH_CTRL0_SQ_ANA_DTC_OFFSET;
+	reg_set(utmi_phy->regs + UTMI_RX_CH_CTRL0_REG, data, mask);
+
+	/* Set External squelch calibration number */
+	mask = UTMI_RX_CH_CTRL1_SQ_AMP_CAL_MASK;
+	data = 0x1 << UTMI_RX_CH_CTRL1_SQ_AMP_CAL_OFFSET;
+	/* Enable the External squelch calibration */
+	mask |= UTMI_RX_CH_CTRL1_SQ_AMP_CAL_EN_MASK;
+	data |= 0x1 << UTMI_RX_CH_CTRL1_SQ_AMP_CAL_EN_OFFSET;
+	reg_set(utmi_phy->regs + UTMI_RX_CH_CTRL1_REG, data, mask);
+
+	/* Set Control VDAT Reference Voltage - 0.325V */
+	mask = UTMI_CHGDTC_CTRL_VDAT_MASK;
+	data = 0x1 << UTMI_CHGDTC_CTRL_VDAT_OFFSET;
+	/* Set Control VSRC Reference Voltage - 0.6V */
+	mask |= UTMI_CHGDTC_CTRL_VSRC_MASK;
+	data |= 0x1 << UTMI_CHGDTC_CTRL_VSRC_OFFSET;
+	reg_set(utmi_phy->regs + UTMI_CHGDTC_CTRL_REG, data, mask);
+}
+
+/* mvebu_cp110_utmi_phy_power_on
+ * The function implements the UTMI power on.
+ * 1) Power off UTMI PHY and PLL
+ * 2) Set SuspendDM
+ * 3) Configure UTMI PHY
+ * 4) Power up PHY
+ * 5) Disable Test UTMI select
+ * 6) Power up PLL
+ * return: 0 for success; non-zero for failed.
+ */
+static int mvebu_cp110_utmi_phy_power_on(struct phy *phy)
+{
+	int ret = 0;
+	u32 data, mask;
+	void __iomem *addr;
+	struct mvebu_utmi_phy *utmi_phy = phy_get_drvdata(phy);
+
+	dev_dbg(&phy->dev, "%s: Enter\n", __func__);
+
+	if (!utmi_phy)
+		return -ENODEV;
+
+	/* It is necessary to power off UTMI before configuration */
+	ret = mvebu_cp110_utmi_phy_power_off(phy);
+	if (ret) {
+		dev_err(&phy->dev, "UTMI power off failed\n");
+		return ret;
+	}
+
+	/*
+	 * If UTMI connected to USB Device, configure mux prior to PHY init
+	 * (Device can be connected to UTMI0 or to UTMI1)
+	 */
+	if (utmi_phy->connect_to == UTMI_PHY_TO_USB3_DEVICE0) {
+		/* USB3 Device UTMI enable */
+		mask = UTMI_USB_CFG_DEVICE_EN_MASK;
+		data = 0x1 << UTMI_USB_CFG_DEVICE_EN_OFFSET;
+		/* USB3 Device UTMI MUX */
+		mask |= UTMI_USB_CFG_DEVICE_MUX_MASK;
+		data |= utmi_phy->index << UTMI_USB_CFG_DEVICE_MUX_OFFSET;
+		mvebu_cp110_usb_cfg_set(utmi_phy, data, mask);
+	}
+
+	/* Set Test suspendm mode */
+	mask = UTMI_CTRL_STATUS0_SUSPENDM_MASK;
+	data = 0x1 << UTMI_CTRL_STATUS0_SUSPENDM_OFFSET;
+	/* Enable Test UTMI select */
+	mask |= UTMI_CTRL_STATUS0_TEST_SEL_MASK;
+	data |= 0x1 << UTMI_CTRL_STATUS0_TEST_SEL_OFFSET;
+	reg_set(utmi_phy->regs + UTMI_CTRL_STATUS0_REG, data, mask);
+
+	/* Wait for UTMI power down */
+	mdelay(1);
+
+	/* PHY config first */
+	mvebu_cp110_utmi_phy_config(phy);
+
+	/* Power UP UTMI PHY */
+	data = 0x1 << UTMI_PHY_CFG_PU_OFFSET;
+	reg_set(utmi_phy->utmi_cfg_reg, data, UTMI_PHY_CFG_PU_MASK);
+
+	/* Disable Test UTMI select */
+	reg_set(utmi_phy->regs + UTMI_CTRL_STATUS0_REG,
+		0x0 << UTMI_CTRL_STATUS0_TEST_SEL_OFFSET,
+		UTMI_CTRL_STATUS0_TEST_SEL_MASK);
+
+	addr = utmi_phy->regs + UTMI_CALIB_CTRL_REG;
+	data = UTMI_CALIB_CTRL_IMPCAL_DONE_MASK;
+	mask = data;
+	ret = poll_reg(addr, data, mask, CP110_PLL_LOCK_TIMEOUT);
+	if (ret) {
+		dev_err(&phy->dev, "Impedance calibration is not done\n");
+		return ret;
+	}
+
+	data = UTMI_CALIB_CTRL_PLLCAL_DONE_MASK;
+	mask = data;
+	ret = poll_reg(addr, data, mask, CP110_PLL_LOCK_TIMEOUT);
+	if (ret) {
+		dev_err(&phy->dev, "PLL calibration is not done\n");
+		return ret;
+	}
+
+	addr = utmi_phy->regs + UTMI_PLL_CTRL_REG;
+	data = UTMI_PLL_CTRL_PLL_RDY_MASK;
+	mask = data;
+	ret = poll_reg(addr, data, mask, CP110_PLL_LOCK_TIMEOUT);
+	if (ret) {
+		dev_err(&phy->dev, "PLL is not ready\n");
+		return ret;
+	}
+
+	/* PLL Power up */
+	dev_dbg(&phy->dev, "stage: UTMI PHY power up PLL\n");
+	mvebu_cp110_usb_cfg_set(utmi_phy,
+				0x1 << UTMI_USB_CFG_PLL_OFFSET,
+				UTMI_USB_CFG_PLL_MASK);
+
+	dev_dbg(&phy->dev, "%s: Exit\n", __func__);
+
+	return 0;
+}
+
+const struct phy_ops armada3700_utmi_phy_ops = {
+	.power_on = mvebu_a3700_utmi_phy_power_on,
+	.power_off = mvebu_a3700_utmi_phy_power_off,
+	.owner = THIS_MODULE,
+};
+
+const struct phy_ops cp110_utmi_phy_ops = {
+	.power_on = mvebu_cp110_utmi_phy_power_on,
+	.power_off = mvebu_cp110_utmi_phy_power_off,
+	.owner = THIS_MODULE,
+};
+
+static const struct of_device_id mvebu_utmi_of_match[] = {
+	{
+		.compatible = "marvell,armada-3700-utmi-phy",
+		.data = &armada3700_utmi_phy_ops
+	},
+	{
+		.compatible = "marvell,cp110-utmi-phy",
+		.data = &cp110_utmi_phy_ops
+	},
+	{ },
+};
+MODULE_DEVICE_TABLE(of, mvebu_utmi_of_match);
+
+static int mvebu_utmi_phy_probe(struct platform_device *pdev)
+{
+	int ret;
+	struct device *dev = &pdev->dev;
+	struct phy *phy;
+	struct resource *res;
+	struct phy_provider *phy_provider;
+	struct mvebu_utmi_phy *utmi_phy;
+	const struct of_device_id *match;
+	struct phy_ops *mvebu_utmi_phy_ops;
+
+	match = of_match_device(mvebu_utmi_of_match, &pdev->dev);
+	mvebu_utmi_phy_ops = (struct phy_ops *)match->data;
+
+	utmi_phy = devm_kzalloc(dev, sizeof(*utmi_phy), GFP_KERNEL);
+	if (!utmi_phy)
+		return  -ENOMEM;
+
+	/* Get UTMI register base */
+	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	if (!res) {
+		dev_err(&pdev->dev, "no UTMI PHY memory resource\n");
+		return -ENODEV;
+	}
+
+	utmi_phy->regs = devm_ioremap_resource(&pdev->dev, res);
+	if (IS_ERR(utmi_phy->regs))
+		return PTR_ERR(utmi_phy->regs);
+
+	/* Get USB and UTMI config reg for CP110 */
+	if (of_device_is_compatible(pdev->dev.of_node,
+				    "marvell,cp110-utmi-phy")) {
+		res = platform_get_resource_byname(pdev, IORESOURCE_MEM,
+						   "usb-cfg-reg");
+		if (!res) {
+			dev_err(&pdev->dev, "No USB config memory resource\n");
+			return -ENODEV;
+		}
+		utmi_phy->usb_cfg_reg = ioremap(res->start,
+						resource_size(res));
+		if (!utmi_phy->usb_cfg_reg) {
+			pr_err("Unable to map USB config register\n");
+			return -ENOMEM;
+		}
+		utmi_phy->usb_cfg_lock = &cp110_usb_cfg_lock;
+
+		res = platform_get_resource_byname(pdev, IORESOURCE_MEM,
+						   "utmi-cfg-reg");
+		if (!res) {
+			dev_err(&pdev->dev, "No UTMI config memory resource\n");
+			return -ENODEV;
+		}
+		utmi_phy->utmi_cfg_reg = devm_ioremap_resource(dev, res);
+		if (IS_ERR(utmi_phy->utmi_cfg_reg))
+			return PTR_ERR(utmi_phy->utmi_cfg_reg);
+	}
+
+	/* Get property of utmi-port, used check the UTMI connect to where */
+	ret = of_property_read_u32(pdev->dev.of_node, "utmi-port",
+				   &utmi_phy->connect_to);
+	if (ret) {
+		dev_err(&pdev->dev, "no property of utmi-port\n");
+		return ret;
+	}
+
+	/* Get the UTMI PHY index in case there are more than one UTMI */
+	ret = of_property_read_u32(pdev->dev.of_node, "utmi-index",
+				   &utmi_phy->index);
+	if (ret)
+		utmi_phy->index = 0;
+
+	phy = devm_phy_create(dev, NULL, mvebu_utmi_phy_ops);
+	if (IS_ERR(phy)) {
+		dev_err(dev, "failed to create PHY\n");
+		return PTR_ERR(phy);
+	}
+
+	utmi_phy->phy = phy;
+	dev_set_drvdata(dev, utmi_phy);
+	phy_set_drvdata(phy, utmi_phy);
+
+	/* Power off the PHY as default */
+	mvebu_utmi_phy_ops->power_off(phy);
+
+	phy_provider = devm_of_phy_provider_register(&pdev->dev,
+						     of_phy_simple_xlate);
+
+	return PTR_ERR_OR_ZERO(phy_provider);
+}
+
+static int mvebu_utmi_phy_remove(struct platform_device *pdev)
+{
+	struct mvebu_utmi_phy *utmi_phy;
+
+	utmi_phy = (struct mvebu_utmi_phy *)dev_get_drvdata(&pdev->dev);
+	/* Unmap USB config reg for CP110 */
+	if (of_device_is_compatible(pdev->dev.of_node,
+				    "marvell,cp110-utmi-phy"))
+		iounmap(utmi_phy->usb_cfg_reg);
+
+	return 0;
+}
+
+static struct platform_driver mvebu_utmi_driver = {
+	.probe	= mvebu_utmi_phy_probe,
+	.remove = mvebu_utmi_phy_remove,
+	.driver	= {
+		.name		= "phy-mvebu-utmi",
+		.owner		= THIS_MODULE,
+		.of_match_table	= mvebu_utmi_of_match,
+	 },
+};
+module_platform_driver(mvebu_utmi_driver);
+
+MODULE_AUTHOR("Evan Wang <xswang@marvell.com>");
+MODULE_DESCRIPTION("Marvell EBU UTMI PHY driver");
+MODULE_LICENSE("GPL");
+
diff --git a/drivers/phy/qualcomm/phy-qcom-usb-hs.c b/drivers/phy/qualcomm/phy-qcom-usb-hs.c
index 5629d56a6257..0229aaf0fccf 100644
--- a/drivers/phy/qualcomm/phy-qcom-usb-hs.c
+++ b/drivers/phy/qualcomm/phy-qcom-usb-hs.c
@@ -42,7 +42,8 @@ struct qcom_usb_hs_phy {
 	struct notifier_block vbus_notify;
 };
 
-static int qcom_usb_hs_phy_set_mode(struct phy *phy, enum phy_mode mode)
+static int qcom_usb_hs_phy_set_mode(struct phy *phy,
+				    enum phy_mode mode, int submode)
 {
 	struct qcom_usb_hs_phy *uphy = phy_get_drvdata(phy);
 	u8 addr;
diff --git a/drivers/phy/ti/phy-da8xx-usb.c b/drivers/phy/ti/phy-da8xx-usb.c
index befb886ff121..d5f4fbc32b52 100644
--- a/drivers/phy/ti/phy-da8xx-usb.c
+++ b/drivers/phy/ti/phy-da8xx-usb.c
@@ -93,7 +93,8 @@ static int da8xx_usb20_phy_power_off(struct phy *phy)
 	return 0;
 }
 
-static int da8xx_usb20_phy_set_mode(struct phy *phy, enum phy_mode mode)
+static int da8xx_usb20_phy_set_mode(struct phy *phy,
+				    enum phy_mode mode, int submode)
 {
 	struct da8xx_usb_phy *d_phy = phy_get_drvdata(phy);
 	u32 val;
diff --git a/drivers/phy/ti/phy-tusb1210.c b/drivers/phy/ti/phy-tusb1210.c
index b8ec39ac4dfc..329fb938099a 100644
--- a/drivers/phy/ti/phy-tusb1210.c
+++ b/drivers/phy/ti/phy-tusb1210.c
@@ -53,7 +53,7 @@ static int tusb1210_power_off(struct phy *phy)
 	return 0;
 }
 
-static int tusb1210_set_mode(struct phy *phy, enum phy_mode mode)
+static int tusb1210_set_mode(struct phy *phy, enum phy_mode mode, int submode)
 {
 	struct tusb1210 *tusb = phy_get_drvdata(phy);
 	int ret;
diff --git a/drivers/pinctrl/mvebu/pinctrl-armada-cp110.c b/drivers/pinctrl/mvebu/pinctrl-armada-cp110.c
index 7f85beb45482..fdd24a43a20c 100644
--- a/drivers/pinctrl/mvebu/pinctrl-armada-cp110.c
+++ b/drivers/pinctrl/mvebu/pinctrl-armada-cp110.c
@@ -36,6 +36,7 @@ enum {
 	V_ARMADA_7K = BIT(0),
 	V_ARMADA_8K_CPM = BIT(1),
 	V_ARMADA_8K_CPS = BIT(2),
+	V_CP115_STANDALONE = BIT(3),
 	V_ARMADA_7K_8K_CPM = (V_ARMADA_7K | V_ARMADA_8K_CPM),
 	V_ARMADA_7K_8K_CPS = (V_ARMADA_7K | V_ARMADA_8K_CPS),
 };
@@ -522,13 +523,13 @@ static struct mvebu_mpp_mode armada_cp110_mpp_modes[] = {
 		 MPP_FUNCTION(4,	"synce1",	"clk"),
 		 MPP_FUNCTION(8,	"led",		"data"),
 		 MPP_FUNCTION(10,	"sdio",		"hw_rst"),
-		 MPP_FUNCTION(11,	"sdio",		"wr_protect")),
+		 MPP_FUNCTION(11,	"sdio_wp",	"wr_protect")),
 	MPP_MODE(55,
 		 MPP_FUNCTION(0,	"gpio",		NULL),
 		 MPP_FUNCTION(1,	"ge1",		"rxctl_rxdv"),
 		 MPP_FUNCTION(3,	"ptp",		"pulse"),
 		 MPP_FUNCTION(10,	"sdio",		"led"),
-		 MPP_FUNCTION(11,	"sdio",		"card_detect")),
+		 MPP_FUNCTION(11,	"sdio_cd",	"card_detect")),
 	MPP_MODE(56,
 		 MPP_FUNCTION(0,	"gpio",		NULL),
 		 MPP_FUNCTION(4,	"tdm",		"drx"),
@@ -601,7 +602,8 @@ static struct mvebu_mpp_mode armada_cp110_mpp_modes[] = {
 		 MPP_FUNCTION(7,	"uart0",	"rxd"),
 		 MPP_FUNCTION(8,	"uart2",	"rxd"),
 		 MPP_FUNCTION(9,	"sata0",	"present_act"),
-		 MPP_FUNCTION(10,	"ge",		"mdc")),
+		 MPP_FUNCTION(10,	"ge",		"mdc"),
+		 MPP_FUNCTION(14,	"sdio",		"ds")),
 };
 
 static const struct of_device_id armada_cp110_pinctrl_of_match[] = {
@@ -617,6 +619,10 @@ static const struct of_device_id armada_cp110_pinctrl_of_match[] = {
 		.compatible	= "marvell,armada-8k-cps-pinctrl",
 		.data		= (void *) V_ARMADA_8K_CPS,
 	},
+	{
+		.compatible	= "marvell,cp115-standalone-pinctrl",
+		.data		= (void *) V_CP115_STANDALONE,
+	},
 	{ },
 };
 
@@ -658,16 +664,20 @@ static int armada_cp110_pinctrl_probe(struct platform_device *pdev)
 
 		switch (i) {
 		case 0 ... 31:
-			mvebu_pinctrl_assign_variant(m, V_ARMADA_7K_8K_CPS);
+			mvebu_pinctrl_assign_variant(m, (V_ARMADA_7K_8K_CPS |
+							 V_CP115_STANDALONE));
 			break;
 		case 32 ... 38:
-			mvebu_pinctrl_assign_variant(m, V_ARMADA_7K_8K_CPM);
+			mvebu_pinctrl_assign_variant(m, (V_ARMADA_7K_8K_CPM |
+							 V_CP115_STANDALONE));
 			break;
 		case 39 ... 43:
-			mvebu_pinctrl_assign_variant(m, V_ARMADA_8K_CPM);
+			mvebu_pinctrl_assign_variant(m, (V_ARMADA_8K_CPM |
+							 V_CP115_STANDALONE));
 			break;
 		case 44 ... 62:
-			mvebu_pinctrl_assign_variant(m, V_ARMADA_7K_8K_CPM);
+			mvebu_pinctrl_assign_variant(m, (V_ARMADA_7K_8K_CPM |
+							 V_CP115_STANDALONE));
 			break;
 		}
 	}
diff --git a/drivers/spi/spi-orion.c b/drivers/spi/spi-orion.c
index 47ef6b1a2e76..651e5c24e301 100644
--- a/drivers/spi/spi-orion.c
+++ b/drivers/spi/spi-orion.c
@@ -328,6 +328,7 @@ orion_spi_setup_transfer(struct spi_device *spi, struct spi_transfer *t)
 static void orion_spi_set_cs(struct spi_device *spi, bool enable)
 {
 	struct orion_spi *orion_spi;
+	u32 val;
 	int cs;
 
 	orion_spi = spi_master_get_devdata(spi->master);
@@ -337,15 +338,17 @@ static void orion_spi_set_cs(struct spi_device *spi, bool enable)
 	else
 		cs = spi->chip_select;
 
-	orion_spi_clrbits(orion_spi, ORION_SPI_IF_CTRL_REG, ORION_SPI_CS_MASK);
-	orion_spi_setbits(orion_spi, ORION_SPI_IF_CTRL_REG,
-				ORION_SPI_CS(cs));
+	val = readl(spi_reg(orion_spi, ORION_SPI_IF_CTRL_REG));
+	val &= ~ORION_SPI_CS_MASK;
+	val |= ORION_SPI_CS(cs);
 
 	/* Chip select logic is inverted from spi_set_cs */
 	if (!enable)
-		orion_spi_setbits(orion_spi, ORION_SPI_IF_CTRL_REG, 0x1);
+		val |= 0x1;
 	else
-		orion_spi_clrbits(orion_spi, ORION_SPI_IF_CTRL_REG, 0x1);
+		val &= ~0x1;
+
+	writel(val, spi_reg(orion_spi, ORION_SPI_IF_CTRL_REG));
 }
 
 static inline int orion_spi_wait_till_ready(struct orion_spi *orion_spi)
@@ -368,8 +371,15 @@ orion_spi_write_read_8bit(struct spi_device *spi,
 {
 	void __iomem *tx_reg, *rx_reg, *int_reg;
 	struct orion_spi *orion_spi;
+	bool cs_single_byte;
+
+	cs_single_byte = spi->mode & SPI_1BYTE_CS;
 
 	orion_spi = spi_master_get_devdata(spi->master);
+
+	if (cs_single_byte)
+		orion_spi_set_cs(spi, 0);
+
 	tx_reg = spi_reg(orion_spi, ORION_SPI_DATA_OUT_REG);
 	rx_reg = spi_reg(orion_spi, ORION_SPI_DATA_IN_REG);
 	int_reg = spi_reg(orion_spi, ORION_SPI_INT_CAUSE_REG);
@@ -383,6 +393,11 @@ orion_spi_write_read_8bit(struct spi_device *spi,
 		writel(0, tx_reg);
 
 	if (orion_spi_wait_till_ready(orion_spi) < 0) {
+		if (cs_single_byte) {
+			orion_spi_set_cs(spi, 1);
+			/* Satisfy some SLIC devices requirements */
+			udelay(4);
+		}
 		dev_err(&spi->dev, "TXS timed out\n");
 		return -1;
 	}
@@ -390,6 +405,12 @@ orion_spi_write_read_8bit(struct spi_device *spi,
 	if (rx_buf && *rx_buf)
 		*(*rx_buf)++ = readl(rx_reg);
 
+	if (cs_single_byte) {
+		orion_spi_set_cs(spi, 1);
+		/* Satisfy some SLIC devices requirements */
+		udelay(4);
+	}
+
 	return 1;
 }
 
@@ -504,6 +525,16 @@ static int orion_spi_transfer_one(struct spi_master *master,
 
 static int orion_spi_setup(struct spi_device *spi)
 {
+	struct orion_spi *orion_spi = spi_master_get_devdata(spi->master);
+
+	/*
+	 * Make sure the clocks are enabled before
+	 * configuring the SPI controller.
+	 */
+	clk_prepare_enable(orion_spi->clk);
+	if (!IS_ERR(orion_spi->axi_clk))
+		clk_prepare_enable(orion_spi->axi_clk);
+
 	if (gpio_is_valid(spi->cs_gpio)) {
 		gpio_direction_output(spi->cs_gpio, !(spi->mode & SPI_CS_HIGH));
 	}
@@ -558,6 +589,13 @@ static const struct orion_spi_dev armada_380_spi_dev_data = {
 	.is_errata_50mhz_ac = true,
 };
 
+static const struct orion_spi_dev armada_cp110_spi_dev_data = {
+	.typ = ARMADA_SPI,
+	.max_hz = 41000000,
+	.max_divisor = 1920,
+	.prescale_mask = ARMADA_SPI_CLK_PRESCALE_MASK,
+};
+
 static const struct of_device_id orion_spi_of_match_table[] = {
 	{
 		.compatible = "marvell,orion-spi",
@@ -579,6 +617,10 @@ static const struct of_device_id orion_spi_of_match_table[] = {
 		.compatible = "marvell,armada-390-spi",
 		.data = &armada_xp_spi_dev_data,
 	},
+	{
+		.compatible = "marvell,armada-cp110-spi",
+		.data = &armada_cp110_spi_dev_data,
+	},
 	{
 		.compatible = "marvell,armada-xp-spi",
 		.data = &armada_xp_spi_dev_data,
@@ -616,7 +658,7 @@ static int orion_spi_probe(struct platform_device *pdev)
 	}
 
 	/* we support all 4 SPI modes and LSB first option */
-	master->mode_bits = SPI_CPHA | SPI_CPOL | SPI_LSB_FIRST;
+	master->mode_bits = SPI_CPHA | SPI_CPOL | SPI_LSB_FIRST | SPI_1BYTE_CS;
 	master->set_cs = orion_spi_set_cs;
 	master->transfer_one = orion_spi_transfer_one;
 	master->num_chipselect = ORION_NUM_CHIPSELECTS;
diff --git a/drivers/spi/spi.c b/drivers/spi/spi.c
index 92e6b6774d98..4cfd63c44246 100644
--- a/drivers/spi/spi.c
+++ b/drivers/spi/spi.c
@@ -1575,6 +1575,8 @@ static int of_spi_parse_dt(struct spi_controller *ctlr, struct spi_device *spi,
 		spi->mode |= SPI_3WIRE;
 	if (of_property_read_bool(nc, "spi-lsb-first"))
 		spi->mode |= SPI_LSB_FIRST;
+	if (of_find_property(nc, "spi-1byte-cs", NULL))
+		spi->mode |= SPI_1BYTE_CS;
 
 	/* Device DUAL/QUAD mode */
 	if (!of_property_read_u32(nc, "spi-tx-bus-width", &value)) {
diff --git a/drivers/usb/host/xhci-plat.c b/drivers/usb/host/xhci-plat.c
index adc437ca83b8..a2e5840851eb 100644
--- a/drivers/usb/host/xhci-plat.c
+++ b/drivers/usb/host/xhci-plat.c
@@ -18,6 +18,7 @@
 #include <linux/usb/phy.h>
 #include <linux/slab.h>
 #include <linux/acpi.h>
+#include <linux/regulator/consumer.h>
 
 #include "xhci.h"
 #include "xhci-plat.h"
@@ -161,6 +162,7 @@ static int xhci_plat_probe(struct platform_device *pdev)
 	struct clk              *reg_clk;
 	int			ret;
 	int			irq;
+	struct regulator	*current_limiter_regulator;
 
 	if (usb_disabled())
 		return -ENODEV;
@@ -302,19 +304,56 @@ static int xhci_plat_probe(struct platform_device *pdev)
 		ret = usb_phy_init(hcd->usb_phy);
 		if (ret)
 			goto put_usb3_hcd;
-		hcd->skip_phy_initialization = 1;
+		current_limiter_regulator =
+			devm_regulator_get_optional((hcd->usb_phy)->dev,
+							"current-limiter");
+		if (!IS_ERR(current_limiter_regulator)) {
+			if (regulator_enable(current_limiter_regulator))
+				dev_err(&pdev->dev,
+					"Failed to enable Current-limiter regulator\n");
+		}
+
 	}
 
-	ret = usb_add_hcd(hcd, irq, IRQF_SHARED);
-	if (ret)
-		goto disable_usb_phy;
+#if 0
+	/*
+	 * When "separated-phys-for-usb2-usb3" is set, it indicates that usb3 host controller
+	 * uses a dedicated utmi phy for USB 2 and another phy for USB 3, for example,
+	 * armada 3700 usb3 host controller uses a dedicated utmi phy for USB 2 and a
+	 * common phy for USB 3;
+	 * usb hcd should be added with phy name as below:
+	 *        - main hcd is added with "usb2"
+	 *        - shared hcd is added with "usb3"
+	 * When "separated-phys-for-usb2-usb3" is not set, USB 2 and USB 3 shares a same phy,
+	 * main hcd and shared hcd are both added with the default phy name of "usb"
+	 */
+	if (of_property_read_bool(pdev->dev.of_node, "separated-phys-for-usb2-usb3"))
+	{
+		ret = usb_add_hcd_with_phy_name(hcd, irq, IRQF_SHARED, "usb2");
+		if (ret)
+			goto disable_usb_phy;
 
-	if (HCC_MAX_PSA(xhci->hcc_params) >= 4)
-		xhci->shared_hcd->can_do_streams = 1;
+		if (HCC_MAX_PSA(xhci->hcc_params) >= 4)
+			xhci->shared_hcd->can_do_streams = 1;
 
-	ret = usb_add_hcd(xhci->shared_hcd, irq, IRQF_SHARED);
-	if (ret)
-		goto dealloc_usb2_hcd;
+		ret = usb_add_hcd_with_phy_name(xhci->shared_hcd, irq, IRQF_SHARED, "usb3");
+		if (ret)
+			goto dealloc_usb2_hcd;
+	}
+	else
+#endif
+	{
+		ret = usb_add_hcd(hcd, irq, IRQF_SHARED);
+		if (ret)
+			goto disable_usb_phy;
+
+		if (HCC_MAX_PSA(xhci->hcc_params) >= 4)
+			xhci->shared_hcd->can_do_streams = 1;
+
+		ret = usb_add_hcd(xhci->shared_hcd, irq, IRQF_SHARED);
+		if (ret)
+			goto dealloc_usb2_hcd;
+	}
 
 	device_enable_async_suspend(&pdev->dev);
 	pm_runtime_put_noidle(&pdev->dev);
diff --git a/include/asm-generic/io.h b/include/asm-generic/io.h
index d356f802945a..c16e0d50fff1 100644
--- a/include/asm-generic/io.h
+++ b/include/asm-generic/io.h
@@ -894,18 +894,6 @@ static inline void iowrite64_rep(volatile void __iomem *addr,
 #include <linux/vmalloc.h>
 #define __io_virt(x) ((void __force *)(x))
 
-#ifndef CONFIG_GENERIC_IOMAP
-struct pci_dev;
-extern void __iomem *pci_iomap(struct pci_dev *dev, int bar, unsigned long max);
-
-#ifndef pci_iounmap
-#define pci_iounmap pci_iounmap
-static inline void pci_iounmap(struct pci_dev *dev, void __iomem *p)
-{
-}
-#endif
-#endif /* CONFIG_GENERIC_IOMAP */
-
 /*
  * Change virtual addresses to physical addresses and vv.
  * These are pretty trivial
@@ -1029,6 +1017,16 @@ static inline void __iomem *ioport_map(unsigned long port, unsigned int nr)
 	port &= IO_SPACE_LIMIT;
 	return (port > MMIO_UPPER_LIMIT) ? NULL : PCI_IOBASE + port;
 }
+#define __pci_ioport_unmap __pci_ioport_unmap
+static inline void __pci_ioport_unmap(void __iomem *p)
+{
+	uintptr_t start = (uintptr_t) PCI_IOBASE;
+	uintptr_t addr = (uintptr_t) p;
+
+	if (addr >= start && addr < start + IO_SPACE_LIMIT)
+		return;
+	iounmap(p);
+}
 #endif
 
 #ifndef ioport_unmap
@@ -1043,6 +1041,23 @@ extern void ioport_unmap(void __iomem *p);
 #endif /* CONFIG_GENERIC_IOMAP */
 #endif /* CONFIG_HAS_IOPORT_MAP */
 
+#ifndef CONFIG_GENERIC_IOMAP
+struct pci_dev;
+extern void __iomem *pci_iomap(struct pci_dev *dev, int bar, unsigned long max);
+
+#ifndef __pci_ioport_unmap
+static inline void __pci_ioport_unmap(void __iomem *p) {}
+#endif
+
+#ifndef pci_iounmap
+#define pci_iounmap pci_iounmap
+static inline void pci_iounmap(struct pci_dev *dev, void __iomem *p)
+{
+	__pci_ioport_unmap(p);
+}
+#endif
+#endif /* CONFIG_GENERIC_IOMAP */
+
 /*
  * Convert a virtual cached pointer to an uncached pointer
  */
diff --git a/include/dt-bindings/phy/phy-comphy-mvebu.h b/include/dt-bindings/phy/phy-comphy-mvebu.h
new file mode 100644
index 000000000000..1299ce0a9d08
--- /dev/null
+++ b/include/dt-bindings/phy/phy-comphy-mvebu.h
@@ -0,0 +1,145 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Copyright (C) 2019 Marvell
+ */
+
+#ifndef _DT_BINDINGS_PHY_COMPHY_MVEBU
+#define _DT_BINDINGS_PHY_COMPHY_MVEBU
+
+/* A lane is described by 4 fields:
+ *      - bit 1~0 represent comphy polarity invert
+ *      - bit 7~2 represent comphy speed
+ *      - bit 11~8 represent unit index
+ *      - bit 16~12 represent mode
+ *      - bit 17 represent comphy indication of clock source
+ *      - bit 31~18 reserved
+ */
+
+#define COMPHY_INVERT_OFFSET	0
+#define COMPHY_INVERT_LEN	2
+#define COMPHY_INVERT_MASK	COMPHY_MASK(COMPHY_INVERT_OFFSET, COMPHY_INVERT_LEN)
+#define COMPHY_SPEED_OFFSET	(COMPHY_INVERT_OFFSET + COMPHY_INVERT_LEN)
+#define COMPHY_SPEED_LEN	6
+#define COMPHY_SPEED_MASK	COMPHY_MASK(COMPHY_SPEED_OFFSET, COMPHY_SPEED_LEN)
+#define COMPHY_UNIT_ID_OFFSET	(COMPHY_SPEED_OFFSET + COMPHY_SPEED_LEN)
+#define COMPHY_UNIT_ID_LEN	4
+#define COMPHY_UNIT_ID_MASK	COMPHY_MASK(COMPHY_UNIT_ID_OFFSET, COMPHY_UNIT_ID_LEN)
+#define COMPHY_MODE_OFFSET	(COMPHY_UNIT_ID_OFFSET + COMPHY_UNIT_ID_LEN)
+#define COMPHY_MODE_LEN		5
+#define COMPHY_MODE_MASK	COMPHY_MASK(COMPHY_MODE_OFFSET, COMPHY_MODE_LEN)
+#define COMPHY_CLK_SRC_OFFSET	(COMPHY_MODE_OFFSET + COMPHY_MODE_LEN)
+#define COMPHY_CLK_SRC_LEN	1
+#define COMPHY_CLK_SRC_MASK	COMPHY_MASK(COMPHY_CLK_SRC_OFFSET, COMPHY_CLK_SRC_LEN)
+#define COMPHY_PCI_WIDTH_OFFSET	(COMPHY_CLK_SRC_OFFSET + COMPHY_CLK_SRC_LEN)
+#define COMPHY_PCI_WIDTH_LEN	3
+#define COMPHY_PCI_WIDTH_MASK	COMPHY_MASK(COMPHY_PCI_WIDTH_OFFSET, COMPHY_PCI_WIDTH_LEN)
+#define COMPHY_DEF(mode, id, speed, invert)	\
+	(((mode) << COMPHY_MODE_OFFSET) | ((id) << COMPHY_UNIT_ID_OFFSET) | \
+	((speed) << COMPHY_SPEED_OFFSET) | ((invert) << COMPHY_INVERT_OFFSET))
+
+#define COMPHY_MASK(offset, len)	(((1 << (len)) - 1) << (offset))
+
+/* Macro the extract the mode from lane description */
+#define COMPHY_GET_MODE(x)		(((x) & COMPHY_MODE_MASK) >> COMPHY_MODE_OFFSET)
+/* Macro the extract the unit index from lane description */
+#define COMPHY_GET_ID(x)		(((x) & COMPHY_UNIT_ID_MASK) >> COMPHY_UNIT_ID_OFFSET)
+/* Macro the extract the speed from lane description */
+#define COMPHY_GET_SPEED(x)		(((x) & COMPHY_SPEED_MASK) >> COMPHY_SPEED_OFFSET)
+/* Macro the extract the polarity invert from lane description */
+#define COMPHY_GET_POLARITY_INVERT(x)	(((x) & COMPHY_INVERT_MASK) >> COMPHY_INVERT_OFFSET)
+/* Macro the extract the clock source indication from lane description */
+#define COMPHY_GET_CLK_SRC(x)		(((x) & COMPHY_CLK_SRC_MASK) >> COMPHY_CLK_SRC_OFFSET)
+
+/* Comphy unit index macro */
+#define COMPHY_UNIT_ID0		0
+#define COMPHY_UNIT_ID1		1
+#define COMPHY_UNIT_ID2		2
+#define COMPHY_UNIT_ID3		3
+
+/* Comphy description macro with default speed and invert */
+#define	COMPHY_UNUSED		0xFFFFFFFF
+#define COMPHY_SATA0		COMPHY_DEF(COMPHY_SATA_MODE,  COMPHY_UNIT_ID0, \
+					COMPHY_SPEED_DEFAULT, COMPHY_POLARITY_NO_INVERT)
+#define COMPHY_SATA1		COMPHY_DEF(COMPHY_SATA_MODE,  COMPHY_UNIT_ID1, \
+					COMPHY_SPEED_DEFAULT, COMPHY_POLARITY_NO_INVERT)
+#define COMPHY_SGMII0		COMPHY_DEF(COMPHY_SGMII_MODE,  COMPHY_UNIT_ID0, \
+					COMPHY_SPEED_DEFAULT, COMPHY_POLARITY_NO_INVERT)	/* SGMII 1G */
+#define COMPHY_SGMII1		COMPHY_DEF(COMPHY_SGMII_MODE,  COMPHY_UNIT_ID1, \
+					COMPHY_SPEED_DEFAULT, COMPHY_POLARITY_NO_INVERT)	/* SGMII 1G */
+#define COMPHY_SGMII2		COMPHY_DEF(COMPHY_SGMII_MODE,  COMPHY_UNIT_ID2, \
+					COMPHY_SPEED_DEFAULT, COMPHY_POLARITY_NO_INVERT)	/* SGMII 1G */
+#define COMPHY_HS_SGMII0	COMPHY_DEF(COMPHY_HS_SGMII_MODE,  COMPHY_UNIT_ID0, \
+					COMPHY_SPEED_DEFAULT, COMPHY_POLARITY_NO_INVERT)	/* SGMII 2.5G */
+#define COMPHY_HS_SGMII1	COMPHY_DEF(COMPHY_HS_SGMII_MODE,  COMPHY_UNIT_ID1, \
+					COMPHY_SPEED_DEFAULT, COMPHY_POLARITY_NO_INVERT)	/* SGMII 2.5G */
+#define COMPHY_HS_SGMII2	COMPHY_DEF(COMPHY_HS_SGMII_MODE,  COMPHY_UNIT_ID2, \
+					COMPHY_SPEED_DEFAULT, COMPHY_POLARITY_NO_INVERT)	/* SGMII 2.5G */
+#define COMPHY_USB3H0		COMPHY_DEF(COMPHY_USB3H_MODE,  COMPHY_UNIT_ID0, \
+					COMPHY_SPEED_DEFAULT, COMPHY_POLARITY_NO_INVERT)
+#define COMPHY_USB3H1		COMPHY_DEF(COMPHY_USB3H_MODE,  COMPHY_UNIT_ID1, \
+					COMPHY_SPEED_DEFAULT, COMPHY_POLARITY_NO_INVERT)
+#define COMPHY_USB3D0		COMPHY_DEF(COMPHY_USB3D_MODE,  COMPHY_UNIT_ID0, \
+					COMPHY_SPEED_DEFAULT, COMPHY_POLARITY_NO_INVERT)
+#define COMPHY_PCIE0		COMPHY_DEF(COMPHY_PCIE_MODE,  COMPHY_UNIT_ID0, \
+					COMPHY_SPEED_DEFAULT, COMPHY_POLARITY_NO_INVERT)
+#define COMPHY_PCIE1		COMPHY_DEF(COMPHY_PCIE_MODE,  COMPHY_UNIT_ID1, \
+					COMPHY_SPEED_DEFAULT, COMPHY_POLARITY_NO_INVERT)
+#define COMPHY_PCIE2		COMPHY_DEF(COMPHY_PCIE_MODE,  COMPHY_UNIT_ID2, \
+					COMPHY_SPEED_DEFAULT, COMPHY_POLARITY_NO_INVERT)
+#define COMPHY_PCIE3		COMPHY_DEF(COMPHY_PCIE_MODE,  COMPHY_UNIT_ID3, \
+					COMPHY_SPEED_DEFAULT, COMPHY_POLARITY_NO_INVERT)
+#define COMPHY_RXAUI0		COMPHY_DEF(COMPHY_RXAUI_MODE,  COMPHY_UNIT_ID0, \
+					COMPHY_SPEED_DEFAULT, COMPHY_POLARITY_NO_INVERT)
+#define COMPHY_RXAUI1		COMPHY_DEF(COMPHY_RXAUI_MODE,  COMPHY_UNIT_ID1, \
+					COMPHY_SPEED_DEFAULT, COMPHY_POLARITY_NO_INVERT)
+#define COMPHY_XFI0		COMPHY_DEF(COMPHY_XFI_MODE,  COMPHY_UNIT_ID0, \
+					COMPHY_SPEED_DEFAULT, COMPHY_POLARITY_NO_INVERT)
+#define COMPHY_SFI0		COMPHY_DEF(COMPHY_SFI_MODE,  COMPHY_UNIT_ID0, \
+					COMPHY_SPEED_DEFAULT, COMPHY_POLARITY_NO_INVERT)
+#define COMPHY_XFI1		COMPHY_DEF(COMPHY_XFI_MODE,  COMPHY_UNIT_ID1, \
+					COMPHY_SPEED_DEFAULT, COMPHY_POLARITY_NO_INVERT)
+#define COMPHY_SFI1		COMPHY_DEF(COMPHY_SFI_MODE,  COMPHY_UNIT_ID1, \
+					COMPHY_SPEED_DEFAULT, COMPHY_POLARITY_NO_INVERT)
+#define COMPHY_USB3		COMPHY_DEF(COMPHY_USB3_MODE,  COMPHY_UNIT_ID0, \
+					COMPHY_SPEED_DEFAULT, COMPHY_POLARITY_NO_INVERT)	/* USB3 Host&Device */
+
+#define COMPHY_SATA_MODE	0x1
+#define COMPHY_SGMII_MODE	0x2	/* SGMII 1G */
+#define COMPHY_HS_SGMII_MODE	0x3	/* SGMII 2.5G */
+#define COMPHY_USB3H_MODE	0x4
+#define COMPHY_USB3D_MODE	0x5
+#define COMPHY_PCIE_MODE	0x6
+#define COMPHY_RXAUI_MODE	0x7
+#define COMPHY_XFI_MODE		0x8
+#define COMPHY_SFI_MODE		0x9
+#define COMPHY_USB3_MODE	0xa
+
+/* Polarity invert macro */
+#define COMPHY_POLARITY_NO_INVERT	0
+#define COMPHY_POLARITY_TXD_INVERT	1
+#define COMPHY_POLARITY_RXD_INVERT	2
+#define COMPHY_POLARITY_ALL_INVERT	(COMPHY_POLARITY_TXD_INVERT | COMPHY_POLARITY_RXD_INVERT)
+
+/* COMPHY speed macro */
+#define COMPHY_SPEED_1_25G		0 /* SGMII 1G */
+#define COMPHY_SPEED_2_5G		1
+#define COMPHY_SPEED_3_125G		2 /* SGMII 2.5G */
+#define COMPHY_SPEED_5G			3
+#define COMPHY_SPEED_5_15625G		4 /* XFI 5G */
+#define COMPHY_SPEED_6G			5
+#define COMPHY_SPEED_10_3125G		6 /* XFI 10G */
+#define COMPHY_SPEED_MAX		0x3F
+/* The  default speed for IO with fixed known speed */
+#define COMPHY_SPEED_DEFAULT		COMPHY_SPEED_MAX
+
+/* Commands for comphy driver */
+#define COMPHY_COMMAND_DIGITAL_PWR_OFF		0x00000001
+#define COMPHY_COMMAND_DIGITAL_PWR_ON		0x00000002
+#define COMPHY_COMMAND_PCIE_WIDTH_1		0x00000003
+#define COMPHY_COMMAND_PCIE_WIDTH_2		0x00000004
+#define COMPHY_COMMAND_PCIE_WIDTH_4		0x00000005
+#define COMPHY_COMMAND_PCIE_WIDTH_UNSUPPORT	0x00000006
+#define COMPHY_COMMAND_SFI_RX_TRAINING		0x00000007
+
+#endif /* _DT_BINDINGS_PHY_COMPHY_MVEBU */
+
diff --git a/include/dt-bindings/phy/phy-utmi-mvebu.h b/include/dt-bindings/phy/phy-utmi-mvebu.h
new file mode 100644
index 000000000000..a132d7300ef4
--- /dev/null
+++ b/include/dt-bindings/phy/phy-utmi-mvebu.h
@@ -0,0 +1,19 @@
+/*
+ * Copyright (C) 2018 Marvell
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ */
+
+#ifndef _DT_BINDINGS_PHY_UTMI_MVEBU
+#define _DT_BINDINGS_PHY_UTMI_MVEBU
+
+#define UTMI_PHY_TO_USB3_HOST0		0
+#define UTMI_PHY_TO_USB3_HOST1		1
+#define UTMI_PHY_TO_USB3_DEVICE0	2
+#define UTMI_PHY_TO_USB2_HOST0		3
+#define UTMI_PHY_INVALID		0xff
+
+#endif /* _DT_BINDINGS_PHY_UTMI_MVEBU */
diff --git a/include/dt-bindings/soc/ap810-stream-id.h b/include/dt-bindings/soc/ap810-stream-id.h
new file mode 100644
index 000000000000..9d32ba46d3e9
--- /dev/null
+++ b/include/dt-bindings/soc/ap810-stream-id.h
@@ -0,0 +1,31 @@
+/*
+ * All the Stream id calculation based on ATF configuration.
+ * Reference for this calculation can be found under
+ * <atf root dir>/drivers/marvell/mochi/<required setup>.h
+ */
+
+/* AP XOR stream IDs: 0x100-0xFFF */
+#define MVEBU_STREAM_ID_AP0_XOR0		0x100
+/* max stream IDs per AP */
+#define MVEBU_STREAM_ID_AP_MAX			0x200
+#define MVEBU_STREAM_ID_APx_XORx(x, ap)		(MVEBU_STREAM_ID_AP0_XOR0 + \
+						(ap * MVEBU_STREAM_ID_AP_MAX) + x)
+
+/* CP stream ID base */
+#define MVEBU_STREAM_ID_BASE			0x40
+
+/* CP max stream IDs */
+#define MVEBU_MAX_STREAM_ID_PER_CP		0x10
+
+/* CP XOR0 stream ID offset */
+#define MVEBU_STREAM_ID_CP_XOR0_OFFSET		0x2
+
+/* CP XOR0 stream ID: 0x42 */
+#define MVEBU_STREAM_ID_CP0_XOR0		(MVEBU_STREAM_ID_BASE + \
+						MVEBU_STREAM_ID_CP_XOR0_OFFSET)
+
+#define MVEBU_STREAM_ID_CPx_XORx(cp_num, xor_num)	\
+	(MVEBU_STREAM_ID_CP0_XOR0 + \
+	((cp_num  % 4) * MVEBU_MAX_STREAM_ID_PER_CP) + xor_num)
+
+
diff --git a/include/linux/armada-pcie-ep.h b/include/linux/armada-pcie-ep.h
new file mode 100644
index 000000000000..e1af0ed549ca
--- /dev/null
+++ b/include/linux/armada-pcie-ep.h
@@ -0,0 +1,54 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Armada PCIe EP
+ * Copyright (c) 2019, Marvell Semiconductor.
+ */
+#ifndef _ARMADA_PCIE_EP_
+#define _ARMADA_PCIE_EP_
+
+#include <linux/msi.h>
+
+struct pci_epf_header {
+	u16	vendor_id;
+	u16	device_id;
+	u16     vf_device_id;
+	u16	subsys_vendor_id;
+	u16	subsys_id;
+	u8	rev_id;
+	u8	progif_code;
+	u8	subclass_code;
+	u8	baseclass_code;
+	u8	cache_line_size;
+	u8	io_en;
+	u8	mem_en;
+};
+
+
+/* BAR bitmaps for use with armada_pcie_ep_disable_bars */
+#define PCIE_EP_BAR0		BIT(0)
+#define PCIE_EP_BAR1		BIT(1)
+#define PCIE_EP_BAR0_64	(PCIE_EP_BAR0 | PCIE_EP_BAR1)
+#define PCIE_EP_BAR2		BIT(2)
+#define PCIE_EP_BAR3		BIT(3)
+#define PCIE_EP_BAR2_64	(PCIE_EP_BAR3 | PCIE_EP_BAR2)
+#define PCIE_EP_BAR4		BIT(4)
+#define PCIE_EP_BAR5		BIT(5)
+#define PCIE_EP_BAR4_64	(PCIE_EP_BAR4 | PCIE_EP_BAR5)
+#define PCIE_EP_BAR_ROM	BIT(8) /* matches the offset, see pci.c */
+#define PCIE_EP_ALL_BARS	((BIT(9) - 1) & ~(BIT(6) || BIT(7)))
+
+void armada_pcie_ep_bar_map(void *ep, u32 func_id, int bar, phys_addr_t addr,
+			u64 size);
+void armada_pcie_ep_setup_bar(void *ep, int func_id, u32 bar_num, u32 props,
+			u64 sz);
+void armada_pcie_ep_disable_bars(void *ep, int func_id, u16 mask);
+void armada_pcie_ep_cfg_enable(void *ep, int func_id);
+int  armada_pcie_ep_get_msi(void *ep, int func_id, int vec_id,
+			struct msi_msg *msg);
+int  armada_pcie_ep_remap_host(void *ep, u32 func_id, u64 local_base,
+			u64 host_base, u64 size);
+void armada_pcie_ep_write_header(void *ep, int func_id,
+				struct pci_epf_header *hdr);
+void *armada_pcie_ep_get(void);
+
+#endif /* _ARMADA_PCIE_EP_ */
diff --git a/include/linux/fcntl.h b/include/linux/fcntl.h
index 27dc7a60693e..d019df946cb2 100644
--- a/include/linux/fcntl.h
+++ b/include/linux/fcntl.h
@@ -12,7 +12,7 @@
 	 O_NOATIME | O_CLOEXEC | O_PATH | __O_TMPFILE)
 
 #ifndef force_o_largefile
-#define force_o_largefile() (BITS_PER_LONG != 32)
+#define force_o_largefile() (!IS_ENABLED(CONFIG_ARCH_32BIT_OFF_T))
 #endif
 
 #if BITS_PER_LONG == 32
diff --git a/include/linux/i2c.h b/include/linux/i2c.h
index 7e748648c7d3..d1afa1660d1a 100644
--- a/include/linux/i2c.h
+++ b/include/linux/i2c.h
@@ -592,6 +592,14 @@ struct i2c_timings {
  *	may configure padmux here for SDA/SCL line or something else they want.
  * @scl_gpiod: gpiod of the SCL line. Only required for GPIO recovery.
  * @sda_gpiod: gpiod of the SDA line. Only required for GPIO recovery.
+ * @pinctrl: pinctrl used by GPIO recovery to change the state of the I2C pins.
+ *      Optional.
+ * @pins_default: default pinctrl state of SCL/SDA lines, when they are assigned
+ *      to the I2C bus. Optional. Populated internally for GPIO recovery, if
+ *      state with the name PINCTRL_STATE_DEFAULT is found and pinctrl is valid.
+ * @pins_gpio: recovery pinctrl state of SCL/SDA lines, when they are used as
+ *      GPIOs. Optional. Populated internally for GPIO recovery, if this state
+ *      is called "gpio" or "recovery" and pinctrl is valid.
  */
 struct i2c_bus_recovery_info {
 	int (*recover_bus)(struct i2c_adapter *adap);
@@ -608,6 +616,9 @@ struct i2c_bus_recovery_info {
 	/* gpio recovery */
 	struct gpio_desc *scl_gpiod;
 	struct gpio_desc *sda_gpiod;
+	struct pinctrl *pinctrl;
+	struct pinctrl_state *pins_default;
+	struct pinctrl_state *pins_gpio;
 };
 
 int i2c_recover_bus(struct i2c_adapter *adap);
diff --git a/include/linux/irqchip/arm-gic-v3.h b/include/linux/irqchip/arm-gic-v3.h
index 1d21e98d6854..1272efaf4a06 100644
--- a/include/linux/irqchip/arm-gic-v3.h
+++ b/include/linux/irqchip/arm-gic-v3.h
@@ -347,6 +347,8 @@
 
 #define GITS_CBASER_InnerShareable					\
 	GIC_BASER_SHAREABILITY(GITS_CBASER, InnerShareable)
+#define GITS_CBASER_NonShareable					\
+	GIC_BASER_SHAREABILITY(GITS_CBASER, NonShareable)
 
 #define GITS_CBASER_nCnB	GIC_BASER_CACHEABILITY(GITS_CBASER, INNER, nCnB)
 #define GITS_CBASER_nC		GIC_BASER_CACHEABILITY(GITS_CBASER, INNER, nC)
@@ -391,6 +393,8 @@
 #define GITS_BASER_SHAREABILITY_SHIFT	(10)
 #define GITS_BASER_InnerShareable					\
 	GIC_BASER_SHAREABILITY(GITS_BASER, InnerShareable)
+#define GITS_BASER_NonShareable						\
+	GIC_BASER_SHAREABILITY(GITS_BASER, NonShareable)
 #define GITS_BASER_PAGE_SIZE_SHIFT	(8)
 #define GITS_BASER_PAGE_SIZE_4K		(0ULL << GITS_BASER_PAGE_SIZE_SHIFT)
 #define GITS_BASER_PAGE_SIZE_16K	(1ULL << GITS_BASER_PAGE_SIZE_SHIFT)
diff --git a/include/linux/irqdomain.h b/include/linux/irqdomain.h
index 092445543258..71a38fef9f06 100644
--- a/include/linux/irqdomain.h
+++ b/include/linux/irqdomain.h
@@ -75,6 +75,7 @@ struct irq_fwspec {
 enum irq_domain_bus_token {
 	DOMAIN_BUS_ANY		= 0,
 	DOMAIN_BUS_WIRED,
+	DOMAIN_BUS_GENERIC_MSI,
 	DOMAIN_BUS_PCI_MSI,
 	DOMAIN_BUS_PLATFORM_MSI,
 	DOMAIN_BUS_NEXUS,
diff --git a/include/linux/kernel.h b/include/linux/kernel.h
index f6f94e54ab96..33c20548d0a0 100644
--- a/include/linux/kernel.h
+++ b/include/linux/kernel.h
@@ -334,6 +334,12 @@ extern int oops_may_print(void);
 void do_exit(long error_code) __noreturn;
 void complete_and_exit(struct completion *, long) __noreturn;
 
+#ifdef CONFIG_MRVL_OCTEONTX_EL0_INTR
+struct task_struct;
+int task_cleanup_handler_add(void (*handler)(struct task_struct *));
+int task_cleanup_handler_remove(void (*handler)(struct task_struct *));
+#endif
+
 #ifdef CONFIG_ARCH_HAS_REFCOUNT
 void refcount_error_report(struct pt_regs *regs, const char *err);
 #else
diff --git a/include/linux/linkmode.h b/include/linux/linkmode.h
new file mode 100644
index 000000000000..9729013501fd
--- /dev/null
+++ b/include/linux/linkmode.h
@@ -0,0 +1,76 @@
+#ifndef __LINKMODE_H
+#define __LINKMODE_H
+
+#include <linux/bitmap.h>
+#include <linux/ethtool.h>
+#include <uapi/linux/ethtool.h>
+
+static inline void linkmode_zero(unsigned long *dst)
+{
+	bitmap_zero(dst, __ETHTOOL_LINK_MODE_MASK_NBITS);
+}
+
+static inline void linkmode_copy(unsigned long *dst, const unsigned long *src)
+{
+	bitmap_copy(dst, src, __ETHTOOL_LINK_MODE_MASK_NBITS);
+}
+
+static inline void linkmode_and(unsigned long *dst, const unsigned long *a,
+				const unsigned long *b)
+{
+	bitmap_and(dst, a, b, __ETHTOOL_LINK_MODE_MASK_NBITS);
+}
+
+static inline void linkmode_or(unsigned long *dst, const unsigned long *a,
+				const unsigned long *b)
+{
+	bitmap_or(dst, a, b, __ETHTOOL_LINK_MODE_MASK_NBITS);
+}
+
+static inline bool linkmode_empty(const unsigned long *src)
+{
+	return bitmap_empty(src, __ETHTOOL_LINK_MODE_MASK_NBITS);
+}
+
+static inline int linkmode_andnot(unsigned long *dst, const unsigned long *src1,
+				  const unsigned long *src2)
+{
+	return bitmap_andnot(dst, src1, src2,  __ETHTOOL_LINK_MODE_MASK_NBITS);
+}
+
+static inline void linkmode_set_bit(int nr, volatile unsigned long *addr)
+{
+	__set_bit(nr, addr);
+}
+
+static inline void linkmode_clear_bit(int nr, volatile unsigned long *addr)
+{
+	__clear_bit(nr, addr);
+}
+
+static inline void linkmode_change_bit(int nr, volatile unsigned long *addr)
+{
+	__change_bit(nr, addr);
+}
+
+static inline int linkmode_test_bit(int nr, volatile unsigned long *addr)
+{
+	return test_bit(nr, addr);
+}
+
+static inline int linkmode_equal(const unsigned long *src1,
+				 const unsigned long *src2)
+{
+	return bitmap_equal(src1, src2, __ETHTOOL_LINK_MODE_MASK_NBITS);
+}
+
+static inline void linkmode_set_bit_array(const int *array, int array_size,
+					  unsigned long *addr)
+{
+	int i;
+
+	for (i = 0; i < array_size; i++)
+		linkmode_set_bit(array[i], addr);
+}
+
+#endif /* __LINKMODE_H */
diff --git a/include/linux/mii.h b/include/linux/mii.h
index 55000ee5c6ad..567047ef0309 100644
--- a/include/linux/mii.h
+++ b/include/linux/mii.h
@@ -10,6 +10,7 @@
 
 
 #include <linux/if.h>
+#include <linux/linkmode.h>
 #include <uapi/linux/mii.h>
 
 struct ethtool_cmd;
diff --git a/include/linux/miscdevice.h b/include/linux/miscdevice.h
index b06b75776a32..b515a4c46e23 100644
--- a/include/linux/miscdevice.h
+++ b/include/linux/miscdevice.h
@@ -21,6 +21,8 @@
 #define APOLLO_MOUSE_MINOR	7	/* unused */
 #define PC110PAD_MINOR		9	/* unused */
 /*#define ADB_MOUSE_MINOR	10	FIXME OBSOLETE */
+#define SLICDEV_MINOR		73	/* Marvell SLIC control device */
+#define TALDEV_MINOR		74	/* Marvell TAL device */
 #define WATCHDOG_MINOR		130	/* Watchdog timer     */
 #define TEMP_MINOR		131	/* Temperature Sensor */
 #define APM_MINOR_DEV		134
diff --git a/include/linux/mv_soc_info.h b/include/linux/mv_soc_info.h
new file mode 100644
index 000000000000..3befa8c096e0
--- /dev/null
+++ b/include/linux/mv_soc_info.h
@@ -0,0 +1,23 @@
+/*
+ * Marvell A8K SoC info definitions.
+ *
+ * Copyright (C) 2018 Marvell Semiconductor
+ *
+ * This file is licensed under the terms of the GNU General Public
+ * License version 2.  This program is licensed "as is" without any
+ * warranty of any kind, whether express or implied.
+ */
+
+#ifndef MV_SOC_INFO_H
+#define MV_SOC_INFO_H
+
+#define GWD_IIDR2_REV_ID_OFFSET	12
+#define GWD_IIDR2_REV_ID_MASK	0xF
+#define APN806_REV_ID_A0	0
+#define APN806_REV_ID_A1	1
+#define APN806_REV_ID_B0	2
+
+int mv_soc_info_get_ap_revision(void);
+
+
+#endif /* MV_SOC_INFO_H */
diff --git a/include/linux/of_pci.h b/include/linux/of_pci.h
index e83d87fc5673..e95a1c60aa6b 100644
--- a/include/linux/of_pci.h
+++ b/include/linux/of_pci.h
@@ -39,6 +39,17 @@ static inline int of_pci_map_rid(struct device_node *np, u32 rid,
 static inline void of_pci_check_probe_only(void) { }
 #endif
 
+
+#if defined(CONFIG_OF_ADDRESS)
+int devm_of_pci_get_host_bridge_resources(struct device *dev,
+			unsigned char busno, unsigned char bus_max,
+			struct list_head *resources, resource_size_t *io_base);
+#else
+static inline int devm_of_pci_get_host_bridge_resources(struct device *dev,
+			unsigned char busno, unsigned char bus_max,
+			struct list_head *resources, resource_size_t *io_base)
+#endif
+
 #if IS_ENABLED(CONFIG_OF_IRQ)
 int of_irq_parse_and_map_pci(const struct pci_dev *dev, u8 slot, u8 pin);
 #else
diff --git a/include/linux/phy.h b/include/linux/phy.h
index 42766e7179d3..44af8e3580ab 100644
--- a/include/linux/phy.h
+++ b/include/linux/phy.h
@@ -19,6 +19,7 @@
 #include <linux/compiler.h>
 #include <linux/spinlock.h>
 #include <linux/ethtool.h>
+#include <linux/linkmode.h>
 #include <linux/mdio.h>
 #include <linux/mii.h>
 #include <linux/module.h>
@@ -84,10 +85,15 @@ typedef enum {
 	PHY_INTERFACE_MODE_TRGMII,
 	PHY_INTERFACE_MODE_1000BASEX,
 	PHY_INTERFACE_MODE_2500BASEX,
+	PHY_INTERFACE_MODE_2500BASET,
 	PHY_INTERFACE_MODE_RXAUI,
 	PHY_INTERFACE_MODE_XAUI,
 	/* 10GBASE-KR, XFI, SFI - single lane 10G Serdes */
 	PHY_INTERFACE_MODE_10GKR,
+	PHY_INTERFACE_MODE_SFI,
+	PHY_INTERFACE_MODE_XFI,
+	/* 5GBASE-KR - Single lane 5G Serdes */
+	PHY_INTERFACE_MODE_5GKR,
 	PHY_INTERFACE_MODE_MAX,
 } phy_interface_t;
 
@@ -154,12 +160,16 @@ static inline const char *phy_modes(phy_interface_t interface)
 		return "1000base-x";
 	case PHY_INTERFACE_MODE_2500BASEX:
 		return "2500base-x";
+	case PHY_INTERFACE_MODE_2500BASET:
+		return "2500base-t";
 	case PHY_INTERFACE_MODE_RXAUI:
 		return "rxaui";
 	case PHY_INTERFACE_MODE_XAUI:
 		return "xaui";
 	case PHY_INTERFACE_MODE_10GKR:
 		return "10gbase-kr";
+	case PHY_INTERFACE_MODE_5GKR:
+		return "5gbase-kr";
 	default:
 		return "unknown";
 	}
diff --git a/include/linux/phy/phy.h b/include/linux/phy/phy.h
index 9713aebdd348..0ffef2f437ac 100644
--- a/include/linux/phy/phy.h
+++ b/include/linux/phy/phy.h
@@ -40,6 +40,9 @@ enum phy_mode {
 	PHY_MODE_10GKR,
 	PHY_MODE_UFS_HS_A,
 	PHY_MODE_UFS_HS_B,
+	PHY_MODE_PCIE,
+	PHY_MODE_SATA,
+	PHY_MODE_ETHERNET,
 };
 
 /**
@@ -51,6 +54,7 @@ enum phy_mode {
  * @set_mode: set the mode of the phy
  * @reset: resetting the phy
  * @calibrate: calibrate the phy
+ * @send_command: request specific operations from the phy
  * @owner: the module owner containing the ops
  */
 struct phy_ops {
@@ -58,9 +62,10 @@ struct phy_ops {
 	int	(*exit)(struct phy *phy);
 	int	(*power_on)(struct phy *phy);
 	int	(*power_off)(struct phy *phy);
-	int	(*set_mode)(struct phy *phy, enum phy_mode mode);
+	int	(*set_mode)(struct phy *phy, enum phy_mode mode, int submode);
 	int	(*reset)(struct phy *phy);
 	int	(*calibrate)(struct phy *phy);
+	int	(*send_command)(struct phy *phy, u32 command);
 	struct module *owner;
 };
 
@@ -162,13 +167,17 @@ int phy_init(struct phy *phy);
 int phy_exit(struct phy *phy);
 int phy_power_on(struct phy *phy);
 int phy_power_off(struct phy *phy);
-int phy_set_mode(struct phy *phy, enum phy_mode mode);
+int phy_set_mode_ext(struct phy *phy, enum phy_mode mode, int submode);
+#define phy_set_mode(phy, mode) \
+	phy_set_mode_ext(phy, mode, 0)
+
 static inline enum phy_mode phy_get_mode(struct phy *phy)
 {
 	return phy->attrs.mode;
 }
 int phy_reset(struct phy *phy);
 int phy_calibrate(struct phy *phy);
+int phy_send_command(struct phy *phy, u32 command);
 static inline int phy_get_bus_width(struct phy *phy)
 {
 	return phy->attrs.bus_width;
@@ -276,13 +285,17 @@ static inline int phy_power_off(struct phy *phy)
 	return -ENOSYS;
 }
 
-static inline int phy_set_mode(struct phy *phy, enum phy_mode mode)
+static inline int phy_set_mode_ext(struct phy *phy, enum phy_mode mode,
+				   int submode)
 {
 	if (!phy)
 		return 0;
 	return -ENOSYS;
 }
 
+#define phy_set_mode(phy, mode) \
+	phy_set_mode_ext(phy, mode, 0)
+
 static inline enum phy_mode phy_get_mode(struct phy *phy)
 {
 	return PHY_MODE_INVALID;
@@ -302,6 +315,13 @@ static inline int phy_calibrate(struct phy *phy)
 	return -ENOSYS;
 }
 
+static inline int phy_send_command(struct phy *phy, u32 command)
+{
+	if (!phy)
+		return 0;
+	return -EOPNOTSUPP;
+}
+
 static inline int phy_get_bus_width(struct phy *phy)
 {
 	return -ENOSYS;
diff --git a/include/linux/sched/task.h b/include/linux/sched/task.h
index 44c6f15800ff..122127d8c99d 100644
--- a/include/linux/sched/task.h
+++ b/include/linux/sched/task.h
@@ -99,6 +99,9 @@ static inline void put_task_struct(struct task_struct *t)
 }
 
 struct task_struct *task_rcu_dereference(struct task_struct **ptask);
+struct task_struct *try_get_task_struct(struct task_struct **ptask);
+struct task_struct *try_get_task_struct_on_cpu(int cpu);
+
 
 #ifdef CONFIG_ARCH_WANTS_DYNAMIC_TASK_STRUCT
 extern int arch_task_struct_size __read_mostly;
diff --git a/include/linux/spi/spi.h b/include/linux/spi/spi.h
index a64235e05321..bb43a80307c5 100644
--- a/include/linux/spi/spi.h
+++ b/include/linux/spi/spi.h
@@ -163,6 +163,7 @@ struct spi_device {
 #define	SPI_TX_QUAD	0x200			/* transmit with 4 wires */
 #define	SPI_RX_DUAL	0x400			/* receive with 2 wires */
 #define	SPI_RX_QUAD	0x800			/* receive with 4 wires */
+#define	SPI_1BYTE_CS	0x1000			/* switch CS every byte */
 	int			irq;
 	void			*controller_state;
 	void			*controller_data;
diff --git a/include/linux/thread_bits.h b/include/linux/thread_bits.h
new file mode 100644
index 000000000000..ceb2ad225208
--- /dev/null
+++ b/include/linux/thread_bits.h
@@ -0,0 +1,88 @@
+/* thread_bits.h: common low-level thread bits accessors */
+
+#ifndef _LINUX_THREAD_BITS_H
+#define _LINUX_THREAD_BITS_H
+
+#ifndef __ASSEMBLY__
+
+/*
+ * For per-arch arch_within_stack_frames() implementations, defined in
+ * asm/thread_info.h.
+ */
+enum {
+	BAD_STACK = -1,
+	NOT_STACK = 0,
+	GOOD_FRAME,
+	GOOD_STACK,
+};
+
+#include <linux/bitops.h>
+#include <asm/thread_info.h>
+
+#ifdef CONFIG_THREAD_INFO_IN_TASK
+/*
+ * For CONFIG_THREAD_INFO_IN_TASK kernels we need <asm/current.h> for the
+ * definition of current, but for !CONFIG_THREAD_INFO_IN_TASK kernels,
+ * including <asm/current.h> can cause a circular dependency on some platforms.
+ */
+#include <asm/current.h>
+#define current_thread_info() ((struct thread_info *)current)
+#endif
+
+#define THREADINFO_GFP		(GFP_KERNEL_ACCOUNT | __GFP_ZERO)
+
+/*
+ * flag set/clear/test wrappers
+ * - pass TIF_xxxx constants to these functions
+ */
+
+static inline void set_ti_thread_flag(struct thread_info *ti, int flag)
+{
+	set_bit(flag, (unsigned long *)&ti->flags);
+}
+
+static inline void clear_ti_thread_flag(struct thread_info *ti, int flag)
+{
+	clear_bit(flag, (unsigned long *)&ti->flags);
+}
+
+static inline void update_ti_thread_flag(struct thread_info *ti, int flag,
+					 bool value)
+{
+	if (value)
+		set_ti_thread_flag(ti, flag);
+	else
+		clear_ti_thread_flag(ti, flag);
+}
+
+static inline int test_and_set_ti_thread_flag(struct thread_info *ti, int flag)
+{
+	return test_and_set_bit(flag, (unsigned long *)&ti->flags);
+}
+
+static inline int test_and_clear_ti_thread_flag(struct thread_info *ti, int flag)
+{
+	return test_and_clear_bit(flag, (unsigned long *)&ti->flags);
+}
+
+static inline int test_ti_thread_flag(struct thread_info *ti, int flag)
+{
+	return test_bit(flag, (unsigned long *)&ti->flags);
+}
+
+#define set_thread_flag(flag) \
+	set_ti_thread_flag(current_thread_info(), flag)
+#define clear_thread_flag(flag) \
+	clear_ti_thread_flag(current_thread_info(), flag)
+#define update_thread_flag(flag, value) \
+	update_ti_thread_flag(current_thread_info(), flag, value)
+#define test_and_set_thread_flag(flag) \
+	test_and_set_ti_thread_flag(current_thread_info(), flag)
+#define test_and_clear_thread_flag(flag) \
+	test_and_clear_ti_thread_flag(current_thread_info(), flag)
+#define test_thread_flag(flag) \
+	test_ti_thread_flag(current_thread_info(), flag)
+
+#define tif_need_resched() test_thread_flag(TIF_NEED_RESCHED)
+#endif /* !__ASSEMBLY__ */
+#endif /* _LINUX_THREAD_BITS_H */
diff --git a/include/linux/thread_info.h b/include/linux/thread_info.h
index 8d8821b3689a..c9e76f9b7a4d 100644
--- a/include/linux/thread_info.h
+++ b/include/linux/thread_info.h
@@ -11,30 +11,9 @@
 #include <linux/types.h>
 #include <linux/bug.h>
 #include <linux/restart_block.h>
-
-#ifdef CONFIG_THREAD_INFO_IN_TASK
-/*
- * For CONFIG_THREAD_INFO_IN_TASK kernels we need <asm/current.h> for the
- * definition of current, but for !CONFIG_THREAD_INFO_IN_TASK kernels,
- * including <asm/current.h> can cause a circular dependency on some platforms.
- */
-#include <asm/current.h>
-#define current_thread_info() ((struct thread_info *)current)
-#endif
+#include <linux/thread_bits.h>
 
 #include <linux/bitops.h>
-
-/*
- * For per-arch arch_within_stack_frames() implementations, defined in
- * asm/thread_info.h.
- */
-enum {
-	BAD_STACK = -1,
-	NOT_STACK = 0,
-	GOOD_FRAME,
-	GOOD_STACK,
-};
-
 #include <asm/thread_info.h>
 
 #ifdef __KERNEL__
@@ -43,62 +22,6 @@ enum {
 #define THREAD_ALIGN	THREAD_SIZE
 #endif
 
-#define THREADINFO_GFP		(GFP_KERNEL_ACCOUNT | __GFP_ZERO)
-
-/*
- * flag set/clear/test wrappers
- * - pass TIF_xxxx constants to these functions
- */
-
-static inline void set_ti_thread_flag(struct thread_info *ti, int flag)
-{
-	set_bit(flag, (unsigned long *)&ti->flags);
-}
-
-static inline void clear_ti_thread_flag(struct thread_info *ti, int flag)
-{
-	clear_bit(flag, (unsigned long *)&ti->flags);
-}
-
-static inline void update_ti_thread_flag(struct thread_info *ti, int flag,
-					 bool value)
-{
-	if (value)
-		set_ti_thread_flag(ti, flag);
-	else
-		clear_ti_thread_flag(ti, flag);
-}
-
-static inline int test_and_set_ti_thread_flag(struct thread_info *ti, int flag)
-{
-	return test_and_set_bit(flag, (unsigned long *)&ti->flags);
-}
-
-static inline int test_and_clear_ti_thread_flag(struct thread_info *ti, int flag)
-{
-	return test_and_clear_bit(flag, (unsigned long *)&ti->flags);
-}
-
-static inline int test_ti_thread_flag(struct thread_info *ti, int flag)
-{
-	return test_bit(flag, (unsigned long *)&ti->flags);
-}
-
-#define set_thread_flag(flag) \
-	set_ti_thread_flag(current_thread_info(), flag)
-#define clear_thread_flag(flag) \
-	clear_ti_thread_flag(current_thread_info(), flag)
-#define update_thread_flag(flag, value) \
-	update_ti_thread_flag(current_thread_info(), flag, value)
-#define test_and_set_thread_flag(flag) \
-	test_and_set_ti_thread_flag(current_thread_info(), flag)
-#define test_and_clear_thread_flag(flag) \
-	test_and_clear_ti_thread_flag(current_thread_info(), flag)
-#define test_thread_flag(flag) \
-	test_ti_thread_flag(current_thread_info(), flag)
-
-#define tif_need_resched() test_thread_flag(TIF_NEED_RESCHED)
-
 #ifndef CONFIG_HAVE_ARCH_WITHIN_STACK_FRAMES
 static inline int arch_within_stack_frames(const void * const stack,
 					   const void * const stackend,
diff --git a/include/linux/usb/hcd.h b/include/linux/usb/hcd.h
index 97e2ddec18b1..8272208012c9 100644
--- a/include/linux/usb/hcd.h
+++ b/include/linux/usb/hcd.h
@@ -457,6 +457,8 @@ extern struct usb_hcd *usb_create_shared_hcd(const struct hc_driver *driver,
 extern struct usb_hcd *usb_get_hcd(struct usb_hcd *hcd);
 extern void usb_put_hcd(struct usb_hcd *hcd);
 extern int usb_hcd_is_primary_hcd(struct usb_hcd *hcd);
+extern int usb_add_hcd_with_phy_name(struct usb_hcd *hcd,
+		unsigned int irqnum, unsigned long irqflags, const char *phy_name);
 extern int usb_add_hcd(struct usb_hcd *hcd,
 		unsigned int irqnum, unsigned long irqflags);
 extern void usb_remove_hcd(struct usb_hcd *hcd);
diff --git a/include/uapi/asm-generic/unistd.h b/include/uapi/asm-generic/unistd.h
index df4bedb9b01c..b538ed1be4eb 100644
--- a/include/uapi/asm-generic/unistd.h
+++ b/include/uapi/asm-generic/unistd.h
@@ -179,7 +179,7 @@ __SYSCALL(__NR_fchownat, sys_fchownat)
 #define __NR_fchown 55
 __SYSCALL(__NR_fchown, sys_fchown)
 #define __NR_openat 56
-__SC_COMP(__NR_openat, sys_openat, compat_sys_openat)
+__SYSCALL(__NR_openat, sys_openat)
 #define __NR_close 57
 __SYSCALL(__NR_close, sys_close)
 #define __NR_vhangup 58
@@ -465,10 +465,15 @@ __SYSCALL(__NR_uname, sys_newuname)
 __SYSCALL(__NR_sethostname, sys_sethostname)
 #define __NR_setdomainname 162
 __SYSCALL(__NR_setdomainname, sys_setdomainname)
+
+#ifdef __ARCH_WANT_SET_GET_RLIMIT
+/* getrlimit and setrlimit are superseded with prlimit64 */
 #define __NR_getrlimit 163
 __SC_COMP(__NR_getrlimit, sys_getrlimit, compat_sys_getrlimit)
 #define __NR_setrlimit 164
 __SC_COMP(__NR_setrlimit, sys_setrlimit, compat_sys_setrlimit)
+#endif
+
 #define __NR_getrusage 165
 __SC_COMP(__NR_getrusage, sys_getrusage, compat_sys_getrusage)
 #define __NR_umask 166
@@ -676,8 +681,7 @@ __SYSCALL(__NR_fanotify_mark, sys_fanotify_mark)
 #define __NR_name_to_handle_at         264
 __SYSCALL(__NR_name_to_handle_at, sys_name_to_handle_at)
 #define __NR_open_by_handle_at         265
-__SC_COMP(__NR_open_by_handle_at, sys_open_by_handle_at, \
-	  compat_sys_open_by_handle_at)
+__SYSCALL(__NR_open_by_handle_at, sys_open_by_handle_at)
 #define __NR_clock_adjtime 266
 __SC_COMP(__NR_clock_adjtime, sys_clock_adjtime, compat_sys_clock_adjtime)
 #define __NR_syncfs 267
diff --git a/include/uapi/linux/ethtool.h b/include/uapi/linux/ethtool.h
index dc69391d2bba..76f10846df49 100644
--- a/include/uapi/linux/ethtool.h
+++ b/include/uapi/linux/ethtool.h
@@ -1457,6 +1457,21 @@ enum ethtool_link_mode_bit_indices {
 	ETHTOOL_LINK_MODE_FEC_NONE_BIT	= 49,
 	ETHTOOL_LINK_MODE_FEC_RS_BIT	= 50,
 	ETHTOOL_LINK_MODE_FEC_BASER_BIT	= 51,
+	ETHTOOL_LINK_MODE_50000baseKR_Full_BIT		 = 52,
+	ETHTOOL_LINK_MODE_50000baseSR_Full_BIT		 = 53,
+	ETHTOOL_LINK_MODE_50000baseCR_Full_BIT		 = 54,
+	ETHTOOL_LINK_MODE_50000baseLR_ER_FR_Full_BIT	 = 55,
+	ETHTOOL_LINK_MODE_50000baseDR_Full_BIT		 = 56,
+	ETHTOOL_LINK_MODE_100000baseKR2_Full_BIT	 = 57,
+	ETHTOOL_LINK_MODE_100000baseSR2_Full_BIT	 = 58,
+	ETHTOOL_LINK_MODE_100000baseCR2_Full_BIT	 = 59,
+	ETHTOOL_LINK_MODE_100000baseLR2_ER2_FR2_Full_BIT = 60,
+	ETHTOOL_LINK_MODE_100000baseDR2_Full_BIT	 = 61,
+	ETHTOOL_LINK_MODE_200000baseKR4_Full_BIT	 = 62,
+	ETHTOOL_LINK_MODE_200000baseSR4_Full_BIT	 = 63,
+	ETHTOOL_LINK_MODE_200000baseLR4_ER4_FR4_Full_BIT = 64,
+	ETHTOOL_LINK_MODE_200000baseDR4_Full_BIT	 = 65,
+	ETHTOOL_LINK_MODE_200000baseCR4_Full_BIT	 = 66,
 
 	/* Last allowed bit for __ETHTOOL_LINK_MODE_LEGACY_MASK is bit
 	 * 31. Please do NOT define any SUPPORTED_* or ADVERTISED_*
@@ -1465,7 +1480,7 @@ enum ethtool_link_mode_bit_indices {
 	 */
 
 	__ETHTOOL_LINK_MODE_LAST
-	  = ETHTOOL_LINK_MODE_FEC_BASER_BIT,
+	  = ETHTOOL_LINK_MODE_200000baseCR4_Full_BIT,
 };
 
 #define __ETHTOOL_LINK_MODE_LEGACY_MASK(base_name)	\
@@ -1573,6 +1588,7 @@ enum ethtool_link_mode_bit_indices {
 #define SPEED_50000		50000
 #define SPEED_56000		56000
 #define SPEED_100000		100000
+#define SPEED_200000		200000
 
 #define SPEED_UNKNOWN		-1
 
diff --git a/include/uapi/linux/pci_regs.h b/include/uapi/linux/pci_regs.h
index ee556ccc93f4..8727dbc448c7 100644
--- a/include/uapi/linux/pci_regs.h
+++ b/include/uapi/linux/pci_regs.h
@@ -371,6 +371,12 @@
 #define PCI_EA_FIRST_ENT_BRIDGE	8	/* First EA Entry for Bridges */
 #define  PCI_EA_ES		0x00000007 /* Entry Size */
 #define  PCI_EA_BEI		0x000000f0 /* BAR Equivalent Indicator */
+
+/* EA fixed Secondary and Subordinate bus numbers for Bridge */
+#define PCI_EA_SEC_BUS_MASK     0xff
+#define PCI_EA_SUB_BUS_MASK     0xff00
+#define PCI_EA_SUB_BUS_SHIFT    8
+
 /* 0-5 map to BARs 0-5 respectively */
 #define   PCI_EA_BEI_BAR0		0
 #define   PCI_EA_BEI_BAR5		5
diff --git a/kernel/exit.c b/kernel/exit.c
index eeaafd4064c9..4ac6e10d0842 100644
--- a/kernel/exit.c
+++ b/kernel/exit.c
@@ -320,6 +320,19 @@ void rcuwait_wake_up(struct rcuwait *w)
 	rcu_read_unlock();
 }
 
+struct task_struct *try_get_task_struct(struct task_struct **ptask)
+{
+	struct task_struct *task;
+
+	rcu_read_lock();
+	task = task_rcu_dereference(ptask);
+	if (task)
+		get_task_struct(task);
+	rcu_read_unlock();
+
+	return task;
+}
+
 /*
  * Determine if a process group is "orphaned", according to the POSIX
  * definition in 2.2.2.52.  Orphaned process groups are not to be affected
@@ -767,6 +780,68 @@ static void check_stack_usage(void)
 static inline void check_stack_usage(void) {}
 #endif
 
+#ifdef CONFIG_MRVL_OCTEONTX_EL0_INTR
+struct task_cleanup_handler {
+	void (*handler)(struct task_struct *);
+	struct list_head list;
+};
+
+static DEFINE_MUTEX(task_cleanup_handlers_mutex);
+static LIST_HEAD(task_cleanup_handlers);
+
+int task_cleanup_handler_add(void (*handler)(struct task_struct *))
+{
+	struct task_cleanup_handler *newhandler;
+
+	newhandler = (struct task_cleanup_handler *)
+		kmalloc(sizeof(struct task_cleanup_handler), GFP_KERNEL);
+	if (newhandler == NULL)
+		return -1;
+	newhandler->handler = handler;
+	mutex_lock(&task_cleanup_handlers_mutex);
+	list_add(&newhandler->list, &task_cleanup_handlers);
+	mutex_unlock(&task_cleanup_handlers_mutex);
+	return 0;
+}
+EXPORT_SYMBOL(task_cleanup_handler_add);
+
+int task_cleanup_handler_remove(void (*handler)(struct task_struct *))
+{
+	struct list_head *pos, *tmppos;
+	struct task_cleanup_handler *curr_task_cleanup_handler;
+	int retval = -1;
+
+	mutex_lock(&task_cleanup_handlers_mutex);
+	list_for_each_safe(pos, tmppos, &task_cleanup_handlers)	{
+		curr_task_cleanup_handler
+			= list_entry(pos, struct task_cleanup_handler, list);
+		if (curr_task_cleanup_handler->handler == handler) {
+			list_del(pos);
+			kfree(curr_task_cleanup_handler);
+			retval = 0;
+		}
+	}
+	mutex_unlock(&task_cleanup_handlers_mutex);
+	return retval;
+}
+EXPORT_SYMBOL(task_cleanup_handler_remove);
+
+static void task_cleanup_handlers_call(struct task_struct *task)
+{
+	struct list_head *pos;
+	struct task_cleanup_handler *curr_task_cleanup_handler;
+
+	mutex_lock(&task_cleanup_handlers_mutex);
+	list_for_each(pos, &task_cleanup_handlers) {
+		curr_task_cleanup_handler =
+			list_entry(pos, struct task_cleanup_handler, list);
+		if (curr_task_cleanup_handler->handler != NULL)
+			curr_task_cleanup_handler->handler(task);
+	}
+	mutex_unlock(&task_cleanup_handlers_mutex);
+}
+#endif
+
 void __noreturn do_exit(long code)
 {
 	struct task_struct *tsk = current;
@@ -871,6 +946,10 @@ void __noreturn do_exit(long code)
 	tsk->exit_code = code;
 	taskstats_exit(tsk, group_dead);
 
+#ifdef CONFIG_MRVL_OCTEONTX_EL0_INTR
+	task_cleanup_handlers_call(tsk);
+#endif
+
 	exit_mm();
 
 	if (group_dead)
diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 3b66c77670d9..72c4232fa047 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -160,6 +160,7 @@ int irq_can_set_affinity(unsigned int irq)
 {
 	return __irq_can_set_affinity(irq_to_desc(irq));
 }
+EXPORT_SYMBOL(irq_can_set_affinity);
 
 /**
  * irq_can_set_affinity_usr - Check if affinity of a irq can be set from user space
@@ -345,6 +346,7 @@ int __irq_set_affinity(unsigned int irq, const struct cpumask *mask, bool force)
 	raw_spin_unlock_irqrestore(&desc->lock, flags);
 	return ret;
 }
+EXPORT_SYMBOL(__irq_set_affinity);
 
 int irq_set_affinity_hint(unsigned int irq, const struct cpumask *m)
 {
diff --git a/kernel/sched/core.c b/kernel/sched/core.c
index faef74f63262..8c92b4e3386a 100644
--- a/kernel/sched/core.c
+++ b/kernel/sched/core.c
@@ -644,6 +644,18 @@ bool sched_can_stop_tick(struct rq *rq)
 	return true;
 }
 #endif /* CONFIG_NO_HZ_FULL */
+
+/*
+ * Return a pointer to the task_struct for the task that is running on
+ * the specified cpu at the time of the call (note that the task may have
+ * exited by the time the caller inspects the resulting task_struct).
+ * Caller must put_task_struct() with the pointer when finished with it.
+ */
+struct task_struct *try_get_task_struct_on_cpu(int cpu)
+{
+	return try_get_task_struct(&cpu_rq(cpu)->curr);
+}
+
 #endif /* CONFIG_SMP */
 
 #if defined(CONFIG_RT_GROUP_SCHED) || (defined(CONFIG_FAIR_GROUP_SCHED) && \
-- 
2.17.1

